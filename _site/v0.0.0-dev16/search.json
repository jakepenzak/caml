[
  {
    "objectID": "05_Contributors/getting_started.html",
    "href": "05_Contributors/getting_started.html",
    "title": "Contributing to CaML",
    "section": "",
    "text": "Welcome to the CaML contributor guide!\nWe manage out project via Github and leverage Github Flow for managing our development process. This guide will help you get started as a contributor and guide you through the process of contributing to CaML.",
    "crumbs": [
      "Contributing to CaML"
    ]
  },
  {
    "objectID": "05_Contributors/getting_started.html#general-contribution-guide",
    "href": "05_Contributors/getting_started.html#general-contribution-guide",
    "title": "Contributing to CaML",
    "section": "General Contribution Guide",
    "text": "General Contribution Guide\nPull requests are the best way to make changes to CaML:\n\nFork the repo and create your branch from main branch\nClone the repository on your local machine\nFor environment setup, see Environment Setup\nFor documentation, see Documentation\nFor testing, see Testing\nCreate a pull request & fill out the generated PR template\n\nCaML follows conventional commits for our PR titles, see here for more details.\nAll github actions & checks will be required to complete successfully prior to merging.",
    "crumbs": [
      "Contributing to CaML"
    ]
  },
  {
    "objectID": "05_Contributors/getting_started.html#report-bugs-using-github-issues",
    "href": "05_Contributors/getting_started.html#report-bugs-using-github-issues",
    "title": "Contributing to CaML",
    "section": "Report Bugs using Github Issues",
    "text": "Report Bugs using Github Issues\nBugs, features, and any other feedback can be submitted using the Github issues page.",
    "crumbs": [
      "Contributing to CaML"
    ]
  },
  {
    "objectID": "05_Contributors/testing.html",
    "href": "05_Contributors/testing.html",
    "title": "Testing",
    "section": "",
    "text": "We utilize marimo notebooks under the notebooks/dev/ directory for testing the api. After setting up the environment, you can run marimo edit to host notebook server on your local machine. For any examples worth including in the documentation, we add these notebooks to the notebooks/examples/ directory.\nFeel free to go about your development process however you see fit, but for any major functionality changes, make sure any examples are updated accordingly. If you choose to develop with Jupyter notebooks, you can convert to marimo via marimo convert *.ipynb -o *.py and vice-versa.",
    "crumbs": [
      "Testing"
    ]
  },
  {
    "objectID": "05_Contributors/testing.html#informal-testingdevelopment",
    "href": "05_Contributors/testing.html#informal-testingdevelopment",
    "title": "Testing",
    "section": "",
    "text": "We utilize marimo notebooks under the notebooks/dev/ directory for testing the api. After setting up the environment, you can run marimo edit to host notebook server on your local machine. For any examples worth including in the documentation, we add these notebooks to the notebooks/examples/ directory.\nFeel free to go about your development process however you see fit, but for any major functionality changes, make sure any examples are updated accordingly. If you choose to develop with Jupyter notebooks, you can convert to marimo via marimo convert *.ipynb -o *.py and vice-versa.",
    "crumbs": [
      "Testing"
    ]
  },
  {
    "objectID": "05_Contributors/testing.html#formal-testing",
    "href": "05_Contributors/testing.html#formal-testing",
    "title": "Testing",
    "section": "Formal Testing",
    "text": "Formal Testing\nWe utilize pytest for testing our codebase.\n\nUnit Testing\nUnit tests are under the tests/caml/ directory following the same structure of the caml/ prefixed by ‚Äútest_‚Äù. For example, if we wanted to write tests for cate.py, we would create a new file to build these tests tests/caml/core/test_cate.py.\nTo run unit tests, simply run pytest from command line. This will run your unit tests (with respective output printed in terminal).\nAdditionally, an html report of the coverage will be exported to tests/reports/htmlcov, which can be a useful tool for interactively evaluating the coverage of your unit tests.\n\n\nAdvanced Testing\nUnit tests are automatically run during PR process via GitHub Actions. Integration & regression testing forthcoming.",
    "crumbs": [
      "Testing"
    ]
  },
  {
    "objectID": "05_Contributors/environment.html",
    "href": "05_Contributors/environment.html",
    "title": "Environment Setup",
    "section": "",
    "text": "To help aid in environment setup, we‚Äôve created a VS Code devcontainer for quick, isolated, and standardized environment creation.\n\n\n\nDocker Desktop or your choice of docker engine\nVisual Studio Code\n\n\n\n\n\nEnsure docker engine is running\nOpen VSCode in cloned project directory\nInstall VSCode Dev Containers extension\nOpen the current folder in dev container",
    "crumbs": [
      "Environment Setup"
    ]
  },
  {
    "objectID": "05_Contributors/environment.html#with-vscode-devcontainers",
    "href": "05_Contributors/environment.html#with-vscode-devcontainers",
    "title": "Environment Setup",
    "section": "",
    "text": "To help aid in environment setup, we‚Äôve created a VS Code devcontainer for quick, isolated, and standardized environment creation.\n\n\n\nDocker Desktop or your choice of docker engine\nVisual Studio Code\n\n\n\n\n\nEnsure docker engine is running\nOpen VSCode in cloned project directory\nInstall VSCode Dev Containers extension\nOpen the current folder in dev container",
    "crumbs": [
      "Environment Setup"
    ]
  },
  {
    "objectID": "05_Contributors/environment.html#without-devcontainers",
    "href": "05_Contributors/environment.html#without-devcontainers",
    "title": "Environment Setup",
    "section": "Without Devcontainers",
    "text": "Without Devcontainers\n\nPrerequisites\n\nuv\npython v3.10\n\n\n\nSetup\n\nOpen repository in ide of choice\nRun uv sync --all-groups --frozen from command line\nActivate the virtual environment via source .venv/bin/activate\nRun pre-commit install to install pre-commit hooks",
    "crumbs": [
      "Environment Setup"
    ]
  },
  {
    "objectID": "05_Contributors/environment.html#project-package-dependency-management",
    "href": "05_Contributors/environment.html#project-package-dependency-management",
    "title": "Environment Setup",
    "section": "Project & Package Dependency Management",
    "text": "Project & Package Dependency Management\nWe use uv for dependency & project management. See uv docs for details.",
    "crumbs": [
      "Environment Setup"
    ]
  },
  {
    "objectID": "01_Home/quickstart.html",
    "href": "01_Home/quickstart.html",
    "title": "Tutorial: Quick Start",
    "section": "",
    "text": "Forthcoming\n\n\n\n Back to top",
    "crumbs": [
      "Tutorial: Quick Start"
    ]
  },
  {
    "objectID": "04_Reference/cate_histogram_plot.html",
    "href": "04_Reference/cate_histogram_plot.html",
    "title": "cate_histogram_plot",
    "section": "",
    "text": "cate_histogram_plot(\n    estimated_cates,\n    *,\n    true_cates=None,\n    figure_kwargs={},\n    hist_kwargs={},\n)\nPlots a histogram the estimated CATEs."
  },
  {
    "objectID": "04_Reference/cate_histogram_plot.html#parameters",
    "href": "04_Reference/cate_histogram_plot.html#parameters",
    "title": "cate_histogram_plot",
    "section": "Parameters",
    "text": "Parameters\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nestimated_cates\nArrayLike\nThe estimated CATEs.\nrequired\n\n\ntrue_cates\nArrayLike | None\nThe true CATEs.\nNone\n\n\nfigure_kwargs\ndict\nMatplotlib figure arguments.\n{}\n\n\nhist_kwargs\ndict\nMatplotlib hist arguments.\n{}"
  },
  {
    "objectID": "04_Reference/cate_histogram_plot.html#returns",
    "href": "04_Reference/cate_histogram_plot.html#returns",
    "title": "cate_histogram_plot",
    "section": "Returns",
    "text": "Returns\n\n\n\nName\nType\nDescription\n\n\n\n\n\nmatplotlib.pyplot.Figure\nThe histogram figure object."
  },
  {
    "objectID": "04_Reference/cate_histogram_plot.html#examples",
    "href": "04_Reference/cate_histogram_plot.html#examples",
    "title": "cate_histogram_plot",
    "section": "Examples",
    "text": "Examples\n\nimport numpy as np\nfrom caml.extensions.plots import cate_histogram_plot\n\nnp.random.seed(42)\ntrue_cates = np.random.normal(0, 1, 1000)\nestimated_cates = true_cates + np.random.normal(0, 0.5, 1000)\n\nfig = cate_histogram_plot(estimated_cates, true_cates=true_cates, hist_kwargs={'bins': 25})\nfig"
  },
  {
    "objectID": "04_Reference/AutoCATE.html",
    "href": "04_Reference/AutoCATE.html",
    "title": "AutoCATE",
    "section": "",
    "text": "AutoCATE(\n    Y,\n    T,\n    X=None,\n    W=None,\n    *,\n    discrete_treatment=True,\n    discrete_outcome=False,\n    model_Y=None,\n    model_T=None,\n    model_regression=None,\n    enable_categorical=False,\n    n_jobs=1,\n    use_ray=False,\n    ray_remote_func_options_kwargs=None,\n    use_spark=False,\n    verbose=2,\n    seed=None,\n)\nThe AutoCATE class is a high-level API facilitating an AutoML framework for CATE estimation, built on top of the EconML library.\nAutoCATE is experimental and may change significantly in future versions.\nThe CATE is defined as \\(\\mathbb{E}[\\tau \\mid \\mathbf{X}]\\) where \\(\\tau\\) is the treatment effect and \\(\\mathbf{X}\\) is the set of features leveraged for treatment effect heterogeneity.\nThis class is built on top of the EconML library and provides a high-level AutoML API for fitting, validating, and making predictions/inference with CATE models, with best practices built directly into the API. The class is designed to be easy to use and understand, while still providing flexibility for advanced users.\nNote that first-stage models are estimated using a full AutoML framework via Flaml, whereas the second-stage models are currently estimated & selected based on a pre-specified set of models (or custom CATE models) passed, thus there is no tuning of hyperparameters. This and other AutoML features are on the roadmap for future versions of AutoCATE.\nFor technical details on the AutoCATE class, see here.\nNote: All the standard assumptions of Causal Inference apply to this class (e.g., exogeneity/unconfoundedness, overlap, positivity, etc.). The class does not check for these assumptions and assumes that the user has already thought through these assumptions before using the class.\nFor outcome/treatment support, see matrix.\nFor a more detailed working example, see AutoCATE Example."
  },
  {
    "objectID": "04_Reference/AutoCATE.html#parameters",
    "href": "04_Reference/AutoCATE.html#parameters",
    "title": "AutoCATE",
    "section": "Parameters",
    "text": "Parameters\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nY\nstr\nThe str representing the column name for the outcome variable.\nrequired\n\n\nT\nstr\nThe str representing the column name(s) for the treatment variable(s).\nrequired\n\n\nX\nSequence[str] | None\nThe sequence of feature names representing the feature set to be utilized for estimating heterogeneity/CATE.\nNone\n\n\nW\nSequence[str] | None\nThe sequence of feature names representing the confounder/control feature set to be utilized only for nuisance function estimation. When W is passed, only Orthogonal learners will be leveraged.\nNone\n\n\ndiscrete_treatment\nbool\nA boolean indicating whether the treatment is discrete/categorical or continuous.\nTrue\n\n\ndiscrete_outcome\nbool\nA boolean indicating whether the outcome is binary or continuous.\nFalse\n\n\nmodel_Y\ndict | BaseEstimator | None\nA dictionary of FLAML kwarg overrides or a BaseEstimator instance for the outcome model - \\(\\mathbb{E}[Y \\mid \\mathbf{X},\\mathbf{W}]\\).\nNone\n\n\nmodel_T\ndict | BaseEstimator | None\nA dictionary of FLAML kwarg overrides or a BaseEstimator instance for the treatment/propensity model - \\(\\mathbb{E}[T \\mid \\mathbf{X},\\mathbf{W}]\\).\nNone\n\n\nmodel_regression\ndict | BaseEstimator | None\nA dictionary of FLAML kwarg overrides or a BaseEstimator instance for the regression model - \\(\\mathbb{E}[Y \\mid \\mathbf{X},\\mathbf{W},T]\\).\nNone\n\n\nenable_categorical\nbool\nA boolean indicating whether to enable categorical encoding for the models. When set to True, pandas categorical types will be converted to ordinal encodings. For one-hot encoding, please implement it prior to passing the data to the model.\nFalse\n\n\nn_jobs\nint\nThe number of jobs to run in parallel for model training.\n1\n\n\nuse_ray\nbool\nA boolean indicating whether to use Ray for distributed computing, utilized in both AutoML for first-stage models and AutoML for CATE models. n_concurrent_tasks defaults to 4 if not specified in FLAML kwarg overrides (e.g., for model_*).\nFalse\n\n\nray_remote_func_options_kwargs\ndict | None\nA dictionary of Ray remote function options for ray remote function that fits each individual CATE model. See here for options.\nNone\n\n\nuse_spark\nbool\nA boolean indicating whether to use Spark for distributed computing, utilized only in AutoML for first-stage models. n_concurrent_tasks defaults to 4 if not specified in FLAML kwarg overrides (e.g., for model_*).\nFalse\n\n\nverbose\nint\nThe verbosity level. 0 = NOTSET, 1 = DEBUG, 2 = INFO, 3 = WARNING, 4 = ERROR, 5 = CRITICAL\n2\n\n\nseed\nint | None\nThe seed to use for the random number generator.\nNone"
  },
  {
    "objectID": "04_Reference/AutoCATE.html#attributes",
    "href": "04_Reference/AutoCATE.html#attributes",
    "title": "AutoCATE",
    "section": "Attributes",
    "text": "Attributes\n\n\n\nName\nType\nDescription\n\n\n\n\nY\nlist[str]\nThe list of str representing the column names for the outcome variable \\(Y\\).\n\n\nT\nlist[str]\nThe list of str representing the column names for the treatment variable \\(T\\).\n\n\nX\nlist[str]\nThe list of str representing the confounder/control feature set \\(\\mathbf{X}\\) to be utilized for estimating heterogeneity/CATE and nuisance function estimation where applicable.\n\n\nW\nlist[str] | None\nThe list of str representing the confounder/control feature set \\(\\mathbf{W}\\) to be utilized only for nuisance function estimation, where applicable. These will be included by default in Meta-Learners.\n\n\navailable_estimators\nlist[str]\nA list of the available CATE estimators out of the box. Validity of estimator at runtime will depend on the outcome and treatment types and be automatically selected.\n\n\nmodel_Y\nBaseEstimator\nThe selected outcome model - \\(\\mathbb{E}[Y \\mid \\mathbf{X},\\mathbf{W}]\\).\n\n\nmodel_T\nBaseEstimator\nThe selected treatment model - \\(\\mathbb{E}[T \\mid \\mathbf{X},\\mathbf{W}]\\).\n\n\nmodel_regression\nBaseEstimator\nThe selected regression model - \\(\\mathbb{E}[Y \\mid \\mathbf{X},\\mathbf{W},T]\\).\n\n\nrscores\ndict[str, float]\nThe dictionary of the Rscores on the validation set for each CATE estimator fitted during model selection.\n\n\ntest_results\ndict[str, float] | EvaluationResults\nThe dictionary of the final test results on the test set for the best_estimator selected, if RScorer is used, otherwise EvaluationResults returned from DRTester.evaluate_all\n\n\nbest_estimator\nBaseCateEstimator\nThe best EconML CATE estimator selected.\n\n\nbest_estimator_name\nstr\nThe name of the best EconML CATE estimator selected as passed to the AutoCateEstimator constructor."
  },
  {
    "objectID": "04_Reference/AutoCATE.html#examples",
    "href": "04_Reference/AutoCATE.html#examples",
    "title": "AutoCATE",
    "section": "Examples",
    "text": "Examples\n\nfrom caml import AutoCATE\nfrom caml.extensions.synthetic_data import SyntheticDataGenerator\n\ndata_generator = SyntheticDataGenerator(seed=10, n_cont_modifiers=1, n_cont_confounders=1)\ndf = data_generator.df\n\nauto_cate = AutoCATE(\n    Y=\"Y1_continuous\",\n    T=\"T1_binary\",\n    X=[c for c in df.columns if \"X\" in c or \"W\" in c],\n    model_Y={\"time_budget\": 10},\n    model_T={\"time_budget\": 10},\n    model_regression={\"time_budget\": 10},\n    discrete_treatment=True,\n    discrete_outcome=False,\n)\n\nprint(auto_cate)\n\n[11/10/25 02:32:04] WARNING  AutoCATE is experimental and may change in future versions.           decorators.py:57\n\n\n\n================== AutoCATE Object ==================\nOutcome Variable: ['Y1_continuous']\nDiscrete Outcome: False\nTreatment Variable: ['T1_binary']\nDiscrete Treatment: True\nFeatures/Confounders for Heterogeneity (X): ['W1_continuous', 'X1_continuous']\nFeatures/Confounders as Controls (W): []\nEnable Categorical: False\nn Jobs: 1\nUse Ray: False\nUse Spark: False\nRandom Seed: None"
  },
  {
    "objectID": "04_Reference/AutoCATE.html#methods",
    "href": "04_Reference/AutoCATE.html#methods",
    "title": "AutoCATE",
    "section": "Methods",
    "text": "Methods\n\n\n\nName\nDescription\n\n\n\n\nfit\nRun end-to-end fitting, validation & model selection, and testing for CATE models.\n\n\nrefit_final\nRefits the final, best estimator on the provided data.\n\n\nestimate_ate\nCalculate the average treatment effect(s) (ATE) \\(\\mathbb{E}[\\tau(\\mathbf{X})]\\).\n\n\nestimate_cate\nCalculate the Conditional Average Treatment Effects (CATE) \\(\\tau(\\mathbf{x})\\).\n\n\npredict\nAlias for estimate_cate.\n\n\neffect\nAlias for estimate_cate.\n\n\n\n\nfit\nAutoCATE.fit(\n    df,\n    *,\n    cate_estimators=list(available_estimators.keys()),\n    additional_cate_estimators=list(),\n    use_cached_models=False,\n    ensemble=False,\n    refit_final=True,\n    bootstrap_inference=False,\n    n_bootstrap_samples=100,\n    validation_fraction=0.2,\n    test_fraction=0.1,\n    rscorer_kwargs=dict(),\n    n_groups_dr_tester=5,\n    n_bootstrap_dr_tester=100,\n)\nRun end-to-end fitting, validation & model selection, and testing for CATE models.\n\nParameters\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\ndf\nPandasConvertibleDataFrame\nThe dataset to fit the CATE model on. Accepts a Pandas DataFrame or a compatible object with a to_pandas() or .toPandas() method.\nrequired\n\n\ncate_estimators\nSequence[str]\nThe out-of-the-box CATE estimators to use. Accessible via self.available_estimators.\nlist(available_estimators.keys())\n\n\nadditional_cate_estimators\nSequence[AutoCateEstimator]\nAdditional CATE estimators to use.\nlist()\n\n\nuse_cached_models\nbool\nWhether to use cached first-stage/nuisance models, if previously fitted.\nFalse\n\n\nensemble\nbool\nWhether to use an ensemble of CATE estimators.\nFalse\n\n\nrefit_final\nbool\nWhether to refit the final CATE estimator on the entire dataset after model selection.\nTrue\n\n\nbootstrap_inference\nbool\nWhether to use bootstrap inference for the final CATE estimator, when other inference methods are not available (e.g., metalearners). This can be computationally expensive.\nFalse\n\n\nn_bootstrap_samples\nint\nThe number of bootstrap samples to use for bootstrap inference, if bootstrap_inference is True.\n100\n\n\nvalidation_fraction\nfloat\nThe fraction of the dataset to use for validation.\n0.2\n\n\ntest_fraction\nfloat\nThe fraction of the dataset to use for testing.\n0.1\n\n\nrscorer_kwargs\ndict\nAdditional keyword arguments to pass to RScorer.\ndict()\n\n\nn_groups_dr_tester\n\nThe number of groups to use for the DRTester.\n5\n\n\nn_bootstrap_dr_tester\n\nThe number of bootstrap samples to use for the DRTester.\n100\n\n\n\n\n\nExamples\n\nfrom caml import AutoCateEstimator\nfrom econml.dml import LinearDML\n\nmy_custom_estimator = AutoCateEstimator(name=\"MyCustomEstimator\",estimator=LinearDML())\n\nauto_cate.fit(\n    df = df,\n    cate_estimators = auto_cate.available_estimators,\n    additional_cate_estimators = [my_custom_estimator],\n)\n\n                    INFO                                                                          decorators.py:111\n                               ____      __  __ _                                                                  \n                              / ___|__ _|  \\/  | |                                                                 \n                             | |   / _` | |\\/| | |                                                                 \n                             | |__| (_| | |  | | |___                                                              \n                              \\____\\__,_|_|  |_|_____|                                                             \n                                                                                                                   \n                                                                                                                   \n\n\n\n                    INFO     ================== AutoCATE Object ==================                      cate.py:298\n                             Outcome Variable: ['Y1_continuous']                                                   \n                             Discrete Outcome: False                                                               \n                             Treatment Variable: ['T1_binary']                                                     \n                             Discrete Treatment: True                                                              \n                             Features/Confounders for Heterogeneity (X): ['W1_continuous',                         \n                             'X1_continuous']                                                                      \n                             Features/Confounders as Controls (W): []                                              \n                             Enable Categorical: False                                                             \n                             n Jobs: 1                                                                             \n                             Use Ray: False                                                                        \n                             Use Spark: False                                                                      \n                             Random Seed: None                                                                     \n                                                                                                                   \n                                                                                                                   \n\n\n\n                    INFO                                                                          decorators.py:111\n                             ==============================                                                        \n                             |üéØ AutoML Nuisance Functions|                                                        \n                             ==============================                                                        \n                                                                                                                   \n\n\n\n                    INFO     Searching for model_Y:                                                     cate.py:678\n\n\n\n[11/10/25 02:32:14] INFO     Best estimator: xgboost with loss 32.22196534987712 found on iteration    _base.py:144\n                             168 in 9.386565208435059 seconds.                                                     \n                                                                                                                   \n\n\n\n                    INFO     Searching for model_regression:                                            cate.py:678\n\n\n\n[11/10/25 02:32:24] INFO     Best estimator: lgbm with loss 1.1523443116910403 found on iteration 68   _base.py:144\n                             in 8.781173706054688 seconds.                                                         \n                                                                                                                   \n\n\n\n                    INFO     Searching for model_T:                                                     cate.py:678\n\n\n\n[11/10/25 02:32:34] INFO     Best estimator: lrl1 with loss 0.6690757120781692 found on iteration 109  _base.py:144\n                             in 10.028990745544434 seconds.                                                        \n                                                                                                                   \n\n\n\n                    INFO     ‚úÖ Completed.                                                        decorators.py:116\n\n\n\n                    INFO                                                                          decorators.py:111\n                             ==========================                                                            \n                             |üéØ AutoML CATE Functions|                                                            \n                             ==========================                                                            \n                                                                                                                   \n\n\n\n[11/10/25 02:32:40] INFO     Best Estimator: 'LinearDML'                                                cate.py:837\n\n\n\n                    INFO     Estimator RScores: {'LinearDML': 0.8045993018348682, 'CausalForestDML':    cate.py:838\n                             0.7901432524643452, 'NonParamDML': 0.7955620653398504,                                \n                             'SparseLinearDML-2D': 0.804587587779655, 'DRLearner': 0.7940534212966462,             \n                             'ForestDRLearner': 0.7913675324602935, 'LinearDRLearner':                             \n                             0.8045605545702345, 'SLearner': 0.7962985602202589, 'TLearner':                       \n                             0.7931100249803363, 'XLearner': 0.7945557559533736, 'MyCustomEstimator':              \n                             0.8045057987308123}                                                                   \n\n\n\n                    INFO     ‚úÖ Completed.                                                        decorators.py:116\n\n\n\n                    INFO                                                                          decorators.py:111\n                             ====================                                                                  \n                             |üß™ Testing Results|                                                                  \n                             ====================                                                                  \n                                                                                                                   \n\n\n\n                    INFO     Discrete treatment specified. Using DRTester for final testing.            cate.py:893\n\n\n\n                    INFO     All validation results suggest that the model has found statistically      cate.py:923\n                             significant heterogeneity.                                                            \n                                                                                                                   \n\n\n\n                    INFO        treatment  blp_est  blp_se  blp_pval  qini_est  qini_se  qini_pval  \\   cate.py:927\n                             0          1    0.986   0.007       0.0      2.28    0.093        0.0                 \n                                                                                                                   \n                                autoc_est  autoc_se  autoc_pval  cal_r_squared                                     \n                             0      6.142     0.288         0.0          0.975                                     \n\n\n\n                    INFO     CALIBRATION CURVE                                                          cate.py:930\n\n\n\n\n\n\n\n\n\n\n                    INFO     QINI CURVE                                                                 cate.py:933\n\n\n\n\n\n\n\n\n\n\n                    INFO     TOC CURVE                                                                  cate.py:936\n\n\n\n\n\n\n\n\n\n\n                    INFO     ‚úÖ Completed.                                                        decorators.py:116\n\n\n\n                    INFO                                                                          decorators.py:111\n                             ==============================                                                        \n                             |üîã Refitting Final Estimator|                                                        \n                             ==============================                                                        \n                                                                                                                   \n\n\n\n[11/10/25 02:32:41] INFO     ‚úÖ Completed.                                                        decorators.py:116\n\n\n\n\n\n\nrefit_final\nAutoCATE.refit_final(df, bootstrap_inference=False, n_bootstrap_samples=100)\nRefits the final, best estimator on the provided data.\n\nParameters\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\ndf\nPandasConvertibleDataFrame\nThe data to fit the estimator on.\nrequired\n\n\nbootstrap_inference\nbool\nWhether to use bootstrap inference for the final CATE estimator, when other inference methods fail. This can be computationally expensive.\nFalse\n\n\n\n\n\n\nestimate_ate\nAutoCATE.estimate_ate(\n    df,\n    *,\n    effect_mode='discrete',\n    T0=0,\n    T1=1,\n    T=None,\n    return_inference=False,\n    alpha=0.05,\n    value=0,\n)\nCalculate the average treatment effect(s) (ATE) \\(\\mathbb{E}[\\tau(\\mathbf{X})]\\).\nThis method can be used for group average treatment effects (GATEs) \\(\\mathbb{E}[\\tau(\\mathbf{X}) \\mid G]\\) by filtering the input df to a specific group.\nTwo effect modes are supported: discrete and marginal.\nIn discrete mode, the effect is calculated between two specific treatment levels T0 and T1 - \\(\\mathbb{E}[\\tau(\\mathbf{X}, T0, T1)]\\).\nIn marginal mode, the effect is calculated for each observation as a gradient around their treatment levels T - \\(\\mathbb{E}[\\partial_{\\tau}(T,\\mathbf{x})]\\)\nSee EconML for more details.\n\nParameters\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\ndf\nPandasConvertibleDataFrame\nThe dataframe containing all of the data passed to fit method.\nrequired\n\n\neffect_mode\nstr\nThe mode of effect calculation. Can be ‚Äúmarginal‚Äù or ‚Äúdiscrete‚Äù.\n'discrete'\n\n\nT0\nint\nThe base treatment level when effect_mode is ‚Äúdiscrete‚Äù.\n0\n\n\nT1\nint\nThe target treatment level when effect_mode is ‚Äúdiscrete‚Äù.\n1\n\n\nT\nnp.ndarray | pd.DataFrame | None\nThe base treatment levels for each observation when effect_mode is ‚Äúmarginal‚Äù.\nNone\n\n\nreturn_inference\nbool\nWhether to return EconML inference results.\nFalse\n\n\nalpha\nfloat\nThe level of confidence in the reported interval.\n0.05\n\n\nvalue\nint\nThe mean value to test under the null hypothesis.\n0\n\n\n\n\n\nReturns\n\n\n\nName\nType\nDescription\n\n\n\n\n\nfloat | PopulationSummaryResults\nThe average treatment effect estimate if return_inference is False. Otherwise, an instance of PopulationSummaryResults is returned.\n\n\n\n\n\nExamples\n\n# Return scalar ATE\nauto_cate.estimate_ate(\n    df = df,\n    effect_mode = \"discrete\",\n    T0 = 0,\n    T1 = 1,\n)\n\n-7.655763175459788\n\n\n\n# Return ATE with Inference\nauto_cate.estimate_ate(\n    df = df,\n    effect_mode = \"discrete\",\n    T0 = 0,\n    T1 = 1,\n    return_inference = True,\n    alpha = 0.05,\n    value = 0,\n)\n\n\nUncertainty of Mean Point Estimate\n\n\nmean_point\nstderr_mean\nzstat\npvalue\nci_mean_lower\nci_mean_upper\n\n\n-7.656\n0.028\n-275.107\n0.0\n-7.71\n-7.601\n\n\n\n\n\n\nDistribution of Point Estimate\n\n\nstd_point\npct_point_lower\npct_point_upper\n\n\n8.241\n-24.934\n10.002\n\n\n\n\n\n\nTotal Variance of Point Estimate\n\n\nstderr_point\nci_point_lower\nci_point_upper\n\n\n8.241\n-25.117\n9.943\n\n\n\n\n\n\n\n\nestimate_cate\nAutoCATE.estimate_cate(\n    df,\n    *,\n    effect_mode='discrete',\n    T0=0,\n    T1=1,\n    T=None,\n    return_inference=False,\n)\nCalculate the Conditional Average Treatment Effects (CATE) \\(\\tau(\\mathbf{x})\\).\nTwo effect modes are supported: discrete and marginal.\nIn discrete mode, the effect is calculated between two specific treatment levels T0 and T1 - \\(\\tau(\\mathbf{X}, T0, T1)\\).\nIn marginal mode, the effect is calculated for each observation as a gradient around their treatment levels - \\(\\partial_{\\tau}(T,\\mathbf{x})\\)\nSee EconML for more details.\n\nParameters\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\ndf\nPandasConvertibleDataFrame\nThe dataframe containing all of the data passed to fit method.\nrequired\n\n\neffect_mode\nstr\nThe mode of effect calculation. Can be ‚Äúmarginal‚Äù or ‚Äúdiscrete‚Äù.\n'discrete'\n\n\nT0\nint\nThe base treatment level when effect_mode is ‚Äúdiscrete‚Äù.\n0\n\n\nT1\nint\nThe target treatment level when effect_mode is ‚Äúdiscrete‚Äù.\n1\n\n\nT\nnp.ndarray | pd.DataFrame | None\nThe base treatment levels for each observation when effect_mode is ‚Äúmarginal‚Äù.\nNone\n\n\nreturn_inference\nbool\nWhether to return EconML inference results.\nFalse\n\n\n\n\n\nReturns\n\n\n\nName\nType\nDescription\n\n\n\n\n\nnp.ndarray | InferenceResults\nThe CATE estimates as an array if return_inference is False. Otherwise, the return value is an instance of NormalInferenceResults if asymptotic inference is available for the best estimator or EmpiricalInferenceResults if not.\n\n\n\n\n\nExamples\n\n# Return CATEs array\nauto_cate.estimate_cate(\n    df = df,\n    effect_mode = \"discrete\",\n    T0 = 0,\n    T1 = 1,\n)[:5]\n\narray([[ 11.44233698],\n       [ -9.13852042],\n       [-32.00094704],\n       [  3.2106793 ],\n       [ -5.30575942]])\n\n\n\n# Return CATEs with Inference\ninference = auto_cate.estimate_cate(\n    df = df,\n    effect_mode = \"discrete\",\n    T0 = 0,\n    T1 = 1,\n    return_inference = True,\n)\n\nprint(inference)\n\n&lt;econml.inference._inference.NormalInferenceResults object at 0x7f710ab0cf10&gt;\n\n\n\n\n\npredict\nAutoCATE.predict(df, **kwargs)\nAlias for estimate_cate.\n\n\neffect\nAutoCATE.effect(df, **kwargs)\nAlias for estimate_cate."
  },
  {
    "objectID": "04_Reference/decorators.html",
    "href": "04_Reference/decorators.html",
    "title": "decorators",
    "section": "",
    "text": "generics.decorators\nDecorator utilities for CaML.\nThis module provides decorators for various functionalities in CaML.\n\n\n\n\n\nName\nDescription\n\n\n\n\nexperimental\nDecorator to mark functions or classes as experimental.\n\n\nmaybe_jit\nDecorator to JIT compile a function using JAX, if available.\n\n\nnarrate\nDecorator to log the execution of a function or method.\n\n\ntimer\nDecorator to measure the execution time of a function or method, logged at DEBUG level.\n\n\n\n\n\ngenerics.decorators.experimental(obj)\nDecorator to mark functions or classes as experimental.\nThis decorator will show a warning when the decorated object is first used, indicating that it is experimental and may change in future versions.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nobj\nCallable\nThe class or function to mark as experimental\nrequired\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\n\n\n\n\n\nCallable\nThe decorated class or function\n\n\n\n\n\n\n\ngenerics.decorators.maybe_jit(func=None, **jit_kwargs)\nDecorator to JIT compile a function using JAX, if available.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nfunc\nCallable | None\nThe function to be JIT compiled.\nNone\n\n\njit_kwargs\ndict\nKeyword arguments to be passed to jax.jit.\n{}\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\n\n\n\n\n\nCallable\nThe decorated function or method\n\n\n\n\n\n\n\ngenerics.decorators.narrate(\n    preamble=None,\n    epilogue=':white_check_mark: Completed.',\n)\nDecorator to log the execution of a function or method.\nThis decorator will log a pre-execution (preamble) message and a post-execution (epilogue) message.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\npreamble\nstr\nThe message to log before the function or method execution.\nNone\n\n\nepilogue\nstr\nThe message to log after the function or method execution.\n':white_check_mark: Completed.'\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\n\n\n\n\n\nCallable\nThe decorated class or function\n\n\n\n\n\n\n\ngenerics.decorators.timer(operation_name=None)\nDecorator to measure the execution time of a function or method, logged at DEBUG level.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\noperation_name\nstr | None\nThe name of the operation to be timed. If None, the name of the function or method will be used.\nNone\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\n\n\n\n\n\nCallable\nThe decorated function or method"
  },
  {
    "objectID": "04_Reference/decorators.html#functions",
    "href": "04_Reference/decorators.html#functions",
    "title": "decorators",
    "section": "",
    "text": "Name\nDescription\n\n\n\n\nexperimental\nDecorator to mark functions or classes as experimental.\n\n\nmaybe_jit\nDecorator to JIT compile a function using JAX, if available.\n\n\nnarrate\nDecorator to log the execution of a function or method.\n\n\ntimer\nDecorator to measure the execution time of a function or method, logged at DEBUG level.\n\n\n\n\n\ngenerics.decorators.experimental(obj)\nDecorator to mark functions or classes as experimental.\nThis decorator will show a warning when the decorated object is first used, indicating that it is experimental and may change in future versions.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nobj\nCallable\nThe class or function to mark as experimental\nrequired\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\n\n\n\n\n\nCallable\nThe decorated class or function\n\n\n\n\n\n\n\ngenerics.decorators.maybe_jit(func=None, **jit_kwargs)\nDecorator to JIT compile a function using JAX, if available.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nfunc\nCallable | None\nThe function to be JIT compiled.\nNone\n\n\njit_kwargs\ndict\nKeyword arguments to be passed to jax.jit.\n{}\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\n\n\n\n\n\nCallable\nThe decorated function or method\n\n\n\n\n\n\n\ngenerics.decorators.narrate(\n    preamble=None,\n    epilogue=':white_check_mark: Completed.',\n)\nDecorator to log the execution of a function or method.\nThis decorator will log a pre-execution (preamble) message and a post-execution (epilogue) message.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\npreamble\nstr\nThe message to log before the function or method execution.\nNone\n\n\nepilogue\nstr\nThe message to log after the function or method execution.\n':white_check_mark: Completed.'\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\n\n\n\n\n\nCallable\nThe decorated class or function\n\n\n\n\n\n\n\ngenerics.decorators.timer(operation_name=None)\nDecorator to measure the execution time of a function or method, logged at DEBUG level.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\noperation_name\nstr | None\nThe name of the operation to be timed. If None, the name of the function or method will be used.\nNone\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\n\n\n\n\n\nCallable\nThe decorated function or method"
  },
  {
    "objectID": "04_Reference/make_fully_heterogeneous_dataset.html",
    "href": "04_Reference/make_fully_heterogeneous_dataset.html",
    "title": "make_fully_heterogeneous_dataset",
    "section": "",
    "text": "make_fully_heterogeneous_dataset(\n    n_obs=1000,\n    n_confounders=5,\n    theta=4.0,\n    seed=None,\n    **doubleml_kwargs,\n)\nSimulate data generating process from an interactive regression model with fully heterogenous treatment effects.\nThe outcome is continuous and the treatment is binary. The dataset is generated using a modified version of make_irm_data function from the doubleml package.\nThe general form of the data generating process is:\n\\[\ny_i= g(d_i,\\mathbf{X_i})+\\epsilon_i\n\\] \\[\nd_i=f(\\mathbf{X_i})+\\eta_i\n\\]\nwhere \\(y_i\\) is the outcome, \\(d_i\\) is the treatment, \\(\\mathbf{X_i}\\) are the confounders utilized for full effect heterogeneity, \\(\\epsilon_i\\) and \\(\\eta_i\\) are the error terms, \\(g\\) is the outcome function, and \\(f\\) is the treatment function.\nSee the doubleml documentation for more details on the specific functional forms of the data generating process.\nNote that the treatment effect is fully heterogenous, thus the CATE is defined as: \\(\\tau = \\mathbb{E}[g(1,\\mathbf{X}) - g(0,\\mathbf{X})|\\mathbf{X}]\\) for any \\(\\mathbf{X}\\).\nThe ATE is defined as the average of the CATE function over all observations: \\(\\mathbb{E}[\\tau (\\cdot)]\\)\nAs a DAG, the data generating process can be roughly represented as:"
  },
  {
    "objectID": "04_Reference/make_fully_heterogeneous_dataset.html#parameters",
    "href": "04_Reference/make_fully_heterogeneous_dataset.html#parameters",
    "title": "make_fully_heterogeneous_dataset",
    "section": "Parameters",
    "text": "Parameters\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nn_obs\nint\nThe number of observations to generate.\n1000\n\n\nn_confounders\nint\nThe number of confounders \\(\\mathbf{X_i}\\) to generate (these are utilized fully for heterogeneity).\n5\n\n\ntheta\nfloat\nThe base parameter for the treatment effect. Note this can differ slightly from the true ATE.\n4.0\n\n\nseed\nint | None\nThe seed to use for the random number generator.\nNone\n\n\n**doubleml_kwargs\n\nAdditional keyword arguments to pass to the data generating process.\n{}"
  },
  {
    "objectID": "04_Reference/make_fully_heterogeneous_dataset.html#returns",
    "href": "04_Reference/make_fully_heterogeneous_dataset.html#returns",
    "title": "make_fully_heterogeneous_dataset",
    "section": "Returns",
    "text": "Returns\n\n\n\n\n\n\n\n\nName\nType\nDescription\n\n\n\n\ndf\npandas.DataFrame\nThe generated dataset where y is the outcome, d is the treatment, and X are the confounders which are fully utilized for heterogeneity.\n\n\ntrue_cates\nnumpy.ndarray\nThe true conditional average treatment effects.\n\n\ntrue_ate\nfloat\nThe true average treatment effect."
  },
  {
    "objectID": "04_Reference/make_fully_heterogeneous_dataset.html#examples",
    "href": "04_Reference/make_fully_heterogeneous_dataset.html#examples",
    "title": "make_fully_heterogeneous_dataset",
    "section": "Examples",
    "text": "Examples\n\nfrom caml.extensions.synthetic_data import make_fully_heterogeneous_dataset\ndf, true_cates, true_ate = make_fully_heterogeneous_dataset(n_obs=1000,\n                                                            n_confounders=5,\n                                                            theta=4.0,\n                                                            seed=1)\n\nprint(f\"True CATEs: {true_cates[:5]}\")\nprint(f\"True ATE: {true_ate}\")\nprint(df.head())\n\nTrue CATEs: [5.10338083 5.0918794  1.93444292 4.36046179 3.89521828]\nTrue ATE: 3.9499484248360175\n         X1        X2        X3        X4        X5         y    d\n0  1.682368 -0.422572 -1.219871 -0.941586 -1.270241  5.828931  1.0\n1  0.684154  1.125168  2.601475  0.441070  0.889493  4.767675  1.0\n2 -2.035148 -1.386116 -0.770108 -0.070788 -0.524494  2.748786  1.0\n3  0.429364 -0.125604 -0.095252 -0.033939  1.243388  5.140932  1.0\n4  0.240024 -0.069628 -1.722948 -1.565808 -1.494064  2.431165  1.0"
  },
  {
    "objectID": "04_Reference/logging.html",
    "href": "04_Reference/logging.html",
    "title": "logging",
    "section": "",
    "text": "generics.logging\nLogging utilities for CaML.\n\n\n\n\n\nName\nDescription\n\n\n\n\nconfigure_logging\nConfigure logging for the entire application.\n\n\nget_section_header\nGenerate a formatted section header with separators.\n\n\n\n\n\ngenerics.logging.configure_logging(level=logging.WARNING)\nConfigure logging for the entire application.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nlevel\nint\nThe logging level to use. Defaults to WARNING. Can be overridden by environment variable CAML_LOG_LEVEL.\nlogging.WARNING\n\n\n\n\n\n\n\ngenerics.logging.get_section_header(title, emoji='', sep_char='=', width=None)\nGenerate a formatted section header with separators.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\ntitle\nstr\nThe title text to display\nrequired\n\n\nemoji\nstr\nOptional emoji to include in the title\n''\n\n\nwidth\nint | None\nWidth for the separators. If None, calculated from title length.\nNone\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\n\n\n\n\n\nstr\nFormatted header with top and bottom separators"
  },
  {
    "objectID": "04_Reference/logging.html#functions",
    "href": "04_Reference/logging.html#functions",
    "title": "logging",
    "section": "",
    "text": "Name\nDescription\n\n\n\n\nconfigure_logging\nConfigure logging for the entire application.\n\n\nget_section_header\nGenerate a formatted section header with separators.\n\n\n\n\n\ngenerics.logging.configure_logging(level=logging.WARNING)\nConfigure logging for the entire application.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nlevel\nint\nThe logging level to use. Defaults to WARNING. Can be overridden by environment variable CAML_LOG_LEVEL.\nlogging.WARNING\n\n\n\n\n\n\n\ngenerics.logging.get_section_header(title, emoji='', sep_char='=', width=None)\nGenerate a formatted section header with separators.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\ntitle\nstr\nThe title text to display\nrequired\n\n\nemoji\nstr\nOptional emoji to include in the title\n''\n\n\nwidth\nint | None\nWidth for the separators. If None, calculated from title length.\nNone\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\n\n\n\n\n\nstr\nFormatted header with top and bottom separators"
  },
  {
    "objectID": "04_Reference/SyntheticDataGenerator.html",
    "href": "04_Reference/SyntheticDataGenerator.html",
    "title": "SyntheticDataGenerator",
    "section": "",
    "text": "SyntheticDataGenerator(\n    n_obs=10000,\n    n_cont_outcomes=1,\n    n_binary_outcomes=0,\n    n_cont_treatments=0,\n    n_binary_treatments=1,\n    n_discrete_treatments=0,\n    n_cont_confounders=0,\n    n_binary_confounders=0,\n    n_discrete_confounders=0,\n    n_cont_modifiers=0,\n    n_binary_modifiers=0,\n    n_discrete_modifiers=0,\n    n_confounding_modifiers=0,\n    stddev_outcome_noise=1.0,\n    stddev_treatment_noise=1.0,\n    causal_model_functional_form='linear',\n    n_nonlinear_transformations=None,\n    seed=None,\n)\nGenerate highly flexible synthetic data for use in causal inference and CaML testing.\nSyntheticDataGenerator is experimental and may change significantly in future versions.\nThe general form of the data generating process is:\n\\[\n\\mathbf{Y_i} = \\tau (\\mathbf{X_i}) \\mathbf{T_i} + g(\\mathbf{W_i}, \\mathbf{X_i}) + \\mathbf{\\epsilon_i}\n\\] \\[\n\\mathbf{T}_i=f(\\mathbf{W}_i, \\mathbf{X_{i,\\mathcal{S}}})+\\mathbf{\\eta_i}\n\\]\nwhere \\(\\mathbf{Y_i}\\) are the outcome(s), \\(\\mathbf{T_i}\\) are the treatment(s), \\(\\mathbf{X_i}\\) are the effect modifiers (leveraged for treatment effect heterogeneity) with an optional random subset \\(\\mathcal{S}\\) selected as confounders, \\(\\mathbf{W_i}\\) are the confounders, \\(\\mathbf{\\epsilon_i}\\) and \\(\\mathbf{\\eta_i}\\) are the error terms drawn from normal distributions with optional specified standard deviation, \\(\\tau\\) is the CATE function, \\(g\\) is the linearly seperable/nuisance component of the outcome function, and \\(f\\) is the treatment function. Note in the case of no modifier variables, we obtain a purely partially linear model, with \\(\\tau\\) as a constant.\nFor linear data generating process, \\(f\\) and \\(g\\) consist of strictly linear terms and untransformed variables. \\(\\tau(\\mathbf{X_i})\\) consists of linear interaction terms.\nFor nonlinear data generating process, \\(f\\) and \\(g\\) are generated via Generalized Additive Models (GAMs) with randomly selected nonlinear transformations. \\(\\tau(\\mathbf{X_i})\\) contains interaction terms with \\(\\mathbf{X}\\) and nonlinear transformations of \\(\\mathbf{X}\\).\nNote in the case of binary/discrete outcomes or treatments, sigmoid and softmax functions are used to transform log odds to probabilities.\nAs a DAG, the data generating process can be roughly represented as:\nFor a more detailed working example, see SyntheticDataGenerator Example."
  },
  {
    "objectID": "04_Reference/SyntheticDataGenerator.html#parameters",
    "href": "04_Reference/SyntheticDataGenerator.html#parameters",
    "title": "SyntheticDataGenerator",
    "section": "Parameters",
    "text": "Parameters\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nn_obs\nint\nNumber of observations.\n10000\n\n\nn_cont_outcomes\nint\nNumber of continuous outcomes (\\(Y\\)).\n1\n\n\nn_binary_outcomes\nint\nNumber of binary outcomes (\\(Y\\)).\n0\n\n\nn_cont_treatments\nint\nNumber of continuous treatments (\\(T\\)).\n0\n\n\nn_binary_treatments\nint\nNumber of binary treatments (\\(T\\)).\n1\n\n\nn_discrete_treatments\nint\nNumber of discrete treatments (\\(T\\)).\n0\n\n\nn_cont_confounders\nint\nNumber of continuous confounders (\\(W\\)).\n0\n\n\nn_binary_confounders\nint\nNumber of binary confounders (\\(W\\)).\n0\n\n\nn_discrete_confounders\nint\nNumber of discrete confounders (\\(W\\)).\n0\n\n\nn_cont_modifiers\nint\nNumber of continuous treatment effect modifiers (\\(X\\)).\n0\n\n\nn_binary_modifiers\nint\nNumber of binary treatment effect modifiers (\\(X\\)).\n0\n\n\nn_discrete_modifiers\nint\nNumber of discrete treatment effect modifiers (\\(X\\)).\n0\n\n\nn_confounding_modifiers\nint\nNumber of confounding treatment effect modifiers (\\(X_{\\mathcal{S}}\\)).\n0\n\n\nstddev_outcome_noise\nfloat\nStandard deviation of the outcome noise (\\(\\epsilon\\)).\n1.0\n\n\nstddev_treatment_noise\nfloat\nStandard deviation of the treatment noise (\\(\\eta\\)).\n1.0\n\n\ncausal_model_functional_form\nstr\nFunctional form of the causal model, can be ‚Äúlinear‚Äù or ‚Äúnonlinear‚Äù.\n'linear'\n\n\nn_nonlinear_transformations\nint | None\nNumber of nonlinear transformations, only applies if causal_model_functional_form=‚Äúnonlinear‚Äù.\nNone\n\n\nseed\nint | None\nRandom seed to use for generating the data.\nNone"
  },
  {
    "objectID": "04_Reference/SyntheticDataGenerator.html#attributes",
    "href": "04_Reference/SyntheticDataGenerator.html#attributes",
    "title": "SyntheticDataGenerator",
    "section": "Attributes",
    "text": "Attributes\n\n\n\n\n\n\n\n\nName\nType\nDescription\n\n\n\n\ndf\npd.DataFrame\nThe data generated by the data generation process.\n\n\ncates\npd.DataFrame\nThe true conditional average treatment effects (CATEs) of the data.\n\n\nates\npd.DataFrame\nThe true average treatment effects (ATEs) of the data.\n\n\ndgp\ndict\nThe true data generating processes of the treatments and outcomes. Contains the design matrix formula, parameters, noise, raw_scores, and function used to generate the data."
  },
  {
    "objectID": "04_Reference/SyntheticDataGenerator.html#examples",
    "href": "04_Reference/SyntheticDataGenerator.html#examples",
    "title": "SyntheticDataGenerator",
    "section": "Examples",
    "text": "Examples\n\nfrom caml.extensions.synthetic_data import SyntheticDataGenerator\n\ndata_generator = SyntheticDataGenerator(n_cont_outcomes=1,\n                                        n_binary_treatments=1,\n                                        n_cont_confounders=2,\n                                        n_cont_modifiers=2,\n                                        seed=10)\ndata_generator.df\n\n\n\n\n\n\n\n\nW1_continuous\nW2_continuous\nX1_continuous\nX2_continuous\nT1_binary\nY1_continuous\n\n\n\n\n0\n0.354380\n-3.252276\n2.715662\n-3.578800\n1\n-10.372900\n\n\n1\n0.568499\n2.484069\n-6.402235\n-2.611815\n0\n13.437245\n\n\n2\n0.162715\n8.842902\n1.288770\n-3.788545\n0\n-51.695014\n\n\n3\n0.362944\n-0.959538\n1.080988\n-3.542550\n1\n-10.163549\n\n\n4\n0.612101\n1.417536\n4.143630\n-4.112453\n0\n-33.613222\n\n\n...\n...\n...\n...\n...\n...\n...\n\n\n9995\n0.340436\n0.241095\n-6.524222\n-3.188783\n1\n28.300943\n\n\n9996\n0.019523\n1.338152\n-2.555492\n-3.643733\n1\n-0.252336\n\n\n9997\n0.325401\n1.258659\n-3.340546\n-4.255203\n1\n5.992318\n\n\n9998\n0.586715\n1.263264\n-2.826709\n-4.149383\n1\n1.543645\n\n\n9999\n0.003002\n6.723381\n1.260782\n-3.660600\n1\n-44.114285\n\n\n\n\n10000 rows √ó 6 columns\n\n\n\n\ndata_generator.cates\n\n\n\n\n\n\n\n\nCATE_of_T1_binary_on_Y1_continuous\n\n\n\n\n0\n-2.446437\n\n\n1\n6.601527\n\n\n2\n-1.289209\n\n\n3\n-0.922547\n\n\n4\n-4.137320\n\n\n...\n...\n\n\n9995\n6.299893\n\n\n9996\n2.337202\n\n\n9997\n2.618441\n\n\n9998\n2.223415\n\n\n9999\n-1.171886\n\n\n\n\n10000 rows √ó 1 columns\n\n\n\n\ndata_generator.ates\n\n\n\n\n\n\n\n\nTreatment\nATE\n\n\n\n\n0\nT1_binary_on_Y1_continuous\n0.678957\n\n\n\n\n\n\n\n\nfor t, df in data_generator.dgp.items():\n    print(f\"\\nDGP for {t}:\")\n    print(df)\n\n\nDGP for T1_binary:\n{'formula': '1 + W1_continuous + W2_continuous', 'params': array([ 0.4609703 ,  0.2566887 , -0.03896251]), 'noise': array([ 0.14476544, -0.51949108, -1.88624383, ..., -0.59020672,\n        0.87157749,  0.0697439 ]), 'raw_scores': array([0.69496136, 0.49765524, 0.15083742, ..., 0.47633017, 0.80751307,\n       0.5669763 ]), 'function': &lt;function SyntheticDataGenerator._create_dgp_function.&lt;locals&gt;.f_binary at 0x7fbdf893bac0&gt;}\n\nDGP for Y1_continuous:\n{'formula': '1 + W1_continuous + W2_continuous + X1_continuous + X2_continuous + T1_binary + T1_binary*X1_continuous + T1_binary*X2_continuous', 'params': array([-1.80242342,  1.11129512, -4.1263484 , -4.82709212,  1.87319625,\n        2.60635605, -0.91633948,  0.71653213]), 'noise': array([-0.12533653, -1.15370094, -0.26681987, ...,  1.85405702,\n       -0.18887322, -0.45736583]), 'raw_scores': array([-10.3729005 ,  13.43724492, -51.69501383, ...,   5.99231789,\n         1.54364473, -44.11428464]), 'function': &lt;function SyntheticDataGenerator._create_dgp_function.&lt;locals&gt;.f_cont at 0x7fbdb8af52d0&gt;}"
  },
  {
    "objectID": "04_Reference/SyntheticDataGenerator.html#methods",
    "href": "04_Reference/SyntheticDataGenerator.html#methods",
    "title": "SyntheticDataGenerator",
    "section": "Methods",
    "text": "Methods\n\n\n\nName\nDescription\n\n\n\n\ncreate_design_matrix\nCreate a design matrix from a formula and data.\n\n\n\n\ncreate_design_matrix\nextensions.synthetic_data.SyntheticDataGenerator.create_design_matrix(\n    df,\n    formula,\n    return_type='dataframe',\n    **kwargs,\n)\nCreate a design matrix from a formula and data.\nThis method can be used to reconstruct the design matrices used to generate the treatment and outcome variables. Furthermore, using dgp attribute, using the returned design matrix, one can generate the original outcomes and treatment variables. See below example.\n\nParameters\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\ndf\npd.DataFrame\nThe input data.\nrequired\n\n\nformula\nstr\nThe formula to be used with patsy.\nrequired\n\n\nreturn_type\nstr\nThe type of the returned design matrix. Can be either ‚Äúdataframe‚Äù or ‚Äúmatrix‚Äù. Default is ‚Äúdataframe‚Äù.\n'dataframe'\n\n\n**kwargs\n\nAdditional keyword arguments to be passed to patsy.dmatrix.\n{}\n\n\n\n\n\nReturns\n\n\n\nName\nType\nDescription\n\n\n\n\n\npd.DataFrame | np.ndarray\nThe design matrix.\n\n\n\n\n\nExamples\n\nimport numpy as np\ndf = data_generator.df\ndgp = data_generator.dgp['Y1_continuous']\n\ndesign_matrix = data_generator.create_design_matrix(df,formula=dgp['formula'])\n\nprint(design_matrix.columns)\n\n# Recreate Y1_continuous\nparams = dgp['params']\nnoise = dgp['noise']\nf = dgp['function']\n\nf(design_matrix,params,noise)\n\nassert np.allclose(f(design_matrix,params,noise), df['Y1_continuous'])\n\nIndex(['Intercept', 'W1_continuous', 'W2_continuous', 'X1_continuous',\n       'X2_continuous', 'T1_binary', 'T1_binary:X1_continuous',\n       'T1_binary:X2_continuous'],\n      dtype='object')"
  },
  {
    "objectID": "04_Reference/FastOLS.html",
    "href": "04_Reference/FastOLS.html",
    "title": "FastOLS",
    "section": "",
    "text": "FastOLS(\n    Y,\n    T,\n    G=None,\n    X=None,\n    W=None,\n    *,\n    xformula=None,\n    discrete_treatment=True,\n    engine='cpu',\n)\nFastOLS is an optimized implementation of the OLS estimator designed specifically with treatment effect estimation in mind.\nFastOLS is experimental and may change significantly in future versions.\nThis class estimates a standard linear regression model for any number of continuous or binary outcomes and a single continuous or binary treatment, and provides estimates for the Average Treatment Effects (ATEs) and Group Average Treatment Effects (GATEs) out of the box. Additionally, methods are provided for estimating custom GATEs & Conditional Average Treatment Effects (CATEs) of individual observations, which can also be used for out-of-sample predictions. Note, this method assumes linear treatment effects and heterogeneity, which is typically sufficient when primarily concerned with ATEs and GATEs.\nThis class leverages JAX for fast numerical computations, which can be installed using pip install caml[jax], defaulting to NumPy if JAX is not available. For GPU acceleration, install JAX with GPU support using pip install caml[jax-gpu].\nFor outcome/treatment support, see Support Matrix.\nFor model specification details, see Model Specifications.\nFor a more detailed working example, see FastOLS Example."
  },
  {
    "objectID": "04_Reference/FastOLS.html#parameters",
    "href": "04_Reference/FastOLS.html#parameters",
    "title": "FastOLS",
    "section": "Parameters",
    "text": "Parameters\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nY\nSequence[str]\nA list of outcome variable names.\nrequired\n\n\nT\nstr\nThe treatment variable name.\nrequired\n\n\nG\nSequence[str] | None\nA list of group variable names. These will be the groups for which GATEs will be estimated.\nNone\n\n\nX\nSequence[str] | None\nA list of covariate variable names. These will be the covariates for which heterogeneity/CATEs can be estimated.\nNone\n\n\nW\nSequence[str] | None\nA list of additional covariate variable names to be used as controls. These will be the additional covariates not used for modeling heterogeneity/CATEs.\nNone\n\n\nxformula\nstr | None\nAdditional formula string to append to the main formula, starting with ‚Äú+‚Äù. For example, ‚Äú+age+gender‚Äù will add age and gender as additional predictors.\nNone\n\n\ndiscrete_treatment\nbool\nWhether the treatment is discrete\nTrue\n\n\nengine\nstr\nThe engine to use for computation. Can be ‚Äúcpu‚Äù or ‚Äúgpu‚Äù. Note ‚Äúgpu‚Äù requires JAX to be installed, which can be installed via pip install caml[jax-gpu].\n'cpu'"
  },
  {
    "objectID": "04_Reference/FastOLS.html#attributes",
    "href": "04_Reference/FastOLS.html#attributes",
    "title": "FastOLS",
    "section": "Attributes",
    "text": "Attributes\n\n\n\n\n\n\n\n\nName\nType\nDescription\n\n\n\n\nY\nSequence[str]\nA list of outcome variable names.\n\n\nT\nstr\nThe treatment variable name.\n\n\nG\nSequence[str] | None\nThe list of group variable names. These will be the groups for which GATEs will be estimated.\n\n\nX\nSequence[str] | None\nThe list of variable names representing the confounder/control feature set to be utilized for estimating heterogeneity/CATEs, that are in addition to G.\n\n\nW\nSequence[str] | None\nThe list of variable names representing the confounder/control feature not utilized for estimating heterogeneity/CATEs.\n\n\nformula\nstr\nThe formula leveraged for design matrix creation via Patsy.\n\n\nparams\nnp.ndarray\nThe estimated parameters of the model.\n\n\nvcv\nnp.ndarray\nThe estimated variance-covariance matrix of the model parameters.\n\n\nstd_err\nnp.ndarray\nThe standard errors of the estimated parameters.\n\n\nfitted_values\nnp.ndarray\nThe predicted values from the model.\n\n\nresiduals\nnp.ndarray\nThe residuals of the model.\n\n\ntreatment_effects\ndict\nThe estimated treatment effects dictionary."
  },
  {
    "objectID": "04_Reference/FastOLS.html#examples",
    "href": "04_Reference/FastOLS.html#examples",
    "title": "FastOLS",
    "section": "Examples",
    "text": "Examples\n\nfrom caml import FastOLS\nfrom caml.extensions.synthetic_data import SyntheticDataGenerator\n\ndata_generator = SyntheticDataGenerator(n_cont_outcomes=1,\n                                            n_binary_outcomes=1,\n                                            n_cont_modifiers=1,\n                                            n_binary_modifiers=2,\n                                            seed=10)\ndf = data_generator.df\n\nfo_obj = FastOLS(\n    Y=[c for c in df.columns if \"Y\" in c],\n    T=\"T1_binary\",\n    G=[c for c in df.columns if \"X\" in c and (\"bin\" in c or \"dis\" in c)],\n    X=[c for c in df.columns if \"X\" in c and \"cont\" in c],\n    W=[c for c in df.columns if \"W\" in c],\n    xformula=None,\n    engine=\"cpu\",\n    discrete_treatment=True,\n)\n\nprint(fo_obj)\n\n================== FastOLS Object ==================\nEngine: cpu\nOutcome Variable: ['Y1_continuous', 'Y2_binary']\nTreatment Variable: T1_binary\nDiscrete Treatment: True\nGroup Variables: ['X2_binary', 'X3_binary']\nFeatures/Confounders for Heterogeneity (X): ['X1_continuous']\nFeatures/Confounders as Controls (W): []\nFormula: Q('Y1_continuous') + Q('Y2_binary') ~ C(Q('T1_binary')) + C(Q('X2_binary'))*C(Q('T1_binary')) + C(Q('X3_binary'))*C(Q('T1_binary')) + Q('X1_continuous')*C(Q('T1_binary'))"
  },
  {
    "objectID": "04_Reference/FastOLS.html#methods",
    "href": "04_Reference/FastOLS.html#methods",
    "title": "FastOLS",
    "section": "Methods",
    "text": "Methods\n\n\n\nName\nDescription\n\n\n\n\nfit\nFits the regression model on the provided data and, optionally, estimates Average Treatment Effect(s) (ATE) and Group Average Treatment Effect(s) (GATE).\n\n\nestimate_ate\nEstimate Average Treatment Effects (ATEs) of T on each Y from fitted model.\n\n\nestimate_cate\nEstimate Conditional Average Treatment Effects (CATEs) of T on each Y from fitted model for all given observations in the dataset.\n\n\npredict\nGenerate predicted conditional average treatment effects (CATEs) or outcomes.\n\n\nprettify_treatment_effects\nConvert treatment effects dictionary to a pandas DataFrame.\n\n\n\n\nfit\nFastOLS.fit(df, *, n_jobs=-1, estimate_effects=True, cov_type='nonrobust')\nFits the regression model on the provided data and, optionally, estimates Average Treatment Effect(s) (ATE) and Group Average Treatment Effect(s) (GATE).\nIf estimate_effects is True, the method estimates Average Treatment Effects (ATEs) and Group Average Treatment Effects (GATEs), based on specified G. This leverages estimate_ate method under the hood, but efficiently reuses the data and parallelizes the computation of GATEs.\n\nParameters\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\ndf\nPandasConvertibleDataFrame\nInput dataframe to fit the model on. Supported formats: pandas DataFrame, PySpark DataFrame, Polars DataFrame, or Any object with toPandas() or to_pandas() method\nrequired\n\n\nn_jobs\nint\nThe number of jobs to use for parallel processing in the estimation of GATEs. Defaults to -1, which uses all available processors. If getting OOM errors, try setting n_jobs to a lower value.\n-1\n\n\nestimate_effects\nbool\nWhether to estimate Average Treatment Effects (ATEs) and Group Average Treatment Effects (GATEs).\nTrue\n\n\ncov_type\nstr\nThe covariance estimator to use for variance-covariance matrix and standard errors. Can be ‚Äúnonrobust‚Äù, ‚ÄúHC0‚Äù, or ‚ÄúHC1‚Äù.\n'nonrobust'\n\n\n\n\n\nExamples\n\nfo_obj.fit(df, n_jobs=4, estimate_effects=True, cov_type='nonrobust')\n\nfo_obj.treatment_effects.keys()\n\ndict_keys(['overall', 'X2_binary-0', 'X2_binary-1', 'X3_binary-1', 'X3_binary-0'])\n\n\n\n\n\nestimate_ate\nFastOLS.estimate_ate(\n    df,\n    *,\n    return_results_dict=False,\n    group='Custom Group',\n    membership=None,\n    _diff_matrix=None,\n)\nEstimate Average Treatment Effects (ATEs) of T on each Y from fitted model.\nIf the entire dataframe is provided, the function will estimate the ATE of the entire population, where the ATE, in the case of binary treatments, is formally defined as: \\[\n    \\tau = \\mathbb{E}_n[\\mathbf{Y}_1 - \\mathbf{Y}_0]\n    \\]\nIf a subset of the dataframe is provided, the function will estimate the ATE of the subset (e.g., GATEs), where the GATE, in the case of binary treatments, is formally defined as: \\[\n    \\tau = \\mathbb{E}_n[\\mathbf{Y}_1 - \\mathbf{Y}_0|\\mathbf{G}=G]\n    \\]\nFor more details on treatment effect estimation, see Model Specifications.\n\nParameters\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\ndf\nPandasConvertibleDataFrame\nDataframe containing the data to estimate the ATEs. Supported formats: pandas DataFrame, PySpark DataFrame, Polars DataFrame, or Any object with toPandas() or to_pandas() method\nrequired\n\n\nreturn_results_dict\nbool\nIf True, the function returns a dictionary containing ATEs/GATEs, standard errors, t-statistics, and p-values. If False, the function returns a numpy array containing ATEs/GATEs alone.\nFalse\n\n\ngroup\nstr\nName of the group to estimate the ATEs for.\n'Custom Group'\n\n\nmembership\nstr | None\nName of the membership variable to estimate the ATEs for.\nNone\n\n\n_diff_matrix\njnp.ndarray | None = None\nPrivate argument used in fit method.\nNone\n\n\n\n\n\nReturns\n\n\n\n\n\n\n\n\nName\nType\nDescription\n\n\n\n\n\njnp.ndarray | dict\nEstimated ATEs/GATEs or dictionary containing the estimated ATEs/GATEs and their standard errors, t-statistics, and p-values.\n\n\n\n\n\nExamples\n\nate = fo_obj.estimate_ate(df, return_results_dict=True, group=\"Overall\")\n\nate\n\n{'Overall': {'outcome': ['Y1_continuous', 'Y2_binary'],\n  'ate': array([[3.75944943, 0.19349086]]),\n  'std_err': array([[0.02012718, 0.00971994]]),\n  't_stat': array([[186.78472875,  19.90658227]]),\n  'pval': array([[0., 0.]]),\n  'n': 10000,\n  'n_treated': 5060,\n  'n_control': 4940}}\n\n\n\ndf_filtered = df.query(\n    \"X3_binary == 0 & X1_continuous &lt; 5\"\n).copy()\n\ncustom_gate = fo_obj.estimate_ate(df_filtered)\n\ncustom_gate\n\narray([[1.39607152, 0.08336419]])\n\n\n\n\n\nestimate_cate\nFastOLS.estimate_cate(df, *, return_results_dict=False)\nEstimate Conditional Average Treatment Effects (CATEs) of T on each Y from fitted model for all given observations in the dataset.\nThe CATE, in the case of binary treatments, is formally defined as: \\[\n    \\tau = \\mathbb{E}_n[\\mathbf{Y}_1 - \\mathbf{Y}_0|\\mathbf{Q}=Q]\n    \\]\nFor more details on treatment effect estimation, see Model Specifications.\n\nParameters\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\ndf\nPandasConvertibleDataFrame\nDataframe containing the data to estimate CATEs for. Supported formats: pandas DataFrame, PySpark DataFrame, Polars DataFrame, or Any object with toPandas() or to_pandas() method\nrequired\n\n\nreturn_results_dict\nbool\nIf True, the function returns a dictionary containing CATEs, standard errors, t-statistics, and p-values. If False, the function returns a numpy array containing CATEs alone.\nFalse\n\n\n\n\n\nReturns\n\n\n\n\n\n\n\n\nName\nType\nDescription\n\n\n\n\n\njnp.ndarray | dict\nCATEs or dictionary containing CATEs, standard errors, t-statistics, and p-values.\n\n\n\n\n\nExamples\n\ncates = fo_obj.estimate_cate(df)\ncates[:5]\n\narray([[3.89639511, 0.17159235],\n       [3.74635426, 0.23789582],\n       [4.5283798 , 0.21765926],\n       [3.87988946, 0.17201947],\n       [3.66232416, 0.24007028]])\n\n\n\nres = fo_obj.estimate_cate(df, return_results_dict=True)\nres.keys()\n\ndict_keys(['outcome', 'cate', 'std_err', 't_stat', 'pval'])\n\n\n\n\n\npredict\nFastOLS.predict(df, *, return_results_dict=False, mode='cate')\nGenerate predicted conditional average treatment effects (CATEs) or outcomes.\nWhen mode is ‚Äúoutcome‚Äù, the function returns predicted outcomes.\nWhen mode is ‚Äúcate‚Äù, the function returns predicted CATEs, behaving as an alias for estimate_cate.\n\nParameters\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\ndf\nPandasConvertibleDataFrame\nDataframe containing the data to estimate CATEs for. Supported formats: pandas DataFrame, PySpark DataFrame, Polars DataFrame, or Any object with toPandas() or to_pandas() method\nrequired\n\n\nreturn_results_dict\nbool\nIf True, the function returns a dictionary containing CATEs, standard errors, t-statistics, and p-values. If False, the function returns a numpy array containing CATEs alone. Does not have any effect when mode is ‚Äúoutcome‚Äù.\nFalse\n\n\nmode\nstr\nThe mode of prediction. Supported modes are ‚Äúcate‚Äù and ‚Äúoutcome‚Äù. If ‚Äúcate‚Äù, the function returns CATEs. If ‚Äúoutcome‚Äù, the function returns predicted outcomes.\n'cate'\n\n\n\n\n\nReturns\n\n\n\n\n\n\n\n\nName\nType\nDescription\n\n\n\n\n\njnp.ndarray | dict\nCATEs or dictionary containing CATEs, standard errors, t-statistics, and p-values.\n\n\n\n\n\nExamples\n\ncates = fo_obj.predict(df)\ncates[:5]\n\narray([[3.89639511, 0.17159235],\n       [3.74635426, 0.23789582],\n       [4.5283798 , 0.21765926],\n       [3.87988946, 0.17201947],\n       [3.66232416, 0.24007028]])\n\n\n\nres = fo_obj.predict(df, return_results_dict=True)\nres.keys()\n\ndict_keys(['outcome', 'cate', 'std_err', 't_stat', 'pval'])\n\n\n\n\n\nprettify_treatment_effects\nFastOLS.prettify_treatment_effects(effects=None)\nConvert treatment effects dictionary to a pandas DataFrame.\nIf no argument is provided, the results are constructed from internal results dictionary. This is useful default behavior. For custom treatment effects, you can pass the results generated by the estimate_ate method.\n\nParameters\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\neffects\ndict\nDictionary of treatment effects. If None, the results are constructed from internal results dictionary.\nNone\n\n\n\n\n\nReturns\n\n\n\nName\nType\nDescription\n\n\n\n\n\npd.DataFrame\nDataFrame of treatment effects.\n\n\n\n\n\nExamples\n\nfo_obj.prettify_treatment_effects()\n\n\n\n\n\n\n\n\ngroup\nmembership\noutcome\nate\nstd_err\nt_stat\npval\nn\nn_treated\nn_control\n\n\n\n\n0\noverall\nNone\nY1_continuous\n3.759449\n0.020127\n186.784729\n0.000000\n10000\n5060\n4940\n\n\n1\noverall\nNone\nY2_binary\n0.193491\n0.009720\n19.906582\n0.000000\n10000\n5060\n4940\n\n\n2\nX2_binary\n0\nY1_continuous\n3.584580\n0.034935\n102.606668\n0.000000\n3320\n1691\n1629\n\n\n3\nX2_binary\n0\nY2_binary\n0.156381\n0.016871\n9.269187\n0.000000\n3320\n1691\n1629\n\n\n4\nX2_binary\n1\nY1_continuous\n3.846360\n0.024626\n156.193627\n0.000000\n6680\n3369\n3311\n\n\n5\nX2_binary\n1\nY2_binary\n0.211934\n0.011892\n17.821080\n0.000000\n6680\n3369\n3311\n\n\n6\nX3_binary\n1\nY1_continuous\n4.081423\n0.021454\n190.238254\n0.000000\n8801\n4451\n4350\n\n\n7\nX3_binary\n1\nY2_binary\n0.208494\n0.010361\n20.123279\n0.000000\n8801\n4451\n4350\n\n\n8\nX3_binary\n0\nY1_continuous\n1.396072\n0.058130\n24.016441\n0.000000\n1199\n609\n590\n\n\n9\nX3_binary\n0\nY2_binary\n0.083364\n0.028072\n2.969612\n0.002982\n1199\n609\n590\n\n\n\n\n\n\n\n\n## Using a custom GATE\ncustom_gate = fo_obj.estimate_ate(df_filtered, return_results_dict=True, group=\"My Custom Group\")\nfo_obj.prettify_treatment_effects(custom_gate)\n\n\n\n\n\n\n\n\ngroup\nmembership\noutcome\nate\nstd_err\nt_stat\npval\nn\nn_treated\nn_control\n\n\n\n\n0\nMy Custom Group\nNone\nY1_continuous\n1.396072\n0.058130\n24.016441\n0.000000\n1199\n609\n590\n\n\n1\nMy Custom Group\nNone\nY2_binary\n0.083364\n0.028072\n2.969612\n0.002982\n1199\n609\n590"
  },
  {
    "objectID": "03_Examples/AutoCATE.html",
    "href": "03_Examples/AutoCATE.html",
    "title": "AutoCATE",
    "section": "",
    "text": "In this notebook, we‚Äôll walk through an example of generating synthetic data, running AutoCATE, and visualizing results using the ground truth as reference.\nAutoCATE is particularly useful when highly accurate CATE estimation is of primary interest in the presence of exogenous treatment, simple linear confounding, or complex non-linear confounding.\nAutoCATE enables the use of various CATE models with varying assumptions on functional form of treatment effects & heterogeneity. When a set of CATE models are considered, the final CATE model is automatically selected based on validation set performance.",
    "crumbs": [
      "AutoCATE"
    ]
  },
  {
    "objectID": "03_Examples/AutoCATE.html#generate-synthetic-data",
    "href": "03_Examples/AutoCATE.html#generate-synthetic-data",
    "title": "AutoCATE",
    "section": "Generate Synthetic Data",
    "text": "Generate Synthetic Data\nHere we‚Äôll leverage the SyntheticDataGenerator class to generate a linear synthetic data generating process, with a binary treatment, continuous outcome, and a mix of confounding/mediating continuous covariates.\n\nfrom caml.extensions.synthetic_data import SyntheticDataGenerator\n\ndata_generator = SyntheticDataGenerator(\n    n_obs=10_000,\n    n_cont_outcomes=1,\n    n_binary_treatments=1,\n    n_cont_confounders=2,\n    n_cont_modifiers=2,\n    n_confounding_modifiers=1,\n    causal_model_functional_form=\"linear\",\n    seed=10,\n)\n\nWe can print our simulated data via:\n\ndata_generator.df\n\n\n\n\n\n\n\n\nW1_continuous\nW2_continuous\nX1_continuous\nX2_continuous\nT1_binary\nY1_continuous\n\n\n\n\n0\n0.354380\n-3.252276\n2.715662\n-3.578800\n1\n11.880305\n\n\n1\n0.568499\n2.484069\n-6.402235\n-2.611815\n0\n-32.292141\n\n\n2\n0.162715\n8.842902\n1.288770\n-3.788545\n1\n-48.696391\n\n\n3\n0.362944\n-0.959538\n1.080988\n-3.542550\n0\n-1.899468\n\n\n4\n0.612101\n1.417536\n4.143630\n-4.112453\n1\n-7.315334\n\n\n...\n...\n...\n...\n...\n...\n...\n\n\n9995\n0.340436\n0.241095\n-6.524222\n-3.188783\n1\n-27.578609\n\n\n9996\n0.019523\n1.338152\n-2.555492\n-3.643733\n1\n-19.692436\n\n\n9997\n0.325401\n1.258659\n-3.340546\n-4.255203\n1\n-26.087316\n\n\n9998\n0.586715\n1.263264\n-2.826709\n-4.149383\n1\n-25.876331\n\n\n9999\n0.003002\n6.723381\n1.260782\n-3.660600\n1\n-38.200522\n\n\n\n\n10000 rows √ó 6 columns\n\n\n\nTo inspect our true data generating process, we can call data_generator.dgp. Furthermore, we will have our true CATEs and ATEs at our disposal via data_generator.cates & data_generator.ates, respectively. We‚Äôll use this as our source of truth for performance evaluation of our CATE estimator.\n\nfor t, df in data_generator.dgp.items():\n    print(f\"\\nDGP for {t}:\")\n    print(df)\n\n\nDGP for T1_binary:\n{'formula': '1 + W1_continuous + W2_continuous + X1_continuous', 'params': array([ 0.4609703 ,  0.2566887 , -0.03896251,  0.07238272]), 'noise': array([-0.51949108, -1.88624383,  0.86927397, ...,  0.87157749,\n        0.0697439 , -0.72616319]), 'raw_scores': array([0.58800598, 0.13710535, 0.75412862, ..., 0.7549587 , 0.60527474,\n       0.39290362]), 'function': &lt;function SyntheticDataGenerator._create_dgp_function.&lt;locals&gt;.f_binary at 0x7efc0e65bc70&gt;}\n\nDGP for Y1_continuous:\n{'formula': '1 + W1_continuous + W2_continuous + X1_continuous + X2_continuous + T1_binary + T1_binary*X1_continuous + T1_binary*X2_continuous', 'params': array([ 1.11129512, -4.1263484 , -4.82709212,  1.87319625,  2.60635605,\n       -0.91633948,  0.71653213, -0.25067306]), 'noise': array([-1.15370094, -0.26681987,  0.05261899, ..., -0.18887322,\n       -0.45736583, -0.57057603]), 'raw_scores': array([ 11.88030508, -32.29214063, -48.69639077, ..., -26.0873159 ,\n       -25.87633114, -38.20052217]), 'function': &lt;function SyntheticDataGenerator._create_dgp_function.&lt;locals&gt;.f_cont at 0x7efbd279d480&gt;}\n\n\n\ndata_generator.cates\n\n\n\n\n\n\n\n\nCATE_of_T1_binary_on_Y1_continuous\n\n\n\n\n0\n1.926628\n\n\n1\n-4.849035\n\n\n2\n0.956792\n\n\n3\n0.746245\n\n\n4\n3.083586\n\n\n...\n...\n\n\n9995\n-4.791812\n\n\n9996\n-1.834046\n\n\n9997\n-2.243283\n\n\n9998\n-1.901629\n\n\n9999\n0.904665\n\n\n\n\n10000 rows √ó 1 columns\n\n\n\n\ndata_generator.ates\n\n\n\n\n\n\n\n\nTreatment\nATE\n\n\n\n\n0\nT1_binary_on_Y1_continuous\n-0.55937",
    "crumbs": [
      "AutoCATE"
    ]
  },
  {
    "objectID": "03_Examples/AutoCATE.html#running-autocate",
    "href": "03_Examples/AutoCATE.html#running-autocate",
    "title": "AutoCATE",
    "section": "Running AutoCATE",
    "text": "Running AutoCATE\n\nClass Instantiation\nWe can instantiate and observe our AutoCATE object via:\n\n\n\n\n\n\nTip\n\n\n\nW can be leveraged if we want to use certain covariates only in our nuisance functions to control for confounding and not in the final CATE estimator. This can be useful if a confounder may be required to include, but for compliance reasons, we don‚Äôt want our CATE model to leverage this feature (e.g., gender). However, this will restrict our available CATE estimators to orthogonal learners, since metalearners necessarily include all covariates. If you don‚Äôt care about W being in the final CATE estimator, pass it as X, as done below.\n\n\n\nfrom caml import AutoCATE\n\nauto_cate = AutoCATE(\n    Y=\"Y1_continuous\",\n    T=\"T1_binary\",\n    X=[c for c in data_generator.df.columns if \"X\" in c]\n    + [c for c in data_generator.df.columns if \"W\" in c],\n    discrete_treatment=True,\n    discrete_outcome=False,\n    model_Y={\n        \"time_budget\": 10,\n        \"estimator_list\": [\"rf\", \"extra_tree\", \"xgb_limitdepth\"],\n    },\n    model_T={\n        \"time_budget\": 10,\n        \"estimator_list\": [\"rf\", \"extra_tree\", \"xgb_limitdepth\"],\n    },\n    model_regression={\n        \"time_budget\": 10,\n        \"estimator_list\": [\"rf\", \"extra_tree\", \"xgb_limitdepth\"],\n    },\n    enable_categorical=True,\n    n_jobs=-1,\n    use_ray=False,\n    ray_remote_func_options_kwargs=None,\n    use_spark=False,\n    seed=None,\n)\n\n[11/10/25 02:30:30] WARNING  AutoCATE is experimental and may change in future versions.           decorators.py:57\n\n\n\n\n\nFitting End-to-End AutoCATE pipeline\nFirst, I can inspect available estimators out of the box:\n\nauto_cate.available_estimators\n\n['LinearDML',\n 'CausalForestDML',\n 'NonParamDML',\n 'SparseLinearDML-2D',\n 'DRLearner',\n 'ForestDRLearner',\n 'LinearDRLearner',\n 'SLearner',\n 'TLearner',\n 'XLearner']\n\n\nAnd create another one if desired:\n\nfrom caml import AutoCateEstimator\nfrom econml.dml import LinearDML\n\nmy_custom_estimator = AutoCateEstimator(name=\"MyCustomEstimator\",estimator=LinearDML())\n\n\nauto_cate.fit(data_generator.df, cate_estimators=['LinearDML','CausalForestDML','TLearner'], additional_cate_estimators=[my_custom_estimator])\n\n                    INFO                                                                          decorators.py:111\n                               ____      __  __ _                                                                  \n                              / ___|__ _|  \\/  | |                                                                 \n                             | |   / _` | |\\/| | |                                                                 \n                             | |__| (_| | |  | | |___                                                              \n                              \\____\\__,_|_|  |_|_____|                                                             \n                                                                                                                   \n                                                                                                                   \n\n\n\n                    INFO     ================== AutoCATE Object ==================                      cate.py:298\n                             Outcome Variable: ['Y1_continuous']                                                   \n                             Discrete Outcome: False                                                               \n                             Treatment Variable: ['T1_binary']                                                     \n                             Discrete Treatment: True                                                              \n                             Features/Confounders for Heterogeneity (X): ['X1_continuous',                         \n                             'X2_continuous', 'W1_continuous', 'W2_continuous']                                    \n                             Features/Confounders as Controls (W): []                                              \n                             Enable Categorical: True                                                              \n                             n Jobs: -1                                                                            \n                             Use Ray: False                                                                        \n                             Use Spark: False                                                                      \n                             Random Seed: None                                                                     \n                                                                                                                   \n                                                                                                                   \n\n\n\n                    INFO                                                                          decorators.py:111\n                             ==============================                                                        \n                             |üéØ AutoML Nuisance Functions|                                                        \n                             ==============================                                                        \n                                                                                                                   \n\n\n\n                    INFO     Searching for model_Y:                                                     cate.py:678\n\n\n\n[11/10/25 02:30:40] INFO     Best estimator: extra_tree with loss 5.939156478409143 found on iteration _base.py:144\n                             33 in 9.728713035583496 seconds.                                                      \n                                                                                                                   \n\n\n\n                    INFO     Searching for model_regression:                                            cate.py:678\n\n\n\n[11/10/25 02:30:51] INFO     Best estimator: extra_tree with loss 3.223916238611213 found on iteration _base.py:144\n                             35 in 10.192770004272461 seconds.                                                     \n                                                                                                                   \n\n\n\n                    INFO     Searching for model_T:                                                     cate.py:678\n\n\n\n[11/10/25 02:31:01] INFO     Best estimator: rf with loss 0.6739378405925094 found on iteration 47 in  _base.py:144\n                             8.12563967704773 seconds.                                                             \n                                                                                                                   \n\n\n\n                    INFO     ‚úÖ Completed.                                                        decorators.py:116\n\n\n\n                    INFO                                                                          decorators.py:111\n                             ==========================                                                            \n                             |üéØ AutoML CATE Functions|                                                            \n                             ==========================                                                            \n                                                                                                                   \n\n\n\n[11/10/25 02:31:06] INFO     Best Estimator: 'CausalForestDML'                                          cate.py:837\n\n\n\n                    INFO     Estimator RScores: {'LinearDML': 0.35609848111516273, 'CausalForestDML':   cate.py:838\n                             0.3571139818084351, 'TLearner': 0.3292191747367066, 'MyCustomEstimator':              \n                             0.35628784494617516}                                                                  \n\n\n\n                    INFO     ‚úÖ Completed.                                                        decorators.py:116\n\n\n\n                    INFO                                                                          decorators.py:111\n                             ====================                                                                  \n                             |üß™ Testing Results|                                                                  \n                             ====================                                                                  \n                                                                                                                   \n\n\n\n                    INFO     Discrete treatment specified. Using DRTester for final testing.            cate.py:893\n\n\n\n[11/10/25 02:31:07] INFO     All validation results suggest that the model has found statistically      cate.py:923\n                             significant heterogeneity.                                                            \n                                                                                                                   \n\n\n\n                    INFO        treatment  blp_est  blp_se  blp_pval  qini_est  qini_se  qini_pval  \\   cate.py:927\n                             0          1    1.046   0.033       0.0     0.984    0.042        0.0                 \n                                                                                                                   \n                                autoc_est  autoc_se  autoc_pval  cal_r_squared                                     \n                             0      2.628     0.126         0.0          0.923                                     \n\n\n\n                    INFO     CALIBRATION CURVE                                                          cate.py:930\n\n\n\n\n\n\n\n\n\n\n[11/10/25 02:31:08] INFO     QINI CURVE                                                                 cate.py:933\n\n\n\n\n\n\n\n\n\n\n                    INFO     TOC CURVE                                                                  cate.py:936\n\n\n\n\n\n\n\n\n\n\n                    INFO     ‚úÖ Completed.                                                        decorators.py:116\n\n\n\n                    INFO                                                                          decorators.py:111\n                             ==============================                                                        \n                             |üîã Refitting Final Estimator|                                                        \n                             ==============================                                                        \n                                                                                                                   \n\n\n\n[11/10/25 02:31:09] INFO     ‚úÖ Completed.                                                        decorators.py:116\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nThe selected CATE model defaults to the one with the highest RScore.",
    "crumbs": [
      "AutoCATE"
    ]
  },
  {
    "objectID": "03_Examples/AutoCATE.html#validating-results-with-ground-truth",
    "href": "03_Examples/AutoCATE.html#validating-results-with-ground-truth",
    "title": "AutoCATE",
    "section": "Validating Results with Ground Truth",
    "text": "Validating Results with Ground Truth\n\nAverage Treatment Effect (ATE)\nWe‚Äôll use the summarize() method after obtaining our predictions above, where our the displayed mean represents our Average Treatment Effect (ATE).\n\nauto_cate.estimate_ate(data_generator.df[auto_cate.X])\n\n-0.5626110272147206\n\n\nNow comparing this to our ground truth, we see the model performed well the true ATE:\n\ndata_generator.ates\n\n\n\n\n\n\n\n\nTreatment\nATE\n\n\n\n\n0\nT1_binary_on_Y1_continuous\n-0.55937\n\n\n\n\n\n\n\n\n\nConditional Average Treatment Effect (CATE)\nNow we want to see how the estimator performed in modeling the true CATEs.\nFirst, we can simply compute the Precision in Estimating Heterogeneous Effects (PEHE), which is simply the Root Mean Squared Error (RMSE):\n\nfrom sklearn.metrics import root_mean_squared_error\n\ncate_predictions = auto_cate.estimate_cate(\n    data_generator.df[auto_cate.X]\n)  # `predict` and `effect` are aliases\ntrue_cates = data_generator.cates.to_numpy()\nroot_mean_squared_error(true_cates, cate_predictions)\n\n0.3395838067179093\n\n\nNot bad! Now let‚Äôs use some visualization techniques:\n\nfrom caml.extensions.plots import cate_true_vs_estimated_plot\n\ncate_true_vs_estimated_plot(\n    true_cates=true_cates, estimated_cates=cate_predictions\n)\n\n\n\n\n\n\n\n\n\nfrom caml.extensions.plots import cate_histogram_plot\n\ncate_histogram_plot(true_cates=true_cates, estimated_cates=cate_predictions)\n\n\n\n\n\n\n\n\n\nfrom caml.extensions.plots import cate_line_plot\n\ncate_line_plot(\n    true_cates=true_cates.flatten(),\n    estimated_cates=cate_predictions.flatten(),\n    window=20,\n)\n\n\n\n\n\n\n\n\nOverall, we can see the model performed remarkably well!\nNow, we can also get standard errors by obtaining the EconML Inference Results by passing return_inference=True to estimate_cate (or predict or effect):\n\ninference = auto_cate.estimate_cate(\n    data_generator.df[auto_cate.X], return_inference=True\n)\nstderrs = inference.stderr\n\ncate_line_plot(\n    true_cates=true_cates.flatten(),\n    estimated_cates=cate_predictions.flatten(),\n    window=20,\n    standard_errors=stderrs,\n)",
    "crumbs": [
      "AutoCATE"
    ]
  },
  {
    "objectID": "03_Examples/FastOLS.html",
    "href": "03_Examples/FastOLS.html",
    "title": "FastOLS",
    "section": "",
    "text": "In this notebook, we‚Äôll walk through an example of generating synthetic data, estimating treatment effects (ATEs, GATEs, and CATEs) using FastOLS, and comparing to our ground truth.\nFastOLS is particularly useful when efficiently estimating ATEs and GATEs is of primary interest and the treatment is exogenous or confounding takes on a particularly simple functional form.\nFastOLS assumes linear treatment effects & heterogeneity. This is generally sufficient for estimation of ATEs and GATEs, but can perform poorly in CATE estimation & prediction when heterogeneity is complex & nonlinear. For high quality CATE estimation, we recommend leveraging AutoCATE.",
    "crumbs": [
      "FastOLS"
    ]
  },
  {
    "objectID": "03_Examples/FastOLS.html#generate-synthetic-data",
    "href": "03_Examples/FastOLS.html#generate-synthetic-data",
    "title": "FastOLS",
    "section": "Generate Synthetic Data",
    "text": "Generate Synthetic Data\nHere we‚Äôll leverage the SyntheticDataGenerator class to generate a linear synthetic data generating process, with an exogenous binary treatment, a continuous & a binary outcome, and binary & continuous mediating covariates.\n\nfrom caml.generics.logging import configure_logging\nimport logging\n\nconfigure_logging(level=logging.DEBUG)\n\n[11/10/25 02:30:11] DEBUG    Logging configured with level: DEBUG                                     logging.py:75\n\n\n\n\nfrom caml.extensions.synthetic_data import SyntheticDataGenerator\n\ndata_generator = SyntheticDataGenerator(\n    n_obs=10_000,\n    n_cont_outcomes=1,\n    n_binary_outcomes=1,\n    n_binary_treatments=1,\n    n_cont_confounders=2,\n    n_cont_modifiers=3,\n    n_binary_modifiers=2,\n    stddev_outcome_noise=1,\n    stddev_treatment_noise=1,\n    causal_model_functional_form=\"linear\",\n    seed=10,\n)\n\n[11/10/25 02:30:12] WARNING  SyntheticDataGenerator is experimental and may change in future       decorators.py:57\n                             versions.                                                                             \n\n\n\nWe can print our simulated data via:\n\ndata_generator.df\n\n\n\n\n\n\n\n\nW1_continuous\nW2_continuous\nX1_continuous\nX2_continuous\nX3_continuous\nX4_binary\nX5_binary\nT1_binary\nY1_continuous\nY2_binary\n\n\n\n\n0\n0.354380\n-3.252276\n2.715662\n-3.578800\n-3.148647\n0\n0\n1\n-11.319410\n0\n\n\n1\n0.568499\n2.484069\n-6.402235\n-2.611815\n-0.311498\n0\n0\n1\n9.167825\n1\n\n\n2\n0.162715\n8.842902\n1.288770\n-3.788545\n-1.780285\n0\n0\n0\n-21.010316\n0\n\n\n3\n0.362944\n-0.959538\n1.080988\n-3.542550\n-5.419263\n1\n0\n1\n-2.194239\n0\n\n\n4\n0.612101\n1.417536\n4.143630\n-4.112453\n-4.551051\n0\n0\n1\n-20.600668\n1\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n9995\n0.340436\n0.241095\n-6.524222\n-3.188783\n-2.313515\n0\n0\n1\n16.349832\n1\n\n\n9996\n0.019523\n1.338152\n-2.555492\n-3.643733\n-5.517065\n0\n1\n1\n5.386195\n1\n\n\n9997\n0.325401\n1.258659\n-3.340546\n-4.255203\n-2.272974\n0\n0\n1\n-1.037638\n0\n\n\n9998\n0.586715\n1.263264\n-2.826709\n-4.149383\n-2.712932\n0\n0\n1\n-0.235958\n1\n\n\n9999\n0.003002\n6.723381\n1.260782\n-3.660600\n-0.962271\n0\n0\n0\n-20.007912\n1\n\n\n\n\n10000 rows √ó 10 columns\n\n\n\nTo inspect our true data generating process, we can call data_generator.dgp. Furthermore, we will have our true CATEs and ATEs at our disposal via data_generator.cates & data_generator.ates, respectively. We‚Äôll use this as our source of truth for performance evaluation of our CATE estimator.\n\nfor t, df in data_generator.dgp.items():\n    print(f\"\\nDGP for {t}:\")\n    print(df)\n\n\nDGP for T1_binary:\n{'formula': '1 + W1_continuous + W2_continuous', 'params': array([0.00323235, 0.14809798, 0.00393589]), 'noise': array([ 0.41708078,  2.72097405, -0.05882655, ...,  0.53984804,\n        1.50464572, -0.08231107]), 'raw_scores': array([0.6130131 , 0.9436502 , 0.50082704, ..., 0.6447923 , 0.83198225,\n       0.48696005]), 'function': &lt;function SyntheticDataGenerator._create_dgp_function.&lt;locals&gt;.f_binary at 0x7f359999b1c0&gt;}\n\nDGP for Y1_continuous:\n{'formula': '1 + W1_continuous + W2_continuous + X1_continuous + X2_continuous + X3_continuous + X4_binary + X5_binary + T1_binary + T1_binary*X1_continuous + T1_binary*X2_continuous + T1_binary*X3_continuous + T1_binary*X4_binary + T1_binary*X5_binary', 'params': array([-0.35986539, -3.30656481, -1.08522702, -2.03156347,  4.15748518,\n       -3.7649075 ,  2.0412171 , -4.06259065,  1.19724956, -1.49108621,\n       -0.33216768,  1.0519125 , -0.68252501,  0.57505328]), 'noise': array([ 0.19963494, -0.500903  ,  1.15056187, ..., -1.08977141,\n        0.79262583,  1.81566293]), 'raw_scores': array([-11.31940995,   9.16782505, -21.01031565, ...,  -1.03763754,\n        -0.23595847, -20.00791171]), 'function': &lt;function SyntheticDataGenerator._create_dgp_function.&lt;locals&gt;.f_cont at 0x7f355d60b910&gt;}\n\nDGP for Y2_binary:\n{'formula': '1 + W1_continuous + W2_continuous + X1_continuous + X2_continuous + X3_continuous + X4_binary + X5_binary + T1_binary + T1_binary*X1_continuous + T1_binary*X2_continuous + T1_binary*X3_continuous + T1_binary*X4_binary + T1_binary*X5_binary', 'params': array([-0.69301323,  0.54152509,  0.39837891,  0.15335688,  0.39980853,\n       -0.31388112, -0.18490127,  0.25395436,  0.19802621, -0.84703988,\n       -0.12066193,  0.09225998,  0.37205785, -0.20954318]), 'noise': array([ 1.07352996,  0.43383419, -1.01413765, ..., -1.15478882,\n        0.58572912,  0.22523345]), 'raw_scores': array([0.06237408, 0.99      , 0.75869455, ..., 0.65949716, 0.91015409,\n       0.77628529]), 'function': &lt;function SyntheticDataGenerator._create_dgp_function.&lt;locals&gt;.f_binary at 0x7f355d60b9a0&gt;}\n\n\n\ndata_generator.cates\n\n\n\n\n\n\n\n\nCATE_of_T1_binary_on_Y1_continuous\nCATE_of_T1_binary_on_Y2_binary\n\n\n\n\n0\n-4.975376\n-0.116864\n\n\n1\n11.283425\n0.779704\n\n\n2\n-1.338690\n-0.070368\n\n\n3\n-5.620992\n-0.088495\n\n\n4\n-8.402543\n-0.582547\n\n\n...\n...\n...\n\n\n9995\n9.551022\n0.857542\n\n\n9996\n0.989622\n0.391185\n\n\n9997\n5.200762\n0.679941\n\n\n9998\n3.936641\n0.602064\n\n\n9999\n-0.478977\n-0.111850\n\n\n\n\n10000 rows √ó 2 columns\n\n\n\n\ndata_generator.ates\n\n\n\n\n\n\n\n\nTreatment\nATE\n\n\n\n\n0\nT1_binary_on_Y1_continuous\n1.195965\n\n\n1\nT1_binary_on_Y2_binary\n0.152762",
    "crumbs": [
      "FastOLS"
    ]
  },
  {
    "objectID": "03_Examples/FastOLS.html#running-fastols",
    "href": "03_Examples/FastOLS.html#running-fastols",
    "title": "FastOLS",
    "section": "Running FastOLS",
    "text": "Running FastOLS\n\nClass Instantiation\nWe can instantiate and observe our FastOLS object via:\n\nfrom caml import FastOLS\n\nfo_obj = FastOLS(\n    Y=[c for c in data_generator.df.columns if \"Y\" in c],\n    T=\"T1_binary\",\n    G=[\n        c\n        for c in data_generator.df.columns\n        if \"X\" in c and (\"bin\" in c or \"dis\" in c)\n    ],\n    X=[c for c in data_generator.df.columns if \"X\" in c and \"cont\" in c],\n    W=[c for c in data_generator.df.columns if \"W\" in c],\n    xformula=\"+ W1_continuous**2\",\n    engine=\"cpu\",\n    discrete_treatment=True,\n)\n\n                    DEBUG    Initializing FastOLS with parameters: Y=['Y1_continuous', 'Y2_binary'],     ols.py:140\n                             T=T1_binary, G=['X4_binary', 'X5_binary'], X=['X1_continuous',                        \n                             'X2_continuous', 'X3_continuous'], W=['W1_continuous', 'W2_continuous'],              \n                             discrete_treatment=True, engine=cpu                                                   \n\n\n\n                    DEBUG    Created formula: Q('Y1_continuous') + Q('Y2_binary') ~ C(Q('T1_binary')) +  ols.py:174\n                             C(Q('X4_binary'))*C(Q('T1_binary')) + C(Q('X5_binary'))*C(Q('T1_binary')) +           \n                             Q('X1_continuous')*C(Q('T1_binary')) + Q('X2_continuous')*C(Q('T1_binary'))           \n                             + Q('X3_continuous')*C(Q('T1_binary')) + Q('W1_continuous') +                         \n                             Q('W2_continuous') + W1_continuous**2                                                 \n\n\n\n                    WARNING  FastOLS is experimental and may change in future versions.            decorators.py:57\n\n\n\n\nprint(fo_obj)\n\n================== FastOLS Object ==================\nEngine: cpu\nOutcome Variable: ['Y1_continuous', 'Y2_binary']\nTreatment Variable: T1_binary\nDiscrete Treatment: True\nGroup Variables: ['X4_binary', 'X5_binary']\nFeatures/Confounders for Heterogeneity (X): ['X1_continuous', 'X2_continuous', 'X3_continuous']\nFeatures/Confounders as Controls (W): ['W1_continuous', 'W2_continuous']\nFormula: Q('Y1_continuous') + Q('Y2_binary') ~ C(Q('T1_binary')) + C(Q('X4_binary'))*C(Q('T1_binary')) + C(Q('X5_binary'))*C(Q('T1_binary')) + Q('X1_continuous')*C(Q('T1_binary')) + Q('X2_continuous')*C(Q('T1_binary')) + Q('X3_continuous')*C(Q('T1_binary')) + Q('W1_continuous') + Q('W2_continuous') + W1_continuous**2\n\n\n\n\n\nFitting OLS model\nWe can now leverage the fit method to estimate the model outlined by fo_obj.formula. To capitalize on efficiency gains and parallelization in the estimation of GATEs, we will pass estimate_effects=True. The n_jobs argument will control the number of parallel jobs (GATE estimations) executed at a time. We will set n_jobs=-1 to use all available cores for parallelization.\n\n\n\n\n\n\nWarning\n\n\n\nWhen dealing with large datasets, setting n_jobs to a more conservative value can help prevent OOM errors.\n\n\nFor heteroskedasticity-robust variance estimation, we will also pass robust_vcv=True.\n\nfo_obj.fit(data_generator.df, n_jobs=-1, estimate_effects=True, cov_type=\"HC1\")\n\n                    DEBUG    Creating model design matrix...                                             ols.py:545\n\n\n\n                    DEBUG    Design Matrix Creation completed in 0.06 seconds                     decorators.py:146\n\n\n\n                    INFO     Fitting regression model...                                                 ols.py:508\n\n\n\n                    DEBUG    Model Fitting completed in 0.02 seconds                              decorators.py:146\n\n\n\n                    DEBUG    Creating treatment difference matrix...                                     ols.py:571\n\n\n\n                    DEBUG    Difference Matrix Creation completed in 0.11 seconds                 decorators.py:146\n\n\n\n                    INFO     Estimating Average Treatment Effects (ATEs)...                              ols.py:293\n\n\n\n                    DEBUG    ATE Estimation completed in 0.00 seconds                             decorators.py:146\n\n\n\n                    INFO     Estimating Group Average Treatment Effects (GATEs)...                       ols.py:667\n\n\n\n                    DEBUG    Starting parallel processing with -1 jobs                                   ols.py:695\n\n\n\n                    DEBUG    Prespecified GATE Estimation completed in 0.02 seconds               decorators.py:146\n\n\n\nWe can now inspect the model fitted results and estimated treatment effects:\n\nfo_obj.params\n# fo_obj.vcv\n# fo_obj.std_err\n# fo_obj.fitted_values\n# fo_obj.residuals\n\narray([[-0.4519221 ,  0.43114593],\n       [ 1.38073585, -0.0744549 ],\n       [ 2.00450453, -0.01259566],\n       [-4.04210602,  0.02437893],\n       [-0.65283268,  0.04810221],\n       [ 0.49183752, -0.01360602],\n       [-2.02552124,  0.02571064],\n       [-1.49027655, -0.10135024],\n       [ 4.14289136,  0.06712511],\n       [-0.28916188, -0.05434839],\n       [-3.76790351, -0.05556488],\n       [ 1.05912299,  0.03298887],\n       [-1.63464173,  0.03581225],\n       [-1.07407314,  0.04467536],\n       [-1.63464173,  0.03581225]])\n\n\n\nfo_obj.treatment_effects.keys()\n\ndict_keys(['overall', 'X4_binary-0', 'X4_binary-1', 'X5_binary-0', 'X5_binary-1'])\n\n\n\nfo_obj.treatment_effects[\"overall\"]\n\n{'outcome': ['Y1_continuous', 'Y2_binary'],\n 'ate': array([[1.19490455, 0.13807782]]),\n 'std_err': array([[0.01986595, 0.00783239]]),\n 't_stat': array([[60.14836561, 17.62907058]]),\n 'pval': array([[0., 0.]]),\n 'n': 10000,\n 'n_treated': 5172,\n 'n_control': 4828}\n\n\nHere we have direct access to the model parameters (fo_obj.params), variance-covariance matrices (fo_obj.vcv]), standard_errors (fo_obj.std_err), and estimated treatment effects (fo_obj.treatment_effects).\nTo make the treatment effect results more readable, we can leverage the prettify_treatment_effects method:\n\nfo_obj.prettify_treatment_effects()\n\n\n\n\n\n\n\n\ngroup\nmembership\noutcome\nate\nstd_err\nt_stat\npval\nn\nn_treated\nn_control\n\n\n\n\n0\noverall\nNone\nY1_continuous\n1.194905\n0.019866\n60.148366\n0.000000e+00\n10000\n5172\n4828\n\n\n1\noverall\nNone\nY2_binary\n0.138078\n0.007832\n17.629071\n0.000000e+00\n10000\n5172\n4828\n\n\n2\nX4_binary\n0\nY1_continuous\n1.336099\n0.021504\n62.133499\n0.000000e+00\n8536\n4374\n4162\n\n\n3\nX4_binary\n0\nY2_binary\n0.134263\n0.008443\n15.902456\n0.000000e+00\n8536\n4374\n4162\n\n\n4\nX4_binary\n1\nY1_continuous\n0.371658\n0.051932\n7.156565\n8.273382e-13\n1464\n798\n666\n\n\n5\nX4_binary\n1\nY2_binary\n0.160322\n0.021007\n7.631865\n2.309264e-14\n1464\n798\n666\n\n\n6\nX5_binary\n0\nY1_continuous\n1.149854\n0.021556\n53.342794\n0.000000e+00\n8564\n4430\n4134\n\n\n7\nX5_binary\n0\nY2_binary\n0.142165\n0.008438\n16.848194\n0.000000e+00\n8564\n4430\n4134\n\n\n8\nX5_binary\n1\nY1_continuous\n1.463574\n0.051157\n28.609334\n0.000000e+00\n1436\n742\n694\n\n\n9\nX5_binary\n1\nY2_binary\n0.113703\n0.020950\n5.427234\n5.723416e-08\n1436\n742\n694\n\n\n\n\n\n\n\nComparing our overall treatment effect (ATE) to the ground truth, we have:\n\ndata_generator.ates\n\n\n\n\n\n\n\n\nTreatment\nATE\n\n\n\n\n0\nT1_binary_on_Y1_continuous\n1.195965\n\n\n1\nT1_binary_on_Y2_binary\n0.152762\n\n\n\n\n\n\n\nWe can also see what our GATEs are using data_generator.cates. Let‚Äôs choose X4_binary in 1 group:\n\ndata_generator.cates.iloc[\n    data_generator.df.query(\"X4_binary == 1\").index\n].mean()\n\nCATE_of_T1_binary_on_Y1_continuous    0.347413\nCATE_of_T1_binary_on_Y2_binary        0.177773\ndtype: float64\n\n\n\n\nCustom Group Average Treatment Effects (GATEs)\nLet‚Äôs now look at how we can estimate any arbitary GATE using estimate_ate method and prettify the results with prettify_treatment_effects.\n\ncustom_gate_df = data_generator.df.query(\n    \"X4_binary == 1 & X2_continuous &lt; -3\"\n).copy()\n\ncustom_gate = fo_obj.estimate_ate(\n    custom_gate_df,\n    group=\"My Custom Group\",\n    membership=\"My Custom Membership\",\n    return_results_dict=True,\n)\nfo_obj.prettify_treatment_effects(effects=custom_gate)\n\n                    INFO     Estimating Average Treatment Effects (ATEs)...                              ols.py:293\n\n\n\n                    DEBUG    Creating treatment difference matrix...                                     ols.py:571\n\n\n\n                    DEBUG    Difference Matrix Creation completed in 0.02 seconds                 decorators.py:146\n\n\n\n                    DEBUG    ATE Estimation completed in 0.03 seconds                             decorators.py:146\n\n\n\n\n\n\n\n\n\n\ngroup\nmembership\noutcome\nate\nstd_err\nt_stat\npval\nn\nn_treated\nn_control\n\n\n\n\n0\nMy Custom Group\nMy Custom Membership\nY1_continuous\n0.541877\n0.052269\n10.367002\n0.0\n1197\n661\n536\n\n\n1\nMy Custom Group\nMy Custom Membership\nY2_binary\n0.184703\n0.021119\n8.746004\n0.0\n1197\n661\n536\n\n\n\n\n\n\n\nLet‚Äôs compare this to the ground truth as well:\n\ndata_generator.cates.iloc[custom_gate_df.index].mean()\n\nCATE_of_T1_binary_on_Y1_continuous    0.530934\nCATE_of_T1_binary_on_Y2_binary        0.198813\ndtype: float64\n\n\n\n\nConditional Average Treatment Effects (CATEs)\nLet‚Äôs now look at how we can estimate CATEs / approximate individual-level treatment effects via estimate_cate method\n\n\n\n\n\n\nNote\n\n\n\nThe predict method is a simple alias for estimate_cate. Either can be used, but namespacing was created to higlight that estimate_cate / predict can be used for out of sample treatment effect prediction.\n\n\n\ncates = fo_obj.estimate_cate(data_generator.df)\n\ncates\n\n                    INFO     Estimating Conditional Average Treatment Effects (CATEs)...                 ols.py:361\n\n\n\n                    DEBUG    Creating treatment difference matrix...                                     ols.py:571\n\n\n\n                    DEBUG    Difference Matrix Creation completed in 0.08 seconds                 decorators.py:146\n\n\n\n                    DEBUG    CATE Estimation completed in 0.08 seconds                            decorators.py:146\n\n\n\narray([[-4.96630384, -0.25905625],\n       [11.3471586 ,  0.70608504],\n       [-1.32992654, -0.05790035],\n       ...,\n       [ 5.18215613,  0.42039076],\n       [ 3.91982932,  0.34804847],\n       [-0.45883511, -0.03503195]])\n\n\nIf we wanted additional information on CATEs (such as standard errors), we can call:\n\nfo_obj.estimate_cate(data_generator.df, return_results_dict=True)\n\n                    INFO     Estimating Conditional Average Treatment Effects (CATEs)...                 ols.py:361\n\n\n\n                    DEBUG    Creating treatment difference matrix...                                     ols.py:571\n\n\n\n                    DEBUG    Difference Matrix Creation completed in 0.08 seconds                 decorators.py:146\n\n\n\n                    DEBUG    CATE Estimation completed in 0.09 seconds                            decorators.py:146\n\n\n\n{'outcome': ['Y1_continuous', 'Y2_binary'],\n 'cate': array([[-4.96630384, -0.25905625],\n        [11.3471586 ,  0.70608504],\n        [-1.32992654, -0.05790035],\n        ...,\n        [ 5.18215613,  0.42039076],\n        [ 3.91982932,  0.34804847],\n        [-0.45883511, -0.03503195]]),\n 'std_err': array([[0.02874559, 0.01134792],\n        [0.04431468, 0.01669346],\n        [0.02526043, 0.00995281],\n        ...,\n        [0.02767557, 0.01025595],\n        [0.02636869, 0.00997712],\n        [0.02779769, 0.01090012]]),\n 't_stat': array([[-172.76749964,  -22.82852289],\n        [ 256.05869601,   42.29711604],\n        [ -52.6486181 ,   -5.8174884 ],\n        ...,\n        [ 187.2465665 ,   40.98993518],\n        [ 148.6546921 ,   34.88465475],\n        [ -16.50623202,   -3.21390529]]),\n 'pval': array([[0.00000000e+00, 0.00000000e+00],\n        [0.00000000e+00, 0.00000000e+00],\n        [0.00000000e+00, 5.97384053e-09],\n        ...,\n        [0.00000000e+00, 0.00000000e+00],\n        [0.00000000e+00, 0.00000000e+00],\n        [0.00000000e+00, 1.30942855e-03]])}\n\n\nNow, let‚Äôs make our cate predictions:\n\ncate_predictions = fo_obj.predict(data_generator.df)\n\n## We can also make predictions of the outcomes, if desired.\n# fo_obj.predict(data_generator.df, mode=\"outcome\")\n\n                    INFO     Estimating Conditional Average Treatment Effects (CATEs)...                 ols.py:361\n\n\n\n                    DEBUG    Creating treatment difference matrix...                                     ols.py:571\n\n\n\n                    DEBUG    Difference Matrix Creation completed in 0.08 seconds                 decorators.py:146\n\n\n\n                    DEBUG    CATE Estimation completed in 0.08 seconds                            decorators.py:146\n\n\n\nLet‚Äôs now look at the Precision in Estimating Heterogeneous Effects (PEHE) (e.g., RMSE) and plot some results for the treatment effects on each outcome:\n\nEffect of binary T1 on continuous Y1\n\nfrom sklearn.metrics import root_mean_squared_error\nfrom caml.extensions.plots import (\n    cate_true_vs_estimated_plot,\n    cate_histogram_plot,\n    cate_line_plot,\n)\n\n\ntrue_cates1 = data_generator.cates.iloc[:, 0]\npredicted_cates1 = cate_predictions[:, 0]\nroot_mean_squared_error(true_cates1, predicted_cates1)\n\n0.05419754264094474\n\n\n\ncate_true_vs_estimated_plot(\n    true_cates=true_cates1, estimated_cates=predicted_cates1\n)\n\n\n\n\n\n\n\n\n\ncate_histogram_plot(true_cates=true_cates1, estimated_cates=predicted_cates1)\n\n\n\n\n\n\n\n\n\ncate_line_plot(\n    true_cates=true_cates1, estimated_cates=predicted_cates1, window=20\n)\n\n\n\n\n\n\n\n\n\n\nEffect of binary T1 on binary Y2\n\ntrue_cates2 = data_generator.cates.iloc[:, 1]\npredicted_cates2 = cate_predictions[:, 1]\nroot_mean_squared_error(true_cates2, predicted_cates2)\n\n0.15683038625127846\n\n\n\ncate_true_vs_estimated_plot(\n    true_cates=true_cates2, estimated_cates=predicted_cates2\n)\n\n\n\n\n\n\n\n\n\ncate_histogram_plot(true_cates=true_cates2, estimated_cates=predicted_cates2)\n\n\n\n\n\n\n\n\n\ncate_line_plot(\n    true_cates=true_cates2, estimated_cates=predicted_cates2, window=20\n)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nThe CATE estimates for binary outcome using simulated data may perform poorly b/c of non-linear transformation (sigmoid) of linear logodds. In general, FastOLS should be prioritized when ATEs and GATEs are of primary interest. For high quality CATE estimation, we recommend leveraging AutoCATE.",
    "crumbs": [
      "FastOLS"
    ]
  },
  {
    "objectID": "02_Concepts/theory.html",
    "href": "02_Concepts/theory.html",
    "title": "Econometric Theory",
    "section": "",
    "text": "Forthcoming\n\n\n\n Back to top",
    "crumbs": [
      "Econometric Theory"
    ]
  },
  {
    "objectID": "02_Concepts/models.html",
    "href": "02_Concepts/models.html",
    "title": "Model Specifications",
    "section": "",
    "text": "The model is given by: \\[\n\\begin{equation}\n\\mathbf{Y} = T \\beta + \\mathbf{Q}\\mathbf{\\Gamma} + \\left(T \\circ \\mathbf{Q}\\right)\\mathbf{\\Omega} + \\mathbf{W}\\mathbf{\\Psi} + \\mathbf{E}\n\\tag{1}\n\\end{equation}\n\\]\nwhere\n\n\\(\\mathbf{Y}_{n \\times p}\\) is the matrix of \\(p\\) outcomes\n\\(T_{n \\times 1}\\) is the treatment variable\n\\(\\mathbf{Q}_{n \\times (j+l)} = \\bigl[\\mathbf{X} \\; \\mathbf{G} \\bigr]\\) is the horizontal stack matrix of \\(j\\) covariates and \\(l\\) group variables\n\\(\\mathbf{W}_{n \\times m}\\) is the matrix of \\(m\\) control covariates\n\\(\\beta_{1 \\times p}\\) is the vector of coefficients on \\(T\\)\n\\(\\mathbf{\\Gamma}_{(j+l) \\times p}\\) is the matrix of coefficients on \\(\\mathbf{Q}\\)\n\\(\\mathbf{\\Omega}_{(j+l) \\times p}\\) is the matrix of coefficients on the interaction terms between \\(T\\) and \\(\\mathbf{Q}\\)\n\\(\\mathbf{\\Psi}_{m \\times p}\\) is the matrix of coefficients on \\(\\mathbf{W}\\)\n\\(\\mathbf{E}_{n \\times p}\\) is the error term matrix\n\n\\(\\mathbf{Q}\\) contains the covariates and group variables used to model treatment effect heterogeneity via interaction terms.\n\n\n\nOur average treatment effects (ATE) \\(\\tau\\) for a binary treatment variable \\(T\\) is defined as:\n\\[\n\\tau = \\mathbb{E}_n[\\mathbf{Y}_1 - \\mathbf{Y}_0]\n\\]\nwhere \\(\\mathbf{Y}_1\\) and \\(\\mathbf{Y}_0\\) are the potential outcomes. Assuming exogeneity in \\(T\\), the ATEs are identified and can be estimated as follows:\n\\[\n\\tau = \\mathbb{E}_n\\left[\\mathbb{E}\\left[\\mathbf{Y} \\mid T = 1\\right] - \\mathbb{E}\\left[\\mathbf{Y} \\mid T = 0\\right]\\right]\n\\]\nWithin the context of (1), this can be estimated via:\n\\[\n\\mathbf{\\tau} = \\mathbf{\\Theta'}\\bar{d}\n\\]\nwhere \\(\\mathbf{\\Theta'} = \\left[\\beta' \\; \\mathbf{\\Gamma'} \\; \\mathbf{\\Omega'} \\; \\mathbf{\\Psi'}\\right]\\) is the horizontally concatenated matrix of transposed coefficient matrices, and \\(\\bar{d} = \\mathbb{E}_n\\left[D_{T=1} - D_{T=0}\\right]\\) is the the average difference in the design matrix \\(D\\) of (1) from toggling the treatment variable across all observations.\nFurthermore, for each outcome \\(k \\in \\{1,2,...,p\\}\\), we can estimate the standard error of the ATE as follows: \\[\n\\text{SE}(\\tau_k) = \\sqrt{\\bar{d}'\\text{VCV}(\\mathbf{\\Theta}_k)\\bar{d}}\n\\]\nwhere \\(\\text{VCV}(\\mathbf{\\Theta}_k)\\) is the variance-covariance matrix of the estimated coefficients for the \\(k\\)-th outcome.\nThis logic extends naturally to the estimation of GATEs and CATEs (e.g., \\(\\bar{d} = \\mathbb{E}_n\\left[D_{T=1} - D_{T=0} | \\mathbf{G}=g\\right]\\), \\(\\bar{d} = \\mathbb{E}_n\\left[D_{T=1} - D_{T=0} | \\mathbf{G}=g, \\mathbf{X}=x\\right]\\), \\(\\dots\\), etc.) and to continuous treatments (e.g., \\(\\bar{d} = \\mathbb{E}_n\\left[D_{T=t+1} - D_{T=t}\\right]\\), \\(\\dots\\), etc.).",
    "crumbs": [
      "Model Specifications"
    ]
  },
  {
    "objectID": "02_Concepts/models.html#fastols",
    "href": "02_Concepts/models.html#fastols",
    "title": "Model Specifications",
    "section": "",
    "text": "The model is given by: \\[\n\\begin{equation}\n\\mathbf{Y} = T \\beta + \\mathbf{Q}\\mathbf{\\Gamma} + \\left(T \\circ \\mathbf{Q}\\right)\\mathbf{\\Omega} + \\mathbf{W}\\mathbf{\\Psi} + \\mathbf{E}\n\\tag{1}\n\\end{equation}\n\\]\nwhere\n\n\\(\\mathbf{Y}_{n \\times p}\\) is the matrix of \\(p\\) outcomes\n\\(T_{n \\times 1}\\) is the treatment variable\n\\(\\mathbf{Q}_{n \\times (j+l)} = \\bigl[\\mathbf{X} \\; \\mathbf{G} \\bigr]\\) is the horizontal stack matrix of \\(j\\) covariates and \\(l\\) group variables\n\\(\\mathbf{W}_{n \\times m}\\) is the matrix of \\(m\\) control covariates\n\\(\\beta_{1 \\times p}\\) is the vector of coefficients on \\(T\\)\n\\(\\mathbf{\\Gamma}_{(j+l) \\times p}\\) is the matrix of coefficients on \\(\\mathbf{Q}\\)\n\\(\\mathbf{\\Omega}_{(j+l) \\times p}\\) is the matrix of coefficients on the interaction terms between \\(T\\) and \\(\\mathbf{Q}\\)\n\\(\\mathbf{\\Psi}_{m \\times p}\\) is the matrix of coefficients on \\(\\mathbf{W}\\)\n\\(\\mathbf{E}_{n \\times p}\\) is the error term matrix\n\n\\(\\mathbf{Q}\\) contains the covariates and group variables used to model treatment effect heterogeneity via interaction terms.\n\n\n\nOur average treatment effects (ATE) \\(\\tau\\) for a binary treatment variable \\(T\\) is defined as:\n\\[\n\\tau = \\mathbb{E}_n[\\mathbf{Y}_1 - \\mathbf{Y}_0]\n\\]\nwhere \\(\\mathbf{Y}_1\\) and \\(\\mathbf{Y}_0\\) are the potential outcomes. Assuming exogeneity in \\(T\\), the ATEs are identified and can be estimated as follows:\n\\[\n\\tau = \\mathbb{E}_n\\left[\\mathbb{E}\\left[\\mathbf{Y} \\mid T = 1\\right] - \\mathbb{E}\\left[\\mathbf{Y} \\mid T = 0\\right]\\right]\n\\]\nWithin the context of (1), this can be estimated via:\n\\[\n\\mathbf{\\tau} = \\mathbf{\\Theta'}\\bar{d}\n\\]\nwhere \\(\\mathbf{\\Theta'} = \\left[\\beta' \\; \\mathbf{\\Gamma'} \\; \\mathbf{\\Omega'} \\; \\mathbf{\\Psi'}\\right]\\) is the horizontally concatenated matrix of transposed coefficient matrices, and \\(\\bar{d} = \\mathbb{E}_n\\left[D_{T=1} - D_{T=0}\\right]\\) is the the average difference in the design matrix \\(D\\) of (1) from toggling the treatment variable across all observations.\nFurthermore, for each outcome \\(k \\in \\{1,2,...,p\\}\\), we can estimate the standard error of the ATE as follows: \\[\n\\text{SE}(\\tau_k) = \\sqrt{\\bar{d}'\\text{VCV}(\\mathbf{\\Theta}_k)\\bar{d}}\n\\]\nwhere \\(\\text{VCV}(\\mathbf{\\Theta}_k)\\) is the variance-covariance matrix of the estimated coefficients for the \\(k\\)-th outcome.\nThis logic extends naturally to the estimation of GATEs and CATEs (e.g., \\(\\bar{d} = \\mathbb{E}_n\\left[D_{T=1} - D_{T=0} | \\mathbf{G}=g\\right]\\), \\(\\bar{d} = \\mathbb{E}_n\\left[D_{T=1} - D_{T=0} | \\mathbf{G}=g, \\mathbf{X}=x\\right]\\), \\(\\dots\\), etc.) and to continuous treatments (e.g., \\(\\bar{d} = \\mathbb{E}_n\\left[D_{T=t+1} - D_{T=t}\\right]\\), \\(\\dots\\), etc.).",
    "crumbs": [
      "Model Specifications"
    ]
  },
  {
    "objectID": "02_Concepts/motivation.html",
    "href": "02_Concepts/motivation.html",
    "title": "Motivation",
    "section": "",
    "text": "Forthcoming\n\n\n\n Back to top",
    "crumbs": [
      "Motivation"
    ]
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "CaML - Causal ML",
    "section": "",
    "text": "Causal Machine Learning",
    "crumbs": [
      "Welcome!"
    ]
  },
  {
    "objectID": "index.html#welcome",
    "href": "index.html#welcome",
    "title": "CaML - Causal ML",
    "section": "Welcome!",
    "text": "Welcome!\nCaML provides a high-level API for an opinionated framework in performing Causal ML to estimate Average Treatment Effects (ATEs), Group Average Treatment Effects (GATEs), and Conditional Average Treatment Effects (CATEs), and to provide mechanisms to utilize these models for out of sample validation, prediction, & policy prescription.\nThe codebase is comprised primarily of extensions & abstractions over top of EconML & DoubleML with techniques motivated heavily by Causal ML Book and additional research.",
    "crumbs": [
      "Welcome!"
    ]
  },
  {
    "objectID": "index.html#background",
    "href": "index.html#background",
    "title": "CaML - Causal ML",
    "section": "Background",
    "text": "Background\nThe origins of CaML are rooted in a desire to develop a set of helper tools to abstract and streamline techniques & best pratices in Causal ML/Econometrics for estimating ATEs, GATEs, and CATEs, along with policy prescription. In addition, we seek to provide a framework for validating & scoring these models on out of sample data to help set the foundations for an AutoML framework for CATE models.\nAs we began working on these helper tools, we begun to see the value in reformulating this framework into a reusable package for wider use amongst the community and to provide an opinionated framework that can be integrated into productionalized systems, particularly experimentation platforms, for efficient estimation of causal parameters for reporting & decision-making purposes.\nAll of the standard assumptions for causal inference still apply in order for these tools & techniques to provide unbiased inference. A great resource for the CausalML landscape is the CausalML book written and publicly available generously by V. Chernozhukov, C. Hansen, N. Kallus, M. Spindler, & V. Syrgkanis.\nGiven a key motivation is to provide a tool for productionalized systems, we are building this package with interoperability and extensibility as core values. As of now, the tools utilized still rely on in-memory datasets for estimation (via EconML for causal models & flaml for AutoML of nuissance functions), but we leverage Ray & Spark for distributing certain processes where appropriate and if available for the user.",
    "crumbs": [
      "Welcome!"
    ]
  },
  {
    "objectID": "03_Examples/SyntheticDataGenerator.html",
    "href": "03_Examples/SyntheticDataGenerator.html",
    "title": "Caml Synthetic Data Generator",
    "section": "",
    "text": "from caml.extensions.synthetic_data import SyntheticDataGenerator\nimport numpy as np",
    "crumbs": [
      "Caml Synthetic Data Generator"
    ]
  },
  {
    "objectID": "03_Examples/SyntheticDataGenerator.html#generate-data",
    "href": "03_Examples/SyntheticDataGenerator.html#generate-data",
    "title": "Caml Synthetic Data Generator",
    "section": "Generate Data",
    "text": "Generate Data\n\ndata_generator = SyntheticDataGenerator(\n    n_obs=10_000,\n    n_cont_outcomes=1,\n    n_binary_outcomes=1,\n    n_cont_treatments=1,\n    n_binary_treatments=1,\n    n_discrete_treatments=1,\n    n_cont_confounders=1,\n    n_binary_confounders=1,\n    n_discrete_confounders=1,\n    n_cont_modifiers=1,\n    n_binary_modifiers=1,\n    n_discrete_modifiers=1,\n    n_confounding_modifiers=1,\n    stddev_outcome_noise=3,\n    stddev_treatment_noise=3,\n    causal_model_functional_form=\"linear\",\n    n_nonlinear_transformations=5,\n    seed=10,\n)",
    "crumbs": [
      "Caml Synthetic Data Generator"
    ]
  },
  {
    "objectID": "03_Examples/SyntheticDataGenerator.html#simulated-dataframe",
    "href": "03_Examples/SyntheticDataGenerator.html#simulated-dataframe",
    "title": "Caml Synthetic Data Generator",
    "section": "Simulated Dataframe",
    "text": "Simulated Dataframe\n\ndata_generator.df\n\n\n\n\n\n\n\n\nW1_continuous\nW2_binary\nW3_discrete\nX1_continuous\nX2_binary\nX3_discrete\nT1_continuous\nT2_binary\nT3_discrete\nY1_continuous\nY2_binary\n\n\n\n\n0\n0.354380\n0\n1\n0.432254\n0\n1\n-3.726761\n0\n0\n-20.927146\n0\n\n\n1\n0.568499\n1\n0\n0.812796\n0\n1\n-3.438992\n1\n4\n-9.747703\n0\n\n\n2\n0.162715\n1\n1\n0.874920\n1\n0\n-2.806232\n0\n0\n-17.370004\n1\n\n\n3\n0.362944\n0\n0\n0.411990\n1\n3\n-0.950123\n1\n2\n-2.274883\n0\n\n\n4\n0.612101\n1\n0\n0.444356\n1\n0\n-2.888419\n1\n4\n-0.420176\n0\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n9995\n0.340436\n0\n1\n0.657928\n1\n0\n3.182961\n1\n2\n8.651162\n0\n\n\n9996\n0.019523\n1\n0\n0.672171\n1\n1\n-0.384001\n1\n1\n3.081509\n0\n\n\n9997\n0.325401\n1\n0\n0.407528\n1\n3\n-7.291501\n0\n0\n-105.683437\n1\n\n\n9998\n0.586715\n1\n0\n0.542052\n1\n0\n-4.196167\n0\n4\n0.847574\n0\n\n\n9999\n0.003002\n1\n1\n0.261432\n1\n4\n5.563359\n0\n4\n113.301968\n0\n\n\n\n\n10000 rows √ó 11 columns",
    "crumbs": [
      "Caml Synthetic Data Generator"
    ]
  },
  {
    "objectID": "03_Examples/SyntheticDataGenerator.html#true-conditional-average-treatment-effects-cates",
    "href": "03_Examples/SyntheticDataGenerator.html#true-conditional-average-treatment-effects-cates",
    "title": "Caml Synthetic Data Generator",
    "section": "True Conditional Average Treatment Effects (CATEs)",
    "text": "True Conditional Average Treatment Effects (CATEs)\n\ndata_generator.cates\n\n\n\n\n\n\n\n\nCATE_of_T1_continuous_on_Y1_continuous\nCATE_of_T2_binary_on_Y1_continuous\nCATE_of_T3_discrete_on_Y1_continuous_level_4_v_0\nCATE_of_T3_discrete_on_Y1_continuous_level_2_v_0\nCATE_of_T3_discrete_on_Y1_continuous_level_1_v_0\nCATE_of_T3_discrete_on_Y1_continuous_level_3_v_0\nCATE_of_T1_continuous_on_Y2_binary\nCATE_of_T2_binary_on_Y2_binary\nCATE_of_T3_discrete_on_Y2_binary_level_4_v_0\nCATE_of_T3_discrete_on_Y2_binary_level_2_v_0\nCATE_of_T3_discrete_on_Y2_binary_level_1_v_0\nCATE_of_T3_discrete_on_Y2_binary_level_3_v_0\n\n\n\n\n0\n6.431287\n2.115750\n5.518583\n2.759291\n1.379646\n4.138937\n-0.022789\n0.023626\n-0.722338\n-0.512221\n-0.256669\n-0.661029\n\n\n1\n7.137688\n3.047866\n7.489986\n3.744993\n1.872497\n5.617490\n-0.004433\n0.009044\n-0.814747\n-0.547820\n-0.241318\n-0.740738\n\n\n2\n3.589688\n0.170688\n14.223319\n7.111660\n3.555830\n10.667489\n-0.033585\n-0.059832\n-0.829362\n-0.328208\n-0.100727\n-0.627206\n\n\n3\n14.923903\n5.855224\n7.506872\n3.753436\n1.876718\n5.630154\n0.000000\n0.000000\n-0.687002\n-0.687002\n-0.603805\n-0.687002\n\n\n4\n2.790430\n-0.883957\n11.992772\n5.996386\n2.998193\n8.994579\n-0.020381\n-0.090014\n-0.744867\n-0.480709\n-0.223118\n-0.659681\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n9995\n3.186885\n-0.360823\n13.099186\n6.549593\n3.274797\n9.824390\n-0.005274\n-0.024819\n-0.124580\n-0.119305\n-0.087765\n-0.124580\n\n\n9996\n7.277843\n1.946885\n11.733566\n5.866783\n2.933392\n8.800175\n-0.055789\n-0.091764\n-0.660311\n-0.621732\n-0.426627\n-0.660311\n\n\n9997\n14.915621\n5.844295\n7.483759\n3.741879\n1.870940\n5.612819\n0.029784\n0.113995\n-0.516854\n-0.516854\n-0.479383\n-0.516854\n\n\n9998\n2.971783\n-0.644656\n12.498887\n6.249444\n3.124722\n9.374165\n-0.080096\n-0.134494\n-0.733551\n-0.231604\n-0.070256\n-0.489847\n\n\n9999\n18.708941\n7.759261\n5.287498\n2.643749\n1.321874\n3.965623\n0.000000\n0.000000\n-0.954142\n-0.948999\n-0.572786\n-0.954142\n\n\n\n\n10000 rows √ó 12 columns",
    "crumbs": [
      "Caml Synthetic Data Generator"
    ]
  },
  {
    "objectID": "03_Examples/SyntheticDataGenerator.html#true-average-treatment-effects-ates",
    "href": "03_Examples/SyntheticDataGenerator.html#true-average-treatment-effects-ates",
    "title": "Caml Synthetic Data Generator",
    "section": "True Average Treatment Effects (ATEs)",
    "text": "True Average Treatment Effects (ATEs)\n\ndata_generator.ates\n\n\n\n\n\n\n\n\nTreatment\nATE\n\n\n\n\n0\nT1_continuous_on_Y1_continuous\n8.832689\n\n\n1\nT2_binary_on_Y1_continuous\n2.723753\n\n\n2\nT3_discrete_on_Y1_continuous_level_4_v_0\n9.625175\n\n\n3\nT3_discrete_on_Y1_continuous_level_2_v_0\n4.812588\n\n\n4\nT3_discrete_on_Y1_continuous_level_1_v_0\n2.406294\n\n\n5\nT3_discrete_on_Y1_continuous_level_3_v_0\n7.218881\n\n\n6\nT1_continuous_on_Y2_binary\n-0.023382\n\n\n7\nT2_binary_on_Y2_binary\n-0.032929\n\n\n8\nT3_discrete_on_Y2_binary_level_4_v_0\n-0.683641\n\n\n9\nT3_discrete_on_Y2_binary_level_2_v_0\n-0.571733\n\n\n10\nT3_discrete_on_Y2_binary_level_1_v_0\n-0.376043\n\n\n11\nT3_discrete_on_Y2_binary_level_3_v_0\n-0.650020",
    "crumbs": [
      "Caml Synthetic Data Generator"
    ]
  },
  {
    "objectID": "03_Examples/SyntheticDataGenerator.html#true-data-generating-process",
    "href": "03_Examples/SyntheticDataGenerator.html#true-data-generating-process",
    "title": "Caml Synthetic Data Generator",
    "section": "True Data Generating Process",
    "text": "True Data Generating Process\n\nfor k, v in data_generator.dgp.items():\n    print(f\"DGP for {k}:\")\n    print(v)\n\nDGP for T1_continuous:\n{'formula': '1 + W1_continuous + W2_binary + W3_discrete + X1_continuous', 'params': array([ 0.06058085,  1.16021218, -1.96203513,  0.36371696, -2.17056973]), 'noise': array([-3.62397606, -0.4328875 ,  0.44179631, ..., -4.88301257,\n       -1.79886609,  7.66507059]), 'raw_scores': array([-3.72676077, -3.43899217, -2.80623211, ..., -7.29150054,\n       -4.19616712,  5.56335924]), 'function': &lt;function SyntheticDataGenerator._create_dgp_function.&lt;locals&gt;.f_cont at 0x7f2894ea79a0&gt;}\nDGP for T2_binary:\n{'formula': '1 + W1_continuous + W2_binary + W3_discrete + X1_continuous', 'params': array([ 0.40298227,  0.46731892, -0.04221048, -1.01745299,  0.75777365]), 'noise': array([ 0.61588584,  3.23845316, -4.20232967, ..., -5.30465767,\n       -4.77383245, -3.11883147]), 'raw_scores': array([0.62118342, 0.98880257, 0.01598516, ..., 0.01117315, 0.0234736 ,\n       0.02722537]), 'function': &lt;function SyntheticDataGenerator._create_dgp_function.&lt;locals&gt;.f_binary at 0x7f2894ea7910&gt;}\nDGP for T3_discrete:\n{'formula': '1 + W1_continuous + W2_binary + W3_discrete + X1_continuous', 'params': array([[ 0.28408456, -0.41400534,  0.89869683, -0.21225787, -0.51305644],\n       [-0.19632837,  0.02928109, -0.76527952, -1.08498952, -0.10759088],\n       [ 0.47243684,  0.23156474, -0.05579596,  0.57863612,  0.2423976 ],\n       [-0.388172  , -0.10787099, -0.09372564,  0.11089256, -0.00356159],\n       [-0.57508702,  0.26987442,  0.26917321,  0.07404752,  0.54707381]]), 'noise': array([[-5.62802687, -1.71188738, -1.6500188 , -0.21256387, -2.52126791],\n       [-1.93444462,  1.17883094, -3.22882543,  5.68613081, -3.1945138 ],\n       [ 3.71485923, -2.99880648,  5.32356089,  1.85843325,  5.28230021],\n       ...,\n       [-0.31659162,  7.97101022, -0.80878524, -2.60107951, -1.99808469],\n       [-2.55599124,  2.33060302, -1.21559451,  1.39676363, -1.08090999],\n       [-0.93239336,  1.08707538,  3.1621623 , -3.38126668, -1.0282605 ]]), 'raw_scores': array([[0.2, 0.2, 0.2, 0.2, 0.2],\n       [0.2, 0.2, 0.2, 0.2, 0.2],\n       [0.2, 0.2, 0.2, 0.2, 0.2],\n       ...,\n       [0.2, 0.2, 0.2, 0.2, 0.2],\n       [0.2, 0.2, 0.2, 0.2, 0.2],\n       [0.2, 0.2, 0.2, 0.2, 0.2]]), 'function': &lt;function SyntheticDataGenerator._create_dgp_function.&lt;locals&gt;.f_discrete at 0x7f2854fd1360&gt;}\nDGP for Y1_continuous:\n{'formula': '1 + W1_continuous + W2_binary + W3_discrete + X1_continuous + X2_binary + X3_discrete + T1_continuous + T2_binary + T3_discrete + T1_continuous*X1_continuous + T1_continuous*X2_binary + T1_continuous*X3_discrete + T2_binary*X1_continuous + T2_binary*X2_binary + T2_binary*X3_discrete + T3_discrete*X1_continuous + T3_discrete*X2_binary + T3_discrete*X3_discrete', 'params': array([-1.24245918, -2.15840213,  1.21168055,  1.88903987, -1.66394546,\n       -2.8238776 ,  2.19040025,  1.56437294, -1.2158549 ,  1.1796722 ,\n        1.85630525,  0.40119701,  4.06451821,  2.44944857, -0.75652854,\n        2.2728199 ,  1.29513067,  1.243022  , -0.35985222]), 'noise': array([ 1.68788239,  4.68077263, -4.52386602, ...,  0.73772796,\n        5.84175262, -3.42458613]), 'raw_scores': array([ -20.92714575,   -9.74770328,  -17.37000412, ..., -105.68343735,\n          0.84757356,  113.30196785]), 'function': &lt;function SyntheticDataGenerator._create_dgp_function.&lt;locals&gt;.f_cont at 0x7f2854fd1510&gt;}\nDGP for Y2_binary:\n{'formula': '1 + W1_continuous + W2_binary + W3_discrete + X1_continuous + X2_binary + X3_discrete + T1_continuous + T2_binary + T3_discrete + T1_continuous*X1_continuous + T1_continuous*X2_binary + T1_continuous*X3_discrete + T2_binary*X1_continuous + T2_binary*X2_binary + T2_binary*X3_discrete + T3_discrete*X1_continuous + T3_discrete*X2_binary + T3_discrete*X3_discrete', 'params': array([ 3.10830726e-01, -8.76756219e-02,  5.06943774e-01,  3.63265570e-01,\n        8.10885598e-02,  1.61061427e-01, -2.64294557e-04, -2.93078750e-01,\n       -6.41686816e-01, -2.78041378e-01, -9.20270247e-02, -1.89629801e-01,\n        2.13406730e-01,  5.55264734e-01, -7.14195311e-01,  5.33709717e-01,\n       -3.91935251e-01, -6.16656576e-01, -6.84033929e-01]), 'noise': array([-2.0490385 ,  0.51909257,  0.81681174, ...,  5.05902104,\n       -2.13548014, -1.22267512]), 'raw_scores': array([0.28372465, 0.05238531, 0.97803581, ..., 0.99      , 0.03363826,\n       0.01      ]), 'function': &lt;function SyntheticDataGenerator._create_dgp_function.&lt;locals&gt;.f_binary at 0x7f2854fd1630&gt;}\n\n\nWe can recreate the raw scores of our treatment and outcome variables too:\n\n# Recreate Y1_continuous\ndf = data_generator.df\ndgp = data_generator.dgp[\"Y1_continuous\"]\n\ndesign_matrix = data_generator.create_design_matrix(df, formula=dgp[\"formula\"])\n\nparams = dgp[\"params\"]\nnoise = dgp[\"noise\"]\nf = dgp[\"function\"]\n\nraw_scores = f(design_matrix, params, noise)\n\nassert np.allclose(raw_scores, df[\"Y1_continuous\"])\nassert np.allclose(raw_scores, dgp[\"raw_scores\"])\n\nraw_scores\n\n0       -20.927146\n1        -9.747703\n2       -17.370004\n3        -2.274883\n4        -0.420176\n           ...    \n9995      8.651162\n9996      3.081509\n9997   -105.683437\n9998      0.847574\n9999    113.301968\nLength: 10000, dtype: float64\n\n\nFor treatment variables, we get back the probabilities:\n\n# Recreate Y2_binary\ndgp_bin = data_generator.dgp[\"Y2_binary\"]\n\ndesign_matrix_bin = data_generator.create_design_matrix(df, formula=dgp_bin[\"formula\"])\n\nparams_bin = dgp_bin[\"params\"]\nnoise_bin = dgp_bin[\"noise\"]\nf_bin = dgp_bin[\"function\"]\n\nraw_scores_bin = f_bin(design_matrix_bin, params_bin, noise_bin)\n\nassert np.allclose(raw_scores_bin, dgp_bin[\"raw_scores\"])\n\nraw_scores_bin\n\n0       0.283725\n1       0.052385\n2       0.978036\n3       0.010000\n4       0.115042\n          ...   \n9995    0.609972\n9996    0.010000\n9997    0.990000\n9998    0.033638\n9999    0.010000\nLength: 10000, dtype: float64",
    "crumbs": [
      "Caml Synthetic Data Generator"
    ]
  },
  {
    "objectID": "04_Reference/cate_line_plot.html",
    "href": "04_Reference/cate_line_plot.html",
    "title": "cate_line_plot",
    "section": "",
    "text": "cate_line_plot(\n    estimated_cates,\n    *,\n    true_cates=None,\n    standard_errors=None,\n    alpha=0.05,\n    window=30,\n    figure_kwargs={},\n    line_kwargs={},\n)\nPlots a line plot of the ordered estimated CATEs as a rolling mean with optional confidence intervals."
  },
  {
    "objectID": "04_Reference/cate_line_plot.html#parameters",
    "href": "04_Reference/cate_line_plot.html#parameters",
    "title": "cate_line_plot",
    "section": "Parameters",
    "text": "Parameters\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nestimated_cates\nnp.ndarray\nThe estimated CATEs.\nrequired\n\n\ntrue_cates\nnp.ndarray | None\nThe true CATEs.\nNone\n\n\nstandard_errors\nnp.ndarray | None\nThe standard errors of the estimated CATEs.\nNone\n\n\nalpha\nfloat\nThe alpha level for the confidence intervals. The default is 0.05, which corresponds to 95% confidence intervals.\n0.05\n\n\nwindow\nint\nThe window size for the moving average.\n30\n\n\nfigure_kwargs\ndict\nMatplotlib figure arguments.\n{}\n\n\nline_kwargs\ndict\nMatplotlib line arguments.\n{}"
  },
  {
    "objectID": "04_Reference/cate_line_plot.html#returns",
    "href": "04_Reference/cate_line_plot.html#returns",
    "title": "cate_line_plot",
    "section": "Returns",
    "text": "Returns\n\n\n\nName\nType\nDescription\n\n\n\n\n\nmatplotlib.pyplot.Figure\nThe line plot figure object."
  },
  {
    "objectID": "04_Reference/cate_line_plot.html#examples",
    "href": "04_Reference/cate_line_plot.html#examples",
    "title": "cate_line_plot",
    "section": "Examples",
    "text": "Examples\n\nimport numpy as np\nfrom caml.extensions.plots import cate_line_plot\n\nnp.random.seed(42)\ntrue_cates = np.random.normal(0, 1, 100)\nestimated_cates = true_cates + np.random.normal(0, 0.5, 100)\nstandard_errors = np.abs(np.random.normal(0, 0.1, 100))\n\nfig = cate_line_plot(estimated_cates, true_cates=true_cates, standard_errors=standard_errors, window=5)\nfig"
  },
  {
    "objectID": "04_Reference/index.html",
    "href": "04_Reference/index.html",
    "title": "API Reference",
    "section": "",
    "text": "from caml import *   Core functionality of CaML for estimating causal effects with cross-sectional data.\n\n\n\nAutoCATE\nThe AutoCATE class is a high-level API facilitating an AutoML framework for CATE estimation, built on top of the EconML library.\n\n\nFastOLS\nFastOLS is an optimized implementation of the OLS estimator designed specifically with treatment effect estimation in mind.\n\n\n\n\n\n\nfrom caml.extensions.synthetic_data import *   Synthetic data generation utilities for CaML.\n\n\n\nSyntheticDataGenerator\nGenerate highly flexible synthetic data for use in causal inference and CaML testing.\n\n\nmake_partially_linear_dataset_simple\nSimulate data generating process from a partially linear model with a simple 1 or 2 dimensional CATE function.\n\n\nmake_partially_linear_dataset_constant\nSimulate a data generating process from a partially linear model with a constant treatment effect (ATE only).\n\n\nmake_fully_heterogeneous_dataset\nSimulate data generating process from an interactive regression model with fully heterogenous treatment effects.\n\n\n\n\n\n\nfrom caml.extensions.plots import *   Plotting utilities for CaML.\n\n\n\ncate_histogram_plot\nPlots a histogram the estimated CATEs.\n\n\ncate_line_plot\nPlots a line plot of the ordered estimated CATEs as a rolling mean with optional confidence intervals.\n\n\ncate_true_vs_estimated_plot\nPlots a scatter plot of the estimated CATEs against the true CATEs.\n\n\n\n\n\n\nDeveloper tools and utilities for CaML.\n\n\n\ndecorators\nDecorator utilities for CaML.\n\n\ninterfaces\nInterface utilities for CaML.\n\n\nutils\nVarious Utilities for CaML.\n\n\nlogging\nLogging utilities for CaML.",
    "crumbs": [
      "API Reference"
    ]
  },
  {
    "objectID": "04_Reference/index.html#caml-core",
    "href": "04_Reference/index.html#caml-core",
    "title": "API Reference",
    "section": "",
    "text": "from caml import *   Core functionality of CaML for estimating causal effects with cross-sectional data.\n\n\n\nAutoCATE\nThe AutoCATE class is a high-level API facilitating an AutoML framework for CATE estimation, built on top of the EconML library.\n\n\nFastOLS\nFastOLS is an optimized implementation of the OLS estimator designed specifically with treatment effect estimation in mind.",
    "crumbs": [
      "API Reference"
    ]
  },
  {
    "objectID": "04_Reference/index.html#synthetic-data-generation",
    "href": "04_Reference/index.html#synthetic-data-generation",
    "title": "API Reference",
    "section": "",
    "text": "from caml.extensions.synthetic_data import *   Synthetic data generation utilities for CaML.\n\n\n\nSyntheticDataGenerator\nGenerate highly flexible synthetic data for use in causal inference and CaML testing.\n\n\nmake_partially_linear_dataset_simple\nSimulate data generating process from a partially linear model with a simple 1 or 2 dimensional CATE function.\n\n\nmake_partially_linear_dataset_constant\nSimulate a data generating process from a partially linear model with a constant treatment effect (ATE only).\n\n\nmake_fully_heterogeneous_dataset\nSimulate data generating process from an interactive regression model with fully heterogenous treatment effects.",
    "crumbs": [
      "API Reference"
    ]
  },
  {
    "objectID": "04_Reference/index.html#plots",
    "href": "04_Reference/index.html#plots",
    "title": "API Reference",
    "section": "",
    "text": "from caml.extensions.plots import *   Plotting utilities for CaML.\n\n\n\ncate_histogram_plot\nPlots a histogram the estimated CATEs.\n\n\ncate_line_plot\nPlots a line plot of the ordered estimated CATEs as a rolling mean with optional confidence intervals.\n\n\ncate_true_vs_estimated_plot\nPlots a scatter plot of the estimated CATEs against the true CATEs.",
    "crumbs": [
      "API Reference"
    ]
  },
  {
    "objectID": "04_Reference/index.html#developer-tools",
    "href": "04_Reference/index.html#developer-tools",
    "title": "API Reference",
    "section": "",
    "text": "Developer tools and utilities for CaML.\n\n\n\ndecorators\nDecorator utilities for CaML.\n\n\ninterfaces\nInterface utilities for CaML.\n\n\nutils\nVarious Utilities for CaML.\n\n\nlogging\nLogging utilities for CaML.",
    "crumbs": [
      "API Reference"
    ]
  },
  {
    "objectID": "04_Reference/cate_true_vs_estimated_plot.html",
    "href": "04_Reference/cate_true_vs_estimated_plot.html",
    "title": "cate_true_vs_estimated_plot",
    "section": "",
    "text": "cate_true_vs_estimated_plot(\n    true_cates,\n    estimated_cates,\n    *,\n    figure_kwargs={},\n    scatter_kwargs={},\n)\nPlots a scatter plot of the estimated CATEs against the true CATEs."
  },
  {
    "objectID": "04_Reference/cate_true_vs_estimated_plot.html#parameters",
    "href": "04_Reference/cate_true_vs_estimated_plot.html#parameters",
    "title": "cate_true_vs_estimated_plot",
    "section": "Parameters",
    "text": "Parameters\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nestimated_cates\nArrayLike\nThe estimated CATEs.\nrequired\n\n\nfigure_kwargs\ndict\nMatplotlib figure arguments.\n{}\n\n\nscatter_kwargs\ndict\nMatplotlib scatter arguments.\n{}"
  },
  {
    "objectID": "04_Reference/cate_true_vs_estimated_plot.html#returns",
    "href": "04_Reference/cate_true_vs_estimated_plot.html#returns",
    "title": "cate_true_vs_estimated_plot",
    "section": "Returns",
    "text": "Returns\n\n\n\nName\nType\nDescription\n\n\n\n\n\nmatplotlib.pyplot.Figure\nThe scatter plot figure object."
  },
  {
    "objectID": "04_Reference/cate_true_vs_estimated_plot.html#examples",
    "href": "04_Reference/cate_true_vs_estimated_plot.html#examples",
    "title": "cate_true_vs_estimated_plot",
    "section": "Examples",
    "text": "Examples\n\nimport numpy as np\nfrom caml.extensions.plots import cate_true_vs_estimated_plot\n\nnp.random.seed(42)\ntrue_cates = np.random.normal(0, 1, 100)\nestimated_cates = true_cates + np.random.normal(0, 0.5, 100)\n\nfig = cate_true_vs_estimated_plot(true_cates, estimated_cates)\nfig"
  },
  {
    "objectID": "04_Reference/make_partially_linear_dataset_simple.html",
    "href": "04_Reference/make_partially_linear_dataset_simple.html",
    "title": "make_partially_linear_dataset_simple",
    "section": "",
    "text": "make_partially_linear_dataset_simple(\n    n_obs=1000,\n    n_confounders=5,\n    dim_heterogeneity=2,\n    binary_treatment=True,\n    seed=None,\n)\nSimulate data generating process from a partially linear model with a simple 1 or 2 dimensional CATE function.\nThe outcome is continuous and the treatment can be binary or continuous. The dataset is generated using the make_heterogeneous_data function from the doubleml package.\nThe general form of the data generating process is, in the case of dim_heterogeneity=1:\n\\[\ny_i= \\tau (x_0) d_i + g(\\mathbf{X_i})+\\epsilon_i\n\\] \\[\nd_i=f(\\mathbf{X_i})+\\eta_i\n\\]\nor, in the case of dim_heterogeneity=2:\n\\[\ny_i= \\tau (x_0,x_1) d_i + g(\\mathbf{X_i})+\\epsilon_i\n\\] \\[\nd_i=f(\\mathbf{X_i})+\\eta_i\n\\]\nwhere \\(y_i\\) is the outcome, \\(d_i\\) is the treatment, \\(\\mathbf{X_i}\\) are the confounders, \\(\\epsilon_i\\) and \\(\\eta_i\\) are the error terms, \\(\\\\tau\\) is the CATE function, \\(g\\) is the outcome function, and \\(f\\) is the treatment function.\nSee the doubleml documentation for more details on the specific functional forms of the data generating process.\nHere the ATE is defined as the average of the CATE function over all observations: \\(\\mathbb{E}[\\tau (\\cdot)]\\)\nAs a DAG, the data generating process can be roughly represented as:"
  },
  {
    "objectID": "04_Reference/make_partially_linear_dataset_simple.html#parameters",
    "href": "04_Reference/make_partially_linear_dataset_simple.html#parameters",
    "title": "make_partially_linear_dataset_simple",
    "section": "Parameters",
    "text": "Parameters\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nn_obs\nint\nThe number of observations to generate.\n1000\n\n\nn_confounders\nint\nThe number of confounders \\(X\\).\n5\n\n\ndim_heterogeneity\nint\nThe dimension of the heterogeneity \\(x_0\\) or \\((x_0,x_1)\\). Can only be 1 or 2.\n2\n\n\nbinary_treatment\nbool\nWhether the treatment \\(d\\) is binary or continuous.\nTrue\n\n\nseed\nint | None\nThe seed to use for the random number generator.\nNone"
  },
  {
    "objectID": "04_Reference/make_partially_linear_dataset_simple.html#returns",
    "href": "04_Reference/make_partially_linear_dataset_simple.html#returns",
    "title": "make_partially_linear_dataset_simple",
    "section": "Returns",
    "text": "Returns\n\n\n\n\n\n\n\n\nName\nType\nDescription\n\n\n\n\ndf\npandas.DataFrame\nThe generated dataset where y is the outcome, d is the treatment, and X are the confounders with a 1d or 2d subset utilized for heterogeneity.\n\n\ntrue_cates\nnumpy.ndarray\nThe true conditional average treatment effects.\n\n\ntrue_ate\nfloat\nThe true average treatment effect."
  },
  {
    "objectID": "04_Reference/make_partially_linear_dataset_simple.html#examples",
    "href": "04_Reference/make_partially_linear_dataset_simple.html#examples",
    "title": "make_partially_linear_dataset_simple",
    "section": "Examples",
    "text": "Examples\n\nfrom caml.extensions.synthetic_data import make_partially_linear_dataset_simple\ndf, true_cates, true_ate = make_partially_linear_dataset_simple(n_obs=1000,\n                                                                n_confounders=5,\n                                                                dim_heterogeneity=2,\n                                                                binary_treatment=True,\n                                                                seed=1)\n\nprint(f\"True CATES: {true_cates[:5]}\")\nprint(f\"True ATE: {true_ate}\")\nprint(df.head())\n\nTrue CATES: [5.07318438 4.22638341 4.84246206 5.02852819 7.30906609]\nTrue ATE: 4.434805144050488\n          y    d        X0        X1        X2        X3        X4\n0  5.814804  1.0  0.560647  0.182920  0.938085  0.721671  0.209634\n1  4.593199  1.0  0.113353  0.358469  0.271148  0.908152  0.497946\n2  1.489081  0.0  0.970009  0.981170  0.319852  0.034913  0.003447\n3  6.569753  1.0  0.386105  0.317130  0.339849  0.232991  0.463512\n4  8.249305  1.0  0.733222  0.360575  0.903222  0.600965  0.110013"
  },
  {
    "objectID": "04_Reference/utils.html",
    "href": "04_Reference/utils.html",
    "title": "utils",
    "section": "",
    "text": "generics.utils\nVarious Utilities for CaML.\nThis module provides various utilities for CaML.\n\n\n\n\n\nName\nDescription\n\n\n\n\nis_module_available\nCheck if a module is available.\n\n\n\n\n\ngenerics.utils.is_module_available(module_name)\nCheck if a module is available.\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nmodule_name\nstr\nThe name of the module to check.\nrequired\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\n\n\n\n\n\nbool\nTrue if the module is available, False otherwise."
  },
  {
    "objectID": "04_Reference/utils.html#functions",
    "href": "04_Reference/utils.html#functions",
    "title": "utils",
    "section": "",
    "text": "Name\nDescription\n\n\n\n\nis_module_available\nCheck if a module is available.\n\n\n\n\n\ngenerics.utils.is_module_available(module_name)\nCheck if a module is available.\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nmodule_name\nstr\nThe name of the module to check.\nrequired\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\n\n\n\n\n\nbool\nTrue if the module is available, False otherwise."
  },
  {
    "objectID": "04_Reference/support_matrix.html",
    "href": "04_Reference/support_matrix.html",
    "title": "Outcome/Treatment Type Support Matrix",
    "section": "",
    "text": "Outcome\nTreatment\nFastOLS\nAutoCATE\n\n\n\n\nContinuous\nBinary\n‚úÖ\n‚úÖ\n\n\nContinuous\nContinuous\n‚úÖ\n‚úÖ\n\n\nContinuous\nCategorical\n‚ùå\n‚úÖ\n\n\nBinary\nBinary\n‚úÖ\n‚úÖ\n\n\nBinary\nContinuous\n‚úÖ\n‚úÖ\n\n\nBinary\nCategorical\n‚ùå\n‚úÖ\n\n\nCategorical\nBinary\n‚ùå\n‚ùå\n\n\nCategorical\nContinuous\n‚ùå\n‚ùå\n\n\nCategorical\nCategorical\n‚ùå\n‚ùå\n\n\nMulti-Dimensional\n-\n‚úÖ\n‚ùå\n\n\n-\nMulti-Dimensional\n‚ùå\n‚ùå\n\n\n\n‚úÖ - Full ¬†¬† üü° - Partial ¬†¬† ‚ùå - Not yet\nIf you have a specific use case that is not covered by the current support matrix, please feel free to open an issue.\n\n\n\n Back to top",
    "crumbs": [
      "Outcome/Treatment Type Support Matrix"
    ]
  },
  {
    "objectID": "04_Reference/make_partially_linear_dataset_constant.html",
    "href": "04_Reference/make_partially_linear_dataset_constant.html",
    "title": "make_partially_linear_dataset_constant",
    "section": "",
    "text": "make_partially_linear_dataset_constant(\n    n_obs=1000,\n    ate=4.0,\n    n_confounders=10,\n    dgp='make_plr_CCDDHNR2018',\n    seed=None,\n    **doubleml_kwargs,\n)\nSimulate a data generating process from a partially linear model with a constant treatment effect (ATE only).\nThe outcome and treatment are both continuous.The dataset is generated using the make_plr_CCDDHNR2018 or make_plr_turrell2018 function from the doubleml package.\nThe general form of the data generating process is:\n\\[\ny_i= \\tau_0 d_i + g(\\mathbf{W_i})+\\epsilon_i\n\\] \\[\nd_i=f(\\mathbf{W_i})+\\eta_i\n\\]\nwhere \\(y_i\\) is the outcome, \\(d_i\\) is the treatment, \\(\\mathbf{W_i}\\) are the confounders, \\(\\epsilon_i\\) and \\(\\eta_i\\) are the error terms, \\(\\tau_0\\) is the ATE parameter, \\(g\\) is the outcome function, and \\(f\\) is the treatment function.\nSee the doubleml documentation for more details on the specific functional forms of the data generating process.\nAs a DAG, the data generating process can be roughly represented as:"
  },
  {
    "objectID": "04_Reference/make_partially_linear_dataset_constant.html#parameters",
    "href": "04_Reference/make_partially_linear_dataset_constant.html#parameters",
    "title": "make_partially_linear_dataset_constant",
    "section": "Parameters",
    "text": "Parameters\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nn_obs\nint\nThe number of observations to generate.\n1000\n\n\nate\nfloat\nThe average treatment effect \\(\\tau_0\\).\n4.0\n\n\nn_confounders\nint\nThe number of confounders \\(\\mathbf{W_i}\\) to generate.\n10\n\n\ndgp\nstr\nThe data generating process to use. Can be ‚Äúmake_plr_CCDDHNR20‚Äù or ‚Äúmake_plr_turrell2018‚Äù.\n'make_plr_CCDDHNR2018'\n\n\nseed\nint | None\nThe seed to use for the random number generator.\nNone\n\n\n**doubleml_kwargs\n\nAdditional keyword arguments to pass to the data generating process.\n{}"
  },
  {
    "objectID": "04_Reference/make_partially_linear_dataset_constant.html#returns",
    "href": "04_Reference/make_partially_linear_dataset_constant.html#returns",
    "title": "make_partially_linear_dataset_constant",
    "section": "Returns",
    "text": "Returns\n\n\n\n\n\n\n\n\nName\nType\nDescription\n\n\n\n\ndf\npandas.DataFrame\nThe generated dataset where y is the outcome, d is the treatment, and W are the confounders.\n\n\ntrue_cates\nnumpy.ndarray\nThe true conditional average treatment effects, which are all equal to the ATE here.\n\n\ntrue_ate\nfloat\nThe true average treatment effect."
  },
  {
    "objectID": "04_Reference/make_partially_linear_dataset_constant.html#examples",
    "href": "04_Reference/make_partially_linear_dataset_constant.html#examples",
    "title": "make_partially_linear_dataset_constant",
    "section": "Examples",
    "text": "Examples\n\nfrom caml.extensions.synthetic_data import make_partially_linear_dataset_constant\ndf, true_cates, true_ate = make_partially_linear_dataset_constant(n_obs=1000,\n                                                    ate=4.0,\n                                                    n_confounders=10,\n                                                    dgp=\"make_plr_CCDDHNR2018\",\n                                                    seed=1)\n\nprint(f\"True CATES: {true_cates[:5]}\")\nprint(f\"True ATE: {true_ate}\")\nprint(df.head())\n\nTrue CATES: [4. 4. 4. 4. 4.]\nTrue ATE: 4.0\n         W1        W2        W3        W4        W5        W6        W7  \\\n0 -1.799808 -0.830362 -0.775800 -2.430475 -1.759428 -0.196538 -0.392579   \n1 -2.238925 -2.107779 -1.619264 -1.816121 -2.084809 -0.456936  0.118781   \n2  1.069028  1.616054  1.959420  1.398880  0.058545  0.370891  0.161045   \n3  0.497020 -0.399126 -0.019305  0.230080  0.640361  1.233185  0.906313   \n4 -1.749809 -0.315699 -0.283176  0.439451  0.819941  0.156514  0.059722   \n\n         W8        W9       W10         y         d  \n0 -0.827537 -0.735652 -1.127103 -6.074658 -1.843476  \n1  0.270647  0.199401  0.049088 -8.534573 -1.969429  \n2  0.118180  0.438721  0.280880  4.915427  0.935840  \n3  1.031123 -0.373092  0.442367 -0.037117 -0.209740  \n4  0.472781  0.030157  1.174463 -7.922597 -1.903480"
  },
  {
    "objectID": "04_Reference/interfaces.html",
    "href": "04_Reference/interfaces.html",
    "title": "interfaces",
    "section": "",
    "text": "generics.interfaces\nInterface utilities for CaML.\nThis module provides interfaces and protocols for various functionalities in CaML.\n\n\n\n\n\nName\nDescription\n\n\n\n\nPandasConvertibleDataFrame\nType alias for DataFrame-like objects that are pandas convertible.\n\n\n\n\n\n\n\n\n\nName\nDescription\n\n\n\n\nFittedAttr\nAttribute that requires _fitted attribute to be True.\n\n\ntoPandasConvertible\nProtocol for DataFrame-like objects that are pandas convertible via toPandas().\n\n\nto_pandasConvertible\nProtocol for DataFrame-like objects that are pandas convertible via to_pandas().\n\n\n\n\n\ngenerics.interfaces.FittedAttr(name)\nAttribute that requires _fitted attribute to be True.\n\n\n\ngenerics.interfaces.toPandasConvertible()\nProtocol for DataFrame-like objects that are pandas convertible via toPandas().\n\n\n\ngenerics.interfaces.to_pandasConvertible()\nProtocol for DataFrame-like objects that are pandas convertible via to_pandas()."
  },
  {
    "objectID": "04_Reference/interfaces.html#attributes",
    "href": "04_Reference/interfaces.html#attributes",
    "title": "interfaces",
    "section": "",
    "text": "Name\nDescription\n\n\n\n\nPandasConvertibleDataFrame\nType alias for DataFrame-like objects that are pandas convertible."
  },
  {
    "objectID": "04_Reference/interfaces.html#classes",
    "href": "04_Reference/interfaces.html#classes",
    "title": "interfaces",
    "section": "",
    "text": "Name\nDescription\n\n\n\n\nFittedAttr\nAttribute that requires _fitted attribute to be True.\n\n\ntoPandasConvertible\nProtocol for DataFrame-like objects that are pandas convertible via toPandas().\n\n\nto_pandasConvertible\nProtocol for DataFrame-like objects that are pandas convertible via to_pandas().\n\n\n\n\n\ngenerics.interfaces.FittedAttr(name)\nAttribute that requires _fitted attribute to be True.\n\n\n\ngenerics.interfaces.toPandasConvertible()\nProtocol for DataFrame-like objects that are pandas convertible via toPandas().\n\n\n\ngenerics.interfaces.to_pandasConvertible()\nProtocol for DataFrame-like objects that are pandas convertible via to_pandas()."
  },
  {
    "objectID": "01_Home/installation.html",
    "href": "01_Home/installation.html",
    "title": "Installation",
    "section": "",
    "text": "The most recent version of CamML can be install via :\npip install caml\nand pinned to a specific version via:\npip install caml=={version}\nTo install optional/extra dependencies, run:\npip install 'caml[extra]'\nWe currently support the following extras: pyspark & polars.\nNote: CaML is in a highly experimental state and no stable release exists. Breaking changes to the API may occur at any time.\n\n\n\n Back to top",
    "crumbs": [
      "Installation"
    ]
  },
  {
    "objectID": "05_Contributors/documentation.html",
    "href": "05_Contributors/documentation.html",
    "title": "Documentation",
    "section": "",
    "text": "This repository uses  & quartodoc for documentation. All files relating to the documentation are under the docs/ directory. Quarto & quartodoc provide very detailed documentation on usage so I will refer the reader to these resources for more details.\nTo build the API documentation, run the following command from the projects root directory:\nquartodoc build --config docs/_quarto.yml\nTo build the example notebooks (under notebooks/examples/, run the following command:\nbash docs/marimo_examples_to_quarto.sh\nAnd to preview the documentation, run the following command:\nquarto preview docs/\nThe documentation preview will be hosted on http://localhost:8000/. Note that the quarto preview will be checking for live updates & applying them in real-time. In some cases, the changes will not manifest until you rerun quartodoc build --config docs/_quarto.yml. In general, this will occur when you make changes to the ‚Äúquartodoc:‚Äù section of the docs/_quarto.yml file or any corresponding API changes.\n\n\n\n Back to top",
    "crumbs": [
      "Documentation"
    ]
  },
  {
    "objectID": "05_Contributors/conventional_commits.html",
    "href": "05_Contributors/conventional_commits.html",
    "title": "Conventional Commits",
    "section": "",
    "text": "This project uses conventional commits for Pull Request titles, as they are ultimately used as the commit names on the main branch. What are conventional commits? In the words of the official documentation:\n\nThe Conventional Commits specification is a lightweight convention on top of commit messages. It provides an easy set of rules for creating an explicit commit history; which makes it easier to write automated tools on top of.\n\nThe PR titles should thus take the general form:\n&lt;type&gt;[optional scope]: &lt;description&gt;\nAn example would be:\nfix(types): make all floats double\nValid types for Caml are as follows:\n\nbuild: Changes that affect the build system or external dependencies\nci: Changes to our CI/CD configuration files and scripts\ndocs: Documentation only changes\nfeat: A new feature\nfix: A bug fix\nperf: A code change that improves performance\nrefactor: A code change that neither fixes a bug nor adds a feature\nstyle: Changes that do not affect the meaning of the code (white-space, formatting, missing semi-colons, etc)\ntest: Adding missing tests or correcting existing tests\nrevert: Reverting code changes to a previous state\nchore: Routine tasks that don‚Äôt fit in any of the above\n\nWe use the following regex to validate PR titles (test it!):\n^(build|chore|ci|docs|feat|fix|perf|refactor|revert|style|test|release)(.+)?(!)?:\\ .+\n\n\n\n Back to top",
    "crumbs": [
      "Conventional Commits"
    ]
  }
]