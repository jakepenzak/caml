[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "CaML - Causal ML",
    "section": "",
    "text": "Causal Machine Learning",
    "crumbs": [
      "Welcome!"
    ]
  },
  {
    "objectID": "index.html#welcome",
    "href": "index.html#welcome",
    "title": "CaML - Causal ML",
    "section": "Welcome!",
    "text": "Welcome!\nCaML provides a high-level API for an opinionated framework in performing Causal ML to estimate Average Treatment Effects (ATEs), Group Average Treatment Effects (GATEs), and Conditional Average Treatment Effects (CATEs), and to provide mechanisms to utilize these models for out of sample validation, prediction, & policy prescription.\nThe codebase is comprised primarily of extensions & abstractions over top of EconML & DoubleML with techniques motivated heavily by Causal ML Book and additional research.",
    "crumbs": [
      "Welcome!"
    ]
  },
  {
    "objectID": "index.html#background",
    "href": "index.html#background",
    "title": "CaML - Causal ML",
    "section": "Background",
    "text": "Background\nThe origins of CaML are rooted in a desire to develop a set of helper tools to abstract and streamline techniques & best pratices in Causal ML/Econometrics for estimating ATEs, GATEs, and CATEs, along with policy prescription. In addition, we seek to provide a framework for validating & scoring these models on out of sample data to help set the foundations for an AutoML framework for CATE models.\nAs we began working on these helper tools, we begun to see the value in reformulating this framework into a reusable package for wider use amongst the community and to provide an opinionated framework that can be integrated into productionalized systems, particularly experimentation platforms, for efficient estimation of causal parameters for reporting & decision-making purposes.\nAll of the standard assumptions for causal inference still apply in order for these tools & techniques to provide unbiased inference. A great resource for the CausalML landscape is the CausalML book written and publicly available generously by V. Chernozhukov, C. Hansen, N. Kallus, M. Spindler, & V. Syrgkanis.\nGiven a key motivation is to provide a tool for productionalized systems, we are building this package with interoperability and extensibility as core values. As of now, the tools utilized still rely on in-memory datasets for estimation (via EconML for causal models & flaml for AutoML of nuissance functions), but we leverage Ray & Spark for distributing certain processes where appropriate and if available for the user.",
    "crumbs": [
      "Welcome!"
    ]
  },
  {
    "objectID": "03_Examples/CamlCATE.html",
    "href": "03_Examples/CamlCATE.html",
    "title": "CamlCATE",
    "section": "",
    "text": "Here we’ll walk through an example of generating synthetic data, running CamlCATE, and visualizing results using the ground truth as reference.\nCamlCATE is particularly useful when highly accurate CATE estimation is of primary interest in the presence of exogenous treatment, simple linear confounding, or complex non-linear confounding exists.\nCamlCATE enables the use of various CATE models with varying assumptions on functional form of treatment effects & heterogeneity. When a set of CATE models are considered, the final CATE model is automatically selected is based on validation set performance.",
    "crumbs": [
      "CamlCATE"
    ]
  },
  {
    "objectID": "03_Examples/CamlCATE.html#generate-synthetic-data",
    "href": "03_Examples/CamlCATE.html#generate-synthetic-data",
    "title": "CamlCATE",
    "section": "Generate Synthetic Data",
    "text": "Generate Synthetic Data\nHere we’ll leverage the SyntheticDataGenerator class to generate a linear synthetic data generating process, with a binary treatment, continuous outcome, and a mix of confounding/mediating continuous covariates.\n\nfrom caml.logging import configure_logging\nimport logging\n\nconfigure_logging(level=logging.DEBUG)\n\n[06/10/25 15:23:02] DEBUG    Logging configured with level: DEBUG                                     logging.py:70\n\n\n\n\nfrom caml.extensions.synthetic_data import SyntheticDataGenerator\n\ndata_generator = SyntheticDataGenerator(\n    n_obs=10_000,\n    n_cont_outcomes=1,\n    n_binary_treatments=1,\n    n_cont_confounders=2,\n    n_cont_modifiers=2,\n    n_confounding_modifiers=1,\n    causal_model_functional_form=\"linear\",\n    seed=10,\n)\n\n                    WARNING  SyntheticDataGenerator is experimental and may change in future         generics.py:44\n                             versions.                                                                             \n\n\n\nWe can print our simulated data via:\n\ndata_generator.df\n\n\n\n\n\n\n\n\nW1_continuous\nW2_continuous\nX1_continuous\nX2_continuous\nT1_binary\nY1_continuous\n\n\n\n\n0\n0.354380\n-3.252276\n2.715662\n-3.578800\n1\n11.880305\n\n\n1\n0.568499\n2.484069\n-6.402235\n-2.611815\n0\n-32.292141\n\n\n2\n0.162715\n8.842902\n1.288770\n-3.788545\n1\n-48.696391\n\n\n3\n0.362944\n-0.959538\n1.080988\n-3.542550\n0\n-1.899468\n\n\n4\n0.612101\n1.417536\n4.143630\n-4.112453\n1\n-7.315334\n\n\n...\n...\n...\n...\n...\n...\n...\n\n\n9995\n0.340436\n0.241095\n-6.524222\n-3.188783\n1\n-27.578609\n\n\n9996\n0.019523\n1.338152\n-2.555492\n-3.643733\n1\n-19.692436\n\n\n9997\n0.325401\n1.258659\n-3.340546\n-4.255203\n1\n-26.087316\n\n\n9998\n0.586715\n1.263264\n-2.826709\n-4.149383\n1\n-25.876331\n\n\n9999\n0.003002\n6.723381\n1.260782\n-3.660600\n1\n-38.200522\n\n\n\n\n10000 rows × 6 columns\n\n\n\nTo inspect our true data generating process, we can call data_generator.dgp. Furthermore, we will have our true CATEs and ATEs at our disposal via data_generator.cates & data_generator.ates, respectively. We’ll use this as our source of truth for performance evaluation of our CATE estimator.\n\nfor t, df in data_generator.dgp.items():\n    print(f\"\\nDGP for {t}:\")\n    print(df)\n\n\nDGP for T1_binary:\n{'formula': '1 + W1_continuous + W2_continuous + X1_continuous', 'params': array([ 0.4609703 ,  0.2566887 , -0.03896251,  0.07238272]), 'noise': array([-0.51949108, -1.88624383,  0.86927397, ...,  0.87157749,\n        0.0697439 , -0.72616319]), 'raw_scores': array([0.58800598, 0.13710535, 0.75412862, ..., 0.7549587 , 0.60527474,\n       0.39290362]), 'function': &lt;function SyntheticDataGenerator._create_dgp_function.&lt;locals&gt;.f_binary at 0x7f9b287b37f0&gt;}\n\nDGP for Y1_continuous:\n{'formula': '1 + W1_continuous + W2_continuous + X1_continuous + X2_continuous + T1_binary + T1_binary*X1_continuous + T1_binary*X2_continuous', 'params': array([ 1.11129512, -4.1263484 , -4.82709212,  1.87319625,  2.60635605,\n       -0.91633948,  0.71653213, -0.25067306]), 'noise': array([-1.15370094, -0.26681987,  0.05261899, ..., -0.18887322,\n       -0.45736583, -0.57057603]), 'raw_scores': array([ 11.88030508, -32.29214063, -48.69639077, ..., -26.0873159 ,\n       -25.87633114, -38.20052217]), 'function': &lt;function SyntheticDataGenerator._create_dgp_function.&lt;locals&gt;.f_cont at 0x7f9b2918d3f0&gt;}\n\n\n\ndata_generator.cates\n\n\n\n\n\n\n\n\nCATE_of_T1_binary_on_Y1_continuous\n\n\n\n\n0\n1.926628\n\n\n1\n-4.849035\n\n\n2\n0.956792\n\n\n3\n0.746245\n\n\n4\n3.083586\n\n\n...\n...\n\n\n9995\n-4.791812\n\n\n9996\n-1.834046\n\n\n9997\n-2.243283\n\n\n9998\n-1.901629\n\n\n9999\n0.904665\n\n\n\n\n10000 rows × 1 columns\n\n\n\n\ndata_generator.ates\n\n\n\n\n\n\n\n\nTreatment\nATE\n\n\n\n\n0\nT1_binary_on_Y1_continuous\n-0.55937",
    "crumbs": [
      "CamlCATE"
    ]
  },
  {
    "objectID": "03_Examples/CamlCATE.html#running-camlcate",
    "href": "03_Examples/CamlCATE.html#running-camlcate",
    "title": "CamlCATE",
    "section": "Running CamlCATE",
    "text": "Running CamlCATE\n\nClass Instantiation\nWe can instantiate and observe our CamlCATE object via:\n\n\n\n\n\n\nTip\n\n\n\nW can be leveraged if we want to use certain covariates only in our nuisance functions to control for confounding and not in the final CATE estimator. This can be useful if a confounder may be required to include, but for compliance reasons, we don’t want our CATE model to leverage this feature (e.g., gender). However, this will restrict our available CATE estimators to orthogonal learners, since metalearners necessarily include all covariates. If you don’t care about W being in the final CATE estimator, pass it as X, as done below.\n\n\n\nfrom caml import CamlCATE\n\ncaml_obj = CamlCATE(\n    df=data_generator.df,\n    Y=\"Y1_continuous\",\n    T=\"T1_binary\",\n    X=[c for c in data_generator.df.columns if \"X\" in c]\n    + [c for c in data_generator.df.columns if \"W\" in c],\n    discrete_treatment=True,\n    discrete_outcome=False,\n)\n\n                    WARNING  CamlCATE is experimental and may change in future versions.             generics.py:44\n\n\n\n\nprint(caml_obj)\n\n================== CamlCATE Object ==================\nData Backend: pandas\nNo. of Observations: 10,000\nOutcome Variable: Y1_continuous\nDiscrete Outcome: False\nTreatment Variable: T1_binary\nDiscrete Treatment: True\nFeatures/Confounders for Heterogeneity (X): ['X1_continuous', 'X2_continuous', 'W1_continuous', 'W2_continuous']\nFeatures/Confounders as Controls (W): []\nRandom Seed: None\n\n\n\n\n\nNuisance Function AutoML\nWe can then obtain our nuisance functions / regression & propensity models via Flaml AutoML:\n\ncaml_obj.auto_nuisance_functions(\n    flaml_Y_kwargs={\n        \"time_budget\": 30,\n        \"verbose\": 0,\n        \"estimator_list\": [\"rf\", \"extra_tree\", \"xgb_limitdepth\"],\n    },\n    flaml_T_kwargs={\n        \"time_budget\": 30,\n        \"verbose\": 0,\n        \"estimator_list\": [\"rf\", \"extra_tree\", \"xgb_limitdepth\"],\n    },\n)\n\n\nprint(caml_obj.model_Y_X_W)\nprint(caml_obj.model_Y_X_W_T)\nprint(caml_obj.model_T_X_W)\n\nExtraTreesRegressor(max_features=0.9924623662362855, max_leaf_nodes=3267,\n                    n_estimators=140, n_jobs=-1, random_state=12032022)\nExtraTreesRegressor(max_features=0.9924623662362855, max_leaf_nodes=3267,\n                    n_estimators=140, n_jobs=-1, random_state=12032022)\nXGBClassifier(base_score=None, booster=None, callbacks=[],\n              colsample_bylevel=0.9366334928584987, colsample_bynode=None,\n              colsample_bytree=0.7801788111200721, device=None,\n              early_stopping_rounds=None, enable_categorical=False,\n              eval_metric=None, feature_types=None, gamma=None,\n              grow_policy=None, importance_type=None,\n              interaction_constraints=None, learning_rate=0.42324459351542365,\n              max_bin=None, max_cat_threshold=None, max_cat_to_onehot=None,\n              max_delta_step=None, max_depth=1, max_leaves=None,\n              min_child_weight=77.88614459419128, missing=nan,\n              monotone_constraints=None, multi_strategy=None, n_estimators=14,\n              n_jobs=-1, num_parallel_tree=None, random_state=None, ...)\n\n\n\n\nFit CATE Estimators\nNow that we have obtained our first-stage models, we can fit our CATE estimators via:\n\n\n\n\n\n\nNote\n\n\n\nThe selected model defaults to the one with the highest RScore. All fitted models are still accessible via the cate_estimators attribute and if you want to change default estimator, you can run caml_obj._validation_estimator = {different_model}.\n\n\n\n🚀Forthcoming: Additional scoring techniques & AutoML for CATE estimators is on our roadmap.\n\n\ncaml_obj.fit_validator(\n    cate_estimators=[\n        \"LinearDML\",\n        \"CausalForestDML\",\n        \"ForestDRLearner\",\n        \"LinearDRLearner\",\n        \"DomainAdaptationLearner\",\n        \"SLearner\",\n        \"TLearner\",\n        \"XLearner\",\n    ],\n    validation_size=0.2,\n    test_size=0.2,\n    n_jobs=-1,\n)\n\n[06/10/25 15:24:54] INFO     Best Estimator: LinearDRLearner                                            cate.py:854\n\n\n\n                    INFO     Estimator RScores: {'LinearDML': 0.4330668250950459, 'CausalForestDML':    cate.py:855\n                             0.42359894037321255, 'ForestDRLearner': 0.43008695668922525,                          \n                             'LinearDRLearner': 0.433440820487627, 'DomainAdaptationLearner':                      \n                             0.4220209999654573, 'SLearner': 0.3955966870782457, 'TLearner':                       \n                             0.39094152379289226, 'XLearner': 0.41786415918575315}                                 \n\n\n\n\ncaml_obj.validation_estimator\n\n&lt;econml.dr._drlearner.LinearDRLearner at 0x7f9b3d1a68c0&gt;\n\n\n\ncaml_obj.cate_estimators\n\n[('LinearDML', &lt;econml.dml.dml.LinearDML at 0x7f9b29114d90&gt;),\n ('CausalForestDML',\n  &lt;econml.dml.causal_forest.CausalForestDML at 0x7f9b29117df0&gt;),\n ('ForestDRLearner', &lt;econml.dr._drlearner.ForestDRLearner at 0x7f9b29157640&gt;),\n ('LinearDRLearner', &lt;econml.dr._drlearner.LinearDRLearner at 0x7f9b3d1a68c0&gt;),\n ('DomainAdaptationLearner',\n  &lt;econml.metalearners._metalearners.DomainAdaptationLearner at 0x7f9b291963b0&gt;),\n ('SLearner', &lt;econml.metalearners._metalearners.SLearner at 0x7f9b4fe080d0&gt;),\n ('TLearner', &lt;econml.metalearners._metalearners.TLearner at 0x7f9b29156500&gt;),\n ('XLearner', &lt;econml.metalearners._metalearners.XLearner at 0x7f9b70950220&gt;)]\n\n\n\n\nValidate model on test hold out set\nHere we can validate our model on the test hold out set. Currently, this is only available for when continuous outcomes and binary treatments exist.\n\ncaml_obj.validate()\n\n[06/10/25 15:24:56] INFO     All validation results suggest that the model has found statistically      cate.py:499\n                             significant heterogeneity.                                                            \n\n\n\n   treatment  blp_est  blp_se  blp_pval  qini_est  qini_se  qini_pval  autoc_est  autoc_se  autoc_pval  cal_r_squared\n0          1    1.018   0.023       0.0     0.975    0.029        0.0      2.611     0.089         0.0          0.973\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nRefit our selected model on the entire dataset\nNow that we have selected our top performer and validated results on the test set, we can fit our final model on the entire dataset.\n\ncaml_obj.fit_final()\n\n\ncaml_obj.final_estimator\n\n&lt;econml.dr._drlearner.LinearDRLearner at 0x7f9b28651a50&gt;",
    "crumbs": [
      "CamlCATE"
    ]
  },
  {
    "objectID": "03_Examples/CamlCATE.html#validating-results-with-ground-truth",
    "href": "03_Examples/CamlCATE.html#validating-results-with-ground-truth",
    "title": "CamlCATE",
    "section": "Validating Results with Ground Truth",
    "text": "Validating Results with Ground Truth\nFirst, we will obtain our predictions.\n\ncate_predictions = caml_obj.predict()\n\n\nAverage Treatment Effect (ATE)\nWe’ll use the summarize() method after obtaining our predictions above, where our the displayed mean represents our Average Treatment Effect (ATE).\n\ncaml_obj.summarize()\n\n\n\n\n\n\n\n\ncate_predictions_0_1\n\n\n\n\ncount\n10000.000000\n\n\nmean\n-0.571645\n\n\nstd\n3.416533\n\n\nmin\n-6.993616\n\n\n25%\n-3.540207\n\n\n50%\n-0.601345\n\n\n75%\n2.377039\n\n\nmax\n6.127550\n\n\n\n\n\n\n\nNow comparing this to our ground truth, we see the model performed well the true ATE:\n\ndata_generator.ates\n\n\n\n\n\n\n\n\nTreatment\nATE\n\n\n\n\n0\nT1_binary_on_Y1_continuous\n-0.55937\n\n\n\n\n\n\n\n\n\nConditional Average Treatment Effect (CATE)\nNow we want to see how the estimator performed in modeling the true CATEs.\nFirst, we can simply compute the Precision in Estimating Heterogeneous Effects (PEHE), which is simply the Root Mean Squared Error (RMSE):\n\nfrom sklearn.metrics import root_mean_squared_error\n\ntrue_cates = data_generator.cates.iloc[:, 0]\nroot_mean_squared_error(true_cates, cate_predictions)\n\n0.14776717903884\n\n\nNot bad! Now let’s use some visualization techniques:\n\nfrom caml.extensions.plots import cate_true_vs_estimated_plot\n\ncate_true_vs_estimated_plot(\n    true_cates=true_cates, estimated_cates=cate_predictions\n)\n\n\n\n\n\n\n\n\n\nfrom caml.extensions.plots import cate_histogram_plot\n\ncate_histogram_plot(true_cates=true_cates, estimated_cates=cate_predictions)\n\n\n\n\n\n\n\n\n\nfrom caml.extensions.plots import cate_line_plot\n\ncate_line_plot(\n    true_cates=true_cates, estimated_cates=cate_predictions, window=20\n)\n\n\n\n\n\n\n\n\nOverall, we can see the model performed remarkably well!~",
    "crumbs": [
      "CamlCATE"
    ]
  },
  {
    "objectID": "03_Examples/CamlCATE.html#obtaining-model-objects-artifacts-for-production-systems",
    "href": "03_Examples/CamlCATE.html#obtaining-model-objects-artifacts-for-production-systems",
    "title": "CamlCATE",
    "section": "Obtaining Model Objects & Artifacts for Production Systems",
    "text": "Obtaining Model Objects & Artifacts for Production Systems\nIn many production settings, we will want to store our model, information on the features used, etc. We provide attributes that to pull key information (more to be added later as class evolves)\nGrabbing final model object:\n\ncaml_obj.final_estimator\n\n&lt;econml.dr._drlearner.LinearDRLearner at 0x7f9b28651a50&gt;\n\n\nGrabbing input features:\n\ncaml_obj.input_names\n\n{'feature_names': ['X1_continuous',\n  'X2_continuous',\n  'W1_continuous',\n  'W2_continuous'],\n 'output_names': 'Y1_continuous',\n 'treatment_names': 'T1_binary'}\n\n\nGrabbing all fitted CATE estimators:\n\ncaml_obj.cate_estimators\n\n[('LinearDML', &lt;econml.dml.dml.LinearDML at 0x7f9b29114d90&gt;),\n ('CausalForestDML',\n  &lt;econml.dml.causal_forest.CausalForestDML at 0x7f9b29117df0&gt;),\n ('ForestDRLearner', &lt;econml.dr._drlearner.ForestDRLearner at 0x7f9b29157640&gt;),\n ('LinearDRLearner', &lt;econml.dr._drlearner.LinearDRLearner at 0x7f9b3d1a68c0&gt;),\n ('DomainAdaptationLearner',\n  &lt;econml.metalearners._metalearners.DomainAdaptationLearner at 0x7f9b291963b0&gt;),\n ('SLearner', &lt;econml.metalearners._metalearners.SLearner at 0x7f9b4fe080d0&gt;),\n ('TLearner', &lt;econml.metalearners._metalearners.TLearner at 0x7f9b29156500&gt;),\n ('XLearner', &lt;econml.metalearners._metalearners.XLearner at 0x7f9b70950220&gt;)]",
    "crumbs": [
      "CamlCATE"
    ]
  },
  {
    "objectID": "05_Contributors/environment.html",
    "href": "05_Contributors/environment.html",
    "title": "Environment Setup",
    "section": "",
    "text": "To help aid in environment setup, we’ve created a VS Code devcontainer for quick, isolated, and standardized environment creation.\n\n\n\nDocker Desktop or your choice of docker engine\nVisual Studio Code\n\n\n\n\n\nEnsure docker engine is running\nOpen VSCode in cloned project directory\nInstall VSCode Dev Containers extension\nOpen the current folder in dev container",
    "crumbs": [
      "Environment Setup"
    ]
  },
  {
    "objectID": "05_Contributors/environment.html#with-vscode-devcontainers",
    "href": "05_Contributors/environment.html#with-vscode-devcontainers",
    "title": "Environment Setup",
    "section": "",
    "text": "To help aid in environment setup, we’ve created a VS Code devcontainer for quick, isolated, and standardized environment creation.\n\n\n\nDocker Desktop or your choice of docker engine\nVisual Studio Code\n\n\n\n\n\nEnsure docker engine is running\nOpen VSCode in cloned project directory\nInstall VSCode Dev Containers extension\nOpen the current folder in dev container",
    "crumbs": [
      "Environment Setup"
    ]
  },
  {
    "objectID": "05_Contributors/environment.html#without-devcontainers",
    "href": "05_Contributors/environment.html#without-devcontainers",
    "title": "Environment Setup",
    "section": "Without Devcontainers",
    "text": "Without Devcontainers\n\nPrerequisites\n\nuv\npython v3.10\n\n\n\nSetup\n\nOpen repository in ide of choice\nRun uv sync --all-groups --frozen from command line\nActivate the virtual environment via source .venv/bin/activate\nRun pre-commit install to install pre-commit hooks",
    "crumbs": [
      "Environment Setup"
    ]
  },
  {
    "objectID": "05_Contributors/environment.html#project-package-dependency-management",
    "href": "05_Contributors/environment.html#project-package-dependency-management",
    "title": "Environment Setup",
    "section": "Project & Package Dependency Management",
    "text": "Project & Package Dependency Management\nWe use uv for dependency & project management. See uv docs for details.",
    "crumbs": [
      "Environment Setup"
    ]
  },
  {
    "objectID": "05_Contributors/documentation.html",
    "href": "05_Contributors/documentation.html",
    "title": "Documentation",
    "section": "",
    "text": "This repository uses  & quartodoc for documentation. All files relating to the documentation are under the docs/ directory. Quarto & quartodoc provide very detailed documentation on usage so I will refer the reader to these resources for more details.\nTo build the API documentation, run the following command from the projects root directory:\nquartodoc build --config docs/_quarto.yml\nTo build the example notebooks (under notebooks/examples/, run the following command:\nbash docs/marimo_examples_to_quarto.sh\nAnd to preview the documentation, run the following command:\nquarto preview docs/\nThe documentation preview will be hosted on http://localhost:8000/. Note that the quarto preview will be checking for live updates & applying them in real-time. In some cases, the changes will not manifest until you rerun quartodoc build --config docs/_quarto.yml. In general, this will occur when you make changes to the “quartodoc:” section of the docs/_quarto.yml file or any corresponding API changes.\n\n\n\n Back to top",
    "crumbs": [
      "Documentation"
    ]
  },
  {
    "objectID": "05_Contributors/getting_started.html",
    "href": "05_Contributors/getting_started.html",
    "title": "Contributing to CaML",
    "section": "",
    "text": "Welcome to the CaML contributor guide!\nWe manage out project via Github and leverage Github Flow for managing our development process. This guide will help you get started as a contributor and guide you through the process of contributing to CaML.",
    "crumbs": [
      "Contributing to CaML"
    ]
  },
  {
    "objectID": "05_Contributors/getting_started.html#general-contribution-guide",
    "href": "05_Contributors/getting_started.html#general-contribution-guide",
    "title": "Contributing to CaML",
    "section": "General Contribution Guide",
    "text": "General Contribution Guide\nPull requests are the best way to make changes to CaML:\n\nFork the repo and create your branch from main branch\nClone the repository on your local machine\nFor environment setup, see Environment Setup\nFor documentation, see Documentation\nFor testing, see Testing\nCreate a pull request & fill out the generated PR template\n\nCaML follows conventional commits for our PR titles, see here for more details.\nAll github actions & checks will be required to complete successfully prior to merging.",
    "crumbs": [
      "Contributing to CaML"
    ]
  },
  {
    "objectID": "05_Contributors/getting_started.html#report-bugs-using-github-issues",
    "href": "05_Contributors/getting_started.html#report-bugs-using-github-issues",
    "title": "Contributing to CaML",
    "section": "Report Bugs using Github Issues",
    "text": "Report Bugs using Github Issues\nBugs, features, and any other feedback can be submitted using the Github issues page.",
    "crumbs": [
      "Contributing to CaML"
    ]
  },
  {
    "objectID": "01_Home/installation.html",
    "href": "01_Home/installation.html",
    "title": "Installation",
    "section": "",
    "text": "The most recent version of CamML can be install via :\npip install caml\nand pinned to a specific version via:\npip install caml=={version}\nTo install optional/extra dependencies, run:\npip install 'caml[extra]'\nWe currently support the following extras: pyspark & polars.\nNote: CaML is in a highly experimental state and no stable release exists. Breaking changes to the API may occur at any time.\n\n\n\n Back to top",
    "crumbs": [
      "Installation"
    ]
  },
  {
    "objectID": "02_Concepts/theory.html",
    "href": "02_Concepts/theory.html",
    "title": "Econometric Theory",
    "section": "",
    "text": "Forthcoming\n\n\n\n Back to top",
    "crumbs": [
      "Econometric Theory"
    ]
  },
  {
    "objectID": "04_Reference/generics.experimental.html",
    "href": "04_Reference/generics.experimental.html",
    "title": "generics.experimental",
    "section": "",
    "text": "generics.experimental(obj)\nDecorator to mark functions or classes as experimental.\nThis decorator will show a warning when the decorated object is first used, indicating that it is experimental and may change in future versions.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nobj\nCallable\nThe class or function to mark as experimental\nrequired\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\n\n\n\n\n\nCallable\nThe decorated class or function"
  },
  {
    "objectID": "04_Reference/generics.experimental.html#parameters",
    "href": "04_Reference/generics.experimental.html#parameters",
    "title": "generics.experimental",
    "section": "",
    "text": "Name\nType\nDescription\nDefault\n\n\n\n\nobj\nCallable\nThe class or function to mark as experimental\nrequired"
  },
  {
    "objectID": "04_Reference/generics.experimental.html#returns",
    "href": "04_Reference/generics.experimental.html#returns",
    "title": "generics.experimental",
    "section": "",
    "text": "Name\nType\nDescription\n\n\n\n\n\nCallable\nThe decorated class or function"
  },
  {
    "objectID": "04_Reference/index.html",
    "href": "04_Reference/index.html",
    "title": "API Reference",
    "section": "",
    "text": "from caml import *   Core functionality of CaML for estimating causal effects with cross-sectional data.\n\n\n\nCamlCATE\nThe CamlCATE class represents an opinionated framework of Causal Machine Learning techniques for estimating highly accurate conditional average treatment effects (CATEs).\n\n\nFastOLS\nFastOLS is an optimized implementation of the OLS estimator designed specifically with treatment effect estimation in mind.\n\n\n\n\n\n\nfrom caml.extensions.synthetic_data import *   Synthetic data generation utilities for CaML.\n\n\n\nSyntheticDataGenerator\nGenerate highly flexible synthetic data for use in causal inference and CaML testing.\n\n\nmake_partially_linear_dataset_simple\nSimulate data generating process from a partially linear model with a simple 1 or 2 dimensional CATE function.\n\n\nmake_partially_linear_dataset_constant\nSimulate a data generating process from a partially linear model with a constant treatment effect (ATE only).\n\n\nmake_fully_heterogeneous_dataset\nSimulate data generating process from an interactive regression model with fully heterogenous treatment effects.\n\n\n\n\n\n\nfrom caml.extensions.plots import *   Plotting utilities for CaML.\n\n\n\ncate_histogram_plot\nPlots a histogram the estimated CATEs.\n\n\ncate_line_plot\nPlots a line plot of the ordered estimated CATEs as a rolling mean with optional confidence intervals.\n\n\ncate_true_vs_estimated_plot\nPlots a scatter plot of the estimated CATEs against the true CATEs.\n\n\n\n\n\n\nDeveloper tools for CaML.\n\n\n\ngenerics.experimental\nDecorator to mark functions or classes as experimental.\n\n\ngenerics.timer\nDecorator to measure the execution time of a function or method, logged at DEBUG level.\n\n\ngenerics.maybe_jit\nDecorator to JIT compile a function using JAX, if available.\n\n\ngenerics.PandasConvertibleDataFrame\nProtocol for DataFrame-like objects that are pandas convertible.\n\n\nlogging.configure_logging\nConfigure logging for the entire application.\n\n\nlogging.set_log_level\nChange the logging level after initial configuration.",
    "crumbs": [
      "API Reference"
    ]
  },
  {
    "objectID": "04_Reference/index.html#caml-core",
    "href": "04_Reference/index.html#caml-core",
    "title": "API Reference",
    "section": "",
    "text": "from caml import *   Core functionality of CaML for estimating causal effects with cross-sectional data.\n\n\n\nCamlCATE\nThe CamlCATE class represents an opinionated framework of Causal Machine Learning techniques for estimating highly accurate conditional average treatment effects (CATEs).\n\n\nFastOLS\nFastOLS is an optimized implementation of the OLS estimator designed specifically with treatment effect estimation in mind.",
    "crumbs": [
      "API Reference"
    ]
  },
  {
    "objectID": "04_Reference/index.html#synthetic-data-generation",
    "href": "04_Reference/index.html#synthetic-data-generation",
    "title": "API Reference",
    "section": "",
    "text": "from caml.extensions.synthetic_data import *   Synthetic data generation utilities for CaML.\n\n\n\nSyntheticDataGenerator\nGenerate highly flexible synthetic data for use in causal inference and CaML testing.\n\n\nmake_partially_linear_dataset_simple\nSimulate data generating process from a partially linear model with a simple 1 or 2 dimensional CATE function.\n\n\nmake_partially_linear_dataset_constant\nSimulate a data generating process from a partially linear model with a constant treatment effect (ATE only).\n\n\nmake_fully_heterogeneous_dataset\nSimulate data generating process from an interactive regression model with fully heterogenous treatment effects.",
    "crumbs": [
      "API Reference"
    ]
  },
  {
    "objectID": "04_Reference/index.html#plots",
    "href": "04_Reference/index.html#plots",
    "title": "API Reference",
    "section": "",
    "text": "from caml.extensions.plots import *   Plotting utilities for CaML.\n\n\n\ncate_histogram_plot\nPlots a histogram the estimated CATEs.\n\n\ncate_line_plot\nPlots a line plot of the ordered estimated CATEs as a rolling mean with optional confidence intervals.\n\n\ncate_true_vs_estimated_plot\nPlots a scatter plot of the estimated CATEs against the true CATEs.",
    "crumbs": [
      "API Reference"
    ]
  },
  {
    "objectID": "04_Reference/index.html#developer-tools",
    "href": "04_Reference/index.html#developer-tools",
    "title": "API Reference",
    "section": "",
    "text": "Developer tools for CaML.\n\n\n\ngenerics.experimental\nDecorator to mark functions or classes as experimental.\n\n\ngenerics.timer\nDecorator to measure the execution time of a function or method, logged at DEBUG level.\n\n\ngenerics.maybe_jit\nDecorator to JIT compile a function using JAX, if available.\n\n\ngenerics.PandasConvertibleDataFrame\nProtocol for DataFrame-like objects that are pandas convertible.\n\n\nlogging.configure_logging\nConfigure logging for the entire application.\n\n\nlogging.set_log_level\nChange the logging level after initial configuration.",
    "crumbs": [
      "API Reference"
    ]
  },
  {
    "objectID": "04_Reference/make_partially_linear_dataset_constant.html",
    "href": "04_Reference/make_partially_linear_dataset_constant.html",
    "title": "make_partially_linear_dataset_constant",
    "section": "",
    "text": "make_partially_linear_dataset_constant(\n    n_obs=1000,\n    ate=4.0,\n    n_confounders=10,\n    dgp='make_plr_CCDDHNR2018',\n    seed=None,\n    **doubleml_kwargs,\n)\nSimulate a data generating process from a partially linear model with a constant treatment effect (ATE only).\nThe outcome and treatment are both continuous.The dataset is generated using the make_plr_CCDDHNR2018 or make_plr_turrell2018 function from the doubleml package.\nThe general form of the data generating process is:\n\\[\ny_i= \\tau_0 d_i + g(\\mathbf{W_i})+\\epsilon_i\n\\] \\[\nd_i=f(\\mathbf{W_i})+\\eta_i\n\\]\nwhere \\(y_i\\) is the outcome, \\(d_i\\) is the treatment, \\(\\mathbf{W_i}\\) are the confounders, \\(\\epsilon_i\\) and \\(\\eta_i\\) are the error terms, \\(\\tau_0\\) is the ATE parameter, \\(g\\) is the outcome function, and \\(f\\) is the treatment function.\nSee the doubleml documentation for more details on the specific functional forms of the data generating process.\nAs a DAG, the data generating process can be roughly represented as:"
  },
  {
    "objectID": "04_Reference/make_partially_linear_dataset_constant.html#parameters",
    "href": "04_Reference/make_partially_linear_dataset_constant.html#parameters",
    "title": "make_partially_linear_dataset_constant",
    "section": "Parameters",
    "text": "Parameters\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nn_obs\nint\nThe number of observations to generate.\n1000\n\n\nate\nfloat\nThe average treatment effect \\(\\tau_0\\).\n4.0\n\n\nn_confounders\nint\nThe number of confounders \\(\\mathbf{W_i}\\) to generate.\n10\n\n\ndgp\nstr\nThe data generating process to use. Can be “make_plr_CCDDHNR20” or “make_plr_turrell2018”.\n'make_plr_CCDDHNR2018'\n\n\nseed\nint | None\nThe seed to use for the random number generator.\nNone\n\n\n**doubleml_kwargs\n\nAdditional keyword arguments to pass to the data generating process.\n{}"
  },
  {
    "objectID": "04_Reference/make_partially_linear_dataset_constant.html#returns",
    "href": "04_Reference/make_partially_linear_dataset_constant.html#returns",
    "title": "make_partially_linear_dataset_constant",
    "section": "Returns",
    "text": "Returns\n\n\n\n\n\n\n\n\nName\nType\nDescription\n\n\n\n\ndf\npandas.DataFrame\nThe generated dataset where y is the outcome, d is the treatment, and W are the confounders.\n\n\ntrue_cates\nnumpy.ndarray\nThe true conditional average treatment effects, which are all equal to the ATE here.\n\n\ntrue_ate\nfloat\nThe true average treatment effect."
  },
  {
    "objectID": "04_Reference/make_partially_linear_dataset_constant.html#examples",
    "href": "04_Reference/make_partially_linear_dataset_constant.html#examples",
    "title": "make_partially_linear_dataset_constant",
    "section": "Examples",
    "text": "Examples\n\nfrom caml.extensions.synthetic_data import make_partially_linear_dataset_constant\ndf, true_cates, true_ate = make_partially_linear_dataset_constant(n_obs=1000,\n                                                    ate=4.0,\n                                                    n_confounders=10,\n                                                    dgp=\"make_plr_CCDDHNR2018\",\n                                                    seed=1)\n\nprint(f\"True CATES: {true_cates[:5]}\")\nprint(f\"True ATE: {true_ate}\")\nprint(df.head())\n\nTrue CATES: [4. 4. 4. 4. 4.]\nTrue ATE: 4.0\n         W1        W2        W3        W4        W5        W6        W7  \\\n0 -1.799808 -0.830362 -0.775800 -2.430475 -1.759428 -0.196538 -0.392579   \n1 -2.238925 -2.107779 -1.619264 -1.816121 -2.084809 -0.456936  0.118781   \n2  1.069028  1.616054  1.959420  1.398880  0.058545  0.370891  0.161045   \n3  0.497020 -0.399126 -0.019305  0.230080  0.640361  1.233185  0.906313   \n4 -1.749809 -0.315699 -0.283176  0.439451  0.819941  0.156514  0.059722   \n\n         W8        W9       W10         y         d  \n0 -0.827537 -0.735652 -1.127103 -6.074658 -1.843476  \n1  0.270647  0.199401  0.049088 -8.534573 -1.969429  \n2  0.118180  0.438721  0.280880  4.915427  0.935840  \n3  1.031123 -0.373092  0.442367 -0.037117 -0.209740  \n4  0.472781  0.030157  1.174463 -7.922597 -1.903480"
  },
  {
    "objectID": "04_Reference/generics.PandasConvertibleDataFrame.html",
    "href": "04_Reference/generics.PandasConvertibleDataFrame.html",
    "title": "generics.PandasConvertibleDataFrame",
    "section": "",
    "text": "generics.PandasConvertibleDataFrame\ngenerics.PandasConvertibleDataFrame()\nProtocol for DataFrame-like objects that are pandas convertible.\nThis includes DataFrames that are either pandas dataframes or can be converted to pandas via to_pandas() or toPandas() methods.\n\n\n\n\n Back to top"
  },
  {
    "objectID": "04_Reference/cate_histogram_plot.html",
    "href": "04_Reference/cate_histogram_plot.html",
    "title": "cate_histogram_plot",
    "section": "",
    "text": "cate_histogram_plot(\n    estimated_cates,\n    *,\n    true_cates=None,\n    figure_kwargs={},\n    hist_kwargs={},\n)\nPlots a histogram the estimated CATEs."
  },
  {
    "objectID": "04_Reference/cate_histogram_plot.html#parameters",
    "href": "04_Reference/cate_histogram_plot.html#parameters",
    "title": "cate_histogram_plot",
    "section": "Parameters",
    "text": "Parameters\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nestimated_cates\nArrayLike\nThe estimated CATEs.\nrequired\n\n\ntrue_cates\nArrayLike | None\nThe true CATEs.\nNone\n\n\nfigure_kwargs\ndict\nMatplotlib figure arguments.\n{}\n\n\nhist_kwargs\ndict\nMatplotlib hist arguments.\n{}"
  },
  {
    "objectID": "04_Reference/cate_histogram_plot.html#returns",
    "href": "04_Reference/cate_histogram_plot.html#returns",
    "title": "cate_histogram_plot",
    "section": "Returns",
    "text": "Returns\n\n\n\nName\nType\nDescription\n\n\n\n\n\nmatplotlib.pyplot.Figure\nThe histogram figure object."
  },
  {
    "objectID": "04_Reference/cate_histogram_plot.html#examples",
    "href": "04_Reference/cate_histogram_plot.html#examples",
    "title": "cate_histogram_plot",
    "section": "Examples",
    "text": "Examples\n\nimport numpy as np\nfrom caml.extensions.plots import cate_histogram_plot\n\nnp.random.seed(42)\ntrue_cates = np.random.normal(0, 1, 1000)\nestimated_cates = true_cates + np.random.normal(0, 0.5, 1000)\n\nfig = cate_histogram_plot(estimated_cates, true_cates=true_cates, hist_kwargs={'bins': 25})\nfig"
  },
  {
    "objectID": "04_Reference/cate_line_plot.html",
    "href": "04_Reference/cate_line_plot.html",
    "title": "cate_line_plot",
    "section": "",
    "text": "cate_line_plot(\n    estimated_cates,\n    *,\n    true_cates=None,\n    standard_errors=None,\n    alpha=0.05,\n    window=30,\n    figure_kwargs={},\n    line_kwargs={},\n)\nPlots a line plot of the ordered estimated CATEs as a rolling mean with optional confidence intervals."
  },
  {
    "objectID": "04_Reference/cate_line_plot.html#parameters",
    "href": "04_Reference/cate_line_plot.html#parameters",
    "title": "cate_line_plot",
    "section": "Parameters",
    "text": "Parameters\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nestimated_cates\nArrayLike\nThe estimated CATEs.\nrequired\n\n\ntrue_cates\nArrayLike | None\nThe true CATEs.\nNone\n\n\nstandard_errors\nArrayLike | None\nThe standard errors of the estimated CATEs.\nNone\n\n\nalpha\nfloat\nThe alpha level for the confidence intervals. The default is 0.05, which corresponds to 95% confidence intervals.\n0.05\n\n\nwindow\nint\nThe window size for the moving average.\n30\n\n\nfigure_kwargs\ndict\nMatplotlib figure arguments.\n{}\n\n\nline_kwargs\ndict\nMatplotlib line arguments.\n{}"
  },
  {
    "objectID": "04_Reference/cate_line_plot.html#returns",
    "href": "04_Reference/cate_line_plot.html#returns",
    "title": "cate_line_plot",
    "section": "Returns",
    "text": "Returns\n\n\n\nName\nType\nDescription\n\n\n\n\n\nmatplotlib.pyplot.Figure\nThe line plot figure object."
  },
  {
    "objectID": "04_Reference/cate_line_plot.html#examples",
    "href": "04_Reference/cate_line_plot.html#examples",
    "title": "cate_line_plot",
    "section": "Examples",
    "text": "Examples\n\nimport numpy as np\nfrom caml.extensions.plots import cate_line_plot\n\nnp.random.seed(42)\ntrue_cates = np.random.normal(0, 1, 100)\nestimated_cates = true_cates + np.random.normal(0, 0.5, 100)\nstandard_errors = np.abs(np.random.normal(0, 0.1, 100))\n\nfig = cate_line_plot(estimated_cates, true_cates=true_cates, standard_errors=standard_errors, window=5)\nfig"
  },
  {
    "objectID": "04_Reference/FastOLS.html",
    "href": "04_Reference/FastOLS.html",
    "title": "FastOLS",
    "section": "",
    "text": "FastOLS(\n    self,\n    Y,\n    T,\n    G=None,\n    X=None,\n    W=None,\n    *,\n    xformula=None,\n    discrete_treatment=False,\n    engine='cpu',\n)\nFastOLS is an optimized implementation of the OLS estimator designed specifically with treatment effect estimation in mind.\nFastOLS is experimental and may change significantly in future versions.\nThis class estimates a standard linear regression model for any number of continuous or binary outcomes and a single continuous or binary treatment, and provides estimates for the Average Treatment Effects (ATEs) and Group Average Treatment Effects (GATEs) out of the box. Additionally, methods are provided for estimating custom GATEs & Conditional Average Treatment Effects (CATEs) of individual observations, which can also be used for out-of-sample predictions. Note, this method assumes linear treatment effects and heterogeneity, which is typically sufficient when primarily concerned with ATEs and GATEs.\nThis class leverages JAX for fast numerical computations, which can be installed using pip install caml[jax], defaulting to NumPy if JAX is not available. For GPU acceleration, install JAX with GPU support using pip install caml[jax-gpu].\nFor outcome/treatment support, see Support Matrix.\nFor model specification details, see Model Specifications.\nFor a more detailed working example, see FastOLS Example."
  },
  {
    "objectID": "04_Reference/FastOLS.html#parameters",
    "href": "04_Reference/FastOLS.html#parameters",
    "title": "FastOLS",
    "section": "Parameters",
    "text": "Parameters\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nY\nCollection[str]\nA list of outcome variable names.\nrequired\n\n\nT\nstr\nThe treatment variable name.\nrequired\n\n\nG\nCollection[str] | None\nA list of group variable names. These will be the groups for which GATEs will be estimated.\nNone\n\n\nX\nCollection[str] | None\nA list of covariate variable names. These will be the covariates for which heterogeneity/CATEs can be estimated.\nNone\n\n\nW\nCollection[str] | None\nA list of additional covariate variable names to be used as controls. These will be the additional covariates not used for modeling heterogeneity/CATEs.\nNone\n\n\nxformula\nstr | None\nAdditional formula string to append to the main formula, starting with “+”. For example, “+age+gender” will add age and gender as additional predictors.\nNone\n\n\ndiscrete_treatment\nbool\nWhether the treatment is discrete\nFalse\n\n\nengine\nstr\nThe engine to use for computation. Can be “cpu” or “gpu”. Note “gpu” requires JAX to be installed, which can be installed via pip install caml[jax-gpu].\n'cpu'"
  },
  {
    "objectID": "04_Reference/FastOLS.html#attributes",
    "href": "04_Reference/FastOLS.html#attributes",
    "title": "FastOLS",
    "section": "Attributes",
    "text": "Attributes\n\n\n\n\n\n\n\n\nName\nType\nDescription\n\n\n\n\nY\nCollection[str]\nA list of outcome variable names.\n\n\nT\nstr\nThe treatment variable name.\n\n\nG\nCollection[str] | None\nThe list of group variable names. These will be the groups for which GATEs will be estimated.\n\n\nX\nCollection[str] | None\nThe list of variable names representing the confounder/control feature set to be utilized for estimating heterogeneity/CATEs, that are in addition to G.\n\n\nW\nCollection[str] | None\nThe list of variable names representing the confounder/control feature not utilized for estimating heterogeneity/CATEs.\n\n\nformula\nstr\nThe formula leveraged for design matrix creation via Patsy.\n\n\nparams\nnp.ndarray\nThe estimated parameters of the model.\n\n\nvcv\nnp.ndarray\nThe estimated variance-covariance matrix of the model parameters.\n\n\nstd_err\nnp.ndarray\nThe standard errors of the estimated parameters.\n\n\nfitted_values\nnp.ndarray\nThe predicted values from the model.\n\n\nresiduals\nnp.ndarray\nThe residuals of the model.\n\n\ntreatment_effects\ndict\nThe estimated treatment effects dictionary."
  },
  {
    "objectID": "04_Reference/FastOLS.html#examples",
    "href": "04_Reference/FastOLS.html#examples",
    "title": "FastOLS",
    "section": "Examples",
    "text": "Examples\n\nfrom caml import FastOLS\nfrom caml.extensions.synthetic_data import SyntheticDataGenerator\n\ndata_generator = SyntheticDataGenerator(n_cont_outcomes=1,\n                                            n_binary_outcomes=1,\n                                            n_cont_modifiers=1,\n                                            n_binary_modifiers=2,\n                                            seed=10)\ndf = data_generator.df\n\nfo_obj = FastOLS(\n    Y=[c for c in df.columns if \"Y\" in c],\n    T=\"T1_binary\",\n    G=[c for c in df.columns if \"X\" in c and (\"bin\" in c or \"dis\" in c)],\n    X=[c for c in df.columns if \"X\" in c and \"cont\" in c],\n    W=[c for c in df.columns if \"W\" in c],\n    xformula=None,\n    engine=\"cpu\",\n    discrete_treatment=True,\n)\n\nprint(fo_obj)\n\n================== FastOLS Object ==================\nEngine: cpu\nOutcome Variable: ['Y1_continuous', 'Y2_binary']\nTreatment Variable: T1_binary\nDiscrete Treatment: True\nGroup Variables: ['X2_binary', 'X3_binary']\nFeatures/Confounders for Heterogeneity (X): ['X1_continuous']\nFeatures/Confounders as Controls (W): []\nFormula: Q('Y1_continuous') + Q('Y2_binary') ~ C(Q('T1_binary')) + C(Q('X2_binary'))*C(Q('T1_binary')) + C(Q('X3_binary'))*C(Q('T1_binary')) + Q('X1_continuous')*C(Q('T1_binary'))"
  },
  {
    "objectID": "04_Reference/FastOLS.html#methods",
    "href": "04_Reference/FastOLS.html#methods",
    "title": "FastOLS",
    "section": "Methods",
    "text": "Methods\n\n\n\nName\nDescription\n\n\n\n\nfit\nFits the regression model on the provided data and, optionally, estimates Average Treatment Effect(s) (ATE) and Group Average Treatment Effect(s) (GATE).\n\n\nestimate_ate\nEstimate Average Treatment Effects (ATEs) of T on each Y from fitted model.\n\n\nestimate_cate\nEstimate Conditional Average Treatment Effects (CATEs) of T on each Y from fitted model for all given observations in the dataset.\n\n\npredict\nGenerate predicted conditional average treatment effects (CATEs) or outcomes.\n\n\nprettify_treatment_effects\nConvert treatment effects dictionary to a pandas DataFrame.\n\n\n\n\nfit\nFastOLS.fit(df, *, n_jobs=-1, estimate_effects=True, cov_type='nonrobust')\nFits the regression model on the provided data and, optionally, estimates Average Treatment Effect(s) (ATE) and Group Average Treatment Effect(s) (GATE).\nIf estimate_effects is True, the method estimates Average Treatment Effects (ATEs) and Group Average Treatment Effects (GATEs), based on specified G. This leverages estimate_ate method under the hood, but efficiently reuses the data and parallelizes the computation of GATEs.\n\nParameters\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\ndf\nPandasConvertibleDataFrame\nInput dataframe to fit the model on. Supported formats: pandas DataFrame, PySpark DataFrame, Polars DataFrame, or Any object with toPandas() or to_pandas() method\nrequired\n\n\nn_jobs\nint\nThe number of jobs to use for parallel processing in the estimation of GATEs. Defaults to -1, which uses all available processors. If getting OOM errors, try setting n_jobs to a lower value.\n-1\n\n\nestimate_effects\nbool\nWhether to estimate Average Treatment Effects (ATEs) and Group Average Treatment Effects (GATEs).\nTrue\n\n\ncov_type\nstr\nThe covariance estimator to use for variance-covariance matrix and standard errors. Can be “nonrobust”, “HC0”, or “HC1”.\n'nonrobust'\n\n\n\n\n\nExamples\n\nfo_obj.fit(df, n_jobs=4, estimate_effects=True, cov_type='nonrobust')\n\nfo_obj.treatment_effects.keys()\n\ndict_keys(['overall', 'X2_binary-0', 'X2_binary-1', 'X3_binary-1', 'X3_binary-0'])\n\n\n\n\n\nestimate_ate\nFastOLS.estimate_ate(\n    df,\n    *,\n    return_results_dict=False,\n    group='Custom Group',\n    membership=None,\n    _diff_matrix=None,\n)\nEstimate Average Treatment Effects (ATEs) of T on each Y from fitted model.\nIf the entire dataframe is provided, the function will estimate the ATE of the entire population, where the ATE, in the case of binary treatments, is formally defined as: \\[\n    \\tau = \\mathbb{E}_n[\\mathbf{Y}_1 - \\mathbf{Y}_0]\n    \\]\nIf a subset of the dataframe is provided, the function will estimate the ATE of the subset (e.g., GATEs), where the GATE, in the case of binary treatments, is formally defined as: \\[\n    \\tau = \\mathbb{E}_n[\\mathbf{Y}_1 - \\mathbf{Y}_0|\\mathbf{G}=G]\n    \\]\nFor more details on treatment effect estimation, see Model Specifications.\n\nParameters\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\ndf\nPandasConvertibleDataFrame\nDataframe containing the data to estimate the ATEs. Supported formats: pandas DataFrame, PySpark DataFrame, Polars DataFrame, or Any object with toPandas() or to_pandas() method\nrequired\n\n\nreturn_results_dict\nbool\nIf True, the function returns a dictionary containing ATEs/GATEs, standard errors, t-statistics, and p-values. If False, the function returns a numpy array containing ATEs/GATEs alone.\nFalse\n\n\ngroup\nstr\nName of the group to estimate the ATEs for.\n'Custom Group'\n\n\nmembership\nstr | None\nName of the membership variable to estimate the ATEs for.\nNone\n\n\n_diff_matrix\njnp.ndarray | None = None\nPrivate argument used in fit method.\nNone\n\n\n\n\n\nReturns\n\n\n\n\n\n\n\n\nName\nType\nDescription\n\n\n\n\n\njnp.ndarray | dict\nEstimated ATEs/GATEs or dictionary containing the estimated ATEs/GATEs and their standard errors, t-statistics, and p-values.\n\n\n\n\n\nExamples\n\nate = fo_obj.estimate_ate(df, return_results_dict=True, group=\"Overall\")\n\nate\n\n{'Overall': {'outcome': ['Y1_continuous', 'Y2_binary'],\n  'ate': array([[3.75944943, 0.19349086]]),\n  'std_err': array([[0.02012718, 0.00971994]]),\n  't_stat': array([[186.78472875,  19.90658227]]),\n  'pval': array([[0., 0.]]),\n  'n': 10000,\n  'n_treated': 5060,\n  'n_control': 4940}}\n\n\n\ndf_filtered = df.query(\n    \"X3_binary == 0 & X1_continuous &lt; 5\"\n).copy()\n\ncustom_gate = fo_obj.estimate_ate(df_filtered)\n\ncustom_gate\n\narray([[1.39607152, 0.08336419]])\n\n\n\n\n\nestimate_cate\nFastOLS.estimate_cate(df, *, return_results_dict=False)\nEstimate Conditional Average Treatment Effects (CATEs) of T on each Y from fitted model for all given observations in the dataset.\nThe CATE, in the case of binary treatments, is formally defined as: \\[\n    \\tau = \\mathbb{E}_n[\\mathbf{Y}_1 - \\mathbf{Y}_0|\\mathbf{Q}=Q]\n    \\]\nFor more details on treatment effect estimation, see Model Specifications.\n\nParameters\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\ndf\nPandasConvertibleDataFrame\nDataframe containing the data to estimate CATEs for. Supported formats: pandas DataFrame, PySpark DataFrame, Polars DataFrame, or Any object with toPandas() or to_pandas() method\nrequired\n\n\nreturn_results_dict\nbool\nIf True, the function returns a dictionary containing CATEs, standard errors, t-statistics, and p-values. If False, the function returns a numpy array containing CATEs alone.\nFalse\n\n\n\n\n\nReturns\n\n\n\n\n\n\n\n\nName\nType\nDescription\n\n\n\n\n\njnp.ndarray | dict\nCATEs or dictionary containing CATEs, standard errors, t-statistics, and p-values.\n\n\n\n\n\nExamples\n\ncates = fo_obj.estimate_cate(df)\ncates[:5]\n\narray([[3.89639511, 0.17159235],\n       [3.74635426, 0.23789582],\n       [4.5283798 , 0.21765926],\n       [3.87988946, 0.17201947],\n       [3.66232416, 0.24007028]])\n\n\n\nres = fo_obj.estimate_cate(df, return_results_dict=True)\nres.keys()\n\ndict_keys(['outcome', 'cate', 'std_err', 't_stat', 'pval'])\n\n\n\n\n\npredict\nFastOLS.predict(df, *, return_results_dict=False, mode='cate')\nGenerate predicted conditional average treatment effects (CATEs) or outcomes.\nWhen mode is “outcome”, the function returns predicted outcomes.\nWhen mode is “cate”, the function returns predicted CATEs, behaving as an alias for estimate_cate.\n\nParameters\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\ndf\nPandasConvertibleDataFrame\nDataframe containing the data to estimate CATEs for. Supported formats: pandas DataFrame, PySpark DataFrame, Polars DataFrame, or Any object with toPandas() or to_pandas() method\nrequired\n\n\nreturn_results_dict\nbool\nIf True, the function returns a dictionary containing CATEs, standard errors, t-statistics, and p-values. If False, the function returns a numpy array containing CATEs alone. Does not have any effect when mode is “outcome”.\nFalse\n\n\nmode\nstr\nThe mode of prediction. Supported modes are “cate” and “outcome”. If “cate”, the function returns CATEs. If “outcome”, the function returns predicted outcomes.\n'cate'\n\n\n\n\n\nReturns\n\n\n\n\n\n\n\n\nName\nType\nDescription\n\n\n\n\n\njnp.ndarray | dict\nCATEs or dictionary containing CATEs, standard errors, t-statistics, and p-values.\n\n\n\n\n\nExamples\n\ncates = fo_obj.predict(df)\ncates[:5]\n\narray([[3.89639511, 0.17159235],\n       [3.74635426, 0.23789582],\n       [4.5283798 , 0.21765926],\n       [3.87988946, 0.17201947],\n       [3.66232416, 0.24007028]])\n\n\n\nres = fo_obj.predict(df, return_results_dict=True)\nres.keys()\n\ndict_keys(['outcome', 'cate', 'std_err', 't_stat', 'pval'])\n\n\n\n\n\nprettify_treatment_effects\nFastOLS.prettify_treatment_effects(effects=None)\nConvert treatment effects dictionary to a pandas DataFrame.\nIf no argument is provided, the results are constructed from internal results dictionary. This is useful default behavior. For custom treatment effects, you can pass the results generated by the estimate_ate method.\n\nParameters\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\neffects\ndict\nDictionary of treatment effects. If None, the results are constructed from internal results dictionary.\nNone\n\n\n\n\n\nReturns\n\n\n\nName\nType\nDescription\n\n\n\n\n\npd.DataFrame\nDataFrame of treatment effects.\n\n\n\n\n\nExamples\n\nfo_obj.prettify_treatment_effects()\n\n\n\n\n\n\n\n\ngroup\nmembership\noutcome\nate\nstd_err\nt_stat\npval\nn\nn_treated\nn_control\n\n\n\n\n0\noverall\nNone\nY1_continuous\n3.759449\n0.020127\n186.784729\n0.000000\n10000\n5060\n4940\n\n\n1\noverall\nNone\nY2_binary\n0.193491\n0.009720\n19.906582\n0.000000\n10000\n5060\n4940\n\n\n2\nX2_binary\n0\nY1_continuous\n3.584580\n0.034935\n102.606668\n0.000000\n3320\n1691\n1629\n\n\n3\nX2_binary\n0\nY2_binary\n0.156381\n0.016871\n9.269187\n0.000000\n3320\n1691\n1629\n\n\n4\nX2_binary\n1\nY1_continuous\n3.846360\n0.024626\n156.193627\n0.000000\n6680\n3369\n3311\n\n\n5\nX2_binary\n1\nY2_binary\n0.211934\n0.011892\n17.821080\n0.000000\n6680\n3369\n3311\n\n\n6\nX3_binary\n1\nY1_continuous\n4.081423\n0.021454\n190.238254\n0.000000\n8801\n4451\n4350\n\n\n7\nX3_binary\n1\nY2_binary\n0.208494\n0.010361\n20.123279\n0.000000\n8801\n4451\n4350\n\n\n8\nX3_binary\n0\nY1_continuous\n1.396072\n0.058130\n24.016441\n0.000000\n1199\n609\n590\n\n\n9\nX3_binary\n0\nY2_binary\n0.083364\n0.028072\n2.969612\n0.002982\n1199\n609\n590\n\n\n\n\n\n\n\n\n## Using a custom GATE\ncustom_gate = fo_obj.estimate_ate(df_filtered, return_results_dict=True, group=\"My Custom Group\")\nfo_obj.prettify_treatment_effects(custom_gate)\n\n\n\n\n\n\n\n\ngroup\nmembership\noutcome\nate\nstd_err\nt_stat\npval\nn\nn_treated\nn_control\n\n\n\n\n0\nMy Custom Group\nNone\nY1_continuous\n1.396072\n0.058130\n24.016441\n0.000000\n1199\n609\n590\n\n\n1\nMy Custom Group\nNone\nY2_binary\n0.083364\n0.028072\n2.969612\n0.002982\n1199\n609\n590"
  },
  {
    "objectID": "04_Reference/generics.timer.html",
    "href": "04_Reference/generics.timer.html",
    "title": "generics.timer",
    "section": "",
    "text": "generics.timer(operation_name=None)\nDecorator to measure the execution time of a function or method, logged at DEBUG level.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\noperation_name\nstr | None\nThe name of the operation to be timed. If None, the name of the function or method will be used.\nNone\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\n\n\n\n\n\nCallable\nThe decorated function or method"
  },
  {
    "objectID": "04_Reference/generics.timer.html#parameters",
    "href": "04_Reference/generics.timer.html#parameters",
    "title": "generics.timer",
    "section": "",
    "text": "Name\nType\nDescription\nDefault\n\n\n\n\noperation_name\nstr | None\nThe name of the operation to be timed. If None, the name of the function or method will be used.\nNone"
  },
  {
    "objectID": "04_Reference/generics.timer.html#returns",
    "href": "04_Reference/generics.timer.html#returns",
    "title": "generics.timer",
    "section": "",
    "text": "Name\nType\nDescription\n\n\n\n\n\nCallable\nThe decorated function or method"
  },
  {
    "objectID": "04_Reference/cate_true_vs_estimated_plot.html",
    "href": "04_Reference/cate_true_vs_estimated_plot.html",
    "title": "cate_true_vs_estimated_plot",
    "section": "",
    "text": "cate_true_vs_estimated_plot(\n    true_cates,\n    estimated_cates,\n    *,\n    figure_kwargs={},\n    scatter_kwargs={},\n)\nPlots a scatter plot of the estimated CATEs against the true CATEs."
  },
  {
    "objectID": "04_Reference/cate_true_vs_estimated_plot.html#parameters",
    "href": "04_Reference/cate_true_vs_estimated_plot.html#parameters",
    "title": "cate_true_vs_estimated_plot",
    "section": "Parameters",
    "text": "Parameters\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nestimated_cates\nArrayLike\nThe estimated CATEs.\nrequired\n\n\nfigure_kwargs\ndict\nMatplotlib figure arguments.\n{}\n\n\nscatter_kwargs\ndict\nMatplotlib scatter arguments.\n{}"
  },
  {
    "objectID": "04_Reference/cate_true_vs_estimated_plot.html#returns",
    "href": "04_Reference/cate_true_vs_estimated_plot.html#returns",
    "title": "cate_true_vs_estimated_plot",
    "section": "Returns",
    "text": "Returns\n\n\n\nName\nType\nDescription\n\n\n\n\n\nmatplotlib.pyplot.Figure\nThe scatter plot figure object."
  },
  {
    "objectID": "04_Reference/cate_true_vs_estimated_plot.html#examples",
    "href": "04_Reference/cate_true_vs_estimated_plot.html#examples",
    "title": "cate_true_vs_estimated_plot",
    "section": "Examples",
    "text": "Examples\n\nimport numpy as np\nfrom caml.extensions.plots import cate_true_vs_estimated_plot\n\nnp.random.seed(42)\ntrue_cates = np.random.normal(0, 1, 100)\nestimated_cates = true_cates + np.random.normal(0, 0.5, 100)\n\nfig = cate_true_vs_estimated_plot(true_cates, estimated_cates)\nfig"
  },
  {
    "objectID": "04_Reference/make_partially_linear_dataset_simple.html",
    "href": "04_Reference/make_partially_linear_dataset_simple.html",
    "title": "make_partially_linear_dataset_simple",
    "section": "",
    "text": "make_partially_linear_dataset_simple(\n    n_obs=1000,\n    n_confounders=5,\n    dim_heterogeneity=2,\n    binary_treatment=True,\n    seed=None,\n)\nSimulate data generating process from a partially linear model with a simple 1 or 2 dimensional CATE function.\nThe outcome is continuous and the treatment can be binary or continuous. The dataset is generated using the make_heterogeneous_data function from the doubleml package.\nThe general form of the data generating process is, in the case of dim_heterogeneity=1:\n\\[\ny_i= \\tau (x_0) d_i + g(\\mathbf{X_i})+\\epsilon_i\n\\] \\[\nd_i=f(\\mathbf{X_i})+\\eta_i\n\\]\nor, in the case of dim_heterogeneity=2:\n\\[\ny_i= \\tau (x_0,x_1) d_i + g(\\mathbf{X_i})+\\epsilon_i\n\\] \\[\nd_i=f(\\mathbf{X_i})+\\eta_i\n\\]\nwhere \\(y_i\\) is the outcome, \\(d_i\\) is the treatment, \\(\\mathbf{X_i}\\) are the confounders, \\(\\epsilon_i\\) and \\(\\eta_i\\) are the error terms, \\(\\\\tau\\) is the CATE function, \\(g\\) is the outcome function, and \\(f\\) is the treatment function.\nSee the doubleml documentation for more details on the specific functional forms of the data generating process.\nHere the ATE is defined as the average of the CATE function over all observations: \\(\\mathbb{E}[\\tau (\\cdot)]\\)\nAs a DAG, the data generating process can be roughly represented as:"
  },
  {
    "objectID": "04_Reference/make_partially_linear_dataset_simple.html#parameters",
    "href": "04_Reference/make_partially_linear_dataset_simple.html#parameters",
    "title": "make_partially_linear_dataset_simple",
    "section": "Parameters",
    "text": "Parameters\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nn_obs\nint\nThe number of observations to generate.\n1000\n\n\nn_confounders\nint\nThe number of confounders \\(X\\).\n5\n\n\ndim_heterogeneity\nint\nThe dimension of the heterogeneity \\(x_0\\) or \\((x_0,x_1)\\). Can only be 1 or 2.\n2\n\n\nbinary_treatment\nbool\nWhether the treatment \\(d\\) is binary or continuous.\nTrue\n\n\nseed\nint | None\nThe seed to use for the random number generator.\nNone"
  },
  {
    "objectID": "04_Reference/make_partially_linear_dataset_simple.html#returns",
    "href": "04_Reference/make_partially_linear_dataset_simple.html#returns",
    "title": "make_partially_linear_dataset_simple",
    "section": "Returns",
    "text": "Returns\n\n\n\n\n\n\n\n\nName\nType\nDescription\n\n\n\n\ndf\npandas.DataFrame\nThe generated dataset where y is the outcome, d is the treatment, and X are the confounders with a 1d or 2d subset utilized for heterogeneity.\n\n\ntrue_cates\nnumpy.ndarray\nThe true conditional average treatment effects.\n\n\ntrue_ate\nfloat\nThe true average treatment effect."
  },
  {
    "objectID": "04_Reference/make_partially_linear_dataset_simple.html#examples",
    "href": "04_Reference/make_partially_linear_dataset_simple.html#examples",
    "title": "make_partially_linear_dataset_simple",
    "section": "Examples",
    "text": "Examples\n\nfrom caml.extensions.synthetic_data import make_partially_linear_dataset_simple\ndf, true_cates, true_ate = make_partially_linear_dataset_simple(n_obs=1000,\n                                                                n_confounders=5,\n                                                                dim_heterogeneity=2,\n                                                                binary_treatment=True,\n                                                                seed=1)\n\nprint(f\"True CATES: {true_cates[:5]}\")\nprint(f\"True ATE: {true_ate}\")\nprint(df.head())\n\nTrue CATES: [5.07318438 4.22638341 4.84246206 5.02852819 7.30906609]\nTrue ATE: 4.434805144050488\n          y    d        X0        X1        X2        X3        X4\n0  5.814804  1.0  0.560647  0.182920  0.938085  0.721671  0.209634\n1  4.593199  1.0  0.113353  0.358469  0.271148  0.908152  0.497946\n2  1.489081  0.0  0.970009  0.981170  0.319852  0.034913  0.003447\n3  6.569753  1.0  0.386105  0.317130  0.339849  0.232991  0.463512\n4  8.249305  1.0  0.733222  0.360575  0.903222  0.600965  0.110013"
  },
  {
    "objectID": "04_Reference/make_fully_heterogeneous_dataset.html",
    "href": "04_Reference/make_fully_heterogeneous_dataset.html",
    "title": "make_fully_heterogeneous_dataset",
    "section": "",
    "text": "make_fully_heterogeneous_dataset(\n    n_obs=1000,\n    n_confounders=5,\n    theta=4.0,\n    seed=None,\n    **doubleml_kwargs,\n)\nSimulate data generating process from an interactive regression model with fully heterogenous treatment effects.\nThe outcome is continuous and the treatment is binary. The dataset is generated using a modified version of make_irm_data function from the doubleml package.\nThe general form of the data generating process is:\n\\[\ny_i= g(d_i,\\mathbf{X_i})+\\epsilon_i\n\\] \\[\nd_i=f(\\mathbf{X_i})+\\eta_i\n\\]\nwhere \\(y_i\\) is the outcome, \\(d_i\\) is the treatment, \\(\\mathbf{X_i}\\) are the confounders utilized for full effect heterogeneity, \\(\\epsilon_i\\) and \\(\\eta_i\\) are the error terms, \\(g\\) is the outcome function, and \\(f\\) is the treatment function.\nSee the doubleml documentation for more details on the specific functional forms of the data generating process.\nNote that the treatment effect is fully heterogenous, thus the CATE is defined as: \\(\\tau = \\mathbb{E}[g(1,\\mathbf{X}) - g(0,\\mathbf{X})|\\mathbf{X}]\\) for any \\(\\mathbf{X}\\).\nThe ATE is defined as the average of the CATE function over all observations: \\(\\mathbb{E}[\\tau (\\cdot)]\\)\nAs a DAG, the data generating process can be roughly represented as:"
  },
  {
    "objectID": "04_Reference/make_fully_heterogeneous_dataset.html#parameters",
    "href": "04_Reference/make_fully_heterogeneous_dataset.html#parameters",
    "title": "make_fully_heterogeneous_dataset",
    "section": "Parameters",
    "text": "Parameters\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nn_obs\nint\nThe number of observations to generate.\n1000\n\n\nn_confounders\nint\nThe number of confounders \\(\\mathbf{X_i}\\) to generate (these are utilized fully for heterogeneity).\n5\n\n\ntheta\nfloat\nThe base parameter for the treatment effect. Note this can differ slightly from the true ATE.\n4.0\n\n\nseed\nint | None\nThe seed to use for the random number generator.\nNone\n\n\n**doubleml_kwargs\n\nAdditional keyword arguments to pass to the data generating process.\n{}"
  },
  {
    "objectID": "04_Reference/make_fully_heterogeneous_dataset.html#returns",
    "href": "04_Reference/make_fully_heterogeneous_dataset.html#returns",
    "title": "make_fully_heterogeneous_dataset",
    "section": "Returns",
    "text": "Returns\n\n\n\n\n\n\n\n\nName\nType\nDescription\n\n\n\n\ndf\npandas.DataFrame\nThe generated dataset where y is the outcome, d is the treatment, and X are the confounders which are fully utilized for heterogeneity.\n\n\ntrue_cates\nnumpy.ndarray\nThe true conditional average treatment effects.\n\n\ntrue_ate\nfloat\nThe true average treatment effect."
  },
  {
    "objectID": "04_Reference/make_fully_heterogeneous_dataset.html#examples",
    "href": "04_Reference/make_fully_heterogeneous_dataset.html#examples",
    "title": "make_fully_heterogeneous_dataset",
    "section": "Examples",
    "text": "Examples\n\nfrom caml.extensions.synthetic_data import make_fully_heterogeneous_dataset\ndf, true_cates, true_ate = make_fully_heterogeneous_dataset(n_obs=1000,\n                                                            n_confounders=5,\n                                                            theta=4.0,\n                                                            seed=1)\n\nprint(f\"True CATEs: {true_cates[:5]}\")\nprint(f\"True ATE: {true_ate}\")\nprint(df.head())\n\nTrue CATEs: [5.10338083 5.0918794  1.93444292 4.36046179 3.89521828]\nTrue ATE: 3.9499484248360175\n         X1        X2        X3        X4        X5         y    d\n0  1.682368 -0.422572 -1.219871 -0.941586 -1.270241  5.828931  1.0\n1  0.684154  1.125168  2.601475  0.441070  0.889493  4.767675  1.0\n2 -2.035148 -1.386116 -0.770108 -0.070788 -0.524494  2.748786  1.0\n3  0.429364 -0.125604 -0.095252 -0.033939  1.243388  5.140932  1.0\n4  0.240024 -0.069628 -1.722948 -1.565808 -1.494064  2.431165  1.0"
  },
  {
    "objectID": "04_Reference/logging.configure_logging.html",
    "href": "04_Reference/logging.configure_logging.html",
    "title": "logging.configure_logging",
    "section": "",
    "text": "logging.configure_logging(level=logging.WARNING)\nConfigure logging for the entire application.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nlevel\nint\nThe logging level to use. Defaults to WARNING. Can be overridden by environment variable CAML_LOG_LEVEL.\nlogging.WARNING"
  },
  {
    "objectID": "04_Reference/logging.configure_logging.html#parameters",
    "href": "04_Reference/logging.configure_logging.html#parameters",
    "title": "logging.configure_logging",
    "section": "",
    "text": "Name\nType\nDescription\nDefault\n\n\n\n\nlevel\nint\nThe logging level to use. Defaults to WARNING. Can be overridden by environment variable CAML_LOG_LEVEL.\nlogging.WARNING"
  },
  {
    "objectID": "04_Reference/support_matrix.html",
    "href": "04_Reference/support_matrix.html",
    "title": "Outcome/Treatment Type Support Matrix",
    "section": "",
    "text": "Outcome\nTreatment\nFastOLS\nCamlCATE\n\n\n\n\nContinuous\nBinary\n✅\n✅\n\n\nContinuous\nContinuous\n✅\n🟡1\n\n\nContinuous\nCategorical\n❌\n✅\n\n\nBinary\nBinary\n✅\n🟡2\n\n\nBinary\nContinuous\n✅\n🟡3\n\n\nBinary\nCategorical\n❌\n🟡4\n\n\nCategorical\nBinary\n❌\n❌\n\n\nCategorical\nContinuous\n❌\n❌\n\n\nCategorical\nCategorical\n❌\n❌\n\n\nMulti-Dimensional\n-\n✅\n❌\n\n\n-\nMulti-Dimensional\n❌\n❌\n✅ - Full    🟡 - Partial    ❌ - Not yet\nIf you have a specific use case that is not covered by the current support matrix, please feel free to open an issue.",
    "crumbs": [
      "Outcome/Treatment Type Support Matrix"
    ]
  },
  {
    "objectID": "04_Reference/support_matrix.html#footnotes",
    "href": "04_Reference/support_matrix.html#footnotes",
    "title": "Outcome/Treatment Type Support Matrix",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nMissing validate method.↩︎\nMissing validate method.↩︎\nMissing validate method.↩︎\nMissing validate method.↩︎",
    "crumbs": [
      "Outcome/Treatment Type Support Matrix"
    ]
  },
  {
    "objectID": "04_Reference/logging.set_log_level.html",
    "href": "04_Reference/logging.set_log_level.html",
    "title": "logging.set_log_level",
    "section": "",
    "text": "logging.set_log_level(level)\nChange the logging level after initial configuration.\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nlevel\nint\nThe new logging level to use.\nrequired"
  },
  {
    "objectID": "04_Reference/logging.set_log_level.html#parameters",
    "href": "04_Reference/logging.set_log_level.html#parameters",
    "title": "logging.set_log_level",
    "section": "",
    "text": "Name\nType\nDescription\nDefault\n\n\n\n\nlevel\nint\nThe new logging level to use.\nrequired"
  },
  {
    "objectID": "04_Reference/generics.maybe_jit.html",
    "href": "04_Reference/generics.maybe_jit.html",
    "title": "generics.maybe_jit",
    "section": "",
    "text": "generics.maybe_jit(func=None, **jit_kwargs)\nDecorator to JIT compile a function using JAX, if available.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nfunc\nCallable | None\nThe function to be JIT compiled.\nNone\n\n\njit_kwargs\ndict\nKeyword arguments to be passed to jax.jit.\n{}\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\n\n\n\n\n\nCallable\nThe decorated function or method"
  },
  {
    "objectID": "04_Reference/generics.maybe_jit.html#parameters",
    "href": "04_Reference/generics.maybe_jit.html#parameters",
    "title": "generics.maybe_jit",
    "section": "",
    "text": "Name\nType\nDescription\nDefault\n\n\n\n\nfunc\nCallable | None\nThe function to be JIT compiled.\nNone\n\n\njit_kwargs\ndict\nKeyword arguments to be passed to jax.jit.\n{}"
  },
  {
    "objectID": "04_Reference/generics.maybe_jit.html#returns",
    "href": "04_Reference/generics.maybe_jit.html#returns",
    "title": "generics.maybe_jit",
    "section": "",
    "text": "Name\nType\nDescription\n\n\n\n\n\nCallable\nThe decorated function or method"
  },
  {
    "objectID": "04_Reference/CamlCATE.html",
    "href": "04_Reference/CamlCATE.html",
    "title": "CamlCATE",
    "section": "",
    "text": "CamlCATE(\n    self,\n    df,\n    Y,\n    T,\n    X,\n    W=None,\n    *,\n    discrete_treatment=True,\n    discrete_outcome=False,\n    seed=None,\n)\nThe CamlCATE class represents an opinionated framework of Causal Machine Learning techniques for estimating highly accurate conditional average treatment effects (CATEs).\nCamlCATE is experimental and may change significantly in future versions.\nThe CATE is defined formally as \\(\\mathbb{E}[\\tau|\\mathbf{X}]\\) where \\(\\tau\\) is the treatment effect and \\(\\mathbf{X}\\) is the set of covariates.\nThis class is built on top of the EconML library and provides a high-level API for fitting, validating, and making inference with CATE models, with best practices built directly into the API. The class is designed to be easy to use and understand, while still providing flexibility for advanced users. The class is designed to be used with pandas, polars, or pyspark backends, which ultimately get converted to NumPy Arrays under the hood to provide a level of extensibility & interoperability across different data processing frameworks.\nThe primary workflow for the CamlCATE class is as follows:\nFor technical details on conditional average treatment effects, see:\nNote: All the standard assumptions of Causal Inference apply to this class (e.g., exogeneity/unconfoundedness, overlap, positivity, etc.). The class does not check for these assumptions and assumes that the user has already thought through these assumptions before using the class.\nFor outcome/treatment support, see matrix.\nFor a more detailed working example, see CamlCATE Example."
  },
  {
    "objectID": "04_Reference/CamlCATE.html#parameters",
    "href": "04_Reference/CamlCATE.html#parameters",
    "title": "CamlCATE",
    "section": "Parameters",
    "text": "Parameters\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\ndf\npandas.DataFrame | polars.DataFrame | pyspark.sql.DataFrame\nThe input DataFrame representing the data for the CamlCATE instance.\nrequired\n\n\nY\nstr\nThe str representing the column name for the outcome variable.\nrequired\n\n\nT\nstr\nThe str representing the column name(s) for the treatment variable(s).\nrequired\n\n\nX\nstr | list[str]\nThe str (if unity) or list of feature names representing the feature set to be utilized for estimating heterogeneity/CATE.\nrequired\n\n\nW\nstr | list[str] | None\nThe str (if unity) or list of feature names representing the confounder/control feature set to be utilized only for nuisance function estimation. When W is passed, only Orthogonal learners will be leveraged.\nNone\n\n\ndiscrete_treatment\nbool\nA boolean indicating whether the treatment is discrete/categorical or continuous.\nTrue\n\n\ndiscrete_outcome\nbool\nA boolean indicating whether the outcome is binary or continuous.\nFalse\n\n\nseed\nint | None\nThe seed to use for the random number generator.\nNone"
  },
  {
    "objectID": "04_Reference/CamlCATE.html#attributes",
    "href": "04_Reference/CamlCATE.html#attributes",
    "title": "CamlCATE",
    "section": "Attributes",
    "text": "Attributes\n\n\n\n\n\n\n\n\nName\nType\nDescription\n\n\n\n\ndf\npandas.DataFrame | polars.DataFrame | pyspark.sql.DataFrame\nThe input DataFrame representing the data for the CamlCATE instance.\n\n\nY\nstr\nThe str representing the column name for the outcome variable.\n\n\nT\nstr\nThe str representing the column name(s) for the treatment variable(s).\n\n\nX\nIterable[str]\nThe str (if unity) or list of variable names representing the confounder/control feature set to be utilized for estimating heterogeneity/CATE and nuisance function estimation where applicable.\n\n\nW\nIterable[str] | None\nThe str (if unity) or list of variable names representing the confounder/control feature set to be utilized only for nuisance function estimation, where applicable. These will be included by default in Meta-Learners.\n\n\ndiscrete_treatment\nbool\nA boolean indicating whether the treatment is discrete/categorical or continuous.\n\n\ndiscrete_outcome\nbool\nA boolean indicating whether the outcome is binary or continuous.\n\n\navailable_estimators\nstr\nA list of the available CATE estimators out of the box. Validity of estimator at runtime will depend on the outcome and treatment types and be automatically selected.\n\n\nmodel_Y_X_W\nsklearn.base.BaseEstimator\nThe fitted nuisance function for the outcome variable.\n\n\nmodel_Y_X_W_T\nsklearn.base.BaseEstimator\nThe fitted nuisance function for the outcome variable with treatment variable.\n\n\nmodel_T_X_W\nsklearn.base.BaseEstimator\nThe fitted nuisance function for the treatment variable.\n\n\ncate_estimators\ndict[str, econml._cate_estimator.BaseCateEstimator | econml.score.EnsembleCateEstimator]\nDictionary of fitted cate estimator objects.\n\n\nrscores\ndict[str, float]\nDictionary of RScore values for each fitted cate estimator.\n\n\nvalidation_estimator\neconml._cate_estimator.BaseCateEstimator | econml.score.EnsembleCateEstimator\nThe fitted EconML estimator object for validation.\n\n\nvalidator_results\neconml.validate.results.EvaluationResults\nThe validation results object.\n\n\nfinal_estimator\neconml._cate_estimator.BaseCateEstimator | econml.score.EnsembleCateEstimator\nThe fitted EconML estimator object on the entire dataset after validation.\n\n\ninput_names\ndict[str, list[str]]\nThe feature, outcome, and treatment names used in the CATE estimators."
  },
  {
    "objectID": "04_Reference/CamlCATE.html#examples",
    "href": "04_Reference/CamlCATE.html#examples",
    "title": "CamlCATE",
    "section": "Examples",
    "text": "Examples\n\nfrom caml import CamlCATE\nfrom caml.extensions.synthetic_data import SyntheticDataGenerator\n\ndata_generator = SyntheticDataGenerator(seed=10, n_cont_modifiers=1, n_cont_confounders=1)\ndf = data_generator.df\n\ncaml_obj = CamlCATE(\n    df = df,\n    Y=\"Y1_continuous\",\n    T=\"T1_binary\",\n    X=[c for c in df.columns if \"X\" in c or \"W\" in c],\n    discrete_treatment=True,\n    discrete_outcome=False,\n    seed=0,\n)\n\nprint(caml_obj)\n\n================== CamlCATE Object ==================\nData Backend: pandas\nNo. of Observations: 10,000\nOutcome Variable: Y1_continuous\nDiscrete Outcome: False\nTreatment Variable: T1_binary\nDiscrete Treatment: True\nFeatures/Confounders for Heterogeneity (X): ['W1_continuous', 'X1_continuous']\nFeatures/Confounders as Controls (W): []\nRandom Seed: 0"
  },
  {
    "objectID": "04_Reference/CamlCATE.html#methods",
    "href": "04_Reference/CamlCATE.html#methods",
    "title": "CamlCATE",
    "section": "Methods",
    "text": "Methods\n\n\n\nName\nDescription\n\n\n\n\nauto_nuisance_functions\nLeverages AutoML to find optimal nuisance functions/regression & propensity models for use in EconML CATE estimators.\n\n\nfit_validator\nFits the CATE models on the training set and evaluates them & ensembles based on the validation set.\n\n\nvalidate\nValidates the fitted CATE models on the test set to check for generalization performance.\n\n\nfit_final\nFits the final estimator on the entire dataset, after validation and testing.\n\n\npredict\nPredicts the CATE based on the fitted final estimator for either the internal dataset or provided Data.\n\n\nsummarize\nProvides population summary statistics for the CATE predictions for either the internal results or provided results.\n\n\n\n\nauto_nuisance_functions\nCamlCATE.auto_nuisance_functions(\n    flaml_Y_kwargs=None,\n    flaml_T_kwargs=None,\n    use_ray=False,\n    use_spark=False,\n)\nLeverages AutoML to find optimal nuisance functions/regression & propensity models for use in EconML CATE estimators.\nSets the model_Y_X_W, model_Y_X_W_T, and model_T_X_W attributes to the fitted nuisance functions.\n\nParameters\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nflaml_Y_kwargs\ndict | None\nThe keyword arguments for the FLAML AutoML search for the outcome model. Default implies the base parameters in CamlBase.\nNone\n\n\nflaml_T_kwargs\ndict | None\nThe keyword arguments for the FLAML AutoML search for the treatment model. Default implies the base parameters in CamlBase.\nNone\n\n\nuse_ray\nbool\nA boolean indicating whether to use Ray for parallel processing.\nFalse\n\n\nuse_spark\nbool\nA boolean indicating whether to use Spark for parallel processing.\nFalse\n\n\n\n\n\nExamples\n\nflaml_Y_kwargs = {\n    \"n_jobs\": -1,\n    \"time_budget\": 10,\n    \"verbose\": 0\n}\n\nflaml_T_kwargs = {\n    \"n_jobs\": -1,\n    \"time_budget\": 10,\n    \"verbose\": 0\n}\n\ncaml_obj.auto_nuisance_functions(\n    flaml_Y_kwargs=flaml_Y_kwargs,\n    flaml_T_kwargs=flaml_T_kwargs,\n    use_ray=False,\n    use_spark=False,\n)\n\nprint(caml_obj.model_Y_X_W)\nprint(caml_obj.model_Y_X_W_T)\nprint(caml_obj.model_T_X_W)\n\nExtraTreesRegressor(max_leaf_nodes=18, n_estimators=24, n_jobs=-1,\n                    random_state=12032022)\nExtraTreesRegressor(max_leaf_nodes=18, n_estimators=24, n_jobs=-1,\n                    random_state=12032022)\nExtraTreesClassifier(criterion='entropy', max_features=0.6334496470801398,\n                     max_leaf_nodes=5, n_estimators=12, n_jobs=-1,\n                     random_state=12032022)\n\n\n\n\n\nfit_validator\nCamlCATE.fit_validator(\n    cate_estimators=['LinearDML', 'CausalForestDML', 'NonParamDML', 'SparseLinearDML-2D', 'DRLearner', 'ForestDRLearner', 'LinearDRLearner', 'DomainAdaptationLearner', 'SLearner', 'TLearner', 'XLearner'],\n    additional_cate_estimators=[],\n    ensemble=False,\n    rscorer_kwargs={},\n    use_ray=False,\n    ray_remote_func_options_kwargs={},\n    validation_size=0.2,\n    test_size=0.2,\n    sample_size=1.0,\n    n_jobs=-1,\n)\nFits the CATE models on the training set and evaluates them & ensembles based on the validation set.\nSets the validation_estimator attribute to the best fitted EconML estimator and cate_estimators attribute to all the fitted CATE models.\n\nParameters\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\ncate_estimators\nIterable[str]\nThe list of CATE estimators to fit and ensemble. Default implies all available models as defined by class.\n['LinearDML', 'CausalForestDML', 'NonParamDML', 'SparseLinearDML-2D', 'DRLearner', 'ForestDRLearner', 'LinearDRLearner', 'DomainAdaptationLearner', 'SLearner', 'TLearner', 'XLearner']\n\n\nadditional_cate_estimators\nlist[tuple[str, BaseCateEstimator]]\nThe list of additional CATE estimators to fit and ensemble\n[]\n\n\nensemble\nbool\nThe boolean indicating whether to ensemble the CATE models & score.\nFalse\n\n\nrscorer_kwargs\ndict\nThe keyword arguments for the econml.score.RScorer object.\n{}\n\n\nuse_ray\nbool\nA boolean indicating whether to use Ray for parallel processing.\nFalse\n\n\nray_remote_func_options_kwargs\ndict\nThe keyword arguments for the Ray remote function options.\n{}\n\n\nvalidation_size\nfloat\nThe fraction of the dataset to use for model scoring via RScorer.\n0.2\n\n\ntest_size\nfloat\nThe fraction of the dataset to hold out for final evaluation in the validate() method.\n0.2\n\n\nsample_size\nfloat\nThe fraction of the datasets to use. Useful for quick testing when dataframe is large. Defaults implies full training data.\n1.0\n\n\nn_jobs\nint\nThe number of parallel jobs to run.\n-1\n\n\n\n\n\nExamples\n\nfrom econml.dr import LinearDRLearner\n\nrscorer_kwargs = {\n    \"cv\": 3,\n    \"mc_iters\": 3,\n}\ncate_estimators = [\"LinearDML\", \"NonParamDML\", \"CausalForestDML\"]\nadditional_cate_estimators = [\n    (\n        \"LinearDRLearner\",\n        LinearDRLearner(\n            model_propensity=caml_obj.model_T_X_W,\n            model_regression=caml_obj.model_Y_X_W_T,\n            discrete_outcome=caml_obj.discrete_outcome,\n            cv=3,\n            random_state=0,\n        ),\n    )\n]\n\ncaml_obj.fit_validator(\n    cate_estimators=cate_estimators,\n    additional_cate_estimators=additional_cate_estimators,\n    rscorer_kwargs=rscorer_kwargs,\n    validation_size=0.2,\n    test_size=0.2\n)\n\nprint(caml_obj.validation_estimator)\nprint(caml_obj.cate_estimators)\n\n&lt;econml.dr._drlearner.LinearDRLearner object at 0x7f0733bbb280&gt;\n[('LinearDML', &lt;econml.dml.dml.LinearDML object at 0x7f0733bb8a00&gt;), ('NonParamDML', &lt;econml.dml.dml.NonParamDML object at 0x7f0733bba200&gt;), ('CausalForestDML', &lt;econml.dml.causal_forest.CausalForestDML object at 0x7f0733bbba00&gt;), ('LinearDRLearner', &lt;econml.dr._drlearner.LinearDRLearner object at 0x7f0733bbb280&gt;)]\n\n\n\n\n\nvalidate\nCamlCATE.validate(\n    n_groups=4,\n    n_bootstrap=100,\n    estimator=None,\n    print_full_report=True,\n)\nValidates the fitted CATE models on the test set to check for generalization performance.\nUses the DRTester class from EconML to obtain the Best Linear Predictor (BLP), Calibration, AUTOC, and QINI. See EconML documentation for more details. In short, we are checking for the ability of the model to find statistically significant heterogeneity in a “well-calibrated” fashion.\nSets the validator_report attribute to the validation report.\n\nParameters\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nn_groups\nint\nThe number of quantile based groups used to calculate calibration scores.\n4\n\n\nn_bootstrap\nint\nThe number of boostrap samples to run when calculating confidence bands.\n100\n\n\nestimator\nBaseCateEstimator | EnsembleCateEstimator | None\nThe estimator to validate. Default implies the best estimator from the validation set.\nNone\n\n\nprint_full_report\nbool\nA boolean indicating whether to print the full validation report.\nTrue\n\n\n\n\n\nExamples\n\ncaml_obj.validate()\n\ncaml_obj.validator_results\n\n   treatment  blp_est  blp_se  blp_pval  qini_est  qini_se  qini_pval  autoc_est  autoc_se  autoc_pval  cal_r_squared\n0          1    0.995   0.006       0.0     2.061    0.061        0.0      5.984     0.222         0.0          0.993\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nfit_final\nCamlCATE.fit_final()\nFits the final estimator on the entire dataset, after validation and testing.\nSets the input_names and final_estimator class attributes.\n\nExamples\n\ncaml_obj.fit_final()\n\nprint(caml_obj.final_estimator)\nprint(caml_obj.input_names)\n\n&lt;econml.dr._drlearner.LinearDRLearner object at 0x7f0733063910&gt;\n{'feature_names': ['W1_continuous', 'X1_continuous'], 'output_names': 'Y1_continuous', 'treatment_names': 'T1_binary'}\n\n\n\n\n\npredict\nCamlCATE.predict(X=None, T0=0, T1=1, T=None)\nPredicts the CATE based on the fitted final estimator for either the internal dataset or provided Data.\nFor binary treatments, the CATE is the estimated effect of the treatment and for a continuous treatment, the CATE is the estimated effect of a one-unit increase in the treatment. This can be modified by setting the T0 and T1 parameters to the desired treatment levels.\n\nParameters\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nX\npandas.DataFrame | np.ndarray | None\nThe DataFrame containing the features (X) for which CATE needs to be predicted. If not provided, defaults to the internal dataset.\nNone\n\n\nT0\nint\nBase treatment for each sample.\n0\n\n\nT1\nint\nTarget treatment for each sample.\n1\n\n\nT\npandas.DataFrame | np.ndarray | None\nTreatment vector if continuous treatment is leveraged for computing marginal effects around treatments for each individual.\nNone\n\n\n\n\n\nReturns\n\n\n\n\n\n\n\n\nName\nType\nDescription\n\n\n\n\n\nnp.ndarray\nThe predicted CATE values if return_predictions is set to True.\n\n\n\n\n\nExamples\n\ncaml_obj.predict()\n\narray([ 11.50064573,  -9.15542281, -32.14314537, ...,  -4.77048878,\n        -4.7504708 , -24.5222364 ])\n\n\n\n\n\nsummarize\nCamlCATE.summarize(cate_predictions=None)\nProvides population summary statistics for the CATE predictions for either the internal results or provided results.\n\nParameters\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\ncate_predictions\nnp.ndarray | None\nThe CATE predictions for which summary statistics will be generated. If not provided, defaults to internal CATE predictions generated by predict() method with X=None.\nNone\n\n\n\n\n\nReturns\n\n\n\n\n\n\n\n\nName\nType\nDescription\n\n\n\n\n\npandas.DataFrame | pandas.Series\nThe summary statistics for the CATE predictions.\n\n\n\n\n\nExamples\n\ncaml_obj.summarize()\n\n\n\n\n\n\n\n\ncate_predictions_0_1\n\n\n\n\ncount\n10000.000000\n\n\nmean\n-7.680559\n\n\nstd\n8.277390\n\n\nmin\n-54.741286\n\n\n25%\n-11.685537\n\n\n50%\n-7.773742\n\n\n75%\n-3.670348\n\n\nmax\n47.041980"
  },
  {
    "objectID": "04_Reference/SyntheticDataGenerator.html",
    "href": "04_Reference/SyntheticDataGenerator.html",
    "title": "SyntheticDataGenerator",
    "section": "",
    "text": "SyntheticDataGenerator(\n    self,\n    n_obs=10000,\n    n_cont_outcomes=1,\n    n_binary_outcomes=0,\n    n_cont_treatments=0,\n    n_binary_treatments=1,\n    n_discrete_treatments=0,\n    n_cont_confounders=0,\n    n_binary_confounders=0,\n    n_discrete_confounders=0,\n    n_cont_modifiers=0,\n    n_binary_modifiers=0,\n    n_discrete_modifiers=0,\n    n_confounding_modifiers=0,\n    stddev_outcome_noise=1.0,\n    stddev_treatment_noise=1.0,\n    causal_model_functional_form='linear',\n    n_nonlinear_transformations=None,\n    seed=None,\n)\nGenerate highly flexible synthetic data for use in causal inference and CaML testing.\nSyntheticDataGenerator is experimental and may change significantly in future versions.\nThe general form of the data generating process is:\n\\[\n\\mathbf{Y_i} = \\tau (\\mathbf{X_i}) \\mathbf{T_i} + g(\\mathbf{W_i}, \\mathbf{X_i}) + \\mathbf{\\epsilon_i}\n\\] \\[\n\\mathbf{T}_i=f(\\mathbf{W}_i, \\mathbf{X_{i,\\mathcal{S}}})+\\mathbf{\\eta_i}\n\\]\nwhere \\(\\mathbf{Y_i}\\) are the outcome(s), \\(\\mathbf{T_i}\\) are the treatment(s), \\(\\mathbf{X_i}\\) are the effect modifiers (leveraged for treatment effect heterogeneity) with an optional random subset \\(\\mathcal{S}\\) selected as confounders, \\(\\mathbf{W_i}\\) are the confounders, \\(\\mathbf{\\epsilon_i}\\) and \\(\\mathbf{\\eta_i}\\) are the error terms drawn from normal distributions with optional specified standard deviation, \\(\\tau\\) is the CATE function, \\(g\\) is the linearly seperable/nuisance component of the outcome function, and \\(f\\) is the treatment function. Note in the case of no modifier variables, we obtain a purely partially linear model, with \\(\\tau\\) as a constant.\nFor linear data generating process, \\(f\\) and \\(g\\) consist of strictly linear terms and untransformed variables. \\(\\tau(\\mathbf{X_i})\\) consists of linear interaction terms.\nFor nonlinear data generating process, \\(f\\) and \\(g\\) are generated via Generalized Additive Models (GAMs) with randomly selected nonlinear transformations. \\(\\tau(\\mathbf{X_i})\\) contains interaction terms with \\(\\mathbf{X}\\) and nonlinear transformations of \\(\\mathbf{X}\\).\nNote in the case of binary/discrete outcomes or treatments, sigmoid and softmax functions are used to transform log odds to probabilities.\nAs a DAG, the data generating process can be roughly represented as:\nFor a more detailed working example, see SyntheticDataGenerator Example."
  },
  {
    "objectID": "04_Reference/SyntheticDataGenerator.html#parameters",
    "href": "04_Reference/SyntheticDataGenerator.html#parameters",
    "title": "SyntheticDataGenerator",
    "section": "Parameters",
    "text": "Parameters\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nn_obs\nint\nNumber of observations.\n10000\n\n\nn_cont_outcomes\nint\nNumber of continuous outcomes (\\(Y\\)).\n1\n\n\nn_binary_outcomes\nint\nNumber of binary outcomes (\\(Y\\)).\n0\n\n\nn_cont_treatments\nint\nNumber of continuous treatments (\\(T\\)).\n0\n\n\nn_binary_treatments\nint\nNumber of binary treatments (\\(T\\)).\n1\n\n\nn_discrete_treatments\nint\nNumber of discrete treatments (\\(T\\)).\n0\n\n\nn_cont_confounders\nint\nNumber of continuous confounders (\\(W\\)).\n0\n\n\nn_binary_confounders\nint\nNumber of binary confounders (\\(W\\)).\n0\n\n\nn_discrete_confounders\nint\nNumber of discrete confounders (\\(W\\)).\n0\n\n\nn_cont_modifiers\nint\nNumber of continuous treatment effect modifiers (\\(X\\)).\n0\n\n\nn_binary_modifiers\nint\nNumber of binary treatment effect modifiers (\\(X\\)).\n0\n\n\nn_discrete_modifiers\nint\nNumber of discrete treatment effect modifiers (\\(X\\)).\n0\n\n\nn_confounding_modifiers\nint\nNumber of confounding treatment effect modifiers (\\(X_{\\mathcal{S}}\\)).\n0\n\n\nstddev_outcome_noise\nfloat\nStandard deviation of the outcome noise (\\(\\epsilon\\)).\n1.0\n\n\nstddev_treatment_noise\nfloat\nStandard deviation of the treatment noise (\\(\\eta\\)).\n1.0\n\n\ncausal_model_functional_form\nstr\nFunctional form of the causal model, can be “linear” or “nonlinear”.\n'linear'\n\n\nn_nonlinear_transformations\nint | None\nNumber of nonlinear transformations, only applies if causal_model_functional_form=“nonlinear”.\nNone\n\n\nseed\nint | None\nRandom seed to use for generating the data.\nNone"
  },
  {
    "objectID": "04_Reference/SyntheticDataGenerator.html#attributes",
    "href": "04_Reference/SyntheticDataGenerator.html#attributes",
    "title": "SyntheticDataGenerator",
    "section": "Attributes",
    "text": "Attributes\n\n\n\n\n\n\n\n\nName\nType\nDescription\n\n\n\n\ndf\npd.DataFrame\nThe data generated by the data generation process.\n\n\ncates\npd.DataFrame\nThe true conditional average treatment effects (CATEs) of the data.\n\n\nates\npd.DataFrame\nThe true average treatment effects (ATEs) of the data.\n\n\ndgp\ndict\nThe true data generating processes of the treatments and outcomes. Contains the design matrix formula, parameters, noise, raw_scores, and function used to generate the data."
  },
  {
    "objectID": "04_Reference/SyntheticDataGenerator.html#examples",
    "href": "04_Reference/SyntheticDataGenerator.html#examples",
    "title": "SyntheticDataGenerator",
    "section": "Examples",
    "text": "Examples\n\nfrom caml.extensions.synthetic_data import SyntheticDataGenerator\n\ndata_generator = SyntheticDataGenerator(n_cont_outcomes=1,\n                                        n_binary_treatments=1,\n                                        n_cont_confounders=2,\n                                        n_cont_modifiers=2,\n                                        seed=10)\ndata_generator.df\n\n\n\n\n\n\n\n\nW1_continuous\nW2_continuous\nX1_continuous\nX2_continuous\nT1_binary\nY1_continuous\n\n\n\n\n0\n0.354380\n-3.252276\n2.715662\n-3.578800\n1\n-10.372900\n\n\n1\n0.568499\n2.484069\n-6.402235\n-2.611815\n0\n13.437245\n\n\n2\n0.162715\n8.842902\n1.288770\n-3.788545\n0\n-51.695014\n\n\n3\n0.362944\n-0.959538\n1.080988\n-3.542550\n1\n-10.163549\n\n\n4\n0.612101\n1.417536\n4.143630\n-4.112453\n0\n-33.613222\n\n\n...\n...\n...\n...\n...\n...\n...\n\n\n9995\n0.340436\n0.241095\n-6.524222\n-3.188783\n1\n28.300943\n\n\n9996\n0.019523\n1.338152\n-2.555492\n-3.643733\n1\n-0.252336\n\n\n9997\n0.325401\n1.258659\n-3.340546\n-4.255203\n1\n5.992318\n\n\n9998\n0.586715\n1.263264\n-2.826709\n-4.149383\n1\n1.543645\n\n\n9999\n0.003002\n6.723381\n1.260782\n-3.660600\n1\n-44.114285\n\n\n\n\n10000 rows × 6 columns\n\n\n\n\ndata_generator.cates\n\n\n\n\n\n\n\n\nCATE_of_T1_binary_on_Y1_continuous\n\n\n\n\n0\n-2.446437\n\n\n1\n6.601527\n\n\n2\n-1.289209\n\n\n3\n-0.922547\n\n\n4\n-4.137320\n\n\n...\n...\n\n\n9995\n6.299893\n\n\n9996\n2.337202\n\n\n9997\n2.618441\n\n\n9998\n2.223415\n\n\n9999\n-1.171886\n\n\n\n\n10000 rows × 1 columns\n\n\n\n\ndata_generator.ates\n\n\n\n\n\n\n\n\nTreatment\nATE\n\n\n\n\n0\nT1_binary_on_Y1_continuous\n0.678957\n\n\n\n\n\n\n\n\nfor t, df in data_generator.dgp.items():\n    print(f\"\\nDGP for {t}:\")\n    print(df)\n\n\nDGP for T1_binary:\n{'formula': '1 + W1_continuous + W2_continuous', 'params': array([ 0.4609703 ,  0.2566887 , -0.03896251]), 'noise': array([ 0.14476544, -0.51949108, -1.88624383, ..., -0.59020672,\n        0.87157749,  0.0697439 ]), 'raw_scores': array([0.69496136, 0.49765524, 0.15083742, ..., 0.47633017, 0.80751307,\n       0.5669763 ]), 'function': &lt;function SyntheticDataGenerator._create_dgp_function.&lt;locals&gt;.f_binary at 0x7efca67dd3f0&gt;}\n\nDGP for Y1_continuous:\n{'formula': '1 + W1_continuous + W2_continuous + X1_continuous + X2_continuous + T1_binary + T1_binary*X1_continuous + T1_binary*X2_continuous', 'params': array([-1.80242342,  1.11129512, -4.1263484 , -4.82709212,  1.87319625,\n        2.60635605, -0.91633948,  0.71653213]), 'noise': array([-0.12533653, -1.15370094, -0.26681987, ...,  1.85405702,\n       -0.18887322, -0.45736583]), 'raw_scores': array([-10.3729005 ,  13.43724492, -51.69501383, ...,   5.99231789,\n         1.54364473, -44.11428464]), 'function': &lt;function SyntheticDataGenerator._create_dgp_function.&lt;locals&gt;.f_cont at 0x7efca67dd480&gt;}"
  },
  {
    "objectID": "04_Reference/SyntheticDataGenerator.html#methods",
    "href": "04_Reference/SyntheticDataGenerator.html#methods",
    "title": "SyntheticDataGenerator",
    "section": "Methods",
    "text": "Methods\n\n\n\nName\nDescription\n\n\n\n\ncreate_design_matrix\nCreate a design matrix from a formula and data.\n\n\n\n\ncreate_design_matrix\nextensions.synthetic_data.SyntheticDataGenerator.create_design_matrix(\n    df,\n    formula,\n    return_type='dataframe',\n    **kwargs,\n)\nCreate a design matrix from a formula and data.\nThis method can be used to reconstruct the design matrices used to generate the treatment and outcome variables. Furthermore, using dgp attribute, using the returned design matrix, one can generate the original outcomes and treatment variables. See below example.\n\nParameters\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\ndf\npd.DataFrame\nThe input data.\nrequired\n\n\nformula\nstr\nThe formula to be used with patsy.\nrequired\n\n\nreturn_type\nstr\nThe type of the returned design matrix. Can be either “dataframe” or “matrix”. Default is “dataframe”.\n'dataframe'\n\n\n**kwargs\n\nAdditional keyword arguments to be passed to patsy.dmatrix.\n{}\n\n\n\n\n\nReturns\n\n\n\nName\nType\nDescription\n\n\n\n\n\npd.DataFrame | np.ndarray\nThe design matrix.\n\n\n\n\n\nExamples\n\nimport numpy as np\ndf = data_generator.df\ndgp = data_generator.dgp['Y1_continuous']\n\ndesign_matrix = data_generator.create_design_matrix(df,formula=dgp['formula'])\n\nprint(design_matrix.columns)\n\n# Recreate Y1_continuous\nparams = dgp['params']\nnoise = dgp['noise']\nf = dgp['function']\n\nf(design_matrix,params,noise)\n\nassert np.allclose(f(design_matrix,params,noise), df['Y1_continuous'])\n\nIndex(['Intercept', 'W1_continuous', 'W2_continuous', 'X1_continuous',\n       'X2_continuous', 'T1_binary', 'T1_binary:X1_continuous',\n       'T1_binary:X2_continuous'],\n      dtype='object')"
  },
  {
    "objectID": "02_Concepts/models.html",
    "href": "02_Concepts/models.html",
    "title": "Model Specifications",
    "section": "",
    "text": "The model is given by: \\[\n\\begin{equation}\n\\mathbf{Y} = T \\beta + \\mathbf{Q}\\mathbf{\\Gamma} + \\left(T \\circ \\mathbf{Q}\\right)\\mathbf{\\Omega} + \\mathbf{W}\\mathbf{\\Psi} + \\mathbf{E}\n\\tag{1}\n\\end{equation}\n\\]\nwhere\n\n\\(\\mathbf{Y}_{n \\times p}\\) is the matrix of \\(p\\) outcomes\n\\(T_{n \\times 1}\\) is the treatment variable\n\\(\\mathbf{Q}_{n \\times (j+l)} = \\bigl[\\mathbf{X} \\; \\mathbf{G} \\bigr]\\) is the horizontal stack matrix of \\(j\\) covariates and \\(l\\) group variables\n\\(\\mathbf{W}_{n \\times m}\\) is the matrix of \\(m\\) control covariates\n\\(\\beta_{1 \\times p}\\) is the vector of coefficients on \\(T\\)\n\\(\\mathbf{\\Gamma}_{(j+l) \\times p}\\) is the matrix of coefficients on \\(\\mathbf{Q}\\)\n\\(\\mathbf{\\Omega}_{(j+l) \\times p}\\) is the matrix of coefficients on the interaction terms between \\(T\\) and \\(\\mathbf{Q}\\)\n\\(\\mathbf{\\Psi}_{m \\times p}\\) is the matrix of coefficients on \\(\\mathbf{W}\\)\n\\(\\mathbf{E}_{n \\times p}\\) is the error term matrix\n\n\\(\\mathbf{Q}\\) contains the covariates and group variables used to model treatment effect heterogeneity via interaction terms.\n\n\n\nOur average treatment effects (ATE) \\(\\tau\\) for a binary treatment variable \\(T\\) is defined as:\n\\[\n\\tau = \\mathbb{E}_n[\\mathbf{Y}_1 - \\mathbf{Y}_0]\n\\]\nwhere \\(\\mathbf{Y}_1\\) and \\(\\mathbf{Y}_0\\) are the potential outcomes. Assuming exogeneity in \\(T\\), the ATEs are identified and can be estimated as follows:\n\\[\n\\tau = \\mathbb{E}_n\\left[\\mathbb{E}\\left[\\mathbf{Y} \\mid T = 1\\right] - \\mathbb{E}\\left[\\mathbf{Y} \\mid T = 0\\right]\\right]\n\\]\nWithin the context of (1), this can be estimated via:\n\\[\n\\mathbf{\\tau} = \\mathbf{\\Theta'}\\bar{d}\n\\]\nwhere \\(\\mathbf{\\Theta'} = \\left[\\beta' \\; \\mathbf{\\Gamma'} \\; \\mathbf{\\Omega'} \\; \\mathbf{\\Psi'}\\right]\\) is the horizontally concatenated matrix of transposed coefficient matrices, and \\(\\bar{d} = \\mathbb{E}_n\\left[D_{T=1} - D_{T=0}\\right]\\) is the the average difference in the design matrix \\(D\\) of (1) from toggling the treatment variable across all observations.\nFurthermore, for each outcome \\(k \\in \\{1,2,...,p\\}\\), we can estimate the standard error of the ATE as follows: \\[\n\\text{SE}(\\tau_k) = \\sqrt{\\bar{d}'\\text{VCV}(\\mathbf{\\Theta}_k)\\bar{d}}\n\\]\nwhere \\(\\text{VCV}(\\mathbf{\\Theta}_k)\\) is the variance-covariance matrix of the estimated coefficients for the \\(k\\)-th outcome.\nThis logic extends naturally to the estimation of GATEs and CATEs (e.g., \\(\\bar{d} = \\mathbb{E}_n\\left[D_{T=1} - D_{T=0} | \\mathbf{G}=g\\right]\\), \\(\\bar{d} = \\mathbb{E}_n\\left[D_{T=1} - D_{T=0} | \\mathbf{G}=g, \\mathbf{X}=x\\right]\\), \\(\\dots\\), etc.) and to continuous treatments (e.g., \\(\\bar{d} = \\mathbb{E}_n\\left[D_{T=t+1} - D_{T=t}\\right]\\), \\(\\dots\\), etc.).",
    "crumbs": [
      "Model Specifications"
    ]
  },
  {
    "objectID": "02_Concepts/models.html#fastols",
    "href": "02_Concepts/models.html#fastols",
    "title": "Model Specifications",
    "section": "",
    "text": "The model is given by: \\[\n\\begin{equation}\n\\mathbf{Y} = T \\beta + \\mathbf{Q}\\mathbf{\\Gamma} + \\left(T \\circ \\mathbf{Q}\\right)\\mathbf{\\Omega} + \\mathbf{W}\\mathbf{\\Psi} + \\mathbf{E}\n\\tag{1}\n\\end{equation}\n\\]\nwhere\n\n\\(\\mathbf{Y}_{n \\times p}\\) is the matrix of \\(p\\) outcomes\n\\(T_{n \\times 1}\\) is the treatment variable\n\\(\\mathbf{Q}_{n \\times (j+l)} = \\bigl[\\mathbf{X} \\; \\mathbf{G} \\bigr]\\) is the horizontal stack matrix of \\(j\\) covariates and \\(l\\) group variables\n\\(\\mathbf{W}_{n \\times m}\\) is the matrix of \\(m\\) control covariates\n\\(\\beta_{1 \\times p}\\) is the vector of coefficients on \\(T\\)\n\\(\\mathbf{\\Gamma}_{(j+l) \\times p}\\) is the matrix of coefficients on \\(\\mathbf{Q}\\)\n\\(\\mathbf{\\Omega}_{(j+l) \\times p}\\) is the matrix of coefficients on the interaction terms between \\(T\\) and \\(\\mathbf{Q}\\)\n\\(\\mathbf{\\Psi}_{m \\times p}\\) is the matrix of coefficients on \\(\\mathbf{W}\\)\n\\(\\mathbf{E}_{n \\times p}\\) is the error term matrix\n\n\\(\\mathbf{Q}\\) contains the covariates and group variables used to model treatment effect heterogeneity via interaction terms.\n\n\n\nOur average treatment effects (ATE) \\(\\tau\\) for a binary treatment variable \\(T\\) is defined as:\n\\[\n\\tau = \\mathbb{E}_n[\\mathbf{Y}_1 - \\mathbf{Y}_0]\n\\]\nwhere \\(\\mathbf{Y}_1\\) and \\(\\mathbf{Y}_0\\) are the potential outcomes. Assuming exogeneity in \\(T\\), the ATEs are identified and can be estimated as follows:\n\\[\n\\tau = \\mathbb{E}_n\\left[\\mathbb{E}\\left[\\mathbf{Y} \\mid T = 1\\right] - \\mathbb{E}\\left[\\mathbf{Y} \\mid T = 0\\right]\\right]\n\\]\nWithin the context of (1), this can be estimated via:\n\\[\n\\mathbf{\\tau} = \\mathbf{\\Theta'}\\bar{d}\n\\]\nwhere \\(\\mathbf{\\Theta'} = \\left[\\beta' \\; \\mathbf{\\Gamma'} \\; \\mathbf{\\Omega'} \\; \\mathbf{\\Psi'}\\right]\\) is the horizontally concatenated matrix of transposed coefficient matrices, and \\(\\bar{d} = \\mathbb{E}_n\\left[D_{T=1} - D_{T=0}\\right]\\) is the the average difference in the design matrix \\(D\\) of (1) from toggling the treatment variable across all observations.\nFurthermore, for each outcome \\(k \\in \\{1,2,...,p\\}\\), we can estimate the standard error of the ATE as follows: \\[\n\\text{SE}(\\tau_k) = \\sqrt{\\bar{d}'\\text{VCV}(\\mathbf{\\Theta}_k)\\bar{d}}\n\\]\nwhere \\(\\text{VCV}(\\mathbf{\\Theta}_k)\\) is the variance-covariance matrix of the estimated coefficients for the \\(k\\)-th outcome.\nThis logic extends naturally to the estimation of GATEs and CATEs (e.g., \\(\\bar{d} = \\mathbb{E}_n\\left[D_{T=1} - D_{T=0} | \\mathbf{G}=g\\right]\\), \\(\\bar{d} = \\mathbb{E}_n\\left[D_{T=1} - D_{T=0} | \\mathbf{G}=g, \\mathbf{X}=x\\right]\\), \\(\\dots\\), etc.) and to continuous treatments (e.g., \\(\\bar{d} = \\mathbb{E}_n\\left[D_{T=t+1} - D_{T=t}\\right]\\), \\(\\dots\\), etc.).",
    "crumbs": [
      "Model Specifications"
    ]
  },
  {
    "objectID": "02_Concepts/motivation.html",
    "href": "02_Concepts/motivation.html",
    "title": "Motivation",
    "section": "",
    "text": "Forthcoming\n\n\n\n Back to top",
    "crumbs": [
      "Motivation"
    ]
  },
  {
    "objectID": "01_Home/quickstart.html",
    "href": "01_Home/quickstart.html",
    "title": "Tutorial: Quick Start",
    "section": "",
    "text": "Forthcoming\n\n\n\n Back to top",
    "crumbs": [
      "Tutorial: Quick Start"
    ]
  },
  {
    "objectID": "05_Contributors/testing.html",
    "href": "05_Contributors/testing.html",
    "title": "Testing",
    "section": "",
    "text": "We utilize marimo notebooks under the notebooks/dev/ directory for testing the api. After setting up the environment, you can run marimo edit to host notebook server on your local machine. For any examples worth including in the documentation, we add these notebooks to the notebooks/examples/ directory.\nFeel free to go about your development process however you see fit, but for any major functionality changes, make sure any examples are updated accordingly. If you choose to develop with Jupyter notebooks, you can convert to marimo via marimo convert *.ipynb -o *.py and vice-versa.",
    "crumbs": [
      "Testing"
    ]
  },
  {
    "objectID": "05_Contributors/testing.html#informal-testingdevelopment",
    "href": "05_Contributors/testing.html#informal-testingdevelopment",
    "title": "Testing",
    "section": "",
    "text": "We utilize marimo notebooks under the notebooks/dev/ directory for testing the api. After setting up the environment, you can run marimo edit to host notebook server on your local machine. For any examples worth including in the documentation, we add these notebooks to the notebooks/examples/ directory.\nFeel free to go about your development process however you see fit, but for any major functionality changes, make sure any examples are updated accordingly. If you choose to develop with Jupyter notebooks, you can convert to marimo via marimo convert *.ipynb -o *.py and vice-versa.",
    "crumbs": [
      "Testing"
    ]
  },
  {
    "objectID": "05_Contributors/testing.html#formal-testing",
    "href": "05_Contributors/testing.html#formal-testing",
    "title": "Testing",
    "section": "Formal Testing",
    "text": "Formal Testing\nWe utilize pytest for testing our codebase.\n\nUnit Testing\nUnit tests are under the tests/caml/ directory following the same structure of the caml/ prefixed by “test_”. For example, if we wanted to write tests for cate.py, we would create a new file to build these tests tests/caml/core/test_cate.py.\nTo run unit tests, simply run pytest from command line. This will run your unit tests (with respective output printed in terminal).\nAdditionally, an html report of the coverage will be exported to tests/reports/htmlcov, which can be a useful tool for interactively evaluating the coverage of your unit tests.\n\n\nAdvanced Testing\nUnit tests are automatically run during PR process via GitHub Actions. Integration & regression testing forthcoming.",
    "crumbs": [
      "Testing"
    ]
  },
  {
    "objectID": "05_Contributors/conventional_commits.html",
    "href": "05_Contributors/conventional_commits.html",
    "title": "Conventional Commits",
    "section": "",
    "text": "This project uses conventional commits for Pull Request titles, as they are ultimately used as the commit names on the main branch. What are conventional commits? In the words of the official documentation:\n\nThe Conventional Commits specification is a lightweight convention on top of commit messages. It provides an easy set of rules for creating an explicit commit history; which makes it easier to write automated tools on top of.\n\nThe PR titles should thus take the general form:\n&lt;type&gt;[optional scope]: &lt;description&gt;\nAn example would be:\nfix(types): make all floats double\nValid types for Caml are as follows:\n\nbuild: Changes that affect the build system or external dependencies\nci: Changes to our CI/CD configuration files and scripts\ndocs: Documentation only changes\nfeat: A new feature\nfix: A bug fix\nperf: A code change that improves performance\nrefactor: A code change that neither fixes a bug nor adds a feature\nstyle: Changes that do not affect the meaning of the code (white-space, formatting, missing semi-colons, etc)\ntest: Adding missing tests or correcting existing tests\nrevert: Reverting code changes to a previous state\nchore: Routine tasks that don’t fit in any of the above\n\nWe use the following regex to validate PR titles (test it!):\n^(build|chore|ci|docs|feat|fix|perf|refactor|revert|style|test|release)(.+)?(!)?:\\ .+\n\n\n\n Back to top",
    "crumbs": [
      "Conventional Commits"
    ]
  },
  {
    "objectID": "03_Examples/FastOLS.html",
    "href": "03_Examples/FastOLS.html",
    "title": "FastOLS",
    "section": "",
    "text": "In this notebook, we’ll walk through an example of generating synthetic data, estimating treatment effects (ATEs, GATEs, and CATEs) using FastOLS, and comparing to our ground truth.\nFastOLS is particularly useful when efficiently estimating ATEs and GATEs is of primary interest and the treatment is exogenous or confounding takes on a particularly simple functional form.\nFastOLS assumes linear treatment effects & heterogeneity. This is generally sufficient for estimation of ATEs and GATEs, but can perform poorly in CATE estimation & prediction when heterogeneity is complex & nonlinear. For high quality CATE estimation, we recommend leveraging CamlCATE.",
    "crumbs": [
      "FastOLS"
    ]
  },
  {
    "objectID": "03_Examples/FastOLS.html#generate-synthetic-data",
    "href": "03_Examples/FastOLS.html#generate-synthetic-data",
    "title": "FastOLS",
    "section": "Generate Synthetic Data",
    "text": "Generate Synthetic Data\nHere we’ll leverage the SyntheticDataGenerator class to generate a linear synthetic data generating process, with an exogenous binary treatment, a continuous & a binary outcome, and binary & continuous mediating covariates.\n\nfrom caml.logging import configure_logging\nimport logging\n\nconfigure_logging(level=logging.DEBUG)\n\n[06/10/25 15:22:53] DEBUG    Logging configured with level: DEBUG                                     logging.py:70\n\n\n\n\nfrom caml.extensions.synthetic_data import SyntheticDataGenerator\n\ndata_generator = SyntheticDataGenerator(\n    n_obs=10_000,\n    n_cont_outcomes=1,\n    n_binary_outcomes=1,\n    n_binary_treatments=1,\n    n_cont_confounders=2,\n    n_cont_modifiers=3,\n    n_binary_modifiers=2,\n    stddev_outcome_noise=1,\n    stddev_treatment_noise=1,\n    causal_model_functional_form=\"linear\",\n    seed=10,\n)\n\n[06/10/25 15:22:54] WARNING  SyntheticDataGenerator is experimental and may change in future         generics.py:44\n                             versions.                                                                             \n\n\n\nWe can print our simulated data via:\n\ndata_generator.df\n\n\n\n\n\n\n\n\nW1_continuous\nW2_continuous\nX1_continuous\nX2_continuous\nX3_continuous\nX4_binary\nX5_binary\nT1_binary\nY1_continuous\nY2_binary\n\n\n\n\n0\n0.354380\n-3.252276\n2.715662\n-3.578800\n-3.148647\n0\n0\n1\n-11.319410\n0\n\n\n1\n0.568499\n2.484069\n-6.402235\n-2.611815\n-0.311498\n0\n0\n1\n9.167825\n1\n\n\n2\n0.162715\n8.842902\n1.288770\n-3.788545\n-1.780285\n0\n0\n0\n-21.010316\n0\n\n\n3\n0.362944\n-0.959538\n1.080988\n-3.542550\n-5.419263\n1\n0\n1\n-2.194239\n0\n\n\n4\n0.612101\n1.417536\n4.143630\n-4.112453\n-4.551051\n0\n0\n1\n-20.600668\n1\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n9995\n0.340436\n0.241095\n-6.524222\n-3.188783\n-2.313515\n0\n0\n1\n16.349832\n1\n\n\n9996\n0.019523\n1.338152\n-2.555492\n-3.643733\n-5.517065\n0\n1\n1\n5.386195\n1\n\n\n9997\n0.325401\n1.258659\n-3.340546\n-4.255203\n-2.272974\n0\n0\n1\n-1.037638\n0\n\n\n9998\n0.586715\n1.263264\n-2.826709\n-4.149383\n-2.712932\n0\n0\n1\n-0.235958\n1\n\n\n9999\n0.003002\n6.723381\n1.260782\n-3.660600\n-0.962271\n0\n0\n0\n-20.007912\n1\n\n\n\n\n10000 rows × 10 columns\n\n\n\nTo inspect our true data generating process, we can call data_generator.dgp. Furthermore, we will have our true CATEs and ATEs at our disposal via data_generator.cates & data_generator.ates, respectively. We’ll use this as our source of truth for performance evaluation of our CATE estimator.\n\nfor t, df in data_generator.dgp.items():\n    print(f\"\\nDGP for {t}:\")\n    print(df)\n\n\nDGP for T1_binary:\n{'formula': '1 + W1_continuous + W2_continuous', 'params': array([0.00323235, 0.14809798, 0.00393589]), 'noise': array([ 0.41708078,  2.72097405, -0.05882655, ...,  0.53984804,\n        1.50464572, -0.08231107]), 'raw_scores': array([0.6130131 , 0.9436502 , 0.50082704, ..., 0.6447923 , 0.83198225,\n       0.48696005]), 'function': &lt;function SyntheticDataGenerator._create_dgp_function.&lt;locals&gt;.f_binary at 0x7f88407cf2e0&gt;}\n\nDGP for Y1_continuous:\n{'formula': '1 + W1_continuous + W2_continuous + X1_continuous + X2_continuous + X3_continuous + X4_binary + X5_binary + T1_binary + T1_binary*X1_continuous + T1_binary*X2_continuous + T1_binary*X3_continuous + T1_binary*X4_binary + T1_binary*X5_binary', 'params': array([-0.35986539, -3.30656481, -1.08522702, -2.03156347,  4.15748518,\n       -3.7649075 ,  2.0412171 , -4.06259065,  1.19724956, -1.49108621,\n       -0.33216768,  1.0519125 , -0.68252501,  0.57505328]), 'noise': array([ 0.19963494, -0.500903  ,  1.15056187, ..., -1.08977141,\n        0.79262583,  1.81566293]), 'raw_scores': array([-11.31940995,   9.16782505, -21.01031565, ...,  -1.03763754,\n        -0.23595847, -20.00791171]), 'function': &lt;function SyntheticDataGenerator._create_dgp_function.&lt;locals&gt;.f_cont at 0x7f88407cf7f0&gt;}\n\nDGP for Y2_binary:\n{'formula': '1 + W1_continuous + W2_continuous + X1_continuous + X2_continuous + X3_continuous + X4_binary + X5_binary + T1_binary + T1_binary*X1_continuous + T1_binary*X2_continuous + T1_binary*X3_continuous + T1_binary*X4_binary + T1_binary*X5_binary', 'params': array([-0.69301323,  0.54152509,  0.39837891,  0.15335688,  0.39980853,\n       -0.31388112, -0.18490127,  0.25395436,  0.19802621, -0.84703988,\n       -0.12066193,  0.09225998,  0.37205785, -0.20954318]), 'noise': array([ 1.07352996,  0.43383419, -1.01413765, ..., -1.15478882,\n        0.58572912,  0.22523345]), 'raw_scores': array([0.06237408, 0.99      , 0.75869455, ..., 0.65949716, 0.91015409,\n       0.77628529]), 'function': &lt;function SyntheticDataGenerator._create_dgp_function.&lt;locals&gt;.f_binary at 0x7f88407e5d80&gt;}\n\n\n\ndata_generator.cates\n\n\n\n\n\n\n\n\nCATE_of_T1_binary_on_Y1_continuous\nCATE_of_T1_binary_on_Y2_binary\n\n\n\n\n0\n-4.975376\n-0.116864\n\n\n1\n11.283425\n0.779704\n\n\n2\n-1.338690\n-0.070368\n\n\n3\n-5.620992\n-0.088495\n\n\n4\n-8.402543\n-0.582547\n\n\n...\n...\n...\n\n\n9995\n9.551022\n0.857542\n\n\n9996\n0.989622\n0.391185\n\n\n9997\n5.200762\n0.679941\n\n\n9998\n3.936641\n0.602064\n\n\n9999\n-0.478977\n-0.111850\n\n\n\n\n10000 rows × 2 columns\n\n\n\n\ndata_generator.ates\n\n\n\n\n\n\n\n\nTreatment\nATE\n\n\n\n\n0\nT1_binary_on_Y1_continuous\n1.195965\n\n\n1\nT1_binary_on_Y2_binary\n0.152762",
    "crumbs": [
      "FastOLS"
    ]
  },
  {
    "objectID": "03_Examples/FastOLS.html#running-fastols",
    "href": "03_Examples/FastOLS.html#running-fastols",
    "title": "FastOLS",
    "section": "Running FastOLS",
    "text": "Running FastOLS\n\nClass Instantiation\nWe can instantiate and observe our FastOLS object via:\n\nfrom caml import FastOLS\n\nfo_obj = FastOLS(\n    Y=[c for c in data_generator.df.columns if \"Y\" in c],\n    T=\"T1_binary\",\n    G=[\n        c\n        for c in data_generator.df.columns\n        if \"X\" in c and (\"bin\" in c or \"dis\" in c)\n    ],\n    X=[c for c in data_generator.df.columns if \"X\" in c and \"cont\" in c],\n    W=[c for c in data_generator.df.columns if \"W\" in c],\n    xformula=\"+ W1_continuous**2\",\n    engine=\"cpu\",\n    discrete_treatment=True,\n)\n\n                    WARNING  FastOLS is experimental and may change in future versions.              generics.py:44\n\n\n\n                    DEBUG    Initializing FastOLS with parameters: Y=['Y1_continuous', 'Y2_binary'],     ols.py:146\n                             T=T1_binary, G=['X4_binary', 'X5_binary'], X=['X1_continuous',                        \n                             'X2_continuous', 'X3_continuous'], W=['W1_continuous', 'W2_continuous'],              \n                             discrete_treatment=True, engine=cpu                                                   \n\n\n\n                    DEBUG    Created formula: Q('Y1_continuous') + Q('Y2_binary') ~ C(Q('T1_binary')) +  ols.py:177\n                             C(Q('X4_binary'))*C(Q('T1_binary')) + C(Q('X5_binary'))*C(Q('T1_binary')) +           \n                             Q('X1_continuous')*C(Q('T1_binary')) + Q('X2_continuous')*C(Q('T1_binary'))           \n                             + Q('X3_continuous')*C(Q('T1_binary')) + Q('W1_continuous') +                         \n                             Q('W2_continuous') + W1_continuous**2                                                 \n\n\n\n\nprint(fo_obj)\n\n================== FastOLS Object ==================\nEngine: cpu\nOutcome Variable: ['Y1_continuous', 'Y2_binary']\nTreatment Variable: T1_binary\nDiscrete Treatment: True\nGroup Variables: ['X4_binary', 'X5_binary']\nFeatures/Confounders for Heterogeneity (X): ['X1_continuous', 'X2_continuous', 'X3_continuous']\nFeatures/Confounders as Controls (W): ['W1_continuous', 'W2_continuous']\nFormula: Q('Y1_continuous') + Q('Y2_binary') ~ C(Q('T1_binary')) + C(Q('X4_binary'))*C(Q('T1_binary')) + C(Q('X5_binary'))*C(Q('T1_binary')) + Q('X1_continuous')*C(Q('T1_binary')) + Q('X2_continuous')*C(Q('T1_binary')) + Q('X3_continuous')*C(Q('T1_binary')) + Q('W1_continuous') + Q('W2_continuous') + W1_continuous**2\n\n\n\n\n\nFitting OLS model\nWe can now leverage the fit method to estimate the model outlined by fo_obj.formula. To capitalize on efficiency gains and parallelization in the estimation of GATEs, we will pass estimate_effects=True. The n_jobs argument will control the number of parallel jobs (GATE estimations) executed at a time. We will set n_jobs=-1 to use all available cores for parallelization.\n\n\n\n\n\n\nWarning\n\n\n\nWhen dealing with large datasets, setting n_jobs to a more conservative value can help prevent OOM errors.\n\n\nFor heteroskedasticity-robust variance estimation, we will also pass robust_vcv=True.\n\nfo_obj.fit(\n    data_generator.df, n_jobs=-1, estimate_effects=True, cov_type=\"HC1\"\n)\n\n                    DEBUG    Creating model matrix...                                                    ols.py:546\n\n\n\n                    DEBUG    Design Matrix Creation completed in 0.06 seconds                        generics.py:73\n\n\n\n                    INFO     Fitting regression model...                                                 ols.py:508\n\n\n\n                    DEBUG    Model Fitting completed in 0.02 seconds                                 generics.py:73\n\n\n\n                    DEBUG    Creating treatment difference matrix...                                     ols.py:560\n\n\n\n                    DEBUG    Design Matrix Creation completed in 0.12 seconds                        generics.py:73\n\n\n\n                    INFO     Estimating Average Treatment Effects (ATEs)...                              ols.py:296\n\n\n\n                    DEBUG    ATE Estimation completed in 0.00 seconds                                generics.py:73\n\n\n\n                    INFO     Estimating Group Average Treatment Effects (GATEs)...                       ols.py:652\n\n\n\n                    DEBUG    Starting parallel processing with -1 jobs                                   ols.py:680\n\n\n\n                    DEBUG    Prespecified GATE Estimation completed in 0.02 seconds                  generics.py:73\n\n\n\nWe can now inspect the model fitted results and estimated treatment effects:\n\nfo_obj.params\n# fo_obj.vcv\n# fo_obj.std_err\n# fo_obj.fitted_values\n# fo_obj.residuals\n\narray([[-0.4519221 ,  0.43114593],\n       [ 1.38073585, -0.0744549 ],\n       [ 2.00450453, -0.01259566],\n       [-4.04210602,  0.02437893],\n       [-0.65283268,  0.04810221],\n       [ 0.49183752, -0.01360602],\n       [-2.02552124,  0.02571064],\n       [-1.49027655, -0.10135024],\n       [ 4.14289136,  0.06712511],\n       [-0.28916188, -0.05434839],\n       [-3.76790351, -0.05556488],\n       [ 1.05912299,  0.03298887],\n       [-1.63464173,  0.03581225],\n       [-1.07407314,  0.04467536],\n       [-1.63464173,  0.03581225]])\n\n\n\nfo_obj.treatment_effects.keys()\n\ndict_keys(['overall', 'X4_binary-0', 'X4_binary-1', 'X5_binary-0', 'X5_binary-1'])\n\n\n\nfo_obj.treatment_effects[\"overall\"]\n\n{'outcome': ['Y1_continuous', 'Y2_binary'],\n 'ate': array([[1.19490455, 0.13807782]]),\n 'std_err': array([[0.01986595, 0.00783239]]),\n 't_stat': array([[60.14836561, 17.62907058]]),\n 'pval': array([[0., 0.]]),\n 'n': 10000,\n 'n_treated': 5172,\n 'n_control': 4828}\n\n\nHere we have direct access to the model parameters (fo_obj.params), variance-covariance matrices (fo_obj.vcv]), standard_errors (fo_obj.std_err), and estimated treatment effects (fo_obj.treatment_effects).\nTo make the treatment effect results more readable, we can leverage the prettify_treatment_effects method:\n\nfo_obj.prettify_treatment_effects()\n\n\n\n\n\n\n\n\ngroup\nmembership\noutcome\nate\nstd_err\nt_stat\npval\nn\nn_treated\nn_control\n\n\n\n\n0\noverall\nNone\nY1_continuous\n1.194905\n0.019866\n60.148366\n0.000000e+00\n10000\n5172\n4828\n\n\n1\noverall\nNone\nY2_binary\n0.138078\n0.007832\n17.629071\n0.000000e+00\n10000\n5172\n4828\n\n\n2\nX4_binary\n0\nY1_continuous\n1.336099\n0.021504\n62.133499\n0.000000e+00\n8536\n4374\n4162\n\n\n3\nX4_binary\n0\nY2_binary\n0.134263\n0.008443\n15.902456\n0.000000e+00\n8536\n4374\n4162\n\n\n4\nX4_binary\n1\nY1_continuous\n0.371658\n0.051932\n7.156565\n8.273382e-13\n1464\n798\n666\n\n\n5\nX4_binary\n1\nY2_binary\n0.160322\n0.021007\n7.631865\n2.309264e-14\n1464\n798\n666\n\n\n6\nX5_binary\n0\nY1_continuous\n1.149854\n0.021556\n53.342794\n0.000000e+00\n8564\n4430\n4134\n\n\n7\nX5_binary\n0\nY2_binary\n0.142165\n0.008438\n16.848194\n0.000000e+00\n8564\n4430\n4134\n\n\n8\nX5_binary\n1\nY1_continuous\n1.463574\n0.051157\n28.609334\n0.000000e+00\n1436\n742\n694\n\n\n9\nX5_binary\n1\nY2_binary\n0.113703\n0.020950\n5.427234\n5.723416e-08\n1436\n742\n694\n\n\n\n\n\n\n\nComparing our overall treatment effect (ATE) to the ground truth, we have:\n\ndata_generator.ates\n\n\n\n\n\n\n\n\nTreatment\nATE\n\n\n\n\n0\nT1_binary_on_Y1_continuous\n1.195965\n\n\n1\nT1_binary_on_Y2_binary\n0.152762\n\n\n\n\n\n\n\nWe can also see what our GATEs are using data_generator.cates. Let’s choose X4_binary in 1 group:\n\ndata_generator.cates.iloc[\n    data_generator.df.query(\"X4_binary == 1\").index\n].mean()\n\nCATE_of_T1_binary_on_Y1_continuous    0.347413\nCATE_of_T1_binary_on_Y2_binary        0.177773\ndtype: float64\n\n\n\n\nCustom Group Average Treatment Effects (GATEs)\nLet’s now look at how we can estimate any arbitary GATE using estimate_ate method and prettify the results with prettify_treatment_effects.\n\ncustom_gate_df = data_generator.df.query(\n    \"X4_binary == 1 & X2_continuous &lt; -3\"\n).copy()\n\ncustom_gate = fo_obj.estimate_ate(\n    custom_gate_df,\n    group=\"My Custom Group\",\n    membership=\"My Custom Membership\",\n    return_results_dict=True,\n)\nfo_obj.prettify_treatment_effects(effects=custom_gate)\n\n                    INFO     Estimating Average Treatment Effects (ATEs)...                              ols.py:296\n\n\n\n                    DEBUG    Creating treatment difference matrix...                                     ols.py:560\n\n\n\n                    DEBUG    Design Matrix Creation completed in 0.03 seconds                        generics.py:73\n\n\n\n                    DEBUG    ATE Estimation completed in 0.03 seconds                                generics.py:73\n\n\n\n\n\n\n\n\n\n\ngroup\nmembership\noutcome\nate\nstd_err\nt_stat\npval\nn\nn_treated\nn_control\n\n\n\n\n0\nMy Custom Group\nMy Custom Membership\nY1_continuous\n0.541877\n0.052269\n10.367002\n0.0\n1197\n661\n536\n\n\n1\nMy Custom Group\nMy Custom Membership\nY2_binary\n0.184703\n0.021119\n8.746004\n0.0\n1197\n661\n536\n\n\n\n\n\n\n\nLet’s compare this to the ground truth as well:\n\ndata_generator.cates.iloc[custom_gate_df.index].mean()\n\nCATE_of_T1_binary_on_Y1_continuous    0.530934\nCATE_of_T1_binary_on_Y2_binary        0.198813\ndtype: float64\n\n\n\n\nConditional Average Treatment Effects (CATEs)\nLet’s now look at how we can estimate CATEs / approximate individual-level treatment effects via estimate_cate method\n\n\n\n\n\n\nNote\n\n\n\nThe predict method is a simple alias for estimate_cate. Either can be used, but namespacing was created to higlight that estimate_cate / predict can be used for out of sample treatment effect prediction.\n\n\n\ncates = fo_obj.estimate_cate(data_generator.df)\n\ncates\n\n                    INFO     Estimating Conditional Average Treatment Effects (CATEs)...                 ols.py:365\n\n\n\n                    DEBUG    Creating treatment difference matrix...                                     ols.py:560\n\n\n\n                    DEBUG    Design Matrix Creation completed in 0.09 seconds                        generics.py:73\n\n\n\n                    DEBUG    CATE Estimation completed in 0.09 seconds                               generics.py:73\n\n\n\narray([[-4.96630384, -0.25905625],\n       [11.3471586 ,  0.70608504],\n       [-1.32992654, -0.05790035],\n       ...,\n       [ 5.18215613,  0.42039076],\n       [ 3.91982932,  0.34804847],\n       [-0.45883511, -0.03503195]])\n\n\nIf we wanted additional information on CATEs (such as standard errors), we can call:\n\nfo_obj.estimate_cate(data_generator.df, return_results_dict=True)\n\n                    INFO     Estimating Conditional Average Treatment Effects (CATEs)...                 ols.py:365\n\n\n\n                    DEBUG    Creating treatment difference matrix...                                     ols.py:560\n\n\n\n                    DEBUG    Design Matrix Creation completed in 0.12 seconds                        generics.py:73\n\n\n\n                    DEBUG    CATE Estimation completed in 0.14 seconds                               generics.py:73\n\n\n\n{'outcome': ['Y1_continuous', 'Y2_binary'],\n 'cate': array([[-4.96630384, -0.25905625],\n        [11.3471586 ,  0.70608504],\n        [-1.32992654, -0.05790035],\n        ...,\n        [ 5.18215613,  0.42039076],\n        [ 3.91982932,  0.34804847],\n        [-0.45883511, -0.03503195]]),\n 'std_err': array([[0.02874559, 0.01134792],\n        [0.04431468, 0.01669346],\n        [0.02526043, 0.00995281],\n        ...,\n        [0.02767557, 0.01025595],\n        [0.02636869, 0.00997712],\n        [0.02779769, 0.01090012]]),\n 't_stat': array([[-172.76749964,  -22.82852289],\n        [ 256.05869601,   42.29711604],\n        [ -52.6486181 ,   -5.8174884 ],\n        ...,\n        [ 187.2465665 ,   40.98993518],\n        [ 148.6546921 ,   34.88465475],\n        [ -16.50623202,   -3.21390529]]),\n 'pval': array([[0.00000000e+00, 0.00000000e+00],\n        [0.00000000e+00, 0.00000000e+00],\n        [0.00000000e+00, 5.97384053e-09],\n        ...,\n        [0.00000000e+00, 0.00000000e+00],\n        [0.00000000e+00, 0.00000000e+00],\n        [0.00000000e+00, 1.30942855e-03]])}\n\n\nNow, let’s make our cate predictions:\n\ncate_predictions = fo_obj.predict(data_generator.df)\n\n## We can also make predictions of the outcomes, if desired.\n# fo_obj.predict(data_generator.df, mode=\"outcome\")\n\n                    INFO     Estimating Conditional Average Treatment Effects (CATEs)...                 ols.py:365\n\n\n\n                    DEBUG    Creating treatment difference matrix...                                     ols.py:560\n\n\n\n[06/10/25 15:22:55] DEBUG    Design Matrix Creation completed in 0.12 seconds                        generics.py:73\n\n\n\n                    DEBUG    CATE Estimation completed in 0.12 seconds                               generics.py:73\n\n\n\nLet’s now look at the Precision in Estimating Heterogeneous Effects (PEHE) (e.g., RMSE) and plot some results for the treatment effects on each outcome:\n\nEffect of binary T1 on continuous Y1\n\nfrom sklearn.metrics import root_mean_squared_error\nfrom caml.extensions.plots import (\n    cate_true_vs_estimated_plot,\n    cate_histogram_plot,\n    cate_line_plot,\n)\n\n\ntrue_cates1 = data_generator.cates.iloc[:, 0]\npredicted_cates1 = cate_predictions[:, 0]\nroot_mean_squared_error(true_cates1, predicted_cates1)\n\n0.054197542640946\n\n\n\ncate_true_vs_estimated_plot(\n    true_cates=true_cates1, estimated_cates=predicted_cates1\n)\n\n\n\n\n\n\n\n\n\ncate_histogram_plot(true_cates=true_cates1, estimated_cates=predicted_cates1)\n\n\n\n\n\n\n\n\n\ncate_line_plot(\n    true_cates=true_cates1, estimated_cates=predicted_cates1, window=20\n)\n\n\n\n\n\n\n\n\n\n\nEffect of binary T1 on binary Y2\n\ntrue_cates2 = data_generator.cates.iloc[:, 1]\npredicted_cates2 = cate_predictions[:, 1]\nroot_mean_squared_error(true_cates2, predicted_cates2)\n\n0.15683038625127854\n\n\n\ncate_true_vs_estimated_plot(\n    true_cates=true_cates2, estimated_cates=predicted_cates2\n)\n\n\n\n\n\n\n\n\n\ncate_histogram_plot(true_cates=true_cates2, estimated_cates=predicted_cates2)\n\n\n\n\n\n\n\n\n\ncate_line_plot(\n    true_cates=true_cates2, estimated_cates=predicted_cates2, window=20\n)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nThe CATE estimates for binary outcome using simulated data may perform poorly b/c of non-linear transformation (sigmoid) of linear logodds. In general, FastOLS should be prioritized when ATEs and GATEs are of primary interest. For high quality CATE estimation, we recommend leveraging CamlCATE.",
    "crumbs": [
      "FastOLS"
    ]
  },
  {
    "objectID": "03_Examples/SyntheticDataGenerator.html",
    "href": "03_Examples/SyntheticDataGenerator.html",
    "title": "Caml Synthetic Data Generator",
    "section": "",
    "text": "from caml.extensions.synthetic_data import SyntheticDataGenerator\nimport numpy as np",
    "crumbs": [
      "Caml Synthetic Data Generator"
    ]
  },
  {
    "objectID": "03_Examples/SyntheticDataGenerator.html#generate-data",
    "href": "03_Examples/SyntheticDataGenerator.html#generate-data",
    "title": "Caml Synthetic Data Generator",
    "section": "Generate Data",
    "text": "Generate Data\n\ndata_generator = SyntheticDataGenerator(\n    n_obs=10_000,\n    n_cont_outcomes=1,\n    n_binary_outcomes=1,\n    n_cont_treatments=1,\n    n_binary_treatments=1,\n    n_discrete_treatments=1,\n    n_cont_confounders=1,\n    n_binary_confounders=1,\n    n_discrete_confounders=1,\n    n_cont_modifiers=1,\n    n_binary_modifiers=1,\n    n_discrete_modifiers=1,\n    n_confounding_modifiers=1,\n    stddev_outcome_noise=3,\n    stddev_treatment_noise=3,\n    causal_model_functional_form=\"linear\",\n    n_nonlinear_transformations=5,\n    seed=10,\n)",
    "crumbs": [
      "Caml Synthetic Data Generator"
    ]
  },
  {
    "objectID": "03_Examples/SyntheticDataGenerator.html#simulated-dataframe",
    "href": "03_Examples/SyntheticDataGenerator.html#simulated-dataframe",
    "title": "Caml Synthetic Data Generator",
    "section": "Simulated Dataframe",
    "text": "Simulated Dataframe\n\ndata_generator.df\n\n\n\n\n\n\n\n\nW1_continuous\nW2_binary\nW3_discrete\nX1_continuous\nX2_binary\nX3_discrete\nT1_continuous\nT2_binary\nT3_discrete\nY1_continuous\nY2_binary\n\n\n\n\n0\n0.354380\n0\n1\n0.432254\n0\n1\n-3.726761\n0\n0\n-20.927146\n0\n\n\n1\n0.568499\n1\n0\n0.812796\n0\n1\n-3.438992\n1\n4\n-9.747703\n0\n\n\n2\n0.162715\n1\n1\n0.874920\n1\n0\n-2.806232\n0\n0\n-17.370004\n1\n\n\n3\n0.362944\n0\n0\n0.411990\n1\n3\n-0.950123\n1\n2\n-2.274883\n0\n\n\n4\n0.612101\n1\n0\n0.444356\n1\n0\n-2.888419\n1\n4\n-0.420176\n0\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n9995\n0.340436\n0\n1\n0.657928\n1\n0\n3.182961\n1\n2\n8.651162\n0\n\n\n9996\n0.019523\n1\n0\n0.672171\n1\n1\n-0.384001\n1\n1\n3.081509\n0\n\n\n9997\n0.325401\n1\n0\n0.407528\n1\n3\n-7.291501\n0\n0\n-105.683437\n1\n\n\n9998\n0.586715\n1\n0\n0.542052\n1\n0\n-4.196167\n0\n4\n0.847574\n0\n\n\n9999\n0.003002\n1\n1\n0.261432\n1\n4\n5.563359\n0\n4\n113.301968\n0\n\n\n\n\n10000 rows × 11 columns",
    "crumbs": [
      "Caml Synthetic Data Generator"
    ]
  },
  {
    "objectID": "03_Examples/SyntheticDataGenerator.html#true-conditional-average-treatment-effects-cates",
    "href": "03_Examples/SyntheticDataGenerator.html#true-conditional-average-treatment-effects-cates",
    "title": "Caml Synthetic Data Generator",
    "section": "True Conditional Average Treatment Effects (CATEs)",
    "text": "True Conditional Average Treatment Effects (CATEs)\n\ndata_generator.cates\n\n\n\n\n\n\n\n\nCATE_of_T1_continuous_on_Y1_continuous\nCATE_of_T2_binary_on_Y1_continuous\nCATE_of_T3_discrete_on_Y1_continuous_level_4_v_0\nCATE_of_T3_discrete_on_Y1_continuous_level_2_v_0\nCATE_of_T3_discrete_on_Y1_continuous_level_1_v_0\nCATE_of_T3_discrete_on_Y1_continuous_level_3_v_0\nCATE_of_T1_continuous_on_Y2_binary\nCATE_of_T2_binary_on_Y2_binary\nCATE_of_T3_discrete_on_Y2_binary_level_4_v_0\nCATE_of_T3_discrete_on_Y2_binary_level_2_v_0\nCATE_of_T3_discrete_on_Y2_binary_level_1_v_0\nCATE_of_T3_discrete_on_Y2_binary_level_3_v_0\n\n\n\n\n0\n6.431287\n2.115750\n5.518583\n2.759291\n1.379646\n4.138937\n-0.022789\n0.023626\n-0.722338\n-0.512221\n-0.256669\n-0.661029\n\n\n1\n7.137688\n3.047866\n7.489986\n3.744993\n1.872497\n5.617490\n-0.004433\n0.009044\n-0.814747\n-0.547820\n-0.241318\n-0.740738\n\n\n2\n3.589688\n0.170688\n14.223319\n7.111660\n3.555830\n10.667489\n-0.033585\n-0.059832\n-0.829362\n-0.328208\n-0.100727\n-0.627206\n\n\n3\n14.923903\n5.855224\n7.506872\n3.753436\n1.876718\n5.630154\n0.000000\n0.000000\n-0.687002\n-0.687002\n-0.603805\n-0.687002\n\n\n4\n2.790430\n-0.883957\n11.992772\n5.996386\n2.998193\n8.994579\n-0.020381\n-0.090014\n-0.744867\n-0.480709\n-0.223118\n-0.659681\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n9995\n3.186885\n-0.360823\n13.099186\n6.549593\n3.274797\n9.824390\n-0.005274\n-0.024819\n-0.124580\n-0.119305\n-0.087765\n-0.124580\n\n\n9996\n7.277843\n1.946885\n11.733566\n5.866783\n2.933392\n8.800175\n-0.055789\n-0.091764\n-0.660311\n-0.621732\n-0.426627\n-0.660311\n\n\n9997\n14.915621\n5.844295\n7.483759\n3.741879\n1.870940\n5.612819\n0.029784\n0.113995\n-0.516854\n-0.516854\n-0.479383\n-0.516854\n\n\n9998\n2.971783\n-0.644656\n12.498887\n6.249444\n3.124722\n9.374165\n-0.080096\n-0.134494\n-0.733551\n-0.231604\n-0.070256\n-0.489847\n\n\n9999\n18.708941\n7.759261\n5.287498\n2.643749\n1.321874\n3.965623\n0.000000\n0.000000\n-0.954142\n-0.948999\n-0.572786\n-0.954142\n\n\n\n\n10000 rows × 12 columns",
    "crumbs": [
      "Caml Synthetic Data Generator"
    ]
  },
  {
    "objectID": "03_Examples/SyntheticDataGenerator.html#true-average-treatment-effects-ates",
    "href": "03_Examples/SyntheticDataGenerator.html#true-average-treatment-effects-ates",
    "title": "Caml Synthetic Data Generator",
    "section": "True Average Treatment Effects (ATEs)",
    "text": "True Average Treatment Effects (ATEs)\n\ndata_generator.ates\n\n\n\n\n\n\n\n\nTreatment\nATE\n\n\n\n\n0\nT1_continuous_on_Y1_continuous\n8.832689\n\n\n1\nT2_binary_on_Y1_continuous\n2.723753\n\n\n2\nT3_discrete_on_Y1_continuous_level_4_v_0\n9.625175\n\n\n3\nT3_discrete_on_Y1_continuous_level_2_v_0\n4.812588\n\n\n4\nT3_discrete_on_Y1_continuous_level_1_v_0\n2.406294\n\n\n5\nT3_discrete_on_Y1_continuous_level_3_v_0\n7.218881\n\n\n6\nT1_continuous_on_Y2_binary\n-0.023382\n\n\n7\nT2_binary_on_Y2_binary\n-0.032929\n\n\n8\nT3_discrete_on_Y2_binary_level_4_v_0\n-0.683641\n\n\n9\nT3_discrete_on_Y2_binary_level_2_v_0\n-0.571733\n\n\n10\nT3_discrete_on_Y2_binary_level_1_v_0\n-0.376043\n\n\n11\nT3_discrete_on_Y2_binary_level_3_v_0\n-0.650020",
    "crumbs": [
      "Caml Synthetic Data Generator"
    ]
  },
  {
    "objectID": "03_Examples/SyntheticDataGenerator.html#true-data-generating-process",
    "href": "03_Examples/SyntheticDataGenerator.html#true-data-generating-process",
    "title": "Caml Synthetic Data Generator",
    "section": "True Data Generating Process",
    "text": "True Data Generating Process\n\nfor k, v in data_generator.dgp.items():\n    print(f\"DGP for {k}:\")\n    print(v)\n\nDGP for T1_continuous:\n{'formula': '1 + W1_continuous + W2_binary + W3_discrete + X1_continuous', 'params': array([ 0.06058085,  1.16021218, -1.96203513,  0.36371696, -2.17056973]), 'noise': array([-3.62397606, -0.4328875 ,  0.44179631, ..., -4.88301257,\n       -1.79886609,  7.66507059]), 'raw_scores': array([-3.72676077, -3.43899217, -2.80623211, ..., -7.29150054,\n       -4.19616712,  5.56335924]), 'function': &lt;function SyntheticDataGenerator._create_dgp_function.&lt;locals&gt;.f_cont at 0x7f13aef69e10&gt;}\nDGP for T2_binary:\n{'formula': '1 + W1_continuous + W2_binary + W3_discrete + X1_continuous', 'params': array([ 0.40298227,  0.46731892, -0.04221048, -1.01745299,  0.75777365]), 'noise': array([ 0.61588584,  3.23845316, -4.20232967, ..., -5.30465767,\n       -4.77383245, -3.11883147]), 'raw_scores': array([0.62118342, 0.98880257, 0.01598516, ..., 0.01117315, 0.0234736 ,\n       0.02722537]), 'function': &lt;function SyntheticDataGenerator._create_dgp_function.&lt;locals&gt;.f_binary at 0x7f13745af490&gt;}\nDGP for T3_discrete:\n{'formula': '1 + W1_continuous + W2_binary + W3_discrete + X1_continuous', 'params': array([[ 0.28408456, -0.41400534,  0.89869683, -0.21225787, -0.51305644],\n       [-0.19632837,  0.02928109, -0.76527952, -1.08498952, -0.10759088],\n       [ 0.47243684,  0.23156474, -0.05579596,  0.57863612,  0.2423976 ],\n       [-0.388172  , -0.10787099, -0.09372564,  0.11089256, -0.00356159],\n       [-0.57508702,  0.26987442,  0.26917321,  0.07404752,  0.54707381]]), 'noise': array([[-5.62802687, -1.71188738, -1.6500188 , -0.21256387, -2.52126791],\n       [-1.93444462,  1.17883094, -3.22882543,  5.68613081, -3.1945138 ],\n       [ 3.71485923, -2.99880648,  5.32356089,  1.85843325,  5.28230021],\n       ...,\n       [-0.31659162,  7.97101022, -0.80878524, -2.60107951, -1.99808469],\n       [-2.55599124,  2.33060302, -1.21559451,  1.39676363, -1.08090999],\n       [-0.93239336,  1.08707538,  3.1621623 , -3.38126668, -1.0282605 ]]), 'raw_scores': array([[0.2, 0.2, 0.2, 0.2, 0.2],\n       [0.2, 0.2, 0.2, 0.2, 0.2],\n       [0.2, 0.2, 0.2, 0.2, 0.2],\n       ...,\n       [0.2, 0.2, 0.2, 0.2, 0.2],\n       [0.2, 0.2, 0.2, 0.2, 0.2],\n       [0.2, 0.2, 0.2, 0.2, 0.2]]), 'function': &lt;function SyntheticDataGenerator._create_dgp_function.&lt;locals&gt;.f_discrete at 0x7f13745af9a0&gt;}\nDGP for Y1_continuous:\n{'formula': '1 + W1_continuous + W2_binary + W3_discrete + X1_continuous + X2_binary + X3_discrete + T1_continuous + T2_binary + T3_discrete + T1_continuous*X1_continuous + T1_continuous*X2_binary + T1_continuous*X3_discrete + T2_binary*X1_continuous + T2_binary*X2_binary + T2_binary*X3_discrete + T3_discrete*X1_continuous + T3_discrete*X2_binary + T3_discrete*X3_discrete', 'params': array([-1.24245918, -2.15840213,  1.21168055,  1.88903987, -1.66394546,\n       -2.8238776 ,  2.19040025,  1.56437294, -1.2158549 ,  1.1796722 ,\n        1.85630525,  0.40119701,  4.06451821,  2.44944857, -0.75652854,\n        2.2728199 ,  1.29513067,  1.243022  , -0.35985222]), 'noise': array([ 1.68788239,  4.68077263, -4.52386602, ...,  0.73772796,\n        5.84175262, -3.42458613]), 'raw_scores': array([ -20.92714575,   -9.74770328,  -17.37000412, ..., -105.68343735,\n          0.84757356,  113.30196785]), 'function': &lt;function SyntheticDataGenerator._create_dgp_function.&lt;locals&gt;.f_cont at 0x7f13745c1fc0&gt;}\nDGP for Y2_binary:\n{'formula': '1 + W1_continuous + W2_binary + W3_discrete + X1_continuous + X2_binary + X3_discrete + T1_continuous + T2_binary + T3_discrete + T1_continuous*X1_continuous + T1_continuous*X2_binary + T1_continuous*X3_discrete + T2_binary*X1_continuous + T2_binary*X2_binary + T2_binary*X3_discrete + T3_discrete*X1_continuous + T3_discrete*X2_binary + T3_discrete*X3_discrete', 'params': array([ 3.10830726e-01, -8.76756219e-02,  5.06943774e-01,  3.63265570e-01,\n        8.10885598e-02,  1.61061427e-01, -2.64294557e-04, -2.93078750e-01,\n       -6.41686816e-01, -2.78041378e-01, -9.20270247e-02, -1.89629801e-01,\n        2.13406730e-01,  5.55264734e-01, -7.14195311e-01,  5.33709717e-01,\n       -3.91935251e-01, -6.16656576e-01, -6.84033929e-01]), 'noise': array([-2.0490385 ,  0.51909257,  0.81681174, ...,  5.05902104,\n       -2.13548014, -1.22267512]), 'raw_scores': array([0.28372465, 0.05238531, 0.97803581, ..., 0.99      , 0.03363826,\n       0.01      ]), 'function': &lt;function SyntheticDataGenerator._create_dgp_function.&lt;locals&gt;.f_binary at 0x7f13745c2050&gt;}\n\n\nWe can recreate the raw scores of our treatment and outcome variables too:\n\n# Recreate Y1_continuous\ndf = data_generator.df\ndgp = data_generator.dgp[\"Y1_continuous\"]\n\ndesign_matrix = data_generator.create_design_matrix(df, formula=dgp[\"formula\"])\n\nparams = dgp[\"params\"]\nnoise = dgp[\"noise\"]\nf = dgp[\"function\"]\n\nraw_scores = f(design_matrix, params, noise)\n\nassert np.allclose(raw_scores, df[\"Y1_continuous\"])\nassert np.allclose(raw_scores, dgp[\"raw_scores\"])\n\nraw_scores\n\n0       -20.927146\n1        -9.747703\n2       -17.370004\n3        -2.274883\n4        -0.420176\n           ...    \n9995      8.651162\n9996      3.081509\n9997   -105.683437\n9998      0.847574\n9999    113.301968\nLength: 10000, dtype: float64\n\n\nFor treatment variables, we get back the probabilities:\n\n# Recreate Y2_binary\ndgp_bin = data_generator.dgp[\"Y2_binary\"]\n\ndesign_matrix_bin = data_generator.create_design_matrix(df, formula=dgp_bin[\"formula\"])\n\nparams_bin = dgp_bin[\"params\"]\nnoise_bin = dgp_bin[\"noise\"]\nf_bin = dgp_bin[\"function\"]\n\nraw_scores_bin = f_bin(design_matrix_bin, params_bin, noise_bin)\n\nassert np.allclose(raw_scores_bin, dgp_bin[\"raw_scores\"])\n\nraw_scores_bin\n\n0       0.283725\n1       0.052385\n2       0.978036\n3       0.010000\n4       0.115042\n          ...   \n9995    0.609972\n9996    0.010000\n9997    0.990000\n9998    0.033638\n9999    0.010000\nLength: 10000, dtype: float64",
    "crumbs": [
      "Caml Synthetic Data Generator"
    ]
  }
]