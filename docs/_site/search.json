[
  {
    "objectID": "04_Contributors/documentation.html",
    "href": "04_Contributors/documentation.html",
    "title": "Documentation",
    "section": "",
    "text": "Note: Windows users must create environment using WSL or Docker container as Quarto requires MacOS or LinuxOS\nThis repository uses  & quartodoc for documentation. All files relating to the documentation are under the docs/ directory. Quarto & quartodoc provide very detailed documentation on usage so I will refer the reader to these resources for more details.\nTo build the documentation, run the following command from the projects root directory:\nquartodoc build --config docs/_quarto.yml\nAnd to preview the documentation, run the following command:\nquarto preview docs/\nThe documentation preview will be hosted on http://localhost:8000/. Note that the quarto preview will be checking for live updates & applying them in real-time. In some cases, the changes will not manifest until you rerun quartodoc build --config docs/_quarto.yml. In general, this will occur when you make changes to the ‚Äúquartodoc:‚Äù section of the docs/_quarto.yml file or any corresponding API changes.\n\n\n\n Back to top",
    "crumbs": [
      "Documentation"
    ]
  },
  {
    "objectID": "04_Contributors/testing.html",
    "href": "04_Contributors/testing.html",
    "title": "Testing",
    "section": "",
    "text": "We utilize pytest for testing our codebase.",
    "crumbs": [
      "Testing"
    ]
  },
  {
    "objectID": "04_Contributors/testing.html#unit-testing",
    "href": "04_Contributors/testing.html#unit-testing",
    "title": "Testing",
    "section": "Unit Testing",
    "text": "Unit Testing\nUnit tests are under the tests/caml/ directory following the same structure of the caml/ prefixed by ‚Äútest_‚Äù. For example, if we wanted to write tests for cate.py, we would create a new file to build these tests tests/caml/core/test_cate.py.\nTo run unit tests, simply run pytest in terminal:\nThis will run your unit tests (with respective output printed in terminal).\nAdditionally, an html report of the coverage will be exported to tests/reports/htmlcov, which can be a useful tool for interactively evaluating the coverage of your unit tests.",
    "crumbs": [
      "Testing"
    ]
  },
  {
    "objectID": "04_Contributors/testing.html#advanced-testing",
    "href": "04_Contributors/testing.html#advanced-testing",
    "title": "Testing",
    "section": "Advanced Testing",
    "text": "Advanced Testing\nUnit tests are automatically run during PR process via GitHub Actions. Integration & regression testing forthcoming.",
    "crumbs": [
      "Testing"
    ]
  },
  {
    "objectID": "02_Concepts/motivation.html",
    "href": "02_Concepts/motivation.html",
    "title": "Motivation",
    "section": "",
    "text": "Forthcoming\n\n\n\n Back to top",
    "crumbs": [
      "Motivation"
    ]
  },
  {
    "objectID": "01_Home/installation.html",
    "href": "01_Home/installation.html",
    "title": "Installation",
    "section": "",
    "text": "Forthcoming\n\n\n\n Back to top",
    "crumbs": [
      "Installation"
    ]
  },
  {
    "objectID": "03_Reference/make_fully_heterogeneous_dataset.html",
    "href": "03_Reference/make_fully_heterogeneous_dataset.html",
    "title": "make_fully_heterogeneous_dataset",
    "section": "",
    "text": "extensions.synthetic_data.make_fully_heterogeneous_dataset(n_obs=1000, n_confounders=5, theta=4.0, seed=None, **doubleml_kwargs)\nSimulate data generating process from an interactive regression model with fully heterogenous treatment effects. The outcome is continuous and the treatment is binary. The dataset is generated using a modified version of make_irm_data function from the doubleml package.\nThe general form of the data generating process is:\n\\[\ny_i= g(d_i,\\mathbf{X_i})+\\epsilon_i\n\\] \\[\nd_i=f(\\mathbf{X_i})+\\eta_i\n\\]\nwhere \\(y_i\\) is the outcome, \\(d_i\\) is the treatment, \\(\\mathbf{X_i}\\) are the confounders utilized for full effect heterogeneity, \\(\\epsilon_i\\) and \\(\\eta_i\\) are the error terms, \\(g\\) is the outcome function, and \\(f\\) is the treatment function.\nSee the doubleml documentation for more details on the specific functional forms of the data generating process.\nNote that the treatment effect is fully heterogenous, thus the CATE is defined as: \\(\\tau = \\mathbb{E}[g(1,\\mathbf{X}) - g(0,\\mathbf{X})|\\mathbf{X}]\\) for any \\(\\mathbf{X}\\).\nThe ATE is defined as the average of the CATE function over all observations: \\(\\mathbb{E}[\\tau (\\cdot)]\\)\nAs a DAG, the data generating process can be roughly represented as:"
  },
  {
    "objectID": "03_Reference/make_fully_heterogeneous_dataset.html#parameters",
    "href": "03_Reference/make_fully_heterogeneous_dataset.html#parameters",
    "title": "make_fully_heterogeneous_dataset",
    "section": "Parameters",
    "text": "Parameters\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nn_obs\nint\nThe number of observations to generate.\n1000\n\n\nn_confounders\nint\nThe number of confounders \\(\\mathbf{X_i}\\) to generate (these are utilized fully for heterogeneity).\n5\n\n\ntheta\nfloat\nThe base parameter for the treatment effect. Note this differs from the ATE.\n4.0\n\n\nseed\nint | None\nThe seed to use for the random number generator.\nNone\n\n\n**doubleml_kwargs\n\nAdditional keyword arguments to pass to the data generating process.\n{}"
  },
  {
    "objectID": "03_Reference/make_fully_heterogeneous_dataset.html#returns",
    "href": "03_Reference/make_fully_heterogeneous_dataset.html#returns",
    "title": "make_fully_heterogeneous_dataset",
    "section": "Returns",
    "text": "Returns\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\npandas.DataFrame\nThe generated dataset where y is the outcome, d is the treatment, and X are the confounders which are fully utilized for heterogeneity.\n\n\nnumpy.ndarray\nThe true conditional average treatment effects.\n\n\nfloat\nThe true average treatment effect."
  },
  {
    "objectID": "03_Reference/make_fully_heterogeneous_dataset.html#examples",
    "href": "03_Reference/make_fully_heterogeneous_dataset.html#examples",
    "title": "make_fully_heterogeneous_dataset",
    "section": "Examples",
    "text": "Examples\n\nfrom caml.extensions.synthetic_data import make_fully_heterogeneous_dataset\ndf, true_cates, true_ate = make_fully_heterogeneous_dataset(n_obs=1000,\n                                                            n_confounders=5,\n                                                            theta=4.0,\n                                                            seed=1)\n\nprint(f\"True CATEs: {true_cates[:5]}\")\nprint(f\"True ATE: {true_ate}\")\nprint(df.head())\n\nTrue CATEs: [5.10338083 5.0918794  1.93444292 4.36046179 3.89521828]\nTrue ATE: 3.9499484248360175\n         X1        X2        X3        X4        X5         y    d\n0  1.682368 -0.422572 -1.219871 -0.941586 -1.270241  5.828931  1.0\n1  0.684154  1.125168  2.601475  0.441070  0.889493  4.767675  1.0\n2 -2.035148 -1.386116 -0.770108 -0.070788 -0.524494  2.748786  1.0\n3  0.429364 -0.125604 -0.095252 -0.033939  1.243388  5.140932  1.0\n4  0.240024 -0.069628 -1.722948 -1.565808 -1.494064  2.431165  1.0"
  },
  {
    "objectID": "03_Reference/cate_true_vs_estimated_plot.html",
    "href": "03_Reference/cate_true_vs_estimated_plot.html",
    "title": "cate_true_vs_estimated_plot",
    "section": "",
    "text": "extensions.plots.cate_true_vs_estimated_plot(true_cates, estimated_cates, *, figure_kwargs={}, scatter_kwargs={})\nPlots a scatter plot of the estimated CATEs against the true CATEs."
  },
  {
    "objectID": "03_Reference/cate_true_vs_estimated_plot.html#parameters",
    "href": "03_Reference/cate_true_vs_estimated_plot.html#parameters",
    "title": "cate_true_vs_estimated_plot",
    "section": "Parameters",
    "text": "Parameters\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nestimated_cates\nnumpy.typing.ArrayLike\nThe estimated CATEs.\nrequired\n\n\nfigure_kwargs\ndict\nMatplotlib figure arguments.\n{}\n\n\nscatter_kwargs\ndict\nMatplotlib line arguments.\n{}"
  },
  {
    "objectID": "03_Reference/cate_true_vs_estimated_plot.html#returns",
    "href": "03_Reference/cate_true_vs_estimated_plot.html#returns",
    "title": "cate_true_vs_estimated_plot",
    "section": "Returns",
    "text": "Returns\n\n\n\nType\nDescription\n\n\n\n\nmatplotlib.figure.Figure\nThe line plot figure object."
  },
  {
    "objectID": "03_Reference/cate_true_vs_estimated_plot.html#examples",
    "href": "03_Reference/cate_true_vs_estimated_plot.html#examples",
    "title": "cate_true_vs_estimated_plot",
    "section": "Examples",
    "text": "Examples\n\nimport numpy as np\nfrom caml.extensions.plots import cate_true_vs_estimated_plot\n\nnp.random.seed(42)\ntrue_cates = np.random.normal(0, 1, 100)\nestimated_cates = true_cates + np.random.normal(0, 0.5, 100)\n\nfig = cate_true_vs_estimated_plot(true_cates, estimated_cates)\nfig"
  },
  {
    "objectID": "03_Reference/utils.generate_random_string.html",
    "href": "03_Reference/utils.generate_random_string.html",
    "title": "utils.generate_random_string",
    "section": "",
    "text": "utils.generate_random_string(N)\nFunction to generate a random string of ascii lowercase letters and digits of length N.\nUtilized to generate a random table name for the Ibis Tables.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nN\nint\nThe length of random string to generate.\nrequired\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nstr: The random string of length N."
  },
  {
    "objectID": "03_Reference/utils.generate_random_string.html#parameters",
    "href": "03_Reference/utils.generate_random_string.html#parameters",
    "title": "utils.generate_random_string",
    "section": "",
    "text": "Name\nType\nDescription\nDefault\n\n\n\n\nN\nint\nThe length of random string to generate.\nrequired"
  },
  {
    "objectID": "03_Reference/utils.generate_random_string.html#returns",
    "href": "03_Reference/utils.generate_random_string.html#returns",
    "title": "utils.generate_random_string",
    "section": "",
    "text": "Type\nDescription\n\n\n\n\nstr: The random string of length N."
  },
  {
    "objectID": "03_Reference/CamlCATE.html",
    "href": "03_Reference/CamlCATE.html",
    "title": "CamlCATE",
    "section": "",
    "text": "CamlCATE(self, df, Y, T, X, W, *, discrete_treatment=True, discrete_outcome=False, seed=None, verbose=1)\nThe CamlCATE class represents an opinionated framework of Causal Machine Learning techniques for estimating highly accurate conditional average treatment effects (CATEs).\nThis class is built on top of the EconML library and provides a high-level API for fitting, validating, and making inference with CATE models, with best practices built directly into the API. The class is designed to be easy to use and understand, while still providing flexibility for advanced users. The class is designed to be used with pandas, polars, or pyspark backends, which ultimately get converted to NumPy Arrays under the hood to provide a level of extensibility & interoperability across different data processing frameworks.\nThe primary workflow for the CamlCATE class is as follows:\n\nInitialize the class with the input DataFrame and the necessary columns.\nUtilize flaml AutoML to find nuisance functions or propensity/regression models to be utilized in the EconML estimators.\nFit the CATE models on the training set and evaluate based on the validation set, then select the top performer/ensemble based on chosen scorer.\nValidate the fitted CATE model on the test set to check for generalization performance.\nFit the final estimator on the entire dataset, after validation and testing.\nPredict the CATE based on the fitted final estimator for either the internal dataset or an out-of-sample dataset.\nSummarize population summary statistics for the CATE predictions for either the internal dataset or out-of-sample predictions.\n\nFor technical details on conditional average treatment effects, see:\n\nCaML Documentation\nEconML documentation\n\nNote: All the standard assumptions of Causal Inference apply to this class (e.g., exogeneity/unconfoundedness, overlap, positivity, etc.). The class does not check for these assumptions and assumes that the user has already thought through these assumptions before using the class.\nOutcome & Treatment Data Type Support Matrix\n\n\n\nOutcome\nTreatment\nSupport\nMissing\n\n\n\n\nContinuous\nBinary\n‚úÖFull\nNone\n\n\nContinuous\nContinuous\nüü°Partial\nValidation\n\n\nContinuous\nCategorical\n‚úÖFull\nNone\n\n\nBinary\nBinary\n‚ùåNot yet\n\n\n\nBinary\nContinuous\n‚ùåNot yet\n\n\n\nBinary\nCategorical\n‚ùåNot yet\n\n\n\nCategorical\nBinary\n‚ùåNot yet\n\n\n\nCategorical\nContinuous\n‚ùåNot yet\n\n\n\nCategorical\nCategorical\n‚ùåNot yet\n\n\n\n\nMulti-dimensional outcomes and treatments are not yet supported.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\ndf\npandas.DataFrame | polars.DataFrame | pyspark.sql.DataFrame\nThe input DataFrame representing the data for the CamlCATE instance.\nrequired\n\n\nY\nstr\nThe str representing the column name for the outcome variable.\nrequired\n\n\nT\nstr\nThe str representing the column name(s) for the treatment variable(s).\nrequired\n\n\nX\nlist[str] | str | None\nThe str (if unity) or list of feature names representing the feature set to be utilized for estimating heterogeneity/CATE.\nrequired\n\n\nW\nlist[str] | str | None\nThe str (if unity) or list of feature names representing the confounder/control feature set to be utilized only for nuisance function estimation where applicable.\nrequired\n\n\ndiscrete_treatment\nbool\nA boolean indicating whether the treatment is discrete/categorical or continuous.\nTrue\n\n\ndiscrete_outcome\nbool\nA boolean indicating whether the outcome is binary or continuous.\nFalse\n\n\nseed\nint | None\nThe seed to use for the random number generator.\nNone\n\n\nverbose\nint\nThe verbosity level for logging. Default implies 1 (INFO). Set to 0 for no logging. Set to 2 for DEBUG.\n1\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\n\n\n\n\ndf\npandas.DataFrame | polars.DataFrame | pyspark.sql.DataFrame | ibis.Table\nThe input DataFrame representing the data for the CamlCATE instance.\n\n\nY\nstr\nThe str representing the column name for the outcome variable.\n\n\nT\nstr\nThe str representing the column name(s) for the treatment variable(s).\n\n\nX\nlist[str] | str\nThe str (if unity) or list/tuple of feature names representing the confounder/control feature set to be utilized for estimating heterogeneity/CATE and nuisance function estimation where applicable.\n\n\nW\nlist[str] | str\nThe str (if unity) or list/tuple of feature names representing the confounder/control feature set to be utilized only for nuisance function estimation, where applicable. These will be included by default in Meta-Learners.\n\n\ndiscrete_treatment\nbool\nA boolean indicating whether the treatment is discrete/categorical or continuous.\n\n\ndiscrete_outcome\nbool\nA boolean indicating whether the outcome is binary or continuous.\n\n\nvalidation_estimator\neconml._cate_estimator.BaseCateEstimator | econml.score.EnsembleCateEstimator\nThe fitted EconML estimator object for validation.\n\n\nfinal_estimator\neconml._cate_estimator.BaseCateEstimator | econml.score.EnsembleCateEstimator\nThe fitted EconML estimator object on the entire dataset after validation.\n\n\ndataframe\npandas.DataFrame | polars.DataFrame | pyspark.sql.DataFrame | ibis.Table\nThe input DataFrame with any modifications (e.g., predictions or rank orderings) made by the class returned to the original backend.\n\n\nmodel_Y_X_W\nsklearn.base.BaseEstimator\nThe fitted nuisance function for the outcome variable.\n\n\nmodel_Y_X_W_T\nsklearn.base.BaseEstimator\nThe fitted nuisance function for the outcome variable with treatment variable.\n\n\nmodel_T_X_W\nsklearn.base.BaseEstimator\nThe fitted nuisance function for the treatment variable.\n\n\n_Y\nibis.Table\nThe outcome variable data as ibis table.\n\n\n_T\nibis.Table\nThe treatment variable data as ibis table.\n\n\n_X\nibis.Table\nThe feature/confounder set data as ibis table.\n\n\n_X_T\nibis.Table\nThe feature/confounder feature set and treatment variable data as ibis table.\n\n\n_nuisances_fitted\nbool\nA boolean indicating whether the nuisance functions have been fitted.\n\n\n_validation_estimator\neconml._cate_estimator.BaseCateEstimator | econml.score.EnsembleCateEstimator\nThe fitted EconML estimator object for validation.\n\n\n_final_estimator\neconml._cate_estimator.BaseCateEstimator | econml.score.EnsembleCateEstimator\nThe fitted EconML estimator object for final predictions.\n\n\n_validator_results\neconml.validate.EvaluationResults\nThe results of the validation tests from DRTester.\n\n\n_cate_models\nlist[tuple[str, econml._cate_estimator.BaseCateEstimator]]\nThe list of CATE models to fit and ensemble.\n\n\n_data_splits\ndict[str, np.ndarray]\nThe dictionary containing the training, validation, and test data splits.\n\n\n_rscorer\neconml.score.RScorer\nThe RScorer object for the validation estimator.\n\n\n\n\n\n\n&gt;&gt;&gt; from caml.core.cate import CamlCATE\n&gt;&gt;&gt; from caml.extensions.synthetic_data import make_fully_heterogeneous_dataset\n&gt;&gt;&gt;\n&gt;&gt;&gt; # Generate synthetic dataset\n&gt;&gt;&gt; df, true_cates, true_ate = make_fully_heterogeneous_dataset(n_obs=1000, n_confounders=10, theta=10, seed=1)\n&gt;&gt;&gt;\n&gt;&gt;&gt; # Instantiate CamlCATE class\n&gt;&gt;&gt; caml_obj= CamlCATE(df=df,\n...                    Y=\"y\",\n...                    T=\"d\",\n...                    X=[c for c in df.columns if \"X\" in c],\n...                    W=[c for c in df.columns if \"W\" in c],\n...                    discrete_treatment=True,\n...                    discrete_outcome=True,\n...                    seed=0,\n...                    verbose=1)\n&gt;&gt;&gt;\n&gt;&gt;&gt; # Standard pipeline\n&gt;&gt;&gt; caml_obj.auto_nuisance_functions()\n&gt;&gt;&gt; caml_obj.fit_validator()\n&gt;&gt;&gt; caml_obj.validate()\n&gt;&gt;&gt; caml_obj.fit_final()\n&gt;&gt;&gt; predictions = caml_obj.predict()\n&gt;&gt;&gt; summarized_predictions = caml_obj.summarize()\n&gt;&gt;&gt;\n&gt;&gt;&gt; # Access final model (can be saved for future inference)\n&gt;&gt;&gt; final_estimator = caml_obj.final_estimator\n\n\n\n\n\n\nName\nDescription\n\n\n\n\nauto_nuisance_functions\nLeverages AutoML to find optimal nuisance functions/regression & propensity models for use in EconML CATE estimators.\n\n\nfit_final\nFits the final estimator on the entire dataset, after validation and testing.\n\n\nfit_validator\nFits the CATE models on the training set and evaluates them & ensembles based on the validation set.\n\n\npredict\nPredicts the CATE based on the fitted final estimator for either the internal dataset or provided Data.\n\n\nsummarize\nProvides population summary statistics for the CATE predictions for either the internal results or provided results.\n\n\nvalidate\nValidates the fitted CATE models on the test set to check for generalization performance. Uses the DRTester class from EconML to obtain the Best\n\n\n\n\n\nCamlCATE.auto_nuisance_functions(flaml_Y_kwargs=None, flaml_T_kwargs=None, use_ray=False, use_spark=False)\nLeverages AutoML to find optimal nuisance functions/regression & propensity models for use in EconML CATE estimators.\nSets the model_Y_X_W, model_Y_X_W_T, and model_T_X_W internal attributes to the fitted nuisance functions.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nflaml_Y_kwargs\ndict | None\nThe keyword arguments for the FLAML AutoML search for the outcome model. Default implies the base parameters in CamlBase.\nNone\n\n\nflaml_T_kwargs\ndict | None\nThe keyword arguments for the FLAML AutoML search for the treatment model. Default implies the base parameters in CamlBase.\nNone\n\n\nuse_ray\nbool\nA boolean indicating whether to use Ray for parallel processing.\nFalse\n\n\nuse_spark\nbool\nA boolean indicating whether to use Spark for parallel processing.\nFalse\n\n\n\n\n\n\n&gt;&gt;&gt; flaml_Y_kwargs = {\n...     \"n_jobs\": -1,\n...     \"time_budget\": 300, # in seconds\n...     }\n&gt;&gt;&gt; flaml_T_kwargs = {\n...     \"n_jobs\": -1,\n...     \"time_budget\": 300,\n...     }\n&gt;&gt;&gt; caml_obj.auto_nuisance_functions(flaml_Y_kwargs=flaml_Y_kwargs, flaml_T_kwargs=flaml_T_kwargs)\n\n\n\n\nCamlCATE.fit_final()\nFits the final estimator on the entire dataset, after validation and testing.\nSets the _final_estimator internal attribute to the fitted EconML estimator.\n\n\n&gt;&gt;&gt; caml_obj.fit_final() # Fits the final estimator on the entire dataset.\n\n\n\n\nCamlCATE.fit_validator(subset_cate_models=['LinearDML', 'CausalForestDML', 'NonParamDML', 'AutoNonParamDML', 'SparseLinearDML-2D', 'DRLearner', 'ForestDRLearner', 'LinearDRLearner', 'SparseLinearDRLearner-2D', 'DomainAdaptationLearner', 'SLearner', 'TLearner', 'XLearner'], additional_cate_models=[], rscorer_kwargs={}, use_ray=False, ray_remote_func_options_kwargs={}, sample_fraction=1.0, n_jobs=1)\nFits the CATE models on the training set and evaluates them & ensembles based on the validation set.\nSets the _validation_estimator and _rscorer internal attributes to the fitted EconML estimator and RScorer object.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nsubset_cate_models\nlist[str]\nThe list of CATE models to fit and ensemble. Default implies all available models as defined by class.\n['LinearDML', 'CausalForestDML', 'NonParamDML', 'AutoNonParamDML', 'SparseLinearDML-2D', 'DRLearner', 'ForestDRLearner', 'LinearDRLearner', 'SparseLinearDRLearner-2D', 'DomainAdaptationLearner', 'SLearner', 'TLearner', 'XLearner']\n\n\nadditional_cate_models\nlist[tuple[str, BaseCateEstimator]]\nThe list of additional CATE models to fit and ensemble\n[]\n\n\nrscorer_kwargs\ndict\nThe keyword arguments for the econml.score.RScorer object.\n{}\n\n\nuse_ray\nbool\nA boolean indicating whether to use Ray for parallel processing.\nFalse\n\n\nray_remote_func_options_kwargs\ndict\nThe keyword arguments for the Ray remote function options.\n{}\n\n\nsample_fraction\nfloat\nThe fraction of the training data to use for fitting the CATE models. Default implies 1.0 (full training data).\n1.0\n\n\nn_jobs\nint\nThe number of parallel jobs to run. Default implies 1 (no parallel jobs).\n1\n\n\n\n\n\n\n&gt;&gt;&gt; rscorer_kwargs = {\n...     \"cv\": 3,\n...     \"mc_iters\": 3,\n...     }\n&gt;&gt;&gt; subset_cate_models = [\"LinearDML\", \"NonParamDML\", \"CausalForestDML\"]\n&gt;&gt;&gt; additional_cate_models = [(\"XLearner\", XLearner(models=caml_obj._model_Y_X_T, cate_models=caml_obj._model_Y_X_T, propensity_model=caml._model_T_X))]\n&gt;&gt;&gt; caml_obj.fit_validator(subset_cate_models=subset_cate_models, additional_cate_models=additional_cate_models, rscorer_kwargs=rscorer_kwargs)\n\n\n\n\nCamlCATE.predict(X=None, T0=0, T1=1)\nPredicts the CATE based on the fitted final estimator for either the internal dataset or provided Data.\nFor binary treatments, the CATE is the estimated effect of the treatment and for a continuous treatment, the CATE is the estimated effect of a one-unit increase in the treatment. This can be modified by setting the T0 and T1 parameters to the desired treatment levels.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nX\npandas.DataFrame | polars.DataFrame | pyspark.sql.DataFrame\nThe DataFrame containing the features (X) for which CATE needs to be predicted. If not provided, defaults to the internal dataset.\nNone\n\n\nT0\nint\nBase treatment for each sample.\n0\n\n\nT1\nint\nTarget treatment for each sample.\n1\n\n\n\n\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nnp.ndarray\nThe predicted CATE values if return_predictions is set to True.\n\n\n\n\n\n\n&gt;&gt;&gt; caml.predict(return_as_dataframe=True)\n\n\n\n\nCamlCATE.summarize(cate_predictions=None)\nProvides population summary statistics for the CATE predictions for either the internal results or provided results.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\ncate_predictions\nnp.ndarray | None\nThe CATE predictions for which summary statistics will be generated. If not provided, defaults to internal CATE predictions genered by predict() method with X=None.\nNone\n\n\n\n\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\npandas.DataFrame | pandas.Series\nThe summary statistics for the CATE predictions.\n\n\n\n\n\n\n&gt;&gt;&gt; caml.summarize() # Summarizes the CATE predictions for the internal DataFrame.\n\n\n\n\nCamlCATE.validate(n_groups=4, n_bootstrap=100, estimator=None, print_full_report=True)\nValidates the fitted CATE models on the test set to check for generalization performance. Uses the DRTester class from EconML to obtain the Best Linear Predictor (BLP), Calibration, AUTOC, and QINI. See EconML documentation for more details. In short, we are checking for the ability of the model to find statistically significant heterogeneity in a ‚Äúwell-calibrated‚Äù fashion.\nSets the _validator_results internal attribute to the results of the DRTester class.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nn_groups\nint\nThe number of quantile based groups used to calculate calibration scores.\n4\n\n\nn_bootstrap\nint\nThe number of boostrap samples to run when calculating confidence bands.\n100\n\n\nestimator\nBaseCateEstimator | EnsembleCateEstimator | None\nThe estimator to validate. Default implies the best estimator from the validation set.\nNone\n\n\nprint_full_report\nbool\nA boolean indicating whether to print the full validation report.\nTrue\n\n\n\n\n\n\n&gt;&gt;&gt; caml_obj.validate(print_full_report=True) # Prints the full validation report."
  },
  {
    "objectID": "03_Reference/CamlCATE.html#parameters",
    "href": "03_Reference/CamlCATE.html#parameters",
    "title": "CamlCATE",
    "section": "",
    "text": "Name\nType\nDescription\nDefault\n\n\n\n\ndf\npandas.DataFrame | polars.DataFrame | pyspark.sql.DataFrame\nThe input DataFrame representing the data for the CamlCATE instance.\nrequired\n\n\nY\nstr\nThe str representing the column name for the outcome variable.\nrequired\n\n\nT\nstr\nThe str representing the column name(s) for the treatment variable(s).\nrequired\n\n\nX\nlist[str] | str | None\nThe str (if unity) or list of feature names representing the feature set to be utilized for estimating heterogeneity/CATE.\nrequired\n\n\nW\nlist[str] | str | None\nThe str (if unity) or list of feature names representing the confounder/control feature set to be utilized only for nuisance function estimation where applicable.\nrequired\n\n\ndiscrete_treatment\nbool\nA boolean indicating whether the treatment is discrete/categorical or continuous.\nTrue\n\n\ndiscrete_outcome\nbool\nA boolean indicating whether the outcome is binary or continuous.\nFalse\n\n\nseed\nint | None\nThe seed to use for the random number generator.\nNone\n\n\nverbose\nint\nThe verbosity level for logging. Default implies 1 (INFO). Set to 0 for no logging. Set to 2 for DEBUG.\n1"
  },
  {
    "objectID": "03_Reference/CamlCATE.html#attributes",
    "href": "03_Reference/CamlCATE.html#attributes",
    "title": "CamlCATE",
    "section": "",
    "text": "Name\nType\nDescription\n\n\n\n\ndf\npandas.DataFrame | polars.DataFrame | pyspark.sql.DataFrame | ibis.Table\nThe input DataFrame representing the data for the CamlCATE instance.\n\n\nY\nstr\nThe str representing the column name for the outcome variable.\n\n\nT\nstr\nThe str representing the column name(s) for the treatment variable(s).\n\n\nX\nlist[str] | str\nThe str (if unity) or list/tuple of feature names representing the confounder/control feature set to be utilized for estimating heterogeneity/CATE and nuisance function estimation where applicable.\n\n\nW\nlist[str] | str\nThe str (if unity) or list/tuple of feature names representing the confounder/control feature set to be utilized only for nuisance function estimation, where applicable. These will be included by default in Meta-Learners.\n\n\ndiscrete_treatment\nbool\nA boolean indicating whether the treatment is discrete/categorical or continuous.\n\n\ndiscrete_outcome\nbool\nA boolean indicating whether the outcome is binary or continuous.\n\n\nvalidation_estimator\neconml._cate_estimator.BaseCateEstimator | econml.score.EnsembleCateEstimator\nThe fitted EconML estimator object for validation.\n\n\nfinal_estimator\neconml._cate_estimator.BaseCateEstimator | econml.score.EnsembleCateEstimator\nThe fitted EconML estimator object on the entire dataset after validation.\n\n\ndataframe\npandas.DataFrame | polars.DataFrame | pyspark.sql.DataFrame | ibis.Table\nThe input DataFrame with any modifications (e.g., predictions or rank orderings) made by the class returned to the original backend.\n\n\nmodel_Y_X_W\nsklearn.base.BaseEstimator\nThe fitted nuisance function for the outcome variable.\n\n\nmodel_Y_X_W_T\nsklearn.base.BaseEstimator\nThe fitted nuisance function for the outcome variable with treatment variable.\n\n\nmodel_T_X_W\nsklearn.base.BaseEstimator\nThe fitted nuisance function for the treatment variable.\n\n\n_Y\nibis.Table\nThe outcome variable data as ibis table.\n\n\n_T\nibis.Table\nThe treatment variable data as ibis table.\n\n\n_X\nibis.Table\nThe feature/confounder set data as ibis table.\n\n\n_X_T\nibis.Table\nThe feature/confounder feature set and treatment variable data as ibis table.\n\n\n_nuisances_fitted\nbool\nA boolean indicating whether the nuisance functions have been fitted.\n\n\n_validation_estimator\neconml._cate_estimator.BaseCateEstimator | econml.score.EnsembleCateEstimator\nThe fitted EconML estimator object for validation.\n\n\n_final_estimator\neconml._cate_estimator.BaseCateEstimator | econml.score.EnsembleCateEstimator\nThe fitted EconML estimator object for final predictions.\n\n\n_validator_results\neconml.validate.EvaluationResults\nThe results of the validation tests from DRTester.\n\n\n_cate_models\nlist[tuple[str, econml._cate_estimator.BaseCateEstimator]]\nThe list of CATE models to fit and ensemble.\n\n\n_data_splits\ndict[str, np.ndarray]\nThe dictionary containing the training, validation, and test data splits.\n\n\n_rscorer\neconml.score.RScorer\nThe RScorer object for the validation estimator."
  },
  {
    "objectID": "03_Reference/CamlCATE.html#examples",
    "href": "03_Reference/CamlCATE.html#examples",
    "title": "CamlCATE",
    "section": "",
    "text": "&gt;&gt;&gt; from caml.core.cate import CamlCATE\n&gt;&gt;&gt; from caml.extensions.synthetic_data import make_fully_heterogeneous_dataset\n&gt;&gt;&gt;\n&gt;&gt;&gt; # Generate synthetic dataset\n&gt;&gt;&gt; df, true_cates, true_ate = make_fully_heterogeneous_dataset(n_obs=1000, n_confounders=10, theta=10, seed=1)\n&gt;&gt;&gt;\n&gt;&gt;&gt; # Instantiate CamlCATE class\n&gt;&gt;&gt; caml_obj= CamlCATE(df=df,\n...                    Y=\"y\",\n...                    T=\"d\",\n...                    X=[c for c in df.columns if \"X\" in c],\n...                    W=[c for c in df.columns if \"W\" in c],\n...                    discrete_treatment=True,\n...                    discrete_outcome=True,\n...                    seed=0,\n...                    verbose=1)\n&gt;&gt;&gt;\n&gt;&gt;&gt; # Standard pipeline\n&gt;&gt;&gt; caml_obj.auto_nuisance_functions()\n&gt;&gt;&gt; caml_obj.fit_validator()\n&gt;&gt;&gt; caml_obj.validate()\n&gt;&gt;&gt; caml_obj.fit_final()\n&gt;&gt;&gt; predictions = caml_obj.predict()\n&gt;&gt;&gt; summarized_predictions = caml_obj.summarize()\n&gt;&gt;&gt;\n&gt;&gt;&gt; # Access final model (can be saved for future inference)\n&gt;&gt;&gt; final_estimator = caml_obj.final_estimator"
  },
  {
    "objectID": "03_Reference/CamlCATE.html#methods",
    "href": "03_Reference/CamlCATE.html#methods",
    "title": "CamlCATE",
    "section": "",
    "text": "Name\nDescription\n\n\n\n\nauto_nuisance_functions\nLeverages AutoML to find optimal nuisance functions/regression & propensity models for use in EconML CATE estimators.\n\n\nfit_final\nFits the final estimator on the entire dataset, after validation and testing.\n\n\nfit_validator\nFits the CATE models on the training set and evaluates them & ensembles based on the validation set.\n\n\npredict\nPredicts the CATE based on the fitted final estimator for either the internal dataset or provided Data.\n\n\nsummarize\nProvides population summary statistics for the CATE predictions for either the internal results or provided results.\n\n\nvalidate\nValidates the fitted CATE models on the test set to check for generalization performance. Uses the DRTester class from EconML to obtain the Best\n\n\n\n\n\nCamlCATE.auto_nuisance_functions(flaml_Y_kwargs=None, flaml_T_kwargs=None, use_ray=False, use_spark=False)\nLeverages AutoML to find optimal nuisance functions/regression & propensity models for use in EconML CATE estimators.\nSets the model_Y_X_W, model_Y_X_W_T, and model_T_X_W internal attributes to the fitted nuisance functions.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nflaml_Y_kwargs\ndict | None\nThe keyword arguments for the FLAML AutoML search for the outcome model. Default implies the base parameters in CamlBase.\nNone\n\n\nflaml_T_kwargs\ndict | None\nThe keyword arguments for the FLAML AutoML search for the treatment model. Default implies the base parameters in CamlBase.\nNone\n\n\nuse_ray\nbool\nA boolean indicating whether to use Ray for parallel processing.\nFalse\n\n\nuse_spark\nbool\nA boolean indicating whether to use Spark for parallel processing.\nFalse\n\n\n\n\n\n\n&gt;&gt;&gt; flaml_Y_kwargs = {\n...     \"n_jobs\": -1,\n...     \"time_budget\": 300, # in seconds\n...     }\n&gt;&gt;&gt; flaml_T_kwargs = {\n...     \"n_jobs\": -1,\n...     \"time_budget\": 300,\n...     }\n&gt;&gt;&gt; caml_obj.auto_nuisance_functions(flaml_Y_kwargs=flaml_Y_kwargs, flaml_T_kwargs=flaml_T_kwargs)\n\n\n\n\nCamlCATE.fit_final()\nFits the final estimator on the entire dataset, after validation and testing.\nSets the _final_estimator internal attribute to the fitted EconML estimator.\n\n\n&gt;&gt;&gt; caml_obj.fit_final() # Fits the final estimator on the entire dataset.\n\n\n\n\nCamlCATE.fit_validator(subset_cate_models=['LinearDML', 'CausalForestDML', 'NonParamDML', 'AutoNonParamDML', 'SparseLinearDML-2D', 'DRLearner', 'ForestDRLearner', 'LinearDRLearner', 'SparseLinearDRLearner-2D', 'DomainAdaptationLearner', 'SLearner', 'TLearner', 'XLearner'], additional_cate_models=[], rscorer_kwargs={}, use_ray=False, ray_remote_func_options_kwargs={}, sample_fraction=1.0, n_jobs=1)\nFits the CATE models on the training set and evaluates them & ensembles based on the validation set.\nSets the _validation_estimator and _rscorer internal attributes to the fitted EconML estimator and RScorer object.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nsubset_cate_models\nlist[str]\nThe list of CATE models to fit and ensemble. Default implies all available models as defined by class.\n['LinearDML', 'CausalForestDML', 'NonParamDML', 'AutoNonParamDML', 'SparseLinearDML-2D', 'DRLearner', 'ForestDRLearner', 'LinearDRLearner', 'SparseLinearDRLearner-2D', 'DomainAdaptationLearner', 'SLearner', 'TLearner', 'XLearner']\n\n\nadditional_cate_models\nlist[tuple[str, BaseCateEstimator]]\nThe list of additional CATE models to fit and ensemble\n[]\n\n\nrscorer_kwargs\ndict\nThe keyword arguments for the econml.score.RScorer object.\n{}\n\n\nuse_ray\nbool\nA boolean indicating whether to use Ray for parallel processing.\nFalse\n\n\nray_remote_func_options_kwargs\ndict\nThe keyword arguments for the Ray remote function options.\n{}\n\n\nsample_fraction\nfloat\nThe fraction of the training data to use for fitting the CATE models. Default implies 1.0 (full training data).\n1.0\n\n\nn_jobs\nint\nThe number of parallel jobs to run. Default implies 1 (no parallel jobs).\n1\n\n\n\n\n\n\n&gt;&gt;&gt; rscorer_kwargs = {\n...     \"cv\": 3,\n...     \"mc_iters\": 3,\n...     }\n&gt;&gt;&gt; subset_cate_models = [\"LinearDML\", \"NonParamDML\", \"CausalForestDML\"]\n&gt;&gt;&gt; additional_cate_models = [(\"XLearner\", XLearner(models=caml_obj._model_Y_X_T, cate_models=caml_obj._model_Y_X_T, propensity_model=caml._model_T_X))]\n&gt;&gt;&gt; caml_obj.fit_validator(subset_cate_models=subset_cate_models, additional_cate_models=additional_cate_models, rscorer_kwargs=rscorer_kwargs)\n\n\n\n\nCamlCATE.predict(X=None, T0=0, T1=1)\nPredicts the CATE based on the fitted final estimator for either the internal dataset or provided Data.\nFor binary treatments, the CATE is the estimated effect of the treatment and for a continuous treatment, the CATE is the estimated effect of a one-unit increase in the treatment. This can be modified by setting the T0 and T1 parameters to the desired treatment levels.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nX\npandas.DataFrame | polars.DataFrame | pyspark.sql.DataFrame\nThe DataFrame containing the features (X) for which CATE needs to be predicted. If not provided, defaults to the internal dataset.\nNone\n\n\nT0\nint\nBase treatment for each sample.\n0\n\n\nT1\nint\nTarget treatment for each sample.\n1\n\n\n\n\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nnp.ndarray\nThe predicted CATE values if return_predictions is set to True.\n\n\n\n\n\n\n&gt;&gt;&gt; caml.predict(return_as_dataframe=True)\n\n\n\n\nCamlCATE.summarize(cate_predictions=None)\nProvides population summary statistics for the CATE predictions for either the internal results or provided results.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\ncate_predictions\nnp.ndarray | None\nThe CATE predictions for which summary statistics will be generated. If not provided, defaults to internal CATE predictions genered by predict() method with X=None.\nNone\n\n\n\n\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\npandas.DataFrame | pandas.Series\nThe summary statistics for the CATE predictions.\n\n\n\n\n\n\n&gt;&gt;&gt; caml.summarize() # Summarizes the CATE predictions for the internal DataFrame.\n\n\n\n\nCamlCATE.validate(n_groups=4, n_bootstrap=100, estimator=None, print_full_report=True)\nValidates the fitted CATE models on the test set to check for generalization performance. Uses the DRTester class from EconML to obtain the Best Linear Predictor (BLP), Calibration, AUTOC, and QINI. See EconML documentation for more details. In short, we are checking for the ability of the model to find statistically significant heterogeneity in a ‚Äúwell-calibrated‚Äù fashion.\nSets the _validator_results internal attribute to the results of the DRTester class.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nn_groups\nint\nThe number of quantile based groups used to calculate calibration scores.\n4\n\n\nn_bootstrap\nint\nThe number of boostrap samples to run when calculating confidence bands.\n100\n\n\nestimator\nBaseCateEstimator | EnsembleCateEstimator | None\nThe estimator to validate. Default implies the best estimator from the validation set.\nNone\n\n\nprint_full_report\nbool\nA boolean indicating whether to print the full validation report.\nTrue\n\n\n\n\n\n\n&gt;&gt;&gt; caml_obj.validate(print_full_report=True) # Prints the full validation report."
  },
  {
    "objectID": "03_Reference/index.html",
    "href": "03_Reference/index.html",
    "title": "API Reference",
    "section": "",
    "text": "from caml import *\n\n\n\nCamlCATE\nThe CamlCATE class represents an opinionated framework of Causal Machine Learning techniques for estimating\n\n\n\n\n\n\nfrom caml.extensions.synthetic_data import *\n\n\n\nmake_partially_linear_dataset_simple\nSimulate data generating process from a partially linear model with a simple 1 or 2 dimensional CATE function. The outcome is continuous and the treatment can be binary or continuous.\n\n\nmake_partially_linear_dataset_constant\nSimulate a data generating process from a partially linear model with a constant treatment effect (ATE only). The outcome and treatment are both continuous.\n\n\nmake_fully_heterogeneous_dataset\nSimulate data generating process from an interactive regression model with fully heterogenous treatment effects. The outcome is continuous and the treatment is binary.\n\n\nmake_dowhy_linear_dataset\nSimulate a linear data generating process with flexible configurations. The outcome and treatment can take on different data types.\n\n\n\n\n\n\nfrom caml.extensions.plots import *\n\n\n\ncate_histogram_plot\nPlots a histogram the estimated CATEs.\n\n\ncate_line_plot\nPlots a line plot of the ordered estimated CATEs as a rolling mean with optional confidence intervals.\n\n\ncate_true_vs_estimated_plot\nPlots a scatter plot of the estimated CATEs against the true CATEs.\n\n\n\n\n\n\n\n\n\nutils.generate_random_string\nFunction to generate a random string of ascii lowercase letters and digits of length N.\n\n\nutils.cls_typechecked\nClass decorator to typecheck all methods of a class.\n\n\nlogging.setup_logging\nSet up logging configuration."
  },
  {
    "objectID": "03_Reference/index.html#caml-core",
    "href": "03_Reference/index.html#caml-core",
    "title": "API Reference",
    "section": "",
    "text": "from caml import *\n\n\n\nCamlCATE\nThe CamlCATE class represents an opinionated framework of Causal Machine Learning techniques for estimating"
  },
  {
    "objectID": "03_Reference/index.html#synthetic-data-generation",
    "href": "03_Reference/index.html#synthetic-data-generation",
    "title": "API Reference",
    "section": "",
    "text": "from caml.extensions.synthetic_data import *\n\n\n\nmake_partially_linear_dataset_simple\nSimulate data generating process from a partially linear model with a simple 1 or 2 dimensional CATE function. The outcome is continuous and the treatment can be binary or continuous.\n\n\nmake_partially_linear_dataset_constant\nSimulate a data generating process from a partially linear model with a constant treatment effect (ATE only). The outcome and treatment are both continuous.\n\n\nmake_fully_heterogeneous_dataset\nSimulate data generating process from an interactive regression model with fully heterogenous treatment effects. The outcome is continuous and the treatment is binary.\n\n\nmake_dowhy_linear_dataset\nSimulate a linear data generating process with flexible configurations. The outcome and treatment can take on different data types."
  },
  {
    "objectID": "03_Reference/index.html#plots",
    "href": "03_Reference/index.html#plots",
    "title": "API Reference",
    "section": "",
    "text": "from caml.extensions.plots import *\n\n\n\ncate_histogram_plot\nPlots a histogram the estimated CATEs.\n\n\ncate_line_plot\nPlots a line plot of the ordered estimated CATEs as a rolling mean with optional confidence intervals.\n\n\ncate_true_vs_estimated_plot\nPlots a scatter plot of the estimated CATEs against the true CATEs."
  },
  {
    "objectID": "03_Reference/index.html#developer-tools",
    "href": "03_Reference/index.html#developer-tools",
    "title": "API Reference",
    "section": "",
    "text": "utils.generate_random_string\nFunction to generate a random string of ascii lowercase letters and digits of length N.\n\n\nutils.cls_typechecked\nClass decorator to typecheck all methods of a class.\n\n\nlogging.setup_logging\nSet up logging configuration."
  },
  {
    "objectID": "03_Reference/make_dowhy_linear_dataset.html",
    "href": "03_Reference/make_dowhy_linear_dataset.html",
    "title": "make_dowhy_linear_dataset",
    "section": "",
    "text": "extensions.synthetic_data.make_dowhy_linear_dataset(beta=2.0, n_obs=1000, n_confounders=10, n_discrete_confounders=0, n_effect_modifiers=5, n_discrete_effect_modifiers=0, n_treatments=1, binary_treatment=False, categorical_treatment=False, binary_outcome=False, seed=None)\nSimulate a linear data generating process with flexible configurations. The outcome and treatment can take on different data types. The dataset is generated using a modified version of the make_linear_data function from the dowhy package.\nThe general form of the data generating process is:\n\\[\ny_i = \\tau (\\mathbf{X_i}) \\mathbf{D_i} + g(\\mathbf{W_i}) + \\epsilon_i\n\\] \\[\n\\mathbf{D_i}=f(\\mathbf{W_i})+\\eta_i\n\\]\nwhere \\(y_i\\) is the outcome, \\(\\mathbf{D_i}\\) are the treatment(s), \\(\\mathbf{X_i}\\) are the effect modifiers (utilized for effect heterogeneity only), \\(\\mathbf{W_i}\\) are the confounders, \\(\\epsilon_i\\) and \\(\\eta_i\\) are the error terms, \\(\\tau\\) is the linear CATE function, \\(g\\) is the linear outcome function, and \\(f\\) is the linear treatment function.\nAs a DAG, the data generating process can be roughly represented as:"
  },
  {
    "objectID": "03_Reference/make_dowhy_linear_dataset.html#parameters",
    "href": "03_Reference/make_dowhy_linear_dataset.html#parameters",
    "title": "make_dowhy_linear_dataset",
    "section": "Parameters",
    "text": "Parameters\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nbeta\nfloat\nThe base effect size of the treatment. Note, this differs from the ATE with effect modifiers.\n2.0\n\n\nn_obs\nint\nThe number of observations to generate.\n1000\n\n\nn_confounders\nint\nThe number of confounders \\(\\mathbf{W_i}\\) to generate.\n10\n\n\nn_discrete_confounders\nint\nThe number of discrete confounders to generate.\n0\n\n\nn_effect_modifiers\nint\nThe number of effect modifiers \\(\\mathbf{X_i}\\) to generate.\n5\n\n\nn_discrete_effect_modifiers\nint\nThe number of discrete effect modifiers to generate.\n0\n\n\nn_treatments\nint\nThe number of treatments \\(\\mathbf{D_i}\\) to generate.\n1\n\n\nbinary_treatment\nbool\nWhether the treatment is binary or continuous.\nFalse\n\n\ncategorical_treatment\nbool\nWhether the treatment is categorical or continuous.\nFalse\n\n\nbinary_outcome\nbool\nWhether the outcome is binary or continuous.\nFalse\n\n\nseed\nint | None\nThe seed to use for the random number generator.\nNone"
  },
  {
    "objectID": "03_Reference/make_dowhy_linear_dataset.html#returns",
    "href": "03_Reference/make_dowhy_linear_dataset.html#returns",
    "title": "make_dowhy_linear_dataset",
    "section": "Returns",
    "text": "Returns\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\npandas.DataFrame\nThe generated dataset where y is the outcome, d are the treatment(s), X are the covariates that are utilized for heterogeneity only, and W are the confounders.\n\n\ndict[str, np.ndarray]\nThe true conditional average treatment effects for each treatment.\n\n\ndict[str, float]\nThe true average treatment effect for each treatment."
  },
  {
    "objectID": "03_Reference/make_dowhy_linear_dataset.html#examples",
    "href": "03_Reference/make_dowhy_linear_dataset.html#examples",
    "title": "make_dowhy_linear_dataset",
    "section": "Examples",
    "text": "Examples\n\nfrom caml.extensions.synthetic_data import make_dowhy_linear_dataset\ndf, true_cates, true_ate = make_dowhy_linear_dataset(beta=2.0,\n                                                    n_obs=1000,\n                                                    n_confounders=10,\n                                                    n_discrete_confounders=0,\n                                                    n_effect_modifiers=5,\n                                                    n_discrete_effect_modifiers=0,\n                                                    n_treatments=1,\n                                                    binary_treatment=False,\n                                                    categorical_treatment=False,\n                                                    binary_outcome=False,\n                                                    seed=1)\n\nprint(f\"True CATEs: {true_cates['d1'][:5]}\")\nprint(f\"True ATE: {true_ate}\")\nprint(df.head())\n\nTrue CATEs: [7.02877025 4.5496771  2.58332253 3.65591464 1.28649085]\nTrue ATE: {'d1': 3.316926309432912}\n         X0        X1        X2        X3        X4        W0        W1  \\\n0 -0.833791  0.489626  2.467073  1.214193  1.629267  1.578856 -0.320558   \n1 -0.419489  2.224769  0.879272  1.229339  0.429658 -0.338384 -0.437209   \n2 -1.254407  0.085966  1.146039 -0.401340  0.536695 -0.288846 -0.495120   \n3 -0.455729 -1.267684  0.705253  1.118711 -0.208877 -1.283266  0.675065   \n4 -0.368183 -0.540464  0.145927 -0.655766  0.101447  0.024959  2.540904   \n\n         W2        W3        W4        W5        W6        W7        W8  \\\n0 -0.680732 -0.644705  0.755620 -2.875464 -0.949897 -0.692933  0.927304   \n1 -0.957558  0.187480 -1.807107  0.329401  0.274111  0.193616  0.694391   \n2 -1.267659  0.135021 -1.398149 -1.212076 -1.314652 -1.154084 -0.877711   \n3  0.660031  0.346709 -0.898324 -1.702952 -1.374638  1.383576 -0.155657   \n4 -0.879612  0.221868 -0.406318 -1.167573 -1.769998 -0.658221 -0.415359   \n\n         W9        d1          y  \n0 -1.022258 -0.402456  -4.033895  \n1 -0.606094 -2.701095 -14.874571  \n2  0.064969 -4.708212 -20.767053  \n3 -0.559362 -0.250823  -6.462511  \n4  0.664257  3.890331   0.872735"
  },
  {
    "objectID": "index.html#welcome",
    "href": "index.html#welcome",
    "title": "\n\n",
    "section": "Welcome!",
    "text": "Welcome!\nCaML = Causal Machine Learning\nCaML provides a high-level API for an opinionated framework in performing Causal ML to estimate Average Treatment Effects (ATEs), Group Average Treatment Effects (GATEs), and Conditional Average Treatment Effects (CATEs), and to provide mechanisms to utilize these models for out of sample prediction & policy prescription.\nThe codebase is comprised primarily of extensions & abstractions over top of EconML & DoubleML with techniques motivated heavily by Causal ML Book and additional research.",
    "crumbs": [
      "Welcome!"
    ]
  },
  {
    "objectID": "index.html#background",
    "href": "index.html#background",
    "title": "\n\n",
    "section": "Background",
    "text": "Background\nThe origins of CaML are rooted in a desire to develop a set of helper tools to abstract and streamline techniques & best pratices in Causal ML/Econometrics for estimating ATEs, GATEs, and CATEs, along with policy prescription.\nAs we began working on these helper tools, we begun to see the value in reformulating this framework into a reusable package for wider use amongst the community and to provide an opinionated framework that can be integrated into productionalized systems, particularly experimentation platforms, for efficient estimation of causal parameters for reporting & decision-making purposes.\nAdmittedly, we were tempted to include the term ‚ÄúAuto‚Äù in the name of this package (e.g., AutoCATE, AutoCausal, etc.), but we quickly realized the potential for misapplication & naive usage that could arise from that type of ‚Äúbranding.‚Äù Indeed, the misapplication of many Causal AI/ML techniques is all too commonplace in the data science community. All of the standard assumptions for causal inference still apply in order for these tools & techniques to provide unbiased inference.\nGiven a key motivation is to provide a tool for productionalized systems, we are building this package with interoperability and extensibility as core values. The degree of interoperability will be limited in scope at first, but we hope to expand this as the code base develops. As of now, the tools utilized still rely on in-memory datasets for estimation (via EconML for causal models & flaml for AutoML of nuissance functions), but we leverage Ray & Spark for distributing certain processes where appropriate and if available for the user.",
    "crumbs": [
      "Welcome!"
    ]
  },
  {
    "objectID": "03_Reference/make_partially_linear_dataset_simple.html",
    "href": "03_Reference/make_partially_linear_dataset_simple.html",
    "title": "make_partially_linear_dataset_simple",
    "section": "",
    "text": "extensions.synthetic_data.make_partially_linear_dataset_simple(n_obs=1000, n_confounders=5, dim_heterogeneity=2, binary_treatment=True, seed=None)\nSimulate data generating process from a partially linear model with a simple 1 or 2 dimensional CATE function. The outcome is continuous and the treatment can be binary or continuous. The dataset is generated using the make_heterogeneous_data function from the doubleml package.\nThe general form of the data generating process is, in the case of dim_heterogeneity=1:\n\\[\ny_i= \\tau (x_0) d_i + g(\\mathbf{X_i})+\\epsilon_i\n\\] \\[\nd_i=f(\\mathbf{X_i})+\\eta_i\n\\]\nor, in the case of dim_heterogeneity=2:\n\\[\ny_i= \\tau (x_0,x_1) d_i + g(\\mathbf{X_i})+\\epsilon_i\n\\] \\[\nd_i=f(\\mathbf{X_i})+\\eta_i\n\\]\nwhere \\(y_i\\) is the outcome, \\(d_i\\) is the treatment, \\(\\mathbf{X_i}\\) are the confounders, \\(\\epsilon_i\\) and \\(\\eta_i\\) are the error terms, \\(\\tau\\) is the CATE function, \\(g\\) is the outcome function, and \\(f\\) is the treatment function.\nSee the doubleml documentation for more details on the specific functional forms of the data generating process.\nHere the ATE is defined as the average of the CATE function over all observations: \\(\\mathbb{E}[\\tau (\\cdot)]\\)\nAs a DAG, the data generating process can be roughly represented as:"
  },
  {
    "objectID": "03_Reference/make_partially_linear_dataset_simple.html#parameters",
    "href": "03_Reference/make_partially_linear_dataset_simple.html#parameters",
    "title": "make_partially_linear_dataset_simple",
    "section": "Parameters",
    "text": "Parameters\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nn_obs\nint\nThe number of observations to generate.\n1000\n\n\nn_confounders\nint\nThe number of confounders \\(\\mathbf{X_i}\\).\n5\n\n\ndim_heterogeneity\nint\nThe dimension of the heterogeneity \\(x_0\\) or \\((x_0,x_1)\\). Can only be 1 or 2.\n2\n\n\nbinary_treatment\nbool\nWhether the treatment \\(d_i\\) is binary or continuous.\nTrue\n\n\nseed\nint | None\nThe seed to use for the random number generator.\nNone"
  },
  {
    "objectID": "03_Reference/make_partially_linear_dataset_simple.html#returns",
    "href": "03_Reference/make_partially_linear_dataset_simple.html#returns",
    "title": "make_partially_linear_dataset_simple",
    "section": "Returns",
    "text": "Returns\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\npandas.DataFrame\nThe generated dataset where y is the outcome, d is the treatment, and X are the confounders with a 1d or 2d subset utilized for heterogeneity.\n\n\nnumpy.ndarray\nThe true conditional average treatment effects.\n\n\nfloat\nThe true average treatment effect."
  },
  {
    "objectID": "03_Reference/make_partially_linear_dataset_simple.html#examples",
    "href": "03_Reference/make_partially_linear_dataset_simple.html#examples",
    "title": "make_partially_linear_dataset_simple",
    "section": "Examples",
    "text": "Examples\n\nfrom caml.extensions.synthetic_data import make_partially_linear_dataset_simple\ndf, true_cates, true_ate = make_partially_linear_dataset_simple(n_obs=1000,\n                                                                n_confounders=5,\n                                                                dim_heterogeneity=2,\n                                                                binary_treatment=True,\n                                                                seed=1)\n\nprint(f\"True CATES: {true_cates[:5]}\")\nprint(f\"True ATE: {true_ate}\")\nprint(df.head())\n\nTrue CATES: [5.07318438 4.22638341 4.84246206 5.02852819 7.30906609]\nTrue ATE: 4.434805144050488\n          y    d        X0        X1        X2        X3        X4\n0  5.814804  1.0  0.560647  0.182920  0.938085  0.721671  0.209634\n1  4.593199  1.0  0.113353  0.358469  0.271148  0.908152  0.497946\n2  1.489081  0.0  0.970009  0.981170  0.319852  0.034913  0.003447\n3  6.569753  1.0  0.386105  0.317130  0.339849  0.232991  0.463512\n4  8.249305  1.0  0.733222  0.360575  0.903222  0.600965  0.110013"
  },
  {
    "objectID": "03_Reference/utils.cls_typechecked.html",
    "href": "03_Reference/utils.cls_typechecked.html",
    "title": "utils.cls_typechecked",
    "section": "",
    "text": "utils.cls_typechecked(cls)\nClass decorator to typecheck all methods of a class.\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\ncls\n\nThe class to decorate.\nrequired\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\ncls: The decorated class."
  },
  {
    "objectID": "03_Reference/utils.cls_typechecked.html#parameters",
    "href": "03_Reference/utils.cls_typechecked.html#parameters",
    "title": "utils.cls_typechecked",
    "section": "",
    "text": "Name\nType\nDescription\nDefault\n\n\n\n\ncls\n\nThe class to decorate.\nrequired"
  },
  {
    "objectID": "03_Reference/utils.cls_typechecked.html#returns",
    "href": "03_Reference/utils.cls_typechecked.html#returns",
    "title": "utils.cls_typechecked",
    "section": "",
    "text": "Type\nDescription\n\n\n\n\ncls: The decorated class."
  },
  {
    "objectID": "03_Reference/logging.setup_logging.html",
    "href": "03_Reference/logging.setup_logging.html",
    "title": "logging.setup_logging",
    "section": "",
    "text": "logging.setup_logging\nlogging.setup_logging(verbose=1)\nSet up logging configuration.\nThis function configures the logging module with a basic configuration. It sets the logging level to INFO and the log message format to only include the message itself. The logging handler used is rich_handler.\n\n\n\n\n Back to top"
  },
  {
    "objectID": "03_Reference/make_partially_linear_dataset_constant.html",
    "href": "03_Reference/make_partially_linear_dataset_constant.html",
    "title": "make_partially_linear_dataset_constant",
    "section": "",
    "text": "extensions.synthetic_data.make_partially_linear_dataset_constant(n_obs=1000, ate=4.0, n_confounders=10, dgp='make_plr_CCDDHNR2018', seed=None, **doubleml_kwargs)\nSimulate a data generating process from a partially linear model with a constant treatment effect (ATE only). The outcome and treatment are both continuous. The dataset is generated using the make_plr_CCDDHNR2018 or make_plr_turrell2018 function from the doubleml package.\nThe general form of the data generating process is:\n\\[\ny_i= \\tau_0 d_i + g(\\mathbf{W_i})+\\epsilon_i\n\\] \\[\nd_i=f(\\mathbf{W_i})+\\eta_i\n\\]\nwhere \\(y_i\\) is the outcome, \\(d_i\\) is the treatment, \\(\\mathbf{W_i}\\) are the confounders, \\(\\epsilon_i\\) and \\(\\eta_i\\) are the error terms, \\(\\tau_0\\) is the ATE parameter, \\(g\\) is the outcome function, and \\(f\\) is the treatment function.\nSee the doubleml documentation for more details on the specific functional forms of the data generating process.\nAs a DAG, the data generating process can be roughly represented as:"
  },
  {
    "objectID": "03_Reference/make_partially_linear_dataset_constant.html#parameters",
    "href": "03_Reference/make_partially_linear_dataset_constant.html#parameters",
    "title": "make_partially_linear_dataset_constant",
    "section": "Parameters",
    "text": "Parameters\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nn_obs\nint\nThe number of observations to generate.\n1000\n\n\nate\nfloat\nThe average treatment effect \\(\\tau_0\\).\n4.0\n\n\nn_confounders\nint\nThe number of confounders \\(\\mathbf{W_i}\\) to generate.\n10\n\n\ndgp\nstr\nThe data generating process to use. Can be ‚Äúmake_plr_CCDDHNR20‚Äù or ‚Äúmake_plr_turrell2018‚Äù.\n'make_plr_CCDDHNR2018'\n\n\nseed\nint | None\nThe seed to use for the random number generator.\nNone\n\n\n**doubleml_kwargs\n\nAdditional keyword arguments to pass to the data generating process.\n{}"
  },
  {
    "objectID": "03_Reference/make_partially_linear_dataset_constant.html#returns",
    "href": "03_Reference/make_partially_linear_dataset_constant.html#returns",
    "title": "make_partially_linear_dataset_constant",
    "section": "Returns",
    "text": "Returns\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\npandas.DataFrame\nThe generated dataset where y is the outcome, d is the treatment, and W are the confounders.\n\n\nnumpy.ndarray\nThe true conditional average treatment effects, which are all equal to the ATE here.\n\n\nfloat\nThe true average treatment effect."
  },
  {
    "objectID": "03_Reference/make_partially_linear_dataset_constant.html#examples",
    "href": "03_Reference/make_partially_linear_dataset_constant.html#examples",
    "title": "make_partially_linear_dataset_constant",
    "section": "Examples",
    "text": "Examples\n\nfrom caml.extensions.synthetic_data import make_partially_linear_dataset_constant\ndf, true_cates, true_ate = make_partially_linear_dataset_constant(n_obs=1000,\n                                                    ate=4.0,\n                                                    n_confounders=10,\n                                                    dgp=\"make_plr_CCDDHNR2018\",\n                                                    seed=1)\n\nprint(f\"True CATES: {true_cates[:5]}\")\nprint(f\"True ATE: {true_ate}\")\nprint(df.head())\n\nTrue CATES: [4. 4. 4. 4. 4.]\nTrue ATE: 4.0\n         W1        W2        W3        W4        W5        W6        W7  \\\n0 -1.799808 -0.830362 -0.775800 -2.430475 -1.759428 -0.196538 -0.392579   \n1 -2.238925 -2.107779 -1.619264 -1.816121 -2.084809 -0.456936  0.118781   \n2  1.069028  1.616054  1.959420  1.398880  0.058545  0.370891  0.161045   \n3  0.497020 -0.399126 -0.019305  0.230080  0.640361  1.233185  0.906313   \n4 -1.749809 -0.315699 -0.283176  0.439451  0.819941  0.156514  0.059722   \n\n         W8        W9       W10         y         d  \n0 -0.827537 -0.735652 -1.127103 -6.074658 -1.843476  \n1  0.270647  0.199401  0.049088 -8.534573 -1.969429  \n2  0.118180  0.438721  0.280880  4.915427  0.935840  \n3  1.031123 -0.373092  0.442367 -0.037117 -0.209740  \n4  0.472781  0.030157  1.174463 -7.922597 -1.903480"
  },
  {
    "objectID": "03_Reference/cate_line_plot.html",
    "href": "03_Reference/cate_line_plot.html",
    "title": "cate_line_plot",
    "section": "",
    "text": "extensions.plots.cate_line_plot(estimated_cates, *, true_cates=None, standard_errors=None, alpha=0.05, window=30, figure_kwargs={}, line_kwargs={})\nPlots a line plot of the ordered estimated CATEs as a rolling mean with optional confidence intervals."
  },
  {
    "objectID": "03_Reference/cate_line_plot.html#parameters",
    "href": "03_Reference/cate_line_plot.html#parameters",
    "title": "cate_line_plot",
    "section": "Parameters",
    "text": "Parameters\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nestimated_cates\nnumpy.typing.ArrayLike\nThe estimated CATEs.\nrequired\n\n\ntrue_cates\nnumpy.typing.ArrayLike | None\nThe true CATEs.\nNone\n\n\nstandard_errors\nnumpy.typing.ArrayLike | None\nThe standard errors of the estimated CATEs.\nNone\n\n\nalpha\nfloat\nThe alpha level for the confidence intervals. The default is 0.05, which corresponds to 95% confidence intervals.\n0.05\n\n\nwindow\nint\nThe window size for the moving average.\n30\n\n\nfigure_kwargs\ndict\nMatplotlib figure arguments.\n{}\n\n\nline_kwargs\ndict\nMatplotlib line arguments.\n{}"
  },
  {
    "objectID": "03_Reference/cate_line_plot.html#returns",
    "href": "03_Reference/cate_line_plot.html#returns",
    "title": "cate_line_plot",
    "section": "Returns",
    "text": "Returns\n\n\n\nType\nDescription\n\n\n\n\nmatplotlib.figure.Figure\nThe line plot figure object."
  },
  {
    "objectID": "03_Reference/cate_line_plot.html#examples",
    "href": "03_Reference/cate_line_plot.html#examples",
    "title": "cate_line_plot",
    "section": "Examples",
    "text": "Examples\n\nimport numpy as np\nfrom caml.extensions.plots import cate_line_plot\n\nnp.random.seed(42)\ntrue_cates = np.random.normal(0, 1, 100)\nestimated_cates = true_cates + np.random.normal(0, 0.5, 100)\nstandard_errors = np.abs(np.random.normal(0, 0.1, 100))\n\nfig = cate_line_plot(estimated_cates, true_cates=true_cates, standard_errors=standard_errors, window=5)\nfig"
  },
  {
    "objectID": "03_Reference/cate_histogram_plot.html",
    "href": "03_Reference/cate_histogram_plot.html",
    "title": "cate_histogram_plot",
    "section": "",
    "text": "extensions.plots.cate_histogram_plot(estimated_cates, *, true_cates=None, figure_kwargs={}, hist_kwargs={})\nPlots a histogram the estimated CATEs."
  },
  {
    "objectID": "03_Reference/cate_histogram_plot.html#parameters",
    "href": "03_Reference/cate_histogram_plot.html#parameters",
    "title": "cate_histogram_plot",
    "section": "Parameters",
    "text": "Parameters\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nestimated_cates\nnumpy.typing.ArrayLike\nThe estimated CATEs.\nrequired\n\n\ntrue_cates\nnumpy.typing.ArrayLike | None\nThe true CATEs.\nNone\n\n\nfigure_kwargs\ndict\nMatplotlib figure arguments.\n{}\n\n\nhist_kwargs\ndict\nMatplotlib hist arguments.\n{}"
  },
  {
    "objectID": "03_Reference/cate_histogram_plot.html#returns",
    "href": "03_Reference/cate_histogram_plot.html#returns",
    "title": "cate_histogram_plot",
    "section": "Returns",
    "text": "Returns\n\n\n\nType\nDescription\n\n\n\n\nmatplotlib.figure.Figure\nThe histogram figure object."
  },
  {
    "objectID": "03_Reference/cate_histogram_plot.html#examples",
    "href": "03_Reference/cate_histogram_plot.html#examples",
    "title": "cate_histogram_plot",
    "section": "Examples",
    "text": "Examples\n\nimport numpy as np\nfrom caml.extensions.plots import cate_histogram_plot\n\nnp.random.seed(42)\ntrue_cates = np.random.normal(0, 1, 1000)\nestimated_cates = true_cates + np.random.normal(0, 0.5, 1000)\n\nfig = cate_histogram_plot(estimated_cates, true_cates=true_cates, hist_kwargs={'bins': 25})\nfig"
  },
  {
    "objectID": "01_Home/quickstart.html",
    "href": "01_Home/quickstart.html",
    "title": "Tutorial: Quick Start",
    "section": "",
    "text": "Forthcoming\n\n\n\n Back to top",
    "crumbs": [
      "Tutorial: Quick Start"
    ]
  },
  {
    "objectID": "02_Concepts/theory.html",
    "href": "02_Concepts/theory.html",
    "title": "Econometric Theory",
    "section": "",
    "text": "Forthcoming\n\n\n\n Back to top",
    "crumbs": [
      "Econometric Theory"
    ]
  },
  {
    "objectID": "04_Contributors/environment.html",
    "href": "04_Contributors/environment.html",
    "title": "Environment & Development",
    "section": "",
    "text": "uv\nWSL (required for Windows users to utilize Quarto for docs)\nOptional: Docker",
    "crumbs": [
      "Environment & Development"
    ]
  },
  {
    "objectID": "04_Contributors/environment.html#prerequisites",
    "href": "04_Contributors/environment.html#prerequisites",
    "title": "Environment & Development",
    "section": "",
    "text": "uv\nWSL (required for Windows users to utilize Quarto for docs)\nOptional: Docker",
    "crumbs": [
      "Environment & Development"
    ]
  },
  {
    "objectID": "04_Contributors/environment.html#environment-setup",
    "href": "04_Contributors/environment.html#environment-setup",
    "title": "Environment & Development",
    "section": "Environment Setup",
    "text": "Environment Setup\nWe primarily utilize Docker for development environment standardization & uv for project, package, and dependency management.\n\nOption 1 (recommended): Docker Development Environment\n\nInstall Docker\nClone repository\n\nWe highly recommend utilizing ssh for cloning the repository.\ngit clone git@github.com:jakepenzak/caml.git\ncd caml\n\nVS Code Users: Set up Dev Containers\n\n\nDownload Dev Containers Extension\nCopy .devcontainer-template.json as .devcontainer.json and fill out {USERNAME} & {EMAIL}\nFollow steps to open current working directory in container\nTest github access - if running into issues, copy .ssh keys into .github_access/ directory. This directory gets copied into .ssh/ directory inside container. DO NOT COMMIT anything stored under .github_access/.\nTest uv pip list to ensure environment dependencies are properly installed - you should see caml installed as an editable package.\n\n\nNon-VS Code Users: Utilize docker-run.sh\n\n\nRun source docker-run.sh with respective flags. Call --help for details. This should spin up a terminal session in docker container.\nTest github access - if running into issues, copy .ssh keys into .github_access/ directory. This directory gets copied into .ssh/ directory inside container. DO NOT COMMIT anything stored under .github_access/.\nTest uv pip list to ensure environment dependencies are properly installed - you should see caml installed as an editable package.\n\n\n\nOption 2: Virtual Environment Only\n\nInstall uv\nRun uv sync --all-extras --frozen\nActivate the .venv via source .venv/bin/activate\nTest uv pip list to ensure environment dependencies are properly installed - you should see caml installed as an editable package.\nRun pre-commit install\nOptional: Install Quarto for edits on documentation, please refer to documentation page",
    "crumbs": [
      "Environment & Development"
    ]
  },
  {
    "objectID": "04_Contributors/environment.html#committing-pull-requests",
    "href": "04_Contributors/environment.html#committing-pull-requests",
    "title": "Environment & Development",
    "section": "Committing & Pull Requests",
    "text": "Committing & Pull Requests\n\nTry best to follow commit message conventions outlined here\nOn PRs, please fill out the generated PR template. All github actions & workflows will be required to complete successfully prior to merging.",
    "crumbs": [
      "Environment & Development"
    ]
  },
  {
    "objectID": "01_Home/example.html",
    "href": "01_Home/example.html",
    "title": "Examples",
    "section": "",
    "text": "Back to top",
    "crumbs": [
      "Examples"
    ]
  },
  {
    "objectID": "assets/marimo/marimo.html",
    "href": "assets/marimo/marimo.html",
    "title": "Marimo",
    "section": "",
    "text": "import marimo as mo\n\nCaml Synthetic Data API Usage\nfrom caml.extensions.synthetic_data import CamlSyntheticDataGenerator\ndata =  CamlSyntheticDataGenerator(n_obs=10_000,\n                                  n_cont_outcomes=1,\n                                  n_binary_outcomes=0,\n                                  n_cont_treatments=1,\n                                  n_binary_treatments=0,\n                                  n_discrete_treatments=0,\n                                  n_cont_confounders=2, \n                                  n_binary_confounders=2,\n                                  n_discrete_confounders=2,\n                                  n_cont_heterogeneity_covariates=4,\n                                  n_binary_heterogeneity_covariates=4,\n                                  n_discrete_heterogeneity_covariates=4,\n                                  n_heterogeneity_confounders=0,\n                                  stddev_outcome_noise=3,\n                                  stddev_treatment_noise=3,\n                                  causal_model_functional_form=\"fully_non_linear\",\n                                  n_nonlinear_transformations=10,\n                                  n_nonlinear_interactions=5,\n                                  treatment_effect_weight=1,\n                                  seed=None)\ndata.df\ndata.cates\ndata.ates\n\n\n\n\n\n Back to top"
  },
  {
    "objectID": "01_Home/marimo.html",
    "href": "01_Home/marimo.html",
    "title": "Marimo",
    "section": "",
    "text": "import marimo as mo\n\nCaml Synthetic Data API Usage\nfrom caml.extensions.synthetic_data import CamlSyntheticDataGenerator\ndata =  CamlSyntheticDataGenerator(n_obs=10_000,\n                                  n_cont_outcomes=1,\n                                  n_binary_outcomes=0,\n                                  n_cont_treatments=1,\n                                  n_binary_treatments=0,\n                                  n_discrete_treatments=0,\n                                  n_cont_confounders=2, \n                                  n_binary_confounders=2,\n                                  n_discrete_confounders=2,\n                                  n_cont_heterogeneity_covariates=4,\n                                  n_binary_heterogeneity_covariates=4,\n                                  n_discrete_heterogeneity_covariates=4,\n                                  n_heterogeneity_confounders=0,\n                                  stddev_outcome_noise=3,\n                                  stddev_treatment_noise=3,\n                                  causal_model_functional_form=\"fully_non_linear\",\n                                  n_nonlinear_transformations=10,\n                                  n_nonlinear_interactions=5,\n                                  treatment_effect_weight=1,\n                                  seed=None)\ndata.df\ndata.cates\ndata.ates\n\n\n\n\n\n Back to top"
  },
  {
    "objectID": "01_Home/marimo_test.html",
    "href": "01_Home/marimo_test.html",
    "title": "Caml Synthetic Data API Usage",
    "section": "",
    "text": "import marimo as mo\n\n\nfrom caml.extensions.synthetic_data import CamlSyntheticDataGenerator\n\n\ndata =  CamlSyntheticDataGenerator(n_obs=10_000,\n                                  n_cont_outcomes=1,\n                                  n_binary_outcomes=0,\n                                  n_cont_treatments=1,\n                                  n_binary_treatments=0,\n                                  n_discrete_treatments=0,\n                                  n_cont_confounders=2, \n                                  n_binary_confounders=2,\n                                  n_discrete_confounders=2,\n                                  n_cont_heterogeneity_covariates=4,\n                                  n_binary_heterogeneity_covariates=4,\n                                  n_discrete_heterogeneity_covariates=4,\n                                  n_heterogeneity_confounders=0,\n                                  stddev_outcome_noise=3,\n                                  stddev_treatment_noise=3,\n                                  causal_model_functional_form=\"fully_non_linear\",\n                                  n_nonlinear_transformations=10,\n                                  n_nonlinear_interactions=5,\n                                  treatment_effect_weight=1,\n                                  seed=None)\n\n\ndata.df\n\n\n\n\n\n\n\n\nW1_continuous\nW2_continuous\nW1_binary\nW2_binary\nW1_discrete\nW2_discrete\nX1_continuous\nX2_continuous\nX3_continuous\nX4_continuous\nX1_binary\nX2_binary\nX3_binary\nX4_binary\nX1_discrete\nX2_discrete\nX3_discrete\nX4_discrete\nT1_continuous\nY1_continuous\n\n\n\n\n0\n1.931717\n1.969342\n1\n0\n3\n1\n3.565042\n0.544375\n0.868016\n-4.033220\n0\n0\n1\n1\n9\n0\n0\n11\n1.596562\n41.808516\n\n\n1\n3.208094\n2.381913\n1\n1\n1\n3\n0.418345\n0.874350\n-3.053576\n-0.549381\n0\n0\n1\n1\n6\n0\n1\n12\n14.406789\n26.427621\n\n\n2\n1.161820\n-0.177105\n1\n1\n0\n3\n2.885750\n0.404411\n-1.686447\n-2.817543\n0\n1\n1\n1\n5\n1\n0\n11\n3.298846\n31.611350\n\n\n3\n6.414697\n0.307045\n1\n0\n3\n3\n2.869292\n0.476825\n9.408844\n-3.300131\n1\n1\n0\n1\n2\n1\n1\n7\n36.819585\n-371.557136\n\n\n4\n3.802716\n1.614601\n0\n0\n1\n3\n-0.897331\n0.512627\n8.321160\n-4.581849\n0\n1\n0\n1\n8\n1\n0\n5\n20.940576\n-172.895861\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n9995\n0.599166\n1.201465\n0\n1\n2\n3\n2.440836\n0.659220\n-7.358641\n-4.929741\n0\n0\n0\n1\n6\n1\n0\n8\n-1.473054\n1.108393\n\n\n9996\n2.949473\n2.039010\n0\n0\n3\n3\n2.888261\n0.540974\n-1.225000\n-5.795339\n0\n0\n1\n1\n4\n1\n1\n12\n5.978606\n40.948642\n\n\n9997\n2.648579\n1.875207\n0\n1\n2\n1\n1.587975\n0.660679\n4.550830\n-2.048226\n0\n0\n1\n1\n8\n1\n1\n5\n5.840796\n8.988197\n\n\n9998\n2.380447\n1.470028\n0\n1\n2\n2\n2.419305\n0.773003\n7.409021\n-4.294858\n0\n0\n1\n0\n6\n1\n1\n4\n9.803385\n-18.460023\n\n\n9999\n2.226606\n3.579205\n0\n1\n0\n3\n1.258415\n0.635425\n-3.119874\n-4.353780\n1\n1\n1\n1\n7\n1\n0\n6\n15.426271\n47.859971\n\n\n\n\n10000 rows √ó 20 columns\n\n\n\n\ndata.cates\n\n\n\n\n\n\n\n\nCATE_of_T1_continuous_on_Y1_continuous\n\n\n\n\n0\n-4.263079\n\n\n1\n-0.123732\n\n\n2\n-1.466176\n\n\n3\n-12.855100\n\n\n4\n-13.613659\n\n\n...\n...\n\n\n9995\n5.716215\n\n\n9996\n1.462958\n\n\n9997\n-5.356014\n\n\n9998\n-9.792288\n\n\n9999\n0.252214\n\n\n\n\n10000 rows √ó 1 columns\n\n\n\n\ndata.ates\n\n\n\n\n\n\n\n\nTreatment\nATE\n\n\n\n\n0\nT1_continuous_on_Y1_continuous\n-2.08028\n\n\n\n\n\n\n\n\n\n\n Back to top",
    "crumbs": [
      "Caml Synthetic Data API Usage"
    ]
  },
  {
    "objectID": "04_Reference/cate_histogram_plot.html",
    "href": "04_Reference/cate_histogram_plot.html",
    "title": "cate_histogram_plot",
    "section": "",
    "text": "extensions.plots.cate_histogram_plot(estimated_cates, *, true_cates=None, figure_kwargs={}, hist_kwargs={})\nPlots a histogram the estimated CATEs."
  },
  {
    "objectID": "04_Reference/cate_histogram_plot.html#parameters",
    "href": "04_Reference/cate_histogram_plot.html#parameters",
    "title": "cate_histogram_plot",
    "section": "Parameters",
    "text": "Parameters\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nestimated_cates\nnumpy.typing.ArrayLike\nThe estimated CATEs.\nrequired\n\n\ntrue_cates\nnumpy.typing.ArrayLike | None\nThe true CATEs.\nNone\n\n\nfigure_kwargs\ndict\nMatplotlib figure arguments.\n{}\n\n\nhist_kwargs\ndict\nMatplotlib hist arguments.\n{}"
  },
  {
    "objectID": "04_Reference/cate_histogram_plot.html#returns",
    "href": "04_Reference/cate_histogram_plot.html#returns",
    "title": "cate_histogram_plot",
    "section": "Returns",
    "text": "Returns\n\n\n\nType\nDescription\n\n\n\n\nmatplotlib.figure.Figure\nThe histogram figure object."
  },
  {
    "objectID": "04_Reference/cate_histogram_plot.html#examples",
    "href": "04_Reference/cate_histogram_plot.html#examples",
    "title": "cate_histogram_plot",
    "section": "Examples",
    "text": "Examples\n\nimport numpy as np\nfrom caml.extensions.plots import cate_histogram_plot\n\nnp.random.seed(42)\ntrue_cates = np.random.normal(0, 1, 1000)\nestimated_cates = true_cates + np.random.normal(0, 0.5, 1000)\n\nfig = cate_histogram_plot(estimated_cates, true_cates=true_cates, hist_kwargs={'bins': 25})\nfig"
  },
  {
    "objectID": "04_Reference/cate_true_vs_estimated_plot.html",
    "href": "04_Reference/cate_true_vs_estimated_plot.html",
    "title": "cate_true_vs_estimated_plot",
    "section": "",
    "text": "extensions.plots.cate_true_vs_estimated_plot(true_cates, estimated_cates, *, figure_kwargs={}, scatter_kwargs={})\nPlots a scatter plot of the estimated CATEs against the true CATEs."
  },
  {
    "objectID": "04_Reference/cate_true_vs_estimated_plot.html#parameters",
    "href": "04_Reference/cate_true_vs_estimated_plot.html#parameters",
    "title": "cate_true_vs_estimated_plot",
    "section": "Parameters",
    "text": "Parameters\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nestimated_cates\nnumpy.typing.ArrayLike\nThe estimated CATEs.\nrequired\n\n\nfigure_kwargs\ndict\nMatplotlib figure arguments.\n{}\n\n\nscatter_kwargs\ndict\nMatplotlib line arguments.\n{}"
  },
  {
    "objectID": "04_Reference/cate_true_vs_estimated_plot.html#returns",
    "href": "04_Reference/cate_true_vs_estimated_plot.html#returns",
    "title": "cate_true_vs_estimated_plot",
    "section": "Returns",
    "text": "Returns\n\n\n\nType\nDescription\n\n\n\n\nmatplotlib.figure.Figure\nThe line plot figure object."
  },
  {
    "objectID": "04_Reference/cate_true_vs_estimated_plot.html#examples",
    "href": "04_Reference/cate_true_vs_estimated_plot.html#examples",
    "title": "cate_true_vs_estimated_plot",
    "section": "Examples",
    "text": "Examples\n\nimport numpy as np\nfrom caml.extensions.plots import cate_true_vs_estimated_plot\n\nnp.random.seed(42)\ntrue_cates = np.random.normal(0, 1, 100)\nestimated_cates = true_cates + np.random.normal(0, 0.5, 100)\n\nfig = cate_true_vs_estimated_plot(true_cates, estimated_cates)\nfig"
  },
  {
    "objectID": "04_Reference/index.html",
    "href": "04_Reference/index.html",
    "title": "API Reference",
    "section": "",
    "text": "from caml import *\n\n\n\nCamlCATE\nThe CamlCATE class represents an opinionated framework of Causal Machine Learning techniques for estimating\n\n\n\n\n\n\nfrom caml.extensions.synthetic_data import *\n\n\n\nmake_partially_linear_dataset_simple\nSimulate data generating process from a partially linear model with a simple 1 or 2 dimensional CATE function. The outcome is continuous and the treatment can be binary or continuous.\n\n\nmake_partially_linear_dataset_constant\nSimulate a data generating process from a partially linear model with a constant treatment effect (ATE only). The outcome and treatment are both continuous.\n\n\nmake_fully_heterogeneous_dataset\nSimulate data generating process from an interactive regression model with fully heterogenous treatment effects. The outcome is continuous and the treatment is binary.\n\n\nmake_dowhy_linear_dataset\nSimulate a linear data generating process with flexible configurations. The outcome and treatment can take on different data types.\n\n\n\n\n\n\nfrom caml.extensions.plots import *\n\n\n\ncate_histogram_plot\nPlots a histogram the estimated CATEs.\n\n\ncate_line_plot\nPlots a line plot of the ordered estimated CATEs as a rolling mean with optional confidence intervals.\n\n\ncate_true_vs_estimated_plot\nPlots a scatter plot of the estimated CATEs against the true CATEs.\n\n\n\n\n\n\n\n\n\nutils.generate_random_string\nFunction to generate a random string of ascii lowercase letters and digits of length N.\n\n\nutils.cls_typechecked\nClass decorator to typecheck all methods of a class.\n\n\nlogging.setup_logging\nSet up logging configuration."
  },
  {
    "objectID": "04_Reference/index.html#caml-core",
    "href": "04_Reference/index.html#caml-core",
    "title": "API Reference",
    "section": "",
    "text": "from caml import *\n\n\n\nCamlCATE\nThe CamlCATE class represents an opinionated framework of Causal Machine Learning techniques for estimating"
  },
  {
    "objectID": "04_Reference/index.html#synthetic-data-generation",
    "href": "04_Reference/index.html#synthetic-data-generation",
    "title": "API Reference",
    "section": "",
    "text": "from caml.extensions.synthetic_data import *\n\n\n\nmake_partially_linear_dataset_simple\nSimulate data generating process from a partially linear model with a simple 1 or 2 dimensional CATE function. The outcome is continuous and the treatment can be binary or continuous.\n\n\nmake_partially_linear_dataset_constant\nSimulate a data generating process from a partially linear model with a constant treatment effect (ATE only). The outcome and treatment are both continuous.\n\n\nmake_fully_heterogeneous_dataset\nSimulate data generating process from an interactive regression model with fully heterogenous treatment effects. The outcome is continuous and the treatment is binary.\n\n\nmake_dowhy_linear_dataset\nSimulate a linear data generating process with flexible configurations. The outcome and treatment can take on different data types."
  },
  {
    "objectID": "04_Reference/index.html#plots",
    "href": "04_Reference/index.html#plots",
    "title": "API Reference",
    "section": "",
    "text": "from caml.extensions.plots import *\n\n\n\ncate_histogram_plot\nPlots a histogram the estimated CATEs.\n\n\ncate_line_plot\nPlots a line plot of the ordered estimated CATEs as a rolling mean with optional confidence intervals.\n\n\ncate_true_vs_estimated_plot\nPlots a scatter plot of the estimated CATEs against the true CATEs."
  },
  {
    "objectID": "04_Reference/index.html#developer-tools",
    "href": "04_Reference/index.html#developer-tools",
    "title": "API Reference",
    "section": "",
    "text": "utils.generate_random_string\nFunction to generate a random string of ascii lowercase letters and digits of length N.\n\n\nutils.cls_typechecked\nClass decorator to typecheck all methods of a class.\n\n\nlogging.setup_logging\nSet up logging configuration."
  },
  {
    "objectID": "04_Reference/make_partially_linear_dataset_simple.html",
    "href": "04_Reference/make_partially_linear_dataset_simple.html",
    "title": "make_partially_linear_dataset_simple",
    "section": "",
    "text": "extensions.synthetic_data.make_partially_linear_dataset_simple(n_obs=1000, n_confounders=5, dim_heterogeneity=2, binary_treatment=True, seed=None)\nSimulate data generating process from a partially linear model with a simple 1 or 2 dimensional CATE function. The outcome is continuous and the treatment can be binary or continuous. The dataset is generated using the make_heterogeneous_data function from the doubleml package.\nThe general form of the data generating process is, in the case of dim_heterogeneity=1:\n\\[\ny_i= \\tau (x_0) d_i + g(\\mathbf{X_i})+\\epsilon_i\n\\] \\[\nd_i=f(\\mathbf{X_i})+\\eta_i\n\\]\nor, in the case of dim_heterogeneity=2:\n\\[\ny_i= \\tau (x_0,x_1) d_i + g(\\mathbf{X_i})+\\epsilon_i\n\\] \\[\nd_i=f(\\mathbf{X_i})+\\eta_i\n\\]\nwhere \\(y_i\\) is the outcome, \\(d_i\\) is the treatment, \\(\\mathbf{X_i}\\) are the confounders, \\(\\epsilon_i\\) and \\(\\eta_i\\) are the error terms, \\(\\tau\\) is the CATE function, \\(g\\) is the outcome function, and \\(f\\) is the treatment function.\nSee the doubleml documentation for more details on the specific functional forms of the data generating process.\nHere the ATE is defined as the average of the CATE function over all observations: \\(\\mathbb{E}[\\tau (\\cdot)]\\)\nAs a DAG, the data generating process can be roughly represented as:"
  },
  {
    "objectID": "04_Reference/make_partially_linear_dataset_simple.html#parameters",
    "href": "04_Reference/make_partially_linear_dataset_simple.html#parameters",
    "title": "make_partially_linear_dataset_simple",
    "section": "Parameters",
    "text": "Parameters\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nn_obs\nint\nThe number of observations to generate.\n1000\n\n\nn_confounders\nint\nThe number of confounders \\(\\mathbf{X_i}\\).\n5\n\n\ndim_heterogeneity\nint\nThe dimension of the heterogeneity \\(x_0\\) or \\((x_0,x_1)\\). Can only be 1 or 2.\n2\n\n\nbinary_treatment\nbool\nWhether the treatment \\(d_i\\) is binary or continuous.\nTrue\n\n\nseed\nint | None\nThe seed to use for the random number generator.\nNone"
  },
  {
    "objectID": "04_Reference/make_partially_linear_dataset_simple.html#returns",
    "href": "04_Reference/make_partially_linear_dataset_simple.html#returns",
    "title": "make_partially_linear_dataset_simple",
    "section": "Returns",
    "text": "Returns\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\npandas.DataFrame\nThe generated dataset where y is the outcome, d is the treatment, and X are the confounders with a 1d or 2d subset utilized for heterogeneity.\n\n\nnumpy.ndarray\nThe true conditional average treatment effects.\n\n\nfloat\nThe true average treatment effect."
  },
  {
    "objectID": "04_Reference/make_partially_linear_dataset_simple.html#examples",
    "href": "04_Reference/make_partially_linear_dataset_simple.html#examples",
    "title": "make_partially_linear_dataset_simple",
    "section": "Examples",
    "text": "Examples\n\nfrom caml.extensions.synthetic_data import make_partially_linear_dataset_simple\ndf, true_cates, true_ate = make_partially_linear_dataset_simple(n_obs=1000,\n                                                                n_confounders=5,\n                                                                dim_heterogeneity=2,\n                                                                binary_treatment=True,\n                                                                seed=1)\n\nprint(f\"True CATES: {true_cates[:5]}\")\nprint(f\"True ATE: {true_ate}\")\nprint(df.head())\n\nTrue CATES: [5.07318438 4.22638341 4.84246206 5.02852819 7.30906609]\nTrue ATE: 4.434805144050488\n          y    d        X0        X1        X2        X3        X4\n0  5.814804  1.0  0.560647  0.182920  0.938085  0.721671  0.209634\n1  4.593199  1.0  0.113353  0.358469  0.271148  0.908152  0.497946\n2  1.489081  0.0  0.970009  0.981170  0.319852  0.034913  0.003447\n3  6.569753  1.0  0.386105  0.317130  0.339849  0.232991  0.463512\n4  8.249305  1.0  0.733222  0.360575  0.903222  0.600965  0.110013"
  },
  {
    "objectID": "04_Reference/make_dowhy_linear_dataset.html",
    "href": "04_Reference/make_dowhy_linear_dataset.html",
    "title": "make_dowhy_linear_dataset",
    "section": "",
    "text": "extensions.synthetic_data.make_dowhy_linear_dataset(beta=2.0, n_obs=1000, n_confounders=10, n_discrete_confounders=0, n_effect_modifiers=5, n_discrete_effect_modifiers=0, n_treatments=1, binary_treatment=False, categorical_treatment=False, binary_outcome=False, seed=None)\nSimulate a linear data generating process with flexible configurations. The outcome and treatment can take on different data types. The dataset is generated using a modified version of the make_linear_data function from the dowhy package.\nThe general form of the data generating process is:\n\\[\ny_i = \\tau (\\mathbf{X_i}) \\mathbf{D_i} + g(\\mathbf{W_i}) + \\epsilon_i\n\\] \\[\n\\mathbf{D_i}=f(\\mathbf{W_i})+\\eta_i\n\\]\nwhere \\(y_i\\) is the outcome, \\(\\mathbf{D_i}\\) are the treatment(s), \\(\\mathbf{X_i}\\) are the effect modifiers (utilized for effect heterogeneity only), \\(\\mathbf{W_i}\\) are the confounders, \\(\\epsilon_i\\) and \\(\\eta_i\\) are the error terms, \\(\\tau\\) is the linear CATE function, \\(g\\) is the linear outcome function, and \\(f\\) is the linear treatment function.\nAs a DAG, the data generating process can be roughly represented as:"
  },
  {
    "objectID": "04_Reference/make_dowhy_linear_dataset.html#parameters",
    "href": "04_Reference/make_dowhy_linear_dataset.html#parameters",
    "title": "make_dowhy_linear_dataset",
    "section": "Parameters",
    "text": "Parameters\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nbeta\nfloat\nThe base effect size of the treatment. Note, this differs from the ATE with effect modifiers.\n2.0\n\n\nn_obs\nint\nThe number of observations to generate.\n1000\n\n\nn_confounders\nint\nThe number of confounders \\(\\mathbf{W_i}\\) to generate.\n10\n\n\nn_discrete_confounders\nint\nThe number of discrete confounders to generate.\n0\n\n\nn_effect_modifiers\nint\nThe number of effect modifiers \\(\\mathbf{X_i}\\) to generate.\n5\n\n\nn_discrete_effect_modifiers\nint\nThe number of discrete effect modifiers to generate.\n0\n\n\nn_treatments\nint\nThe number of treatments \\(\\mathbf{D_i}\\) to generate.\n1\n\n\nbinary_treatment\nbool\nWhether the treatment is binary or continuous.\nFalse\n\n\ncategorical_treatment\nbool\nWhether the treatment is categorical or continuous.\nFalse\n\n\nbinary_outcome\nbool\nWhether the outcome is binary or continuous.\nFalse\n\n\nseed\nint | None\nThe seed to use for the random number generator.\nNone"
  },
  {
    "objectID": "04_Reference/make_dowhy_linear_dataset.html#returns",
    "href": "04_Reference/make_dowhy_linear_dataset.html#returns",
    "title": "make_dowhy_linear_dataset",
    "section": "Returns",
    "text": "Returns\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\npandas.DataFrame\nThe generated dataset where y is the outcome, d are the treatment(s), X are the covariates that are utilized for heterogeneity only, and W are the confounders.\n\n\ndict[str, np.ndarray]\nThe true conditional average treatment effects for each treatment.\n\n\ndict[str, float]\nThe true average treatment effect for each treatment."
  },
  {
    "objectID": "04_Reference/make_dowhy_linear_dataset.html#examples",
    "href": "04_Reference/make_dowhy_linear_dataset.html#examples",
    "title": "make_dowhy_linear_dataset",
    "section": "Examples",
    "text": "Examples\n\nfrom caml.extensions.synthetic_data import make_dowhy_linear_dataset\ndf, true_cates, true_ate = make_dowhy_linear_dataset(beta=2.0,\n                                                    n_obs=1000,\n                                                    n_confounders=10,\n                                                    n_discrete_confounders=0,\n                                                    n_effect_modifiers=5,\n                                                    n_discrete_effect_modifiers=0,\n                                                    n_treatments=1,\n                                                    binary_treatment=False,\n                                                    categorical_treatment=False,\n                                                    binary_outcome=False,\n                                                    seed=1)\n\nprint(f\"True CATEs: {true_cates['d1'][:5]}\")\nprint(f\"True ATE: {true_ate}\")\nprint(df.head())\n\nTrue CATEs: [7.02877025 4.5496771  2.58332253 3.65591464 1.28649085]\nTrue ATE: {'d1': 3.316926309432912}\n         X0        X1        X2        X3        X4        W0        W1  \\\n0 -0.833791  0.489626  2.467073  1.214193  1.629267  1.578856 -0.320558   \n1 -0.419489  2.224769  0.879272  1.229339  0.429658 -0.338384 -0.437209   \n2 -1.254407  0.085966  1.146039 -0.401340  0.536695 -0.288846 -0.495120   \n3 -0.455729 -1.267684  0.705253  1.118711 -0.208877 -1.283266  0.675065   \n4 -0.368183 -0.540464  0.145927 -0.655766  0.101447  0.024959  2.540904   \n\n         W2        W3        W4        W5        W6        W7        W8  \\\n0 -0.680732 -0.644705  0.755620 -2.875464 -0.949897 -0.692933  0.927304   \n1 -0.957558  0.187480 -1.807107  0.329401  0.274111  0.193616  0.694391   \n2 -1.267659  0.135021 -1.398149 -1.212076 -1.314652 -1.154084 -0.877711   \n3  0.660031  0.346709 -0.898324 -1.702952 -1.374638  1.383576 -0.155657   \n4 -0.879612  0.221868 -0.406318 -1.167573 -1.769998 -0.658221 -0.415359   \n\n         W9        d1          y  \n0 -1.022258 -0.402456  -4.033895  \n1 -0.606094 -2.701095 -14.874571  \n2  0.064969 -4.708212 -20.767053  \n3 -0.559362 -0.250823  -6.462511  \n4  0.664257  3.890331   0.872735"
  },
  {
    "objectID": "04_Reference/make_fully_heterogeneous_dataset.html",
    "href": "04_Reference/make_fully_heterogeneous_dataset.html",
    "title": "make_fully_heterogeneous_dataset",
    "section": "",
    "text": "extensions.synthetic_data.make_fully_heterogeneous_dataset(n_obs=1000, n_confounders=5, theta=4.0, seed=None, **doubleml_kwargs)\nSimulate data generating process from an interactive regression model with fully heterogenous treatment effects. The outcome is continuous and the treatment is binary. The dataset is generated using a modified version of make_irm_data function from the doubleml package.\nThe general form of the data generating process is:\n\\[\ny_i= g(d_i,\\mathbf{X_i})+\\epsilon_i\n\\] \\[\nd_i=f(\\mathbf{X_i})+\\eta_i\n\\]\nwhere \\(y_i\\) is the outcome, \\(d_i\\) is the treatment, \\(\\mathbf{X_i}\\) are the confounders utilized for full effect heterogeneity, \\(\\epsilon_i\\) and \\(\\eta_i\\) are the error terms, \\(g\\) is the outcome function, and \\(f\\) is the treatment function.\nSee the doubleml documentation for more details on the specific functional forms of the data generating process.\nNote that the treatment effect is fully heterogenous, thus the CATE is defined as: \\(\\tau = \\mathbb{E}[g(1,\\mathbf{X}) - g(0,\\mathbf{X})|\\mathbf{X}]\\) for any \\(\\mathbf{X}\\).\nThe ATE is defined as the average of the CATE function over all observations: \\(\\mathbb{E}[\\tau (\\cdot)]\\)\nAs a DAG, the data generating process can be roughly represented as:"
  },
  {
    "objectID": "04_Reference/make_fully_heterogeneous_dataset.html#parameters",
    "href": "04_Reference/make_fully_heterogeneous_dataset.html#parameters",
    "title": "make_fully_heterogeneous_dataset",
    "section": "Parameters",
    "text": "Parameters\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nn_obs\nint\nThe number of observations to generate.\n1000\n\n\nn_confounders\nint\nThe number of confounders \\(\\mathbf{X_i}\\) to generate (these are utilized fully for heterogeneity).\n5\n\n\ntheta\nfloat\nThe base parameter for the treatment effect. Note this differs from the ATE.\n4.0\n\n\nseed\nint | None\nThe seed to use for the random number generator.\nNone\n\n\n**doubleml_kwargs\n\nAdditional keyword arguments to pass to the data generating process.\n{}"
  },
  {
    "objectID": "04_Reference/make_fully_heterogeneous_dataset.html#returns",
    "href": "04_Reference/make_fully_heterogeneous_dataset.html#returns",
    "title": "make_fully_heterogeneous_dataset",
    "section": "Returns",
    "text": "Returns\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\npandas.DataFrame\nThe generated dataset where y is the outcome, d is the treatment, and X are the confounders which are fully utilized for heterogeneity.\n\n\nnumpy.ndarray\nThe true conditional average treatment effects.\n\n\nfloat\nThe true average treatment effect."
  },
  {
    "objectID": "04_Reference/make_fully_heterogeneous_dataset.html#examples",
    "href": "04_Reference/make_fully_heterogeneous_dataset.html#examples",
    "title": "make_fully_heterogeneous_dataset",
    "section": "Examples",
    "text": "Examples\n\nfrom caml.extensions.synthetic_data import make_fully_heterogeneous_dataset\ndf, true_cates, true_ate = make_fully_heterogeneous_dataset(n_obs=1000,\n                                                            n_confounders=5,\n                                                            theta=4.0,\n                                                            seed=1)\n\nprint(f\"True CATEs: {true_cates[:5]}\")\nprint(f\"True ATE: {true_ate}\")\nprint(df.head())\n\nTrue CATEs: [5.10338083 5.0918794  1.93444292 4.36046179 3.89521828]\nTrue ATE: 3.9499484248360175\n         X1        X2        X3        X4        X5         y    d\n0  1.682368 -0.422572 -1.219871 -0.941586 -1.270241  5.828931  1.0\n1  0.684154  1.125168  2.601475  0.441070  0.889493  4.767675  1.0\n2 -2.035148 -1.386116 -0.770108 -0.070788 -0.524494  2.748786  1.0\n3  0.429364 -0.125604 -0.095252 -0.033939  1.243388  5.140932  1.0\n4  0.240024 -0.069628 -1.722948 -1.565808 -1.494064  2.431165  1.0"
  },
  {
    "objectID": "05_Contributors/documentation.html",
    "href": "05_Contributors/documentation.html",
    "title": "Documentation",
    "section": "",
    "text": "Note: Windows users must create environment using WSL or Docker container as Quarto requires MacOS or LinuxOS\nThis repository uses  & quartodoc for documentation. All files relating to the documentation are under the docs/ directory. Quarto & quartodoc provide very detailed documentation on usage so I will refer the reader to these resources for more details.\nTo build the documentation, run the following command from the projects root directory:\nquartodoc build --config docs/_quarto.yml\nAnd to preview the documentation, run the following command:\nquarto preview docs/\nThe documentation preview will be hosted on http://localhost:8000/. Note that the quarto preview will be checking for live updates & applying them in real-time. In some cases, the changes will not manifest until you rerun quartodoc build --config docs/_quarto.yml. In general, this will occur when you make changes to the ‚Äúquartodoc:‚Äù section of the docs/_quarto.yml file or any corresponding API changes.\n\n\n\n Back to top",
    "crumbs": [
      "Documentation"
    ]
  },
  {
    "objectID": "05_Contributors/environment.html",
    "href": "05_Contributors/environment.html",
    "title": "Environment & Development",
    "section": "",
    "text": "uv\nWSL (required for Windows users to utilize Quarto for docs)\nOptional: Docker",
    "crumbs": [
      "Environment & Development"
    ]
  },
  {
    "objectID": "05_Contributors/environment.html#prerequisites",
    "href": "05_Contributors/environment.html#prerequisites",
    "title": "Environment & Development",
    "section": "",
    "text": "uv\nWSL (required for Windows users to utilize Quarto for docs)\nOptional: Docker",
    "crumbs": [
      "Environment & Development"
    ]
  },
  {
    "objectID": "05_Contributors/environment.html#environment-setup",
    "href": "05_Contributors/environment.html#environment-setup",
    "title": "Environment & Development",
    "section": "Environment Setup",
    "text": "Environment Setup\nWe primarily utilize Docker for development environment standardization & uv for project, package, and dependency management.\n\nOption 1 (recommended): Docker Development Environment\n\nInstall Docker\nClone repository\n\nWe highly recommend utilizing ssh for cloning the repository.\ngit clone git@github.com:jakepenzak/caml.git\ncd caml\n\nVS Code Users: Set up Dev Containers\n\n\nDownload Dev Containers Extension\nCopy .devcontainer-template.json as .devcontainer.json and fill out {USERNAME} & {EMAIL}\nFollow steps to open current working directory in container\nTest github access - if running into issues, copy .ssh keys into .github_access/ directory. This directory gets copied into .ssh/ directory inside container. DO NOT COMMIT anything stored under .github_access/.\nTest uv pip list to ensure environment dependencies are properly installed - you should see caml installed as an editable package.\n\n\nNon-VS Code Users: Utilize docker-run.sh\n\n\nRun source docker-run.sh with respective flags. Call --help for details. This should spin up a terminal session in docker container.\nTest github access - if running into issues, copy .ssh keys into .github_access/ directory. This directory gets copied into .ssh/ directory inside container. DO NOT COMMIT anything stored under .github_access/.\nTest uv pip list to ensure environment dependencies are properly installed - you should see caml installed as an editable package.\n\n\n\nOption 2: Virtual Environment Only\n\nInstall uv\nRun uv sync --all-extras --frozen\nActivate the .venv via source .venv/bin/activate\nTest uv pip list to ensure environment dependencies are properly installed - you should see caml installed as an editable package.\nRun pre-commit install\nOptional: Install Quarto for edits on documentation, please refer to documentation page",
    "crumbs": [
      "Environment & Development"
    ]
  },
  {
    "objectID": "05_Contributors/environment.html#committing-pull-requests",
    "href": "05_Contributors/environment.html#committing-pull-requests",
    "title": "Environment & Development",
    "section": "Committing & Pull Requests",
    "text": "Committing & Pull Requests\n\nTry best to follow commit message conventions outlined here\nOn PRs, please fill out the generated PR template. All github actions & workflows will be required to complete successfully prior to merging.",
    "crumbs": [
      "Environment & Development"
    ]
  },
  {
    "objectID": "05_Contributors/testing.html",
    "href": "05_Contributors/testing.html",
    "title": "Testing",
    "section": "",
    "text": "We utilize pytest for testing our codebase.",
    "crumbs": [
      "Testing"
    ]
  },
  {
    "objectID": "05_Contributors/testing.html#unit-testing",
    "href": "05_Contributors/testing.html#unit-testing",
    "title": "Testing",
    "section": "Unit Testing",
    "text": "Unit Testing\nUnit tests are under the tests/caml/ directory following the same structure of the caml/ prefixed by ‚Äútest_‚Äù. For example, if we wanted to write tests for cate.py, we would create a new file to build these tests tests/caml/core/test_cate.py.\nTo run unit tests, simply run pytest in terminal:\nThis will run your unit tests (with respective output printed in terminal).\nAdditionally, an html report of the coverage will be exported to tests/reports/htmlcov, which can be a useful tool for interactively evaluating the coverage of your unit tests.",
    "crumbs": [
      "Testing"
    ]
  },
  {
    "objectID": "05_Contributors/testing.html#advanced-testing",
    "href": "05_Contributors/testing.html#advanced-testing",
    "title": "Testing",
    "section": "Advanced Testing",
    "text": "Advanced Testing\nUnit tests are automatically run during PR process via GitHub Actions. Integration & regression testing forthcoming.",
    "crumbs": [
      "Testing"
    ]
  },
  {
    "objectID": "04_Reference/cate_line_plot.html",
    "href": "04_Reference/cate_line_plot.html",
    "title": "cate_line_plot",
    "section": "",
    "text": "extensions.plots.cate_line_plot(estimated_cates, *, true_cates=None, standard_errors=None, alpha=0.05, window=30, figure_kwargs={}, line_kwargs={})\nPlots a line plot of the ordered estimated CATEs as a rolling mean with optional confidence intervals."
  },
  {
    "objectID": "04_Reference/cate_line_plot.html#parameters",
    "href": "04_Reference/cate_line_plot.html#parameters",
    "title": "cate_line_plot",
    "section": "Parameters",
    "text": "Parameters\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nestimated_cates\nnumpy.typing.ArrayLike\nThe estimated CATEs.\nrequired\n\n\ntrue_cates\nnumpy.typing.ArrayLike | None\nThe true CATEs.\nNone\n\n\nstandard_errors\nnumpy.typing.ArrayLike | None\nThe standard errors of the estimated CATEs.\nNone\n\n\nalpha\nfloat\nThe alpha level for the confidence intervals. The default is 0.05, which corresponds to 95% confidence intervals.\n0.05\n\n\nwindow\nint\nThe window size for the moving average.\n30\n\n\nfigure_kwargs\ndict\nMatplotlib figure arguments.\n{}\n\n\nline_kwargs\ndict\nMatplotlib line arguments.\n{}"
  },
  {
    "objectID": "04_Reference/cate_line_plot.html#returns",
    "href": "04_Reference/cate_line_plot.html#returns",
    "title": "cate_line_plot",
    "section": "Returns",
    "text": "Returns\n\n\n\nType\nDescription\n\n\n\n\nmatplotlib.figure.Figure\nThe line plot figure object."
  },
  {
    "objectID": "04_Reference/cate_line_plot.html#examples",
    "href": "04_Reference/cate_line_plot.html#examples",
    "title": "cate_line_plot",
    "section": "Examples",
    "text": "Examples\n\nimport numpy as np\nfrom caml.extensions.plots import cate_line_plot\n\nnp.random.seed(42)\ntrue_cates = np.random.normal(0, 1, 100)\nestimated_cates = true_cates + np.random.normal(0, 0.5, 100)\nstandard_errors = np.abs(np.random.normal(0, 0.1, 100))\n\nfig = cate_line_plot(estimated_cates, true_cates=true_cates, standard_errors=standard_errors, window=5)\nfig"
  },
  {
    "objectID": "04_Reference/make_partially_linear_dataset_constant.html",
    "href": "04_Reference/make_partially_linear_dataset_constant.html",
    "title": "make_partially_linear_dataset_constant",
    "section": "",
    "text": "extensions.synthetic_data.make_partially_linear_dataset_constant(n_obs=1000, ate=4.0, n_confounders=10, dgp='make_plr_CCDDHNR2018', seed=None, **doubleml_kwargs)\nSimulate a data generating process from a partially linear model with a constant treatment effect (ATE only). The outcome and treatment are both continuous. The dataset is generated using the make_plr_CCDDHNR2018 or make_plr_turrell2018 function from the doubleml package.\nThe general form of the data generating process is:\n\\[\ny_i= \\tau_0 d_i + g(\\mathbf{W_i})+\\epsilon_i\n\\] \\[\nd_i=f(\\mathbf{W_i})+\\eta_i\n\\]\nwhere \\(y_i\\) is the outcome, \\(d_i\\) is the treatment, \\(\\mathbf{W_i}\\) are the confounders, \\(\\epsilon_i\\) and \\(\\eta_i\\) are the error terms, \\(\\tau_0\\) is the ATE parameter, \\(g\\) is the outcome function, and \\(f\\) is the treatment function.\nSee the doubleml documentation for more details on the specific functional forms of the data generating process.\nAs a DAG, the data generating process can be roughly represented as:"
  },
  {
    "objectID": "04_Reference/make_partially_linear_dataset_constant.html#parameters",
    "href": "04_Reference/make_partially_linear_dataset_constant.html#parameters",
    "title": "make_partially_linear_dataset_constant",
    "section": "Parameters",
    "text": "Parameters\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nn_obs\nint\nThe number of observations to generate.\n1000\n\n\nate\nfloat\nThe average treatment effect \\(\\tau_0\\).\n4.0\n\n\nn_confounders\nint\nThe number of confounders \\(\\mathbf{W_i}\\) to generate.\n10\n\n\ndgp\nstr\nThe data generating process to use. Can be ‚Äúmake_plr_CCDDHNR20‚Äù or ‚Äúmake_plr_turrell2018‚Äù.\n'make_plr_CCDDHNR2018'\n\n\nseed\nint | None\nThe seed to use for the random number generator.\nNone\n\n\n**doubleml_kwargs\n\nAdditional keyword arguments to pass to the data generating process.\n{}"
  },
  {
    "objectID": "04_Reference/make_partially_linear_dataset_constant.html#returns",
    "href": "04_Reference/make_partially_linear_dataset_constant.html#returns",
    "title": "make_partially_linear_dataset_constant",
    "section": "Returns",
    "text": "Returns\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\npandas.DataFrame\nThe generated dataset where y is the outcome, d is the treatment, and W are the confounders.\n\n\nnumpy.ndarray\nThe true conditional average treatment effects, which are all equal to the ATE here.\n\n\nfloat\nThe true average treatment effect."
  },
  {
    "objectID": "04_Reference/make_partially_linear_dataset_constant.html#examples",
    "href": "04_Reference/make_partially_linear_dataset_constant.html#examples",
    "title": "make_partially_linear_dataset_constant",
    "section": "Examples",
    "text": "Examples\n\nfrom caml.extensions.synthetic_data import make_partially_linear_dataset_constant\ndf, true_cates, true_ate = make_partially_linear_dataset_constant(n_obs=1000,\n                                                    ate=4.0,\n                                                    n_confounders=10,\n                                                    dgp=\"make_plr_CCDDHNR2018\",\n                                                    seed=1)\n\nprint(f\"True CATES: {true_cates[:5]}\")\nprint(f\"True ATE: {true_ate}\")\nprint(df.head())\n\nTrue CATES: [4. 4. 4. 4. 4.]\nTrue ATE: 4.0\n         W1        W2        W3        W4        W5        W6        W7  \\\n0 -1.799808 -0.830362 -0.775800 -2.430475 -1.759428 -0.196538 -0.392579   \n1 -2.238925 -2.107779 -1.619264 -1.816121 -2.084809 -0.456936  0.118781   \n2  1.069028  1.616054  1.959420  1.398880  0.058545  0.370891  0.161045   \n3  0.497020 -0.399126 -0.019305  0.230080  0.640361  1.233185  0.906313   \n4 -1.749809 -0.315699 -0.283176  0.439451  0.819941  0.156514  0.059722   \n\n         W8        W9       W10         y         d  \n0 -0.827537 -0.735652 -1.127103 -6.074658 -1.843476  \n1  0.270647  0.199401  0.049088 -8.534573 -1.969429  \n2  0.118180  0.438721  0.280880  4.915427  0.935840  \n3  1.031123 -0.373092  0.442367 -0.037117 -0.209740  \n4  0.472781  0.030157  1.174463 -7.922597 -1.903480"
  },
  {
    "objectID": "04_Reference/utils.generate_random_string.html",
    "href": "04_Reference/utils.generate_random_string.html",
    "title": "utils.generate_random_string",
    "section": "",
    "text": "utils.generate_random_string(N)\nFunction to generate a random string of ascii lowercase letters and digits of length N.\nUtilized to generate a random table name for the Ibis Tables.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nN\nint\nThe length of random string to generate.\nrequired\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nstr: The random string of length N."
  },
  {
    "objectID": "04_Reference/utils.generate_random_string.html#parameters",
    "href": "04_Reference/utils.generate_random_string.html#parameters",
    "title": "utils.generate_random_string",
    "section": "",
    "text": "Name\nType\nDescription\nDefault\n\n\n\n\nN\nint\nThe length of random string to generate.\nrequired"
  },
  {
    "objectID": "04_Reference/utils.generate_random_string.html#returns",
    "href": "04_Reference/utils.generate_random_string.html#returns",
    "title": "utils.generate_random_string",
    "section": "",
    "text": "Type\nDescription\n\n\n\n\nstr: The random string of length N."
  },
  {
    "objectID": "04_Reference/utils.cls_typechecked.html",
    "href": "04_Reference/utils.cls_typechecked.html",
    "title": "utils.cls_typechecked",
    "section": "",
    "text": "utils.cls_typechecked(cls)\nClass decorator to typecheck all methods of a class.\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\ncls\n\nThe class to decorate.\nrequired\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\ncls: The decorated class."
  },
  {
    "objectID": "04_Reference/utils.cls_typechecked.html#parameters",
    "href": "04_Reference/utils.cls_typechecked.html#parameters",
    "title": "utils.cls_typechecked",
    "section": "",
    "text": "Name\nType\nDescription\nDefault\n\n\n\n\ncls\n\nThe class to decorate.\nrequired"
  },
  {
    "objectID": "04_Reference/utils.cls_typechecked.html#returns",
    "href": "04_Reference/utils.cls_typechecked.html#returns",
    "title": "utils.cls_typechecked",
    "section": "",
    "text": "Type\nDescription\n\n\n\n\ncls: The decorated class."
  },
  {
    "objectID": "04_Reference/CamlCATE.html",
    "href": "04_Reference/CamlCATE.html",
    "title": "CamlCATE",
    "section": "",
    "text": "CamlCATE(self, df, Y, T, X, W=None, *, discrete_treatment=True, discrete_outcome=False, seed=None, verbose=1)\nThe CamlCATE class represents an opinionated framework of Causal Machine Learning techniques for estimating highly accurate conditional average treatment effects (CATEs).\nThis class is built on top of the EconML library and provides a high-level API for fitting, validating, and making inference with CATE models, with best practices built directly into the API. The class is designed to be easy to use and understand, while still providing flexibility for advanced users. The class is designed to be used with pandas, polars, or pyspark backends, which ultimately get converted to NumPy Arrays under the hood to provide a level of extensibility & interoperability across different data processing frameworks.\nThe primary workflow for the CamlCATE class is as follows:\n\nInitialize the class with the input DataFrame and the necessary columns.\nUtilize flaml AutoML to find nuisance functions or propensity/regression models to be utilized in the EconML estimators.\nFit the CATE models on the training set and evaluate based on the validation set, then select the top performer/ensemble based on chosen scorer.\nValidate the fitted CATE model on the test set to check for generalization performance.\nFit the final estimator on the entire dataset, after validation and testing.\nPredict the CATE based on the fitted final estimator for either the internal dataset or an out-of-sample dataset.\nSummarize population summary statistics for the CATE predictions for either the internal dataset or out-of-sample predictions.\n\nFor technical details on conditional average treatment effects, see:\n\nCaML Documentation\nEconML documentation\n\nNote: All the standard assumptions of Causal Inference apply to this class (e.g., exogeneity/unconfoundedness, overlap, positivity, etc.). The class does not check for these assumptions and assumes that the user has already thought through these assumptions before using the class.\nOutcome & Treatment Data Type Support Matrix\n\n\n\nOutcome\nTreatment\nSupport\nMissing\n\n\n\n\nContinuous\nBinary\n‚úÖFull\n\n\n\nContinuous\nContinuous\nüü°Partial\nvalidate()\n\n\nContinuous\nCategorical\n‚úÖFull\n\n\n\nBinary\nBinary\n‚ùåNot yet\n\n\n\nBinary\nContinuous\n‚ùåNot yet\n\n\n\nBinary\nCategorical\n‚ùåNot yet\n\n\n\nCategorical\nBinary\n‚ùåNot yet\n\n\n\nCategorical\nContinuous\n‚ùåNot yet\n\n\n\nCategorical\nCategorical\n‚ùåNot yet\n\n\n\n\nMulti-dimensional outcomes and treatments are not yet supported.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\ndf\npandas.DataFrame | polars.DataFrame | pyspark.sql.DataFrame\nThe input DataFrame representing the data for the CamlCATE instance.\nrequired\n\n\nY\nstr\nThe str representing the column name for the outcome variable.\nrequired\n\n\nT\nstr\nThe str representing the column name(s) for the treatment variable(s).\nrequired\n\n\nX\nlist[str] | str | None\nThe str (if unity) or list of feature names representing the feature set to be utilized for estimating heterogeneity/CATE.\nrequired\n\n\nW\nlist[str] | str | None\nThe str (if unity) or list of feature names representing the confounder/control feature set to be utilized only for nuisance function estimation where applicable.\nNone\n\n\ndiscrete_treatment\nbool\nA boolean indicating whether the treatment is discrete/categorical or continuous.\nTrue\n\n\ndiscrete_outcome\nbool\nA boolean indicating whether the outcome is binary or continuous.\nFalse\n\n\nseed\nint | None\nThe seed to use for the random number generator.\nNone\n\n\nverbose\nint\nThe verbosity level for logging. Default implies 1 (INFO). Set to 0 for no logging. Set to 2 for DEBUG.\n1\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\n\n\n\n\ndf\npandas.DataFrame | polars.DataFrame | pyspark.sql.DataFrame | ibis.Table\nThe input DataFrame representing the data for the CamlCATE instance.\n\n\nY\nstr\nThe str representing the column name for the outcome variable.\n\n\nT\nstr\nThe str representing the column name(s) for the treatment variable(s).\n\n\nX\nlist[str] | str\nThe str (if unity) or list/tuple of feature names representing the confounder/control feature set to be utilized for estimating heterogeneity/CATE and nuisance function estimation where applicable.\n\n\nW\nlist[str] | str\nThe str (if unity) or list/tuple of feature names representing the confounder/control feature set to be utilized only for nuisance function estimation, where applicable. These will be included by default in Meta-Learners.\n\n\ndiscrete_treatment\nbool\nA boolean indicating whether the treatment is discrete/categorical or continuous.\n\n\ndiscrete_outcome\nbool\nA boolean indicating whether the outcome is binary or continuous.\n\n\nvalidation_estimator\neconml._cate_estimator.BaseCateEstimator | econml.score.EnsembleCateEstimator\nThe fitted EconML estimator object for validation.\n\n\nfinal_estimator\neconml._cate_estimator.BaseCateEstimator | econml.score.EnsembleCateEstimator\nThe fitted EconML estimator object on the entire dataset after validation.\n\n\ndataframe\npandas.DataFrame | polars.DataFrame | pyspark.sql.DataFrame | ibis.Table\nThe input DataFrame with any modifications (e.g., predictions or rank orderings) made by the class returned to the original backend.\n\n\nmodel_Y_X_W\nsklearn.base.BaseEstimator\nThe fitted nuisance function for the outcome variable.\n\n\nmodel_Y_X_W_T\nsklearn.base.BaseEstimator\nThe fitted nuisance function for the outcome variable with treatment variable.\n\n\nmodel_T_X_W\nsklearn.base.BaseEstimator\nThe fitted nuisance function for the treatment variable.\n\n\n_Y\nibis.Table\nThe outcome variable data as ibis table.\n\n\n_T\nibis.Table\nThe treatment variable data as ibis table.\n\n\n_X\nibis.Table\nThe feature/confounder set data as ibis table.\n\n\n_X_T\nibis.Table\nThe feature/confounder feature set and treatment variable data as ibis table.\n\n\n_nuisances_fitted\nbool\nA boolean indicating whether the nuisance functions have been fitted.\n\n\n_validation_estimator\neconml._cate_estimator.BaseCateEstimator | econml.score.EnsembleCateEstimator\nThe fitted EconML estimator object for validation.\n\n\n_final_estimator\neconml._cate_estimator.BaseCateEstimator | econml.score.EnsembleCateEstimator\nThe fitted EconML estimator object for final predictions.\n\n\n_validator_results\neconml.validate.EvaluationResults\nThe results of the validation tests from DRTester.\n\n\n_cate_models\nlist[tuple[str, econml._cate_estimator.BaseCateEstimator]]\nThe list of CATE models to fit and ensemble.\n\n\n_data_splits\ndict[str, np.ndarray]\nThe dictionary containing the training, validation, and test data splits.\n\n\n_rscorer\neconml.score.RScorer\nThe RScorer object for the validation estimator.\n\n\n\n\n\n\n&gt;&gt;&gt; from caml.core.cate import CamlCATE\n&gt;&gt;&gt; from caml.extensions.synthetic_data import make_fully_heterogeneous_dataset\n&gt;&gt;&gt;\n&gt;&gt;&gt; # Generate synthetic dataset\n&gt;&gt;&gt; df, true_cates, true_ate = make_fully_heterogeneous_dataset(n_obs=1000, n_confounders=10, theta=10, seed=1)\n&gt;&gt;&gt;\n&gt;&gt;&gt; # Instantiate CamlCATE class\n&gt;&gt;&gt; caml_obj= CamlCATE(df=df,\n...                    Y=\"y\",\n...                    T=\"d\",\n...                    X=[c for c in df.columns if \"X\" in c],\n...                    W=[c for c in df.columns if \"W\" in c],\n...                    discrete_treatment=True,\n...                    discrete_outcome=True,\n...                    seed=0,\n...                    verbose=1)\n&gt;&gt;&gt;\n&gt;&gt;&gt; # Standard pipeline\n&gt;&gt;&gt; caml_obj.auto_nuisance_functions()\n&gt;&gt;&gt; caml_obj.fit_validator()\n&gt;&gt;&gt; caml_obj.validate()\n&gt;&gt;&gt; caml_obj.fit_final()\n&gt;&gt;&gt; predictions = caml_obj.predict()\n&gt;&gt;&gt; summarized_predictions = caml_obj.summarize()\n&gt;&gt;&gt;\n&gt;&gt;&gt; # Access final model (can be saved for future inference)\n&gt;&gt;&gt; final_estimator = caml_obj.final_estimator\n\n\n\n\n\n\nName\nDescription\n\n\n\n\nauto_nuisance_functions\nLeverages AutoML to find optimal nuisance functions/regression & propensity models for use in EconML CATE estimators.\n\n\nfit_final\nFits the final estimator on the entire dataset, after validation and testing.\n\n\nfit_validator\nFits the CATE models on the training set and evaluates them & ensembles based on the validation set.\n\n\npredict\nPredicts the CATE based on the fitted final estimator for either the internal dataset or provided Data.\n\n\nsummarize\nProvides population summary statistics for the CATE predictions for either the internal results or provided results.\n\n\nvalidate\nValidates the fitted CATE models on the test set to check for generalization performance. Uses the DRTester class from EconML to obtain the Best\n\n\n\n\n\nCamlCATE.auto_nuisance_functions(flaml_Y_kwargs=None, flaml_T_kwargs=None, use_ray=False, use_spark=False)\nLeverages AutoML to find optimal nuisance functions/regression & propensity models for use in EconML CATE estimators.\nSets the model_Y_X_W, model_Y_X_W_T, and model_T_X_W internal attributes to the fitted nuisance functions.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nflaml_Y_kwargs\ndict | None\nThe keyword arguments for the FLAML AutoML search for the outcome model. Default implies the base parameters in CamlBase.\nNone\n\n\nflaml_T_kwargs\ndict | None\nThe keyword arguments for the FLAML AutoML search for the treatment model. Default implies the base parameters in CamlBase.\nNone\n\n\nuse_ray\nbool\nA boolean indicating whether to use Ray for parallel processing.\nFalse\n\n\nuse_spark\nbool\nA boolean indicating whether to use Spark for parallel processing.\nFalse\n\n\n\n\n\n\n&gt;&gt;&gt; flaml_Y_kwargs = {\n...     \"n_jobs\": -1,\n...     \"time_budget\": 300, # in seconds\n...     }\n&gt;&gt;&gt; flaml_T_kwargs = {\n...     \"n_jobs\": -1,\n...     \"time_budget\": 300,\n...     }\n&gt;&gt;&gt; caml_obj.auto_nuisance_functions(flaml_Y_kwargs=flaml_Y_kwargs, flaml_T_kwargs=flaml_T_kwargs)\n\n\n\n\nCamlCATE.fit_final()\nFits the final estimator on the entire dataset, after validation and testing.\nSets the _final_estimator internal attribute to the fitted EconML estimator.\n\n\n&gt;&gt;&gt; caml_obj.fit_final() # Fits the final estimator on the entire dataset.\n\n\n\n\nCamlCATE.fit_validator(subset_cate_models=['LinearDML', 'CausalForestDML', 'NonParamDML', 'AutoNonParamDML', 'SparseLinearDML-2D', 'DRLearner', 'ForestDRLearner', 'LinearDRLearner', 'SparseLinearDRLearner-2D', 'DomainAdaptationLearner', 'SLearner', 'TLearner', 'XLearner'], additional_cate_models=[], rscorer_kwargs={}, use_ray=False, ray_remote_func_options_kwargs={}, sample_fraction=1.0, n_jobs=1)\nFits the CATE models on the training set and evaluates them & ensembles based on the validation set.\nSets the _validation_estimator and _rscorer internal attributes to the fitted EconML estimator and RScorer object.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nsubset_cate_models\nlist[str]\nThe list of CATE models to fit and ensemble. Default implies all available models as defined by class.\n['LinearDML', 'CausalForestDML', 'NonParamDML', 'AutoNonParamDML', 'SparseLinearDML-2D', 'DRLearner', 'ForestDRLearner', 'LinearDRLearner', 'SparseLinearDRLearner-2D', 'DomainAdaptationLearner', 'SLearner', 'TLearner', 'XLearner']\n\n\nadditional_cate_models\nlist[tuple[str, BaseCateEstimator]]\nThe list of additional CATE models to fit and ensemble\n[]\n\n\nrscorer_kwargs\ndict\nThe keyword arguments for the econml.score.RScorer object.\n{}\n\n\nuse_ray\nbool\nA boolean indicating whether to use Ray for parallel processing.\nFalse\n\n\nray_remote_func_options_kwargs\ndict\nThe keyword arguments for the Ray remote function options.\n{}\n\n\nsample_fraction\nfloat\nThe fraction of the training data to use for fitting the CATE models. Default implies 1.0 (full training data).\n1.0\n\n\nn_jobs\nint\nThe number of parallel jobs to run. Default implies 1 (no parallel jobs).\n1\n\n\n\n\n\n\n&gt;&gt;&gt; rscorer_kwargs = {\n...     \"cv\": 3,\n...     \"mc_iters\": 3,\n...     }\n&gt;&gt;&gt; subset_cate_models = [\"LinearDML\", \"NonParamDML\", \"CausalForestDML\"]\n&gt;&gt;&gt; additional_cate_models = [(\"XLearner\", XLearner(models=caml_obj._model_Y_X_T, cate_models=caml_obj._model_Y_X_T, propensity_model=caml._model_T_X))]\n&gt;&gt;&gt; caml_obj.fit_validator(subset_cate_models=subset_cate_models, additional_cate_models=additional_cate_models, rscorer_kwargs=rscorer_kwargs)\n\n\n\n\nCamlCATE.predict(X=None, T0=0, T1=1)\nPredicts the CATE based on the fitted final estimator for either the internal dataset or provided Data.\nFor binary treatments, the CATE is the estimated effect of the treatment and for a continuous treatment, the CATE is the estimated effect of a one-unit increase in the treatment. This can be modified by setting the T0 and T1 parameters to the desired treatment levels.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nX\npandas.DataFrame | polars.DataFrame | pyspark.sql.DataFrame\nThe DataFrame containing the features (X) for which CATE needs to be predicted. If not provided, defaults to the internal dataset.\nNone\n\n\nT0\nint\nBase treatment for each sample.\n0\n\n\nT1\nint\nTarget treatment for each sample.\n1\n\n\n\n\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nnp.ndarray\nThe predicted CATE values if return_predictions is set to True.\n\n\n\n\n\n\n&gt;&gt;&gt; caml.predict(return_as_dataframe=True)\n\n\n\n\nCamlCATE.summarize(cate_predictions=None)\nProvides population summary statistics for the CATE predictions for either the internal results or provided results.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\ncate_predictions\nnp.ndarray | None\nThe CATE predictions for which summary statistics will be generated. If not provided, defaults to internal CATE predictions genered by predict() method with X=None.\nNone\n\n\n\n\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\npandas.DataFrame | pandas.Series\nThe summary statistics for the CATE predictions.\n\n\n\n\n\n\n&gt;&gt;&gt; caml.summarize() # Summarizes the CATE predictions for the internal DataFrame.\n\n\n\n\nCamlCATE.validate(n_groups=4, n_bootstrap=100, estimator=None, print_full_report=True)\nValidates the fitted CATE models on the test set to check for generalization performance. Uses the DRTester class from EconML to obtain the Best Linear Predictor (BLP), Calibration, AUTOC, and QINI. See EconML documentation for more details. In short, we are checking for the ability of the model to find statistically significant heterogeneity in a ‚Äúwell-calibrated‚Äù fashion.\nSets the _validator_results internal attribute to the results of the DRTester class.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nn_groups\nint\nThe number of quantile based groups used to calculate calibration scores.\n4\n\n\nn_bootstrap\nint\nThe number of boostrap samples to run when calculating confidence bands.\n100\n\n\nestimator\nBaseCateEstimator | EnsembleCateEstimator | None\nThe estimator to validate. Default implies the best estimator from the validation set.\nNone\n\n\nprint_full_report\nbool\nA boolean indicating whether to print the full validation report.\nTrue\n\n\n\n\n\n\n&gt;&gt;&gt; caml_obj.validate(print_full_report=True) # Prints the full validation report."
  },
  {
    "objectID": "04_Reference/CamlCATE.html#parameters",
    "href": "04_Reference/CamlCATE.html#parameters",
    "title": "CamlCATE",
    "section": "",
    "text": "Name\nType\nDescription\nDefault\n\n\n\n\ndf\npandas.DataFrame | polars.DataFrame | pyspark.sql.DataFrame\nThe input DataFrame representing the data for the CamlCATE instance.\nrequired\n\n\nY\nstr\nThe str representing the column name for the outcome variable.\nrequired\n\n\nT\nstr\nThe str representing the column name(s) for the treatment variable(s).\nrequired\n\n\nX\nlist[str] | str | None\nThe str (if unity) or list of feature names representing the feature set to be utilized for estimating heterogeneity/CATE.\nrequired\n\n\nW\nlist[str] | str | None\nThe str (if unity) or list of feature names representing the confounder/control feature set to be utilized only for nuisance function estimation where applicable.\nNone\n\n\ndiscrete_treatment\nbool\nA boolean indicating whether the treatment is discrete/categorical or continuous.\nTrue\n\n\ndiscrete_outcome\nbool\nA boolean indicating whether the outcome is binary or continuous.\nFalse\n\n\nseed\nint | None\nThe seed to use for the random number generator.\nNone\n\n\nverbose\nint\nThe verbosity level for logging. Default implies 1 (INFO). Set to 0 for no logging. Set to 2 for DEBUG.\n1"
  },
  {
    "objectID": "04_Reference/CamlCATE.html#attributes",
    "href": "04_Reference/CamlCATE.html#attributes",
    "title": "CamlCATE",
    "section": "",
    "text": "Name\nType\nDescription\n\n\n\n\ndf\npandas.DataFrame | polars.DataFrame | pyspark.sql.DataFrame | ibis.Table\nThe input DataFrame representing the data for the CamlCATE instance.\n\n\nY\nstr\nThe str representing the column name for the outcome variable.\n\n\nT\nstr\nThe str representing the column name(s) for the treatment variable(s).\n\n\nX\nlist[str] | str\nThe str (if unity) or list/tuple of feature names representing the confounder/control feature set to be utilized for estimating heterogeneity/CATE and nuisance function estimation where applicable.\n\n\nW\nlist[str] | str\nThe str (if unity) or list/tuple of feature names representing the confounder/control feature set to be utilized only for nuisance function estimation, where applicable. These will be included by default in Meta-Learners.\n\n\ndiscrete_treatment\nbool\nA boolean indicating whether the treatment is discrete/categorical or continuous.\n\n\ndiscrete_outcome\nbool\nA boolean indicating whether the outcome is binary or continuous.\n\n\nvalidation_estimator\neconml._cate_estimator.BaseCateEstimator | econml.score.EnsembleCateEstimator\nThe fitted EconML estimator object for validation.\n\n\nfinal_estimator\neconml._cate_estimator.BaseCateEstimator | econml.score.EnsembleCateEstimator\nThe fitted EconML estimator object on the entire dataset after validation.\n\n\ndataframe\npandas.DataFrame | polars.DataFrame | pyspark.sql.DataFrame | ibis.Table\nThe input DataFrame with any modifications (e.g., predictions or rank orderings) made by the class returned to the original backend.\n\n\nmodel_Y_X_W\nsklearn.base.BaseEstimator\nThe fitted nuisance function for the outcome variable.\n\n\nmodel_Y_X_W_T\nsklearn.base.BaseEstimator\nThe fitted nuisance function for the outcome variable with treatment variable.\n\n\nmodel_T_X_W\nsklearn.base.BaseEstimator\nThe fitted nuisance function for the treatment variable.\n\n\n_Y\nibis.Table\nThe outcome variable data as ibis table.\n\n\n_T\nibis.Table\nThe treatment variable data as ibis table.\n\n\n_X\nibis.Table\nThe feature/confounder set data as ibis table.\n\n\n_X_T\nibis.Table\nThe feature/confounder feature set and treatment variable data as ibis table.\n\n\n_nuisances_fitted\nbool\nA boolean indicating whether the nuisance functions have been fitted.\n\n\n_validation_estimator\neconml._cate_estimator.BaseCateEstimator | econml.score.EnsembleCateEstimator\nThe fitted EconML estimator object for validation.\n\n\n_final_estimator\neconml._cate_estimator.BaseCateEstimator | econml.score.EnsembleCateEstimator\nThe fitted EconML estimator object for final predictions.\n\n\n_validator_results\neconml.validate.EvaluationResults\nThe results of the validation tests from DRTester.\n\n\n_cate_models\nlist[tuple[str, econml._cate_estimator.BaseCateEstimator]]\nThe list of CATE models to fit and ensemble.\n\n\n_data_splits\ndict[str, np.ndarray]\nThe dictionary containing the training, validation, and test data splits.\n\n\n_rscorer\neconml.score.RScorer\nThe RScorer object for the validation estimator."
  },
  {
    "objectID": "04_Reference/CamlCATE.html#examples",
    "href": "04_Reference/CamlCATE.html#examples",
    "title": "CamlCATE",
    "section": "",
    "text": "&gt;&gt;&gt; from caml.core.cate import CamlCATE\n&gt;&gt;&gt; from caml.extensions.synthetic_data import make_fully_heterogeneous_dataset\n&gt;&gt;&gt;\n&gt;&gt;&gt; # Generate synthetic dataset\n&gt;&gt;&gt; df, true_cates, true_ate = make_fully_heterogeneous_dataset(n_obs=1000, n_confounders=10, theta=10, seed=1)\n&gt;&gt;&gt;\n&gt;&gt;&gt; # Instantiate CamlCATE class\n&gt;&gt;&gt; caml_obj= CamlCATE(df=df,\n...                    Y=\"y\",\n...                    T=\"d\",\n...                    X=[c for c in df.columns if \"X\" in c],\n...                    W=[c for c in df.columns if \"W\" in c],\n...                    discrete_treatment=True,\n...                    discrete_outcome=True,\n...                    seed=0,\n...                    verbose=1)\n&gt;&gt;&gt;\n&gt;&gt;&gt; # Standard pipeline\n&gt;&gt;&gt; caml_obj.auto_nuisance_functions()\n&gt;&gt;&gt; caml_obj.fit_validator()\n&gt;&gt;&gt; caml_obj.validate()\n&gt;&gt;&gt; caml_obj.fit_final()\n&gt;&gt;&gt; predictions = caml_obj.predict()\n&gt;&gt;&gt; summarized_predictions = caml_obj.summarize()\n&gt;&gt;&gt;\n&gt;&gt;&gt; # Access final model (can be saved for future inference)\n&gt;&gt;&gt; final_estimator = caml_obj.final_estimator"
  },
  {
    "objectID": "04_Reference/CamlCATE.html#methods",
    "href": "04_Reference/CamlCATE.html#methods",
    "title": "CamlCATE",
    "section": "",
    "text": "Name\nDescription\n\n\n\n\nauto_nuisance_functions\nLeverages AutoML to find optimal nuisance functions/regression & propensity models for use in EconML CATE estimators.\n\n\nfit_final\nFits the final estimator on the entire dataset, after validation and testing.\n\n\nfit_validator\nFits the CATE models on the training set and evaluates them & ensembles based on the validation set.\n\n\npredict\nPredicts the CATE based on the fitted final estimator for either the internal dataset or provided Data.\n\n\nsummarize\nProvides population summary statistics for the CATE predictions for either the internal results or provided results.\n\n\nvalidate\nValidates the fitted CATE models on the test set to check for generalization performance. Uses the DRTester class from EconML to obtain the Best\n\n\n\n\n\nCamlCATE.auto_nuisance_functions(flaml_Y_kwargs=None, flaml_T_kwargs=None, use_ray=False, use_spark=False)\nLeverages AutoML to find optimal nuisance functions/regression & propensity models for use in EconML CATE estimators.\nSets the model_Y_X_W, model_Y_X_W_T, and model_T_X_W internal attributes to the fitted nuisance functions.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nflaml_Y_kwargs\ndict | None\nThe keyword arguments for the FLAML AutoML search for the outcome model. Default implies the base parameters in CamlBase.\nNone\n\n\nflaml_T_kwargs\ndict | None\nThe keyword arguments for the FLAML AutoML search for the treatment model. Default implies the base parameters in CamlBase.\nNone\n\n\nuse_ray\nbool\nA boolean indicating whether to use Ray for parallel processing.\nFalse\n\n\nuse_spark\nbool\nA boolean indicating whether to use Spark for parallel processing.\nFalse\n\n\n\n\n\n\n&gt;&gt;&gt; flaml_Y_kwargs = {\n...     \"n_jobs\": -1,\n...     \"time_budget\": 300, # in seconds\n...     }\n&gt;&gt;&gt; flaml_T_kwargs = {\n...     \"n_jobs\": -1,\n...     \"time_budget\": 300,\n...     }\n&gt;&gt;&gt; caml_obj.auto_nuisance_functions(flaml_Y_kwargs=flaml_Y_kwargs, flaml_T_kwargs=flaml_T_kwargs)\n\n\n\n\nCamlCATE.fit_final()\nFits the final estimator on the entire dataset, after validation and testing.\nSets the _final_estimator internal attribute to the fitted EconML estimator.\n\n\n&gt;&gt;&gt; caml_obj.fit_final() # Fits the final estimator on the entire dataset.\n\n\n\n\nCamlCATE.fit_validator(subset_cate_models=['LinearDML', 'CausalForestDML', 'NonParamDML', 'AutoNonParamDML', 'SparseLinearDML-2D', 'DRLearner', 'ForestDRLearner', 'LinearDRLearner', 'SparseLinearDRLearner-2D', 'DomainAdaptationLearner', 'SLearner', 'TLearner', 'XLearner'], additional_cate_models=[], rscorer_kwargs={}, use_ray=False, ray_remote_func_options_kwargs={}, sample_fraction=1.0, n_jobs=1)\nFits the CATE models on the training set and evaluates them & ensembles based on the validation set.\nSets the _validation_estimator and _rscorer internal attributes to the fitted EconML estimator and RScorer object.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nsubset_cate_models\nlist[str]\nThe list of CATE models to fit and ensemble. Default implies all available models as defined by class.\n['LinearDML', 'CausalForestDML', 'NonParamDML', 'AutoNonParamDML', 'SparseLinearDML-2D', 'DRLearner', 'ForestDRLearner', 'LinearDRLearner', 'SparseLinearDRLearner-2D', 'DomainAdaptationLearner', 'SLearner', 'TLearner', 'XLearner']\n\n\nadditional_cate_models\nlist[tuple[str, BaseCateEstimator]]\nThe list of additional CATE models to fit and ensemble\n[]\n\n\nrscorer_kwargs\ndict\nThe keyword arguments for the econml.score.RScorer object.\n{}\n\n\nuse_ray\nbool\nA boolean indicating whether to use Ray for parallel processing.\nFalse\n\n\nray_remote_func_options_kwargs\ndict\nThe keyword arguments for the Ray remote function options.\n{}\n\n\nsample_fraction\nfloat\nThe fraction of the training data to use for fitting the CATE models. Default implies 1.0 (full training data).\n1.0\n\n\nn_jobs\nint\nThe number of parallel jobs to run. Default implies 1 (no parallel jobs).\n1\n\n\n\n\n\n\n&gt;&gt;&gt; rscorer_kwargs = {\n...     \"cv\": 3,\n...     \"mc_iters\": 3,\n...     }\n&gt;&gt;&gt; subset_cate_models = [\"LinearDML\", \"NonParamDML\", \"CausalForestDML\"]\n&gt;&gt;&gt; additional_cate_models = [(\"XLearner\", XLearner(models=caml_obj._model_Y_X_T, cate_models=caml_obj._model_Y_X_T, propensity_model=caml._model_T_X))]\n&gt;&gt;&gt; caml_obj.fit_validator(subset_cate_models=subset_cate_models, additional_cate_models=additional_cate_models, rscorer_kwargs=rscorer_kwargs)\n\n\n\n\nCamlCATE.predict(X=None, T0=0, T1=1)\nPredicts the CATE based on the fitted final estimator for either the internal dataset or provided Data.\nFor binary treatments, the CATE is the estimated effect of the treatment and for a continuous treatment, the CATE is the estimated effect of a one-unit increase in the treatment. This can be modified by setting the T0 and T1 parameters to the desired treatment levels.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nX\npandas.DataFrame | polars.DataFrame | pyspark.sql.DataFrame\nThe DataFrame containing the features (X) for which CATE needs to be predicted. If not provided, defaults to the internal dataset.\nNone\n\n\nT0\nint\nBase treatment for each sample.\n0\n\n\nT1\nint\nTarget treatment for each sample.\n1\n\n\n\n\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nnp.ndarray\nThe predicted CATE values if return_predictions is set to True.\n\n\n\n\n\n\n&gt;&gt;&gt; caml.predict(return_as_dataframe=True)\n\n\n\n\nCamlCATE.summarize(cate_predictions=None)\nProvides population summary statistics for the CATE predictions for either the internal results or provided results.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\ncate_predictions\nnp.ndarray | None\nThe CATE predictions for which summary statistics will be generated. If not provided, defaults to internal CATE predictions genered by predict() method with X=None.\nNone\n\n\n\n\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\npandas.DataFrame | pandas.Series\nThe summary statistics for the CATE predictions.\n\n\n\n\n\n\n&gt;&gt;&gt; caml.summarize() # Summarizes the CATE predictions for the internal DataFrame.\n\n\n\n\nCamlCATE.validate(n_groups=4, n_bootstrap=100, estimator=None, print_full_report=True)\nValidates the fitted CATE models on the test set to check for generalization performance. Uses the DRTester class from EconML to obtain the Best Linear Predictor (BLP), Calibration, AUTOC, and QINI. See EconML documentation for more details. In short, we are checking for the ability of the model to find statistically significant heterogeneity in a ‚Äúwell-calibrated‚Äù fashion.\nSets the _validator_results internal attribute to the results of the DRTester class.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nn_groups\nint\nThe number of quantile based groups used to calculate calibration scores.\n4\n\n\nn_bootstrap\nint\nThe number of boostrap samples to run when calculating confidence bands.\n100\n\n\nestimator\nBaseCateEstimator | EnsembleCateEstimator | None\nThe estimator to validate. Default implies the best estimator from the validation set.\nNone\n\n\nprint_full_report\nbool\nA boolean indicating whether to print the full validation report.\nTrue\n\n\n\n\n\n\n&gt;&gt;&gt; caml_obj.validate(print_full_report=True) # Prints the full validation report."
  },
  {
    "objectID": "04_Reference/logging.setup_logging.html",
    "href": "04_Reference/logging.setup_logging.html",
    "title": "logging.setup_logging",
    "section": "",
    "text": "logging.setup_logging\nlogging.setup_logging(verbose=1)\nSet up logging configuration.\nThis function configures the logging module with a basic configuration. It sets the logging level to INFO and the log message format to only include the message itself. The logging handler used is rich_handler.\n\n\n\n\n Back to top"
  },
  {
    "objectID": "03_Examples/Synthetic Data Generation.html",
    "href": "03_Examples/Synthetic Data Generation.html",
    "title": "Caml Synthetic Data API Usage",
    "section": "",
    "text": "import marimo as mo\n\n\nfrom caml.extensions.synthetic_data import CamlSyntheticDataGenerator\n\n\ndata =  CamlSyntheticDataGenerator(n_obs=10_000,\n                                  n_cont_outcomes=1,\n                                  n_binary_outcomes=0,\n                                  n_cont_treatments=1,\n                                  n_binary_treatments=0,\n                                  n_discrete_treatments=0,\n                                  n_cont_confounders=2,\n                                  n_binary_confounders=2,\n                                  n_discrete_confounders=2,\n                                  n_cont_heterogeneity_covariates=4,\n                                  n_binary_heterogeneity_covariates=4,\n                                  n_discrete_heterogeneity_covariates=4,\n                                  n_heterogeneity_confounders=0,\n                                  stddev_outcome_noise=3,\n                                  stddev_treatment_noise=3,\n                                  causal_model_functional_form=\"fully_non_linear\",\n                                  n_nonlinear_transformations=10,\n                                  n_nonlinear_interactions=5,\n                                  treatment_effect_weight=1,\n                                  seed=None)\n\n\ndata.df\n\n\n\n\n\n\n\n\nW1_continuous\nW2_continuous\nW1_binary\nW2_binary\nW1_discrete\nW2_discrete\nX1_continuous\nX2_continuous\nX3_continuous\nX4_continuous\nX1_binary\nX2_binary\nX3_binary\nX4_binary\nX1_discrete\nX2_discrete\nX3_discrete\nX4_discrete\nT1_continuous\nY1_continuous\n\n\n\n\n0\n-4.240734\n1.008884\n1\n1\n2\n3\n2.993743\n7.646004\n5.729336\n0.683936\n0\n1\n0\n1\n3\n3\n0\n1\n39.751182\n-1963.341986\n\n\n1\n1.576644\n-5.258750\n0\n1\n4\n1\n0.944679\n4.417811\n-1.380192\n-3.067390\n0\n1\n1\n1\n0\n3\n1\n1\n-40.810360\n647.467106\n\n\n2\n-3.976223\n-3.410041\n0\n1\n3\n1\n10.511970\n2.488775\n-2.310012\n-2.241203\n1\n1\n0\n1\n0\n2\n0\n1\n-3.264910\n23.421061\n\n\n3\n-1.239920\n0.712298\n0\n0\n0\n1\n0.237527\n8.789375\n5.375974\n0.400596\n0\n1\n1\n1\n1\n4\n0\n1\n6.908180\n-456.084144\n\n\n4\n-3.770211\n0.457719\n0\n0\n0\n1\n0.951525\n6.633808\n0.222287\n-1.237366\n0\n1\n0\n1\n3\n6\n0\n1\n30.930535\n-1189.148773\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n9995\n-2.796119\n-6.012242\n0\n1\n2\n1\n2.037188\n8.432082\n5.550546\n-2.423230\n0\n1\n1\n1\n3\n3\n1\n1\n-14.613953\n864.306606\n\n\n9996\n-3.055806\n1.715886\n1\n1\n2\n1\n1.205181\n2.985404\n4.510643\n-1.286539\n0\n1\n1\n1\n3\n4\n0\n1\n18.715407\n-147.224358\n\n\n9997\n-2.666599\n-4.025828\n1\n1\n0\n4\n0.534706\n1.548265\n2.240959\n-0.960122\n1\n0\n1\n1\n3\n4\n0\n0\n12.800946\n-45.419954\n\n\n9998\n-0.451689\n-1.285235\n0\n1\n1\n1\n1.494708\n6.411211\n1.231493\n-0.172919\n0\n1\n1\n1\n1\n2\n0\n1\n-2.175441\n76.382973\n\n\n9999\n0.797167\n-1.000465\n1\n1\n0\n1\n0.442355\n6.110947\n0.093449\n-2.210299\n1\n1\n1\n1\n4\n1\n3\n0\n-0.531193\n20.080568\n\n\n\n\n10000 rows √ó 20 columns\n\n\n\n\ndata.cates\n\n\n\n\n\n\n\n\nCATE_of_T1_continuous_on_Y1_continuous\n\n\n\n\n0\n-49.484870\n\n\n1\n-15.765517\n\n\n2\n-4.453159\n\n\n3\n-65.677132\n\n\n4\n-37.977532\n\n\n...\n...\n\n\n9995\n-59.310533\n\n\n9996\n-7.817613\n\n\n9997\n-2.241066\n\n\n9998\n-34.688522\n\n\n9999\n-30.136570\n\n\n\n\n10000 rows √ó 1 columns\n\n\n\n\ndata.ates\n\n\n\n\n\n\n\n\nTreatment\nATE\n\n\n\n\n0\nT1_continuous_on_Y1_continuous\n-21.540344\n\n\n\n\n\n\n\n\n\n\n Back to top",
    "crumbs": [
      "Caml Synthetic Data API Usage"
    ]
  },
  {
    "objectID": "assets/marimo/Synthetic Data Generation.html",
    "href": "assets/marimo/Synthetic Data Generation.html",
    "title": "Caml Synthetic Data API Usage",
    "section": "",
    "text": "from caml.extensions.synthetic_data import CamlSyntheticDataGenerator\n\n\ndata = CamlSyntheticDataGenerator(\n    n_obs=10_000,\n    n_cont_outcomes=1,\n    n_binary_outcomes=0,\n    n_cont_treatments=1,\n    n_binary_treatments=0,\n    n_discrete_treatments=0,\n    n_cont_confounders=2,\n    n_binary_confounders=2,\n    n_discrete_confounders=2,\n    n_cont_heterogeneity_covariates=4,\n    n_binary_heterogeneity_covariates=4,\n    n_discrete_heterogeneity_covariates=4,\n    n_heterogeneity_confounders=0,\n    stddev_outcome_noise=3,\n    stddev_treatment_noise=3,\n    causal_model_functional_form=\"fully_non_linear\",\n    n_nonlinear_transformations=10,\n    n_nonlinear_interactions=5,\n    treatment_effect_weight=1,\n    seed=None,\n)\n\n\ndata.df\n\n\ndata.cates\n\n\ndata.ates\n\n\n\n\n Back to top"
  }
]
