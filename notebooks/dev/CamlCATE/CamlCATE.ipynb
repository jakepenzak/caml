{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Caml API Usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "os.environ[\"PYSPARK_PYTHON\"] = sys.executable\n",
    "os.environ[\"PYSPARK_DRIVER_PYTHON\"] = sys.executable\n",
    "\n",
    "datasets = [\n",
    "    \"partially_linear_simple\",\n",
    "    \"fully_heterogenous\",\n",
    "    \"partially_linear_constant\",\n",
    "    \"dowhy_linear\",\n",
    "]\n",
    "backends = [\"pandas\", \"pyspark\", \"polars\"]\n",
    "\n",
    "df_backend = backends[0]\n",
    "dataset = datasets[3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Synthetic Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "from caml.extensions.synthetic_data import (\n",
    "    make_partially_linear_dataset_simple,\n",
    "    make_fully_heterogeneous_dataset,\n",
    "    make_partially_linear_dataset_constant,\n",
    "    make_dowhy_linear_dataset,\n",
    ")\n",
    "\n",
    "if dataset == \"partially_linear_simple\":\n",
    "    df, true_cates, true_ate = make_partially_linear_dataset_simple(\n",
    "        n_obs=5000,\n",
    "        n_confounders=5,\n",
    "        dim_heterogeneity=2,\n",
    "        binary_treatment=True,\n",
    "        seed=None,\n",
    "    )\n",
    "    df[\"true_cates\"] = true_cates\n",
    "elif dataset == \"fully_heterogenous\":\n",
    "    df, true_cates, true_ate = make_fully_heterogeneous_dataset(\n",
    "        n_obs=10_000,\n",
    "        n_confounders=10,\n",
    "        theta=4.0,\n",
    "        seed=None,\n",
    "    )\n",
    "    df[\"true_cates\"] = true_cates\n",
    "elif dataset == \"partially_linear_constant\":\n",
    "    df, true_cates, true_ate = make_partially_linear_dataset_constant(\n",
    "        n_obs=5000,\n",
    "        ate=4.0,\n",
    "        n_confounders=5,\n",
    "        dgp=\"make_plr_CCDDHNR2018\",  # make_plr_turrell2018\n",
    "        seed=None,\n",
    "    )\n",
    "    df[\"true_cates\"] = true_cates\n",
    "elif dataset == \"dowhy_linear\":\n",
    "    df, true_cates, true_ate = make_dowhy_linear_dataset(\n",
    "        beta=2.0,\n",
    "        n_obs=10_000,\n",
    "        n_confounders=10,\n",
    "        n_discrete_confounders=3,\n",
    "        n_effect_modifiers=10,\n",
    "        n_discrete_effect_modifiers=3,\n",
    "        n_treatments=1,\n",
    "        binary_treatment=True,\n",
    "        categorical_treatment=False,\n",
    "        binary_outcome=False,\n",
    "        seed=12,\n",
    "    )\n",
    "\n",
    "    for i in range(1, len(true_cates) + 1):\n",
    "        if isinstance(true_cates[f\"d{i}\"], list):\n",
    "            df[f\"true_cate_d{i}_1\"] = true_cates[f\"d{i}\"][0]\n",
    "            df[f\"true_cate_d{i}_2\"] = true_cates[f\"d{i}\"][1]\n",
    "        else:\n",
    "            df[f\"true_cate_d{i}\"] = true_cates[f\"d{i}\"]\n",
    "\n",
    "\n",
    "df[\"uuid\"] = df.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import polars as pl\n",
    "    from pyspark.sql import SparkSession\n",
    "except ImportError:\n",
    "    pass\n",
    "\n",
    "if df_backend == \"polars\":\n",
    "    df = pl.from_pandas(df)\n",
    "    spark = None\n",
    "elif df_backend == \"pandas\":\n",
    "    spark = None\n",
    "    pass\n",
    "elif df_backend == \"pyspark\":\n",
    "    spark = (\n",
    "        SparkSession.builder.master(\"local[1]\")\n",
    "        .appName(\"local-tests\")\n",
    "        .config(\"spark.executor.cores\", \"1\")\n",
    "        .config(\"spark.executor.instances\", \"1\")\n",
    "        .config(\"spark.sql.shuffle.partitions\", \"1\")\n",
    "        .getOrCreate()\n",
    "    )\n",
    "    df = spark.createDataFrame(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X0</th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "      <th>X3</th>\n",
       "      <th>X4</th>\n",
       "      <th>X5</th>\n",
       "      <th>X6</th>\n",
       "      <th>X7</th>\n",
       "      <th>X8</th>\n",
       "      <th>X9</th>\n",
       "      <th>...</th>\n",
       "      <th>W4</th>\n",
       "      <th>W5</th>\n",
       "      <th>W6</th>\n",
       "      <th>W7</th>\n",
       "      <th>W8</th>\n",
       "      <th>W9</th>\n",
       "      <th>d1</th>\n",
       "      <th>y</th>\n",
       "      <th>true_cate_d1</th>\n",
       "      <th>uuid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.860128</td>\n",
       "      <td>1.263800</td>\n",
       "      <td>-1.621480</td>\n",
       "      <td>-1.243014</td>\n",
       "      <td>0.119318</td>\n",
       "      <td>0.138299</td>\n",
       "      <td>-2.190976</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.777832</td>\n",
       "      <td>3.709313</td>\n",
       "      <td>0.203607</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>4.197980</td>\n",
       "      <td>0.793035</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.085828</td>\n",
       "      <td>-0.258028</td>\n",
       "      <td>0.648743</td>\n",
       "      <td>-1.045765</td>\n",
       "      <td>-0.128647</td>\n",
       "      <td>0.435518</td>\n",
       "      <td>0.108749</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.000380</td>\n",
       "      <td>2.047290</td>\n",
       "      <td>1.303302</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>8.774372</td>\n",
       "      <td>5.340261</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.077397</td>\n",
       "      <td>-0.389245</td>\n",
       "      <td>0.503995</td>\n",
       "      <td>-1.182757</td>\n",
       "      <td>-1.419884</td>\n",
       "      <td>1.466198</td>\n",
       "      <td>-1.111965</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.189385</td>\n",
       "      <td>0.190063</td>\n",
       "      <td>0.273025</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>-6.610495</td>\n",
       "      <td>7.983276</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.864333</td>\n",
       "      <td>0.424140</td>\n",
       "      <td>0.705238</td>\n",
       "      <td>1.087511</td>\n",
       "      <td>-0.978616</td>\n",
       "      <td>1.553906</td>\n",
       "      <td>-1.056368</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.935434</td>\n",
       "      <td>0.159549</td>\n",
       "      <td>0.229549</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>8.211690</td>\n",
       "      <td>10.040109</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.042030</td>\n",
       "      <td>-2.178140</td>\n",
       "      <td>0.773407</td>\n",
       "      <td>-1.260931</td>\n",
       "      <td>0.600929</td>\n",
       "      <td>0.659652</td>\n",
       "      <td>-0.311650</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-4.118267</td>\n",
       "      <td>1.372630</td>\n",
       "      <td>1.033920</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "      <td>3.598249</td>\n",
       "      <td>4.030683</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>1.173214</td>\n",
       "      <td>1.718103</td>\n",
       "      <td>0.527236</td>\n",
       "      <td>-0.833312</td>\n",
       "      <td>0.857061</td>\n",
       "      <td>-0.963238</td>\n",
       "      <td>-0.802704</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1.446361</td>\n",
       "      <td>0.877547</td>\n",
       "      <td>0.160547</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>10.896206</td>\n",
       "      <td>6.942622</td>\n",
       "      <td>9995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>0.916397</td>\n",
       "      <td>0.691821</td>\n",
       "      <td>0.512401</td>\n",
       "      <td>-0.098800</td>\n",
       "      <td>-0.721480</td>\n",
       "      <td>0.789828</td>\n",
       "      <td>0.042103</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.341384</td>\n",
       "      <td>-0.574287</td>\n",
       "      <td>2.923056</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>10.268397</td>\n",
       "      <td>9.750975</td>\n",
       "      <td>9996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>3.512478</td>\n",
       "      <td>-0.894800</td>\n",
       "      <td>1.119166</td>\n",
       "      <td>-1.482994</td>\n",
       "      <td>-1.278946</td>\n",
       "      <td>-0.029847</td>\n",
       "      <td>-0.221000</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.698003</td>\n",
       "      <td>1.961363</td>\n",
       "      <td>0.020335</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>11.488667</td>\n",
       "      <td>11.082038</td>\n",
       "      <td>9997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>0.615903</td>\n",
       "      <td>1.969203</td>\n",
       "      <td>0.407985</td>\n",
       "      <td>0.945009</td>\n",
       "      <td>0.580888</td>\n",
       "      <td>0.783290</td>\n",
       "      <td>-1.168335</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.156037</td>\n",
       "      <td>1.078907</td>\n",
       "      <td>1.013377</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "      <td>12.162188</td>\n",
       "      <td>11.152002</td>\n",
       "      <td>9998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>0.858440</td>\n",
       "      <td>0.199468</td>\n",
       "      <td>1.723768</td>\n",
       "      <td>-1.405161</td>\n",
       "      <td>-0.082894</td>\n",
       "      <td>-1.798955</td>\n",
       "      <td>-1.702678</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.996489</td>\n",
       "      <td>0.676400</td>\n",
       "      <td>1.498534</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "      <td>2.904599</td>\n",
       "      <td>3.363482</td>\n",
       "      <td>9999</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            X0        X1        X2        X3        X4        X5        X6 X7  \\\n",
       "0     0.860128  1.263800 -1.621480 -1.243014  0.119318  0.138299 -2.190976  3   \n",
       "1     0.085828 -0.258028  0.648743 -1.045765 -0.128647  0.435518  0.108749  3   \n",
       "2     1.077397 -0.389245  0.503995 -1.182757 -1.419884  1.466198 -1.111965  3   \n",
       "3     1.864333  0.424140  0.705238  1.087511 -0.978616  1.553906 -1.056368  1   \n",
       "4     0.042030 -2.178140  0.773407 -1.260931  0.600929  0.659652 -0.311650  0   \n",
       "...        ...       ...       ...       ...       ...       ...       ... ..   \n",
       "9995  1.173214  1.718103  0.527236 -0.833312  0.857061 -0.963238 -0.802704  0   \n",
       "9996  0.916397  0.691821  0.512401 -0.098800 -0.721480  0.789828  0.042103  2   \n",
       "9997  3.512478 -0.894800  1.119166 -1.482994 -1.278946 -0.029847 -0.221000  3   \n",
       "9998  0.615903  1.969203  0.407985  0.945009  0.580888  0.783290 -1.168335  1   \n",
       "9999  0.858440  0.199468  1.723768 -1.405161 -0.082894 -1.798955 -1.702678  2   \n",
       "\n",
       "     X8 X9  ...        W4        W5        W6  W7  W8  W9     d1          y  \\\n",
       "0     0  2  ... -1.777832  3.709313  0.203607   2   3   0   True   4.197980   \n",
       "1     0  2  ... -2.000380  2.047290  1.303302   2   2   2   True   8.774372   \n",
       "2     3  2  ... -3.189385  0.190063  0.273025   1   2   1  False  -6.610495   \n",
       "3     3  0  ... -0.935434  0.159549  0.229549   1   3   2   True   8.211690   \n",
       "4     3  0  ... -4.118267  1.372630  1.033920   3   0   3   True   3.598249   \n",
       "...  .. ..  ...       ...       ...       ...  ..  ..  ..    ...        ...   \n",
       "9995  2  2  ...  1.446361  0.877547  0.160547   0   1   1   True  10.896206   \n",
       "9996  2  2  ... -1.341384 -0.574287  2.923056   2   2   1   True  10.268397   \n",
       "9997  3  2  ... -1.698003  1.961363  0.020335   2   1   2   True  11.488667   \n",
       "9998  3  2  ... -2.156037  1.078907  1.013377   2   0   3   True  12.162188   \n",
       "9999  2  1  ... -1.996489  0.676400  1.498534   3   0   3   True   2.904599   \n",
       "\n",
       "     true_cate_d1  uuid  \n",
       "0        0.793035     0  \n",
       "1        5.340261     1  \n",
       "2        7.983276     2  \n",
       "3       10.040109     3  \n",
       "4        4.030683     4  \n",
       "...           ...   ...  \n",
       "9995     6.942622  9995  \n",
       "9996     9.750975  9996  \n",
       "9997    11.082038  9997  \n",
       "9998    11.152002  9998  \n",
       "9999     3.363482  9999  \n",
       "\n",
       "[10000 rows x 24 columns]"
      ]
     },
     "execution_count": 273,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>W1_continuous</th>\n",
       "      <th>W2_continuous</th>\n",
       "      <th>W1_binary</th>\n",
       "      <th>W2_binary</th>\n",
       "      <th>W1_discrete</th>\n",
       "      <th>W2_discrete</th>\n",
       "      <th>X1_continuous</th>\n",
       "      <th>X2_continuous</th>\n",
       "      <th>X3_continuous</th>\n",
       "      <th>X4_continuous</th>\n",
       "      <th>X1_binary</th>\n",
       "      <th>X2_binary</th>\n",
       "      <th>X3_binary</th>\n",
       "      <th>X4_binary</th>\n",
       "      <th>X1_discrete</th>\n",
       "      <th>X2_discrete</th>\n",
       "      <th>X3_discrete</th>\n",
       "      <th>X4_discrete</th>\n",
       "      <th>T1_continuous</th>\n",
       "      <th>Y1_continuous</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.406044</td>\n",
       "      <td>-0.151649</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>4.232622</td>\n",
       "      <td>0.747387</td>\n",
       "      <td>4.874727</td>\n",
       "      <td>0.726902</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-19.115807</td>\n",
       "      <td>1079.464650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.438724</td>\n",
       "      <td>-2.336934</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0.117746</td>\n",
       "      <td>6.535678</td>\n",
       "      <td>4.143518</td>\n",
       "      <td>3.091032</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-11.178740</td>\n",
       "      <td>68.928005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.884024</td>\n",
       "      <td>-2.542391</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>5.219183</td>\n",
       "      <td>3.807166</td>\n",
       "      <td>2.748808</td>\n",
       "      <td>2.267096</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-19.722470</td>\n",
       "      <td>827.325915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.113439</td>\n",
       "      <td>-0.581423</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>5.691499</td>\n",
       "      <td>7.863248</td>\n",
       "      <td>3.874850</td>\n",
       "      <td>1.311375</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>-32.111036</td>\n",
       "      <td>1997.805122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.112845</td>\n",
       "      <td>-2.602360</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>4.319512</td>\n",
       "      <td>1.853090</td>\n",
       "      <td>3.062959</td>\n",
       "      <td>4.061395</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>-41.549068</td>\n",
       "      <td>1706.448421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>0.620626</td>\n",
       "      <td>0.955814</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>45</td>\n",
       "      <td>2.212935</td>\n",
       "      <td>5.095046</td>\n",
       "      <td>4.062946</td>\n",
       "      <td>0.967618</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>-71.640000</td>\n",
       "      <td>1966.545754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>0.016592</td>\n",
       "      <td>-0.768066</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0.026808</td>\n",
       "      <td>9.745895</td>\n",
       "      <td>3.225506</td>\n",
       "      <td>3.098420</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>-6.595926</td>\n",
       "      <td>26.114568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>0.322272</td>\n",
       "      <td>-2.021281</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.981227</td>\n",
       "      <td>7.759381</td>\n",
       "      <td>3.956030</td>\n",
       "      <td>5.489068</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.000034</td>\n",
       "      <td>16.652740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>1.727967</td>\n",
       "      <td>-2.057457</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>2.102762</td>\n",
       "      <td>8.927030</td>\n",
       "      <td>4.238957</td>\n",
       "      <td>1.386538</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-7.485863</td>\n",
       "      <td>229.205593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>0.342372</td>\n",
       "      <td>-2.659079</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.978098</td>\n",
       "      <td>4.422247</td>\n",
       "      <td>3.057222</td>\n",
       "      <td>13.347594</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>-2.590074</td>\n",
       "      <td>30.334865</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      W1_continuous  W2_continuous  W1_binary  W2_binary  W1_discrete  \\\n",
       "0          0.406044      -0.151649          0          0            1   \n",
       "1          1.438724      -2.336934          1          1            1   \n",
       "2          2.884024      -2.542391          1          0            1   \n",
       "3          0.113439      -0.581423          1          1            1   \n",
       "4          5.112845      -2.602360          1          0            1   \n",
       "...             ...            ...        ...        ...          ...   \n",
       "9995       0.620626       0.955814          0          1            1   \n",
       "9996       0.016592      -0.768066          0          0            2   \n",
       "9997       0.322272      -2.021281          0          1            1   \n",
       "9998       1.727967      -2.057457          0          0            1   \n",
       "9999       0.342372      -2.659079          1          0            1   \n",
       "\n",
       "      W2_discrete  X1_continuous  X2_continuous  X3_continuous  X4_continuous  \\\n",
       "0              10       4.232622       0.747387       4.874727       0.726902   \n",
       "1               6       0.117746       6.535678       4.143518       3.091032   \n",
       "2              13       5.219183       3.807166       2.748808       2.267096   \n",
       "3              19       5.691499       7.863248       3.874850       1.311375   \n",
       "4              25       4.319512       1.853090       3.062959       4.061395   \n",
       "...           ...            ...            ...            ...            ...   \n",
       "9995           45       2.212935       5.095046       4.062946       0.967618   \n",
       "9996            4       0.026808       9.745895       3.225506       3.098420   \n",
       "9997            1       1.981227       7.759381       3.956030       5.489068   \n",
       "9998            6       2.102762       8.927030       4.238957       1.386538   \n",
       "9999            4       0.978098       4.422247       3.057222      13.347594   \n",
       "\n",
       "      X1_binary  X2_binary  X3_binary  X4_binary  X1_discrete  X2_discrete  \\\n",
       "0             0          1          1          0            6            0   \n",
       "1             0          1          1          0            8            0   \n",
       "2             0          1          0          0            8            1   \n",
       "3             1          1          1          1            7            0   \n",
       "4             0          1          0          1            9            0   \n",
       "...         ...        ...        ...        ...          ...          ...   \n",
       "9995          0          1          0          0           11            0   \n",
       "9996          0          1          0          1            7            0   \n",
       "9997          0          0          1          0            6            1   \n",
       "9998          1          1          1          0            6            0   \n",
       "9999          1          1          1          0            6            0   \n",
       "\n",
       "      X3_discrete  X4_discrete  T1_continuous  Y1_continuous  \n",
       "0               1            0     -19.115807    1079.464650  \n",
       "1               1            0     -11.178740      68.928005  \n",
       "2               1            0     -19.722470     827.325915  \n",
       "3               2            1     -32.111036    1997.805122  \n",
       "4               1            3     -41.549068    1706.448421  \n",
       "...           ...          ...            ...            ...  \n",
       "9995            1            4     -71.640000    1966.545754  \n",
       "9996            2            2      -6.595926      26.114568  \n",
       "9997            2            0      -0.000034      16.652740  \n",
       "9998            0            0      -7.485863     229.205593  \n",
       "9999            2            1      -2.590074      30.334865  \n",
       "\n",
       "[10000 rows x 20 columns]"
      ]
     },
     "execution_count": 274,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from caml.extensions.synthetic_data import CamlSyntheticDataGenerator\n",
    "\n",
    "data =  CamlSyntheticDataGenerator(n_obs=10_000,\n",
    "                                  n_cont_outcomes=1,\n",
    "                                  n_binary_outcomes=0,\n",
    "                                  n_cont_treatments=1,\n",
    "                                  n_binary_treatments=0,\n",
    "                                  n_discrete_treatments=0,\n",
    "                                  n_cont_confounders=2, \n",
    "                                  n_binary_confounders=2,\n",
    "                                  n_discrete_confounders=2,\n",
    "                                  n_cont_heterogeneity_covariates=4,\n",
    "                                  n_binary_heterogeneity_covariates=4,\n",
    "                                  n_discrete_heterogeneity_covariates=4,\n",
    "                                  n_heterogeneity_confounders=0,\n",
    "                                  stddev_outcome_noise=3,\n",
    "                                  stddev_treatment_noise=3,\n",
    "                                  causal_model_functional_form=\"fully_non_linear\",\n",
    "                                  n_nonlinear_transformations=10,\n",
    "                                  n_nonlinear_interactions=5,\n",
    "                                  treatment_effect_weight=1,\n",
    "                                  seed=None)\n",
    "\n",
    "synthetic_df = data.df\n",
    "cate_df = data.cates\n",
    "ate_df = data.ates\n",
    "dgp = data.dgp\n",
    "\n",
    "df = synthetic_df.copy()\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CATE_of_T1_continuous_on_Y1_continuous</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-59.074667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-4.133320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-44.380636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-63.083630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-42.443864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>-27.384826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>-0.099239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>-20.968952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>-31.481700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>-9.509243</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      CATE_of_T1_continuous_on_Y1_continuous\n",
       "0                                 -59.074667\n",
       "1                                  -4.133320\n",
       "2                                 -44.380636\n",
       "3                                 -63.083630\n",
       "4                                 -42.443864\n",
       "...                                      ...\n",
       "9995                              -27.384826\n",
       "9996                               -0.099239\n",
       "9997                              -20.968952\n",
       "9998                              -31.481700\n",
       "9999                               -9.509243\n",
       "\n",
       "[10000 rows x 1 columns]"
      ]
     },
     "execution_count": 275,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cate_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Treatment</th>\n",
       "      <th>ATE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>T1_continuous_on_Y1_continuous</td>\n",
       "      <td>-21.791433</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Treatment        ATE\n",
       "0  T1_continuous_on_Y1_continuous -21.791433"
      ]
     },
     "execution_count": 276,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ate_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>covariates</th>\n",
       "      <th>params</th>\n",
       "      <th>transformation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>W1_continuous</td>\n",
       "      <td>1.692535</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>W2_continuous</td>\n",
       "      <td>1.301720</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>W1_binary</td>\n",
       "      <td>-1.749237</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>W2_binary</td>\n",
       "      <td>-0.417859</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>W1_discrete</td>\n",
       "      <td>-2.600975</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>W2_discrete</td>\n",
       "      <td>-2.569533</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>X1_continuous</td>\n",
       "      <td>-2.701080</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>X2_continuous</td>\n",
       "      <td>1.644644</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>X3_continuous</td>\n",
       "      <td>2.192629</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>X4_continuous</td>\n",
       "      <td>0.192064</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>X1_binary</td>\n",
       "      <td>1.572315</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>X2_binary</td>\n",
       "      <td>-0.548345</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>X3_binary</td>\n",
       "      <td>0.519325</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>X4_binary</td>\n",
       "      <td>1.218628</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>X1_discrete</td>\n",
       "      <td>1.767951</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>X2_discrete</td>\n",
       "      <td>-2.163289</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>X3_discrete</td>\n",
       "      <td>2.749738</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>X4_discrete</td>\n",
       "      <td>-1.882364</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>T1_continuous</td>\n",
       "      <td>-2.907896</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>square_X4_discrete</td>\n",
       "      <td>0.997407</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>sin_W1_continuous</td>\n",
       "      <td>-0.246048</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2Dint_W1_continuous_T1_continuous</td>\n",
       "      <td>-1.079383</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2Dint_X1_continuous_X3_continuous</td>\n",
       "      <td>-1.276618</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>sin_X4_continuous</td>\n",
       "      <td>-1.421981</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>cos_X2_discrete</td>\n",
       "      <td>-0.707110</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2Dint_W2_discrete_W2_binary</td>\n",
       "      <td>2.172669</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>cos_X1_discrete</td>\n",
       "      <td>-2.706031</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>sqrt_X1_continuous</td>\n",
       "      <td>-1.360527</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>int_T1_continuous_sin_X4_continuous</td>\n",
       "      <td>-0.698409</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>int_T1_continuous_2Dint_X1_continuous_X3_conti...</td>\n",
       "      <td>-2.749392</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>int_T1_continuous_X4_continuous</td>\n",
       "      <td>0.101806</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>int_T1_continuous_X3_discrete</td>\n",
       "      <td>1.389502</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>int_T1_continuous_X1_binary</td>\n",
       "      <td>-1.656482</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           covariates    params transformation\n",
       "0                                       W1_continuous  1.692535           None\n",
       "1                                       W2_continuous  1.301720           None\n",
       "2                                           W1_binary -1.749237           None\n",
       "3                                           W2_binary -0.417859           None\n",
       "4                                         W1_discrete -2.600975           None\n",
       "5                                         W2_discrete -2.569533           None\n",
       "6                                       X1_continuous -2.701080           None\n",
       "7                                       X2_continuous  1.644644           None\n",
       "8                                       X3_continuous  2.192629           None\n",
       "9                                       X4_continuous  0.192064           None\n",
       "10                                          X1_binary  1.572315           None\n",
       "11                                          X2_binary -0.548345           None\n",
       "12                                          X3_binary  0.519325           None\n",
       "13                                          X4_binary  1.218628           None\n",
       "14                                        X1_discrete  1.767951           None\n",
       "15                                        X2_discrete -2.163289           None\n",
       "16                                        X3_discrete  2.749738           None\n",
       "17                                        X4_discrete -1.882364           None\n",
       "18                                      T1_continuous -2.907896           None\n",
       "19                                 square_X4_discrete  0.997407           None\n",
       "20                                  sin_W1_continuous -0.246048           None\n",
       "21                  2Dint_W1_continuous_T1_continuous -1.079383           None\n",
       "22                  2Dint_X1_continuous_X3_continuous -1.276618           None\n",
       "23                                  sin_X4_continuous -1.421981           None\n",
       "24                                    cos_X2_discrete -0.707110           None\n",
       "25                        2Dint_W2_discrete_W2_binary  2.172669           None\n",
       "26                                    cos_X1_discrete -2.706031           None\n",
       "27                                 sqrt_X1_continuous -1.360527           None\n",
       "28                int_T1_continuous_sin_X4_continuous -0.698409           None\n",
       "29  int_T1_continuous_2Dint_X1_continuous_X3_conti... -2.749392           None\n",
       "30                    int_T1_continuous_X4_continuous  0.101806           None\n",
       "31                      int_T1_continuous_X3_discrete  1.389502           None\n",
       "32                        int_T1_continuous_X1_binary -1.656482           None"
      ]
     },
     "execution_count": 277,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dgp['Y1_continuous']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Core API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CamlCATE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Class Instantiation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[12/16/24 19:00:43] </span><span style=\"color: #008000; text-decoration-color: #008000\">INFO    </span> Logging has been set up.                                                 <a href=\"file:///home/jakep/projects/caml/caml/logging.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">logging.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/jakep/projects/caml/caml/logging.py#51\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">51</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[12/16/24 19:00:43]\u001b[0m\u001b[2;36m \u001b[0m\u001b[32mINFO    \u001b[0m Logging has been set up.                                                 \u001b]8;id=615488;file:///home/jakep/projects/caml/caml/logging.py\u001b\\\u001b[2mlogging.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=125715;file:///home/jakep/projects/caml/caml/logging.py#51\u001b\\\u001b[2m51\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #808000; text-decoration-color: #808000\">WARNING </span> Validation for continuous treatments is not supported yet.                 <a href=\"file:///home/jakep/projects/caml/caml/core/cate.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">cate.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/jakep/projects/caml/caml/core/cate.py#243\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">243</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[33mWARNING \u001b[0m Validation for continuous treatments is not supported yet.                 \u001b]8;id=258599;file:///home/jakep/projects/caml/caml/core/cate.py\u001b\\\u001b[2mcate.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=132745;file:///home/jakep/projects/caml/caml/core/cate.py#243\u001b\\\u001b[2m243\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from caml import CamlCATE\n",
    "\n",
    "caml = CamlCATE(\n",
    "    df=df,\n",
    "    Y=\"Y1_continuous\",\n",
    "    T=\"T1_continuous\",\n",
    "    X=[c for c in df.columns if \"X\" in c or \"W\" in c],\n",
    "    W=[],\n",
    "    discrete_treatment=False,\n",
    "    discrete_outcome=False,\n",
    "    seed=10,\n",
    "    verbose=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================== CamlCATE Object ==================\n",
      "Data Backend: pandas\n",
      "No. of Observations: 10,000\n",
      "Outcome Variable: Y1_continuous\n",
      "Discrete Outcome: False\n",
      "Treatment Variable: T1_continuous\n",
      "Discrete Treatment: False\n",
      "Features/Confounders for Heterogeneity (X): ['W1_continuous', 'W2_continuous', 'W1_binary', 'W2_binary', 'W1_discrete', 'W2_discrete', 'X1_continuous', 'X2_continuous', 'X3_continuous', 'X4_continuous', 'X1_binary', 'X2_binary', 'X3_binary', 'X4_binary', 'X1_discrete', 'X2_discrete', 'X3_discrete', 'X4_discrete']\n",
      "Features/Confounders as Controls (W): []\n",
      "Random Seed: 10\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(caml)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Nuissance Function AutoML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[flaml.automl.logger: 12-16 19:00:45] {1680} INFO - task = regression\n",
      "[flaml.automl.logger: 12-16 19:00:45] {1691} INFO - Evaluation method: cv\n",
      "[flaml.automl.logger: 12-16 19:00:45] {1789} INFO - Minimizing error metric: mse\n",
      "[flaml.automl.logger: 12-16 19:00:45] {1901} INFO - List of ML learners in AutoML Run: ['rf', 'xgboost', 'extra_tree', 'xgb_limitdepth']\n",
      "[flaml.automl.logger: 12-16 19:00:45] {2219} INFO - iteration 0, current learner rf\n",
      "[flaml.automl.logger: 12-16 19:00:45] {2345} INFO - Estimated sufficient time budget=1076s. Estimated necessary time budget=4s.\n",
      "[flaml.automl.logger: 12-16 19:00:45] {2392} INFO -  at 0.1s,\testimator rf's best error=89051.6247,\tbest estimator rf's best error=89051.6247\n",
      "[flaml.automl.logger: 12-16 19:00:45] {2219} INFO - iteration 1, current learner xgboost\n",
      "[flaml.automl.logger: 12-16 19:00:45] {2392} INFO -  at 0.2s,\testimator xgboost's best error=130380.7344,\tbest estimator rf's best error=89051.6247\n",
      "[flaml.automl.logger: 12-16 19:00:45] {2219} INFO - iteration 2, current learner xgboost\n",
      "[flaml.automl.logger: 12-16 19:00:45] {2392} INFO -  at 0.2s,\testimator xgboost's best error=130380.7344,\tbest estimator rf's best error=89051.6247\n",
      "[flaml.automl.logger: 12-16 19:00:45] {2219} INFO - iteration 3, current learner xgboost\n",
      "[flaml.automl.logger: 12-16 19:00:45] {2392} INFO -  at 0.3s,\testimator xgboost's best error=48569.2787,\tbest estimator xgboost's best error=48569.2787\n",
      "[flaml.automl.logger: 12-16 19:00:45] {2219} INFO - iteration 4, current learner rf\n",
      "[flaml.automl.logger: 12-16 19:00:46] {2392} INFO -  at 0.4s,\testimator rf's best error=83456.1080,\tbest estimator xgboost's best error=48569.2787\n",
      "[flaml.automl.logger: 12-16 19:00:46] {2219} INFO - iteration 5, current learner xgboost\n",
      "[flaml.automl.logger: 12-16 19:00:46] {2392} INFO -  at 0.5s,\testimator xgboost's best error=48569.2787,\tbest estimator xgboost's best error=48569.2787\n",
      "[flaml.automl.logger: 12-16 19:00:46] {2219} INFO - iteration 6, current learner xgboost\n",
      "[flaml.automl.logger: 12-16 19:00:46] {2392} INFO -  at 0.5s,\testimator xgboost's best error=29700.2070,\tbest estimator xgboost's best error=29700.2070\n",
      "[flaml.automl.logger: 12-16 19:00:46] {2219} INFO - iteration 7, current learner xgboost\n",
      "[flaml.automl.logger: 12-16 19:00:46] {2392} INFO -  at 0.6s,\testimator xgboost's best error=29700.2070,\tbest estimator xgboost's best error=29700.2070\n",
      "[flaml.automl.logger: 12-16 19:00:46] {2219} INFO - iteration 8, current learner xgboost\n",
      "[flaml.automl.logger: 12-16 19:00:46] {2392} INFO -  at 0.7s,\testimator xgboost's best error=25693.0614,\tbest estimator xgboost's best error=25693.0614\n",
      "[flaml.automl.logger: 12-16 19:00:46] {2219} INFO - iteration 9, current learner extra_tree\n",
      "[flaml.automl.logger: 12-16 19:00:46] {2392} INFO -  at 0.8s,\testimator extra_tree's best error=92013.9239,\tbest estimator xgboost's best error=25693.0614\n",
      "[flaml.automl.logger: 12-16 19:00:46] {2219} INFO - iteration 10, current learner xgboost\n",
      "[flaml.automl.logger: 12-16 19:00:46] {2392} INFO -  at 0.8s,\testimator xgboost's best error=25693.0614,\tbest estimator xgboost's best error=25693.0614\n",
      "[flaml.automl.logger: 12-16 19:00:46] {2219} INFO - iteration 11, current learner xgboost\n",
      "[flaml.automl.logger: 12-16 19:00:46] {2392} INFO -  at 1.0s,\testimator xgboost's best error=24803.0049,\tbest estimator xgboost's best error=24803.0049\n",
      "[flaml.automl.logger: 12-16 19:00:46] {2219} INFO - iteration 12, current learner extra_tree\n",
      "[flaml.automl.logger: 12-16 19:00:46] {2392} INFO -  at 1.1s,\testimator extra_tree's best error=90094.9081,\tbest estimator xgboost's best error=24803.0049\n",
      "[flaml.automl.logger: 12-16 19:00:46] {2219} INFO - iteration 13, current learner xgboost\n",
      "[flaml.automl.logger: 12-16 19:00:47] {2392} INFO -  at 1.6s,\testimator xgboost's best error=24803.0049,\tbest estimator xgboost's best error=24803.0049\n",
      "[flaml.automl.logger: 12-16 19:00:47] {2219} INFO - iteration 14, current learner xgboost\n",
      "[flaml.automl.logger: 12-16 19:00:47] {2392} INFO -  at 1.7s,\testimator xgboost's best error=21457.7270,\tbest estimator xgboost's best error=21457.7270\n",
      "[flaml.automl.logger: 12-16 19:00:47] {2219} INFO - iteration 15, current learner xgboost\n",
      "[flaml.automl.logger: 12-16 19:00:47] {2392} INFO -  at 1.8s,\testimator xgboost's best error=21457.7270,\tbest estimator xgboost's best error=21457.7270\n",
      "[flaml.automl.logger: 12-16 19:00:47] {2219} INFO - iteration 16, current learner xgboost\n",
      "[flaml.automl.logger: 12-16 19:00:47] {2392} INFO -  at 1.9s,\testimator xgboost's best error=21457.7270,\tbest estimator xgboost's best error=21457.7270\n",
      "[flaml.automl.logger: 12-16 19:00:47] {2219} INFO - iteration 17, current learner rf\n",
      "[flaml.automl.logger: 12-16 19:00:47] {2392} INFO -  at 2.0s,\testimator rf's best error=66947.6328,\tbest estimator xgboost's best error=21457.7270\n",
      "[flaml.automl.logger: 12-16 19:00:47] {2219} INFO - iteration 18, current learner xgboost\n",
      "[flaml.automl.logger: 12-16 19:00:47] {2392} INFO -  at 2.1s,\testimator xgboost's best error=21457.7270,\tbest estimator xgboost's best error=21457.7270\n",
      "[flaml.automl.logger: 12-16 19:00:47] {2219} INFO - iteration 19, current learner rf\n",
      "[flaml.automl.logger: 12-16 19:00:47] {2392} INFO -  at 2.2s,\testimator rf's best error=66947.6328,\tbest estimator xgboost's best error=21457.7270\n",
      "[flaml.automl.logger: 12-16 19:00:47] {2219} INFO - iteration 20, current learner xgboost\n",
      "[flaml.automl.logger: 12-16 19:00:47] {2392} INFO -  at 2.3s,\testimator xgboost's best error=21457.7270,\tbest estimator xgboost's best error=21457.7270\n",
      "[flaml.automl.logger: 12-16 19:00:47] {2219} INFO - iteration 21, current learner rf\n",
      "[flaml.automl.logger: 12-16 19:00:48] {2392} INFO -  at 2.5s,\testimator rf's best error=58497.7739,\tbest estimator xgboost's best error=21457.7270\n",
      "[flaml.automl.logger: 12-16 19:00:48] {2219} INFO - iteration 22, current learner xgboost\n",
      "[flaml.automl.logger: 12-16 19:00:48] {2392} INFO -  at 2.7s,\testimator xgboost's best error=18456.1351,\tbest estimator xgboost's best error=18456.1351\n",
      "[flaml.automl.logger: 12-16 19:00:48] {2219} INFO - iteration 23, current learner xgboost\n",
      "[flaml.automl.logger: 12-16 19:00:48] {2392} INFO -  at 2.8s,\testimator xgboost's best error=18456.1351,\tbest estimator xgboost's best error=18456.1351\n",
      "[flaml.automl.logger: 12-16 19:00:48] {2219} INFO - iteration 24, current learner extra_tree\n",
      "[flaml.automl.logger: 12-16 19:00:48] {2392} INFO -  at 2.9s,\testimator extra_tree's best error=73107.9041,\tbest estimator xgboost's best error=18456.1351\n",
      "[flaml.automl.logger: 12-16 19:00:48] {2219} INFO - iteration 25, current learner xgboost\n",
      "[flaml.automl.logger: 12-16 19:00:49] {2392} INFO -  at 3.4s,\testimator xgboost's best error=18456.1351,\tbest estimator xgboost's best error=18456.1351\n",
      "[flaml.automl.logger: 12-16 19:00:49] {2219} INFO - iteration 26, current learner extra_tree\n",
      "[flaml.automl.logger: 12-16 19:00:49] {2392} INFO -  at 3.5s,\testimator extra_tree's best error=73107.9041,\tbest estimator xgboost's best error=18456.1351\n",
      "[flaml.automl.logger: 12-16 19:00:49] {2219} INFO - iteration 27, current learner extra_tree\n",
      "[flaml.automl.logger: 12-16 19:00:49] {2392} INFO -  at 3.6s,\testimator extra_tree's best error=63748.0857,\tbest estimator xgboost's best error=18456.1351\n",
      "[flaml.automl.logger: 12-16 19:00:49] {2219} INFO - iteration 28, current learner extra_tree\n",
      "[flaml.automl.logger: 12-16 19:00:49] {2392} INFO -  at 3.8s,\testimator extra_tree's best error=47545.4938,\tbest estimator xgboost's best error=18456.1351\n",
      "[flaml.automl.logger: 12-16 19:00:49] {2219} INFO - iteration 29, current learner rf\n",
      "[flaml.automl.logger: 12-16 19:00:49] {2392} INFO -  at 3.9s,\testimator rf's best error=42435.7041,\tbest estimator xgboost's best error=18456.1351\n",
      "[flaml.automl.logger: 12-16 19:00:49] {2219} INFO - iteration 30, current learner rf\n",
      "[flaml.automl.logger: 12-16 19:00:49] {2392} INFO -  at 4.1s,\testimator rf's best error=42435.7041,\tbest estimator xgboost's best error=18456.1351\n",
      "[flaml.automl.logger: 12-16 19:00:49] {2219} INFO - iteration 31, current learner rf\n",
      "[flaml.automl.logger: 12-16 19:00:49] {2392} INFO -  at 4.2s,\testimator rf's best error=42435.7041,\tbest estimator xgboost's best error=18456.1351\n",
      "[flaml.automl.logger: 12-16 19:00:49] {2219} INFO - iteration 32, current learner extra_tree\n",
      "[flaml.automl.logger: 12-16 19:00:49] {2392} INFO -  at 4.3s,\testimator extra_tree's best error=47545.4938,\tbest estimator xgboost's best error=18456.1351\n",
      "[flaml.automl.logger: 12-16 19:00:49] {2219} INFO - iteration 33, current learner rf\n",
      "[flaml.automl.logger: 12-16 19:00:50] {2392} INFO -  at 4.5s,\testimator rf's best error=37617.6388,\tbest estimator xgboost's best error=18456.1351\n",
      "[flaml.automl.logger: 12-16 19:00:50] {2219} INFO - iteration 34, current learner xgboost\n",
      "[flaml.automl.logger: 12-16 19:00:50] {2392} INFO -  at 4.7s,\testimator xgboost's best error=18456.1351,\tbest estimator xgboost's best error=18456.1351\n",
      "[flaml.automl.logger: 12-16 19:00:50] {2219} INFO - iteration 35, current learner extra_tree\n",
      "[flaml.automl.logger: 12-16 19:00:50] {2392} INFO -  at 4.8s,\testimator extra_tree's best error=47545.4938,\tbest estimator xgboost's best error=18456.1351\n",
      "[flaml.automl.logger: 12-16 19:00:50] {2219} INFO - iteration 36, current learner xgboost\n",
      "[flaml.automl.logger: 12-16 19:00:50] {2392} INFO -  at 4.9s,\testimator xgboost's best error=18456.1351,\tbest estimator xgboost's best error=18456.1351\n",
      "[flaml.automl.logger: 12-16 19:00:50] {2219} INFO - iteration 37, current learner extra_tree\n",
      "[flaml.automl.logger: 12-16 19:00:50] {2392} INFO -  at 5.0s,\testimator extra_tree's best error=37628.6181,\tbest estimator xgboost's best error=18456.1351\n",
      "[flaml.automl.logger: 12-16 19:00:50] {2219} INFO - iteration 38, current learner xgboost\n",
      "[flaml.automl.logger: 12-16 19:00:51] {2392} INFO -  at 5.5s,\testimator xgboost's best error=18456.1351,\tbest estimator xgboost's best error=18456.1351\n",
      "[flaml.automl.logger: 12-16 19:00:51] {2219} INFO - iteration 39, current learner extra_tree\n",
      "[flaml.automl.logger: 12-16 19:00:51] {2392} INFO -  at 5.6s,\testimator extra_tree's best error=37628.6181,\tbest estimator xgboost's best error=18456.1351\n",
      "[flaml.automl.logger: 12-16 19:00:51] {2219} INFO - iteration 40, current learner extra_tree\n",
      "[flaml.automl.logger: 12-16 19:00:51] {2392} INFO -  at 5.8s,\testimator extra_tree's best error=31456.6978,\tbest estimator xgboost's best error=18456.1351\n",
      "[flaml.automl.logger: 12-16 19:00:51] {2219} INFO - iteration 41, current learner rf\n",
      "[flaml.automl.logger: 12-16 19:00:51] {2392} INFO -  at 6.0s,\testimator rf's best error=37617.6388,\tbest estimator xgboost's best error=18456.1351\n",
      "[flaml.automl.logger: 12-16 19:00:51] {2219} INFO - iteration 42, current learner extra_tree\n",
      "[flaml.automl.logger: 12-16 19:00:51] {2392} INFO -  at 6.1s,\testimator extra_tree's best error=28480.4064,\tbest estimator xgboost's best error=18456.1351\n",
      "[flaml.automl.logger: 12-16 19:00:51] {2219} INFO - iteration 43, current learner extra_tree\n",
      "[flaml.automl.logger: 12-16 19:00:51] {2392} INFO -  at 6.2s,\testimator extra_tree's best error=28480.4064,\tbest estimator xgboost's best error=18456.1351\n",
      "[flaml.automl.logger: 12-16 19:00:51] {2219} INFO - iteration 44, current learner extra_tree\n",
      "[flaml.automl.logger: 12-16 19:00:51] {2392} INFO -  at 6.3s,\testimator extra_tree's best error=28480.4064,\tbest estimator xgboost's best error=18456.1351\n",
      "[flaml.automl.logger: 12-16 19:00:51] {2219} INFO - iteration 45, current learner xgboost\n",
      "[flaml.automl.logger: 12-16 19:00:52] {2392} INFO -  at 6.5s,\testimator xgboost's best error=18456.1351,\tbest estimator xgboost's best error=18456.1351\n",
      "[flaml.automl.logger: 12-16 19:00:52] {2219} INFO - iteration 46, current learner extra_tree\n",
      "[flaml.automl.logger: 12-16 19:00:52] {2392} INFO -  at 6.6s,\testimator extra_tree's best error=28480.4064,\tbest estimator xgboost's best error=18456.1351\n",
      "[flaml.automl.logger: 12-16 19:00:52] {2219} INFO - iteration 47, current learner rf\n",
      "[flaml.automl.logger: 12-16 19:00:52] {2392} INFO -  at 6.8s,\testimator rf's best error=31225.9777,\tbest estimator xgboost's best error=18456.1351\n",
      "[flaml.automl.logger: 12-16 19:00:52] {2219} INFO - iteration 48, current learner xgboost\n",
      "[flaml.automl.logger: 12-16 19:00:52] {2392} INFO -  at 7.1s,\testimator xgboost's best error=18456.1351,\tbest estimator xgboost's best error=18456.1351\n",
      "[flaml.automl.logger: 12-16 19:00:52] {2219} INFO - iteration 49, current learner extra_tree\n",
      "[flaml.automl.logger: 12-16 19:00:52] {2392} INFO -  at 7.2s,\testimator extra_tree's best error=28029.3517,\tbest estimator xgboost's best error=18456.1351\n",
      "[flaml.automl.logger: 12-16 19:00:52] {2219} INFO - iteration 50, current learner rf\n",
      "[flaml.automl.logger: 12-16 19:00:53] {2392} INFO -  at 7.4s,\testimator rf's best error=30717.5746,\tbest estimator xgboost's best error=18456.1351\n",
      "[flaml.automl.logger: 12-16 19:00:53] {2219} INFO - iteration 51, current learner xgboost\n",
      "[flaml.automl.logger: 12-16 19:00:53] {2392} INFO -  at 8.1s,\testimator xgboost's best error=18456.1351,\tbest estimator xgboost's best error=18456.1351\n",
      "[flaml.automl.logger: 12-16 19:00:53] {2219} INFO - iteration 52, current learner rf\n",
      "[flaml.automl.logger: 12-16 19:00:53] {2392} INFO -  at 8.2s,\testimator rf's best error=30717.5746,\tbest estimator xgboost's best error=18456.1351\n",
      "[flaml.automl.logger: 12-16 19:00:53] {2219} INFO - iteration 53, current learner rf\n",
      "[flaml.automl.logger: 12-16 19:00:54] {2392} INFO -  at 8.4s,\testimator rf's best error=30717.5746,\tbest estimator xgboost's best error=18456.1351\n",
      "[flaml.automl.logger: 12-16 19:00:54] {2219} INFO - iteration 54, current learner xgboost\n",
      "[flaml.automl.logger: 12-16 19:00:54] {2392} INFO -  at 8.5s,\testimator xgboost's best error=18456.1351,\tbest estimator xgboost's best error=18456.1351\n",
      "[flaml.automl.logger: 12-16 19:00:54] {2219} INFO - iteration 55, current learner xgboost\n",
      "[flaml.automl.logger: 12-16 19:00:54] {2392} INFO -  at 9.1s,\testimator xgboost's best error=18456.1351,\tbest estimator xgboost's best error=18456.1351\n",
      "[flaml.automl.logger: 12-16 19:00:54] {2219} INFO - iteration 56, current learner xgboost\n",
      "[flaml.automl.logger: 12-16 19:00:54] {2392} INFO -  at 9.2s,\testimator xgboost's best error=18456.1351,\tbest estimator xgboost's best error=18456.1351\n",
      "[flaml.automl.logger: 12-16 19:00:54] {2219} INFO - iteration 57, current learner xgboost\n",
      "[flaml.automl.logger: 12-16 19:00:55] {2392} INFO -  at 9.6s,\testimator xgboost's best error=18456.1351,\tbest estimator xgboost's best error=18456.1351\n",
      "[flaml.automl.logger: 12-16 19:00:55] {2219} INFO - iteration 58, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 12-16 19:00:55] {2392} INFO -  at 9.6s,\testimator xgb_limitdepth's best error=23847.2155,\tbest estimator xgboost's best error=18456.1351\n",
      "[flaml.automl.logger: 12-16 19:00:55] {2219} INFO - iteration 59, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 12-16 19:00:55] {2392} INFO -  at 9.8s,\testimator xgb_limitdepth's best error=23847.2155,\tbest estimator xgboost's best error=18456.1351\n",
      "[flaml.automl.logger: 12-16 19:00:55] {2219} INFO - iteration 60, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 12-16 19:00:55] {2392} INFO -  at 9.8s,\testimator xgb_limitdepth's best error=23847.2155,\tbest estimator xgboost's best error=18456.1351\n",
      "[flaml.automl.logger: 12-16 19:00:55] {2219} INFO - iteration 61, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 12-16 19:00:55] {2392} INFO -  at 9.9s,\testimator xgb_limitdepth's best error=23847.2155,\tbest estimator xgboost's best error=18456.1351\n",
      "[flaml.automl.logger: 12-16 19:00:55] {2219} INFO - iteration 62, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 12-16 19:00:55] {2392} INFO -  at 10.0s,\testimator xgb_limitdepth's best error=21240.1029,\tbest estimator xgboost's best error=18456.1351\n",
      "[flaml.automl.logger: 12-16 19:00:55] {2219} INFO - iteration 63, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 12-16 19:00:55] {2392} INFO -  at 10.1s,\testimator xgb_limitdepth's best error=21240.1029,\tbest estimator xgboost's best error=18456.1351\n",
      "[flaml.automl.logger: 12-16 19:00:55] {2219} INFO - iteration 64, current learner xgboost\n",
      "[flaml.automl.logger: 12-16 19:00:55] {2392} INFO -  at 10.2s,\testimator xgboost's best error=18456.1351,\tbest estimator xgboost's best error=18456.1351\n",
      "[flaml.automl.logger: 12-16 19:00:55] {2219} INFO - iteration 65, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 12-16 19:00:55] {2392} INFO -  at 10.3s,\testimator xgb_limitdepth's best error=21240.1029,\tbest estimator xgboost's best error=18456.1351\n",
      "[flaml.automl.logger: 12-16 19:00:55] {2219} INFO - iteration 66, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 12-16 19:00:55] {2392} INFO -  at 10.4s,\testimator xgb_limitdepth's best error=21240.1029,\tbest estimator xgboost's best error=18456.1351\n",
      "[flaml.automl.logger: 12-16 19:00:55] {2219} INFO - iteration 67, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 12-16 19:00:56] {2392} INFO -  at 10.6s,\testimator xgb_limitdepth's best error=19516.6114,\tbest estimator xgboost's best error=18456.1351\n",
      "[flaml.automl.logger: 12-16 19:00:56] {2219} INFO - iteration 68, current learner xgboost\n",
      "[flaml.automl.logger: 12-16 19:00:56] {2392} INFO -  at 10.8s,\testimator xgboost's best error=18456.1351,\tbest estimator xgboost's best error=18456.1351\n",
      "[flaml.automl.logger: 12-16 19:00:56] {2219} INFO - iteration 69, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 12-16 19:00:57] {2392} INFO -  at 11.6s,\testimator xgb_limitdepth's best error=19516.6114,\tbest estimator xgboost's best error=18456.1351\n",
      "[flaml.automl.logger: 12-16 19:00:57] {2219} INFO - iteration 70, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 12-16 19:00:57] {2392} INFO -  at 11.8s,\testimator xgb_limitdepth's best error=19516.6114,\tbest estimator xgboost's best error=18456.1351\n",
      "[flaml.automl.logger: 12-16 19:00:57] {2219} INFO - iteration 71, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 12-16 19:00:57] {2392} INFO -  at 11.9s,\testimator xgb_limitdepth's best error=19516.6114,\tbest estimator xgboost's best error=18456.1351\n",
      "[flaml.automl.logger: 12-16 19:00:57] {2219} INFO - iteration 72, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 12-16 19:00:58] {2392} INFO -  at 12.7s,\testimator xgb_limitdepth's best error=19516.6114,\tbest estimator xgboost's best error=18456.1351\n",
      "[flaml.automl.logger: 12-16 19:00:58] {2219} INFO - iteration 73, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 12-16 19:00:58] {2392} INFO -  at 13.0s,\testimator xgb_limitdepth's best error=19516.6114,\tbest estimator xgboost's best error=18456.1351\n",
      "[flaml.automl.logger: 12-16 19:00:58] {2219} INFO - iteration 74, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 12-16 19:00:58] {2392} INFO -  at 13.2s,\testimator xgb_limitdepth's best error=19516.6114,\tbest estimator xgboost's best error=18456.1351\n",
      "[flaml.automl.logger: 12-16 19:00:58] {2219} INFO - iteration 75, current learner xgboost\n",
      "[flaml.automl.logger: 12-16 19:00:59] {2392} INFO -  at 13.6s,\testimator xgboost's best error=18456.1351,\tbest estimator xgboost's best error=18456.1351\n",
      "[flaml.automl.logger: 12-16 19:00:59] {2219} INFO - iteration 76, current learner xgboost\n",
      "[flaml.automl.logger: 12-16 19:01:01] {2392} INFO -  at 15.4s,\testimator xgboost's best error=18057.7387,\tbest estimator xgboost's best error=18057.7387\n",
      "[flaml.automl.logger: 12-16 19:01:01] {2219} INFO - iteration 77, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 12-16 19:01:01] {2392} INFO -  at 16.0s,\testimator xgb_limitdepth's best error=19516.6114,\tbest estimator xgboost's best error=18057.7387\n",
      "[flaml.automl.logger: 12-16 19:01:01] {2219} INFO - iteration 78, current learner xgboost\n",
      "[flaml.automl.logger: 12-16 19:01:01] {2392} INFO -  at 16.3s,\testimator xgboost's best error=18057.7387,\tbest estimator xgboost's best error=18057.7387\n",
      "[flaml.automl.logger: 12-16 19:01:01] {2219} INFO - iteration 79, current learner xgboost\n",
      "[flaml.automl.logger: 12-16 19:01:02] {2392} INFO -  at 16.6s,\testimator xgboost's best error=18057.7387,\tbest estimator xgboost's best error=18057.7387\n",
      "[flaml.automl.logger: 12-16 19:01:02] {2219} INFO - iteration 80, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 12-16 19:01:02] {2392} INFO -  at 16.9s,\testimator xgb_limitdepth's best error=19132.2328,\tbest estimator xgboost's best error=18057.7387\n",
      "[flaml.automl.logger: 12-16 19:01:02] {2219} INFO - iteration 81, current learner xgboost\n",
      "[flaml.automl.logger: 12-16 19:01:17] {2392} INFO -  at 31.9s,\testimator xgboost's best error=18057.7387,\tbest estimator xgboost's best error=18057.7387\n",
      "[flaml.automl.logger: 12-16 19:01:17] {2219} INFO - iteration 82, current learner extra_tree\n",
      "[flaml.automl.logger: 12-16 19:01:17] {2392} INFO -  at 32.0s,\testimator extra_tree's best error=28029.3517,\tbest estimator xgboost's best error=18057.7387\n",
      "[flaml.automl.logger: 12-16 19:01:17] {2219} INFO - iteration 83, current learner extra_tree\n",
      "[flaml.automl.logger: 12-16 19:01:17] {2392} INFO -  at 32.1s,\testimator extra_tree's best error=24680.1376,\tbest estimator xgboost's best error=18057.7387\n",
      "[flaml.automl.logger: 12-16 19:01:17] {2219} INFO - iteration 84, current learner extra_tree\n",
      "[flaml.automl.logger: 12-16 19:01:17] {2392} INFO -  at 32.2s,\testimator extra_tree's best error=24680.1376,\tbest estimator xgboost's best error=18057.7387\n",
      "[flaml.automl.logger: 12-16 19:01:17] {2219} INFO - iteration 85, current learner extra_tree\n",
      "[flaml.automl.logger: 12-16 19:01:17] {2392} INFO -  at 32.3s,\testimator extra_tree's best error=24680.1376,\tbest estimator xgboost's best error=18057.7387\n",
      "[flaml.automl.logger: 12-16 19:01:17] {2219} INFO - iteration 86, current learner extra_tree\n",
      "[flaml.automl.logger: 12-16 19:01:18] {2392} INFO -  at 32.5s,\testimator extra_tree's best error=23325.9945,\tbest estimator xgboost's best error=18057.7387\n",
      "[flaml.automl.logger: 12-16 19:01:18] {2219} INFO - iteration 87, current learner extra_tree\n",
      "[flaml.automl.logger: 12-16 19:01:18] {2392} INFO -  at 32.7s,\testimator extra_tree's best error=23325.9945,\tbest estimator xgboost's best error=18057.7387\n",
      "[flaml.automl.logger: 12-16 19:01:18] {2219} INFO - iteration 88, current learner xgboost\n",
      "[flaml.automl.logger: 12-16 19:01:18] {2392} INFO -  at 32.9s,\testimator xgboost's best error=18057.7387,\tbest estimator xgboost's best error=18057.7387\n",
      "[flaml.automl.logger: 12-16 19:01:18] {2219} INFO - iteration 89, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 12-16 19:01:18] {2392} INFO -  at 33.2s,\testimator xgb_limitdepth's best error=19132.2328,\tbest estimator xgboost's best error=18057.7387\n",
      "[flaml.automl.logger: 12-16 19:01:18] {2219} INFO - iteration 90, current learner extra_tree\n",
      "[flaml.automl.logger: 12-16 19:01:19] {2392} INFO -  at 33.4s,\testimator extra_tree's best error=23289.5892,\tbest estimator xgboost's best error=18057.7387\n",
      "[flaml.automl.logger: 12-16 19:01:19] {2219} INFO - iteration 91, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 12-16 19:01:19] {2392} INFO -  at 33.6s,\testimator xgb_limitdepth's best error=17310.0425,\tbest estimator xgb_limitdepth's best error=17310.0425\n",
      "[flaml.automl.logger: 12-16 19:01:19] {2219} INFO - iteration 92, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 12-16 19:01:19] {2392} INFO -  at 33.7s,\testimator xgb_limitdepth's best error=17310.0425,\tbest estimator xgb_limitdepth's best error=17310.0425\n",
      "[flaml.automl.logger: 12-16 19:01:19] {2219} INFO - iteration 93, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 12-16 19:01:19] {2392} INFO -  at 34.1s,\testimator xgb_limitdepth's best error=17310.0425,\tbest estimator xgb_limitdepth's best error=17310.0425\n",
      "[flaml.automl.logger: 12-16 19:01:19] {2219} INFO - iteration 94, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 12-16 19:01:19] {2392} INFO -  at 34.2s,\testimator xgb_limitdepth's best error=17310.0425,\tbest estimator xgb_limitdepth's best error=17310.0425\n",
      "[flaml.automl.logger: 12-16 19:01:19] {2219} INFO - iteration 95, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 12-16 19:01:20] {2392} INFO -  at 34.5s,\testimator xgb_limitdepth's best error=17310.0425,\tbest estimator xgb_limitdepth's best error=17310.0425\n",
      "[flaml.automl.logger: 12-16 19:01:20] {2219} INFO - iteration 96, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 12-16 19:01:20] {2392} INFO -  at 34.7s,\testimator xgb_limitdepth's best error=17310.0425,\tbest estimator xgb_limitdepth's best error=17310.0425\n",
      "[flaml.automl.logger: 12-16 19:01:20] {2219} INFO - iteration 97, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 12-16 19:01:20] {2392} INFO -  at 34.8s,\testimator xgb_limitdepth's best error=17310.0425,\tbest estimator xgb_limitdepth's best error=17310.0425\n",
      "[flaml.automl.logger: 12-16 19:01:20] {2219} INFO - iteration 98, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 12-16 19:01:20] {2392} INFO -  at 35.2s,\testimator xgb_limitdepth's best error=17310.0425,\tbest estimator xgb_limitdepth's best error=17310.0425\n",
      "[flaml.automl.logger: 12-16 19:01:20] {2219} INFO - iteration 99, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 12-16 19:01:20] {2392} INFO -  at 35.3s,\testimator xgb_limitdepth's best error=17310.0425,\tbest estimator xgb_limitdepth's best error=17310.0425\n",
      "[flaml.automl.logger: 12-16 19:01:20] {2219} INFO - iteration 100, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 12-16 19:01:21] {2392} INFO -  at 35.6s,\testimator xgb_limitdepth's best error=17310.0425,\tbest estimator xgb_limitdepth's best error=17310.0425\n",
      "[flaml.automl.logger: 12-16 19:01:21] {2219} INFO - iteration 101, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 12-16 19:01:21] {2392} INFO -  at 35.7s,\testimator xgb_limitdepth's best error=17310.0425,\tbest estimator xgb_limitdepth's best error=17310.0425\n",
      "[flaml.automl.logger: 12-16 19:01:21] {2219} INFO - iteration 102, current learner rf\n",
      "[flaml.automl.logger: 12-16 19:01:21] {2392} INFO -  at 35.9s,\testimator rf's best error=30717.5746,\tbest estimator xgb_limitdepth's best error=17310.0425\n",
      "[flaml.automl.logger: 12-16 19:01:21] {2219} INFO - iteration 103, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 12-16 19:01:21] {2392} INFO -  at 36.0s,\testimator xgb_limitdepth's best error=17310.0425,\tbest estimator xgb_limitdepth's best error=17310.0425\n",
      "[flaml.automl.logger: 12-16 19:01:21] {2219} INFO - iteration 104, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 12-16 19:01:21] {2392} INFO -  at 36.2s,\testimator xgb_limitdepth's best error=17310.0425,\tbest estimator xgb_limitdepth's best error=17310.0425\n",
      "[flaml.automl.logger: 12-16 19:01:21] {2219} INFO - iteration 105, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 12-16 19:01:22] {2392} INFO -  at 36.8s,\testimator xgb_limitdepth's best error=16866.3720,\tbest estimator xgb_limitdepth's best error=16866.3720\n",
      "[flaml.automl.logger: 12-16 19:01:22] {2219} INFO - iteration 106, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 12-16 19:01:22] {2392} INFO -  at 36.9s,\testimator xgb_limitdepth's best error=16866.3720,\tbest estimator xgb_limitdepth's best error=16866.3720\n",
      "[flaml.automl.logger: 12-16 19:01:22] {2219} INFO - iteration 107, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 12-16 19:01:22] {2392} INFO -  at 37.0s,\testimator xgb_limitdepth's best error=16866.3720,\tbest estimator xgb_limitdepth's best error=16866.3720\n",
      "[flaml.automl.logger: 12-16 19:01:22] {2219} INFO - iteration 108, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 12-16 19:01:26] {2392} INFO -  at 40.9s,\testimator xgb_limitdepth's best error=16866.3720,\tbest estimator xgb_limitdepth's best error=16866.3720\n",
      "[flaml.automl.logger: 12-16 19:01:26] {2219} INFO - iteration 109, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 12-16 19:01:26] {2392} INFO -  at 41.1s,\testimator xgb_limitdepth's best error=16866.3720,\tbest estimator xgb_limitdepth's best error=16866.3720\n",
      "[flaml.automl.logger: 12-16 19:01:26] {2219} INFO - iteration 110, current learner rf\n",
      "[flaml.automl.logger: 12-16 19:01:26] {2392} INFO -  at 41.3s,\testimator rf's best error=30042.8867,\tbest estimator xgb_limitdepth's best error=16866.3720\n",
      "[flaml.automl.logger: 12-16 19:01:26] {2219} INFO - iteration 111, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 12-16 19:01:30] {2392} INFO -  at 45.1s,\testimator xgb_limitdepth's best error=16866.3720,\tbest estimator xgb_limitdepth's best error=16866.3720\n",
      "[flaml.automl.logger: 12-16 19:01:30] {2219} INFO - iteration 112, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 12-16 19:01:31] {2392} INFO -  at 45.7s,\testimator xgb_limitdepth's best error=16866.3720,\tbest estimator xgb_limitdepth's best error=16866.3720\n",
      "[flaml.automl.logger: 12-16 19:01:31] {2219} INFO - iteration 113, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 12-16 19:01:32] {2392} INFO -  at 46.5s,\testimator xgb_limitdepth's best error=16866.3720,\tbest estimator xgb_limitdepth's best error=16866.3720\n",
      "[flaml.automl.logger: 12-16 19:01:32] {2219} INFO - iteration 114, current learner rf\n",
      "[flaml.automl.logger: 12-16 19:01:32] {2392} INFO -  at 46.7s,\testimator rf's best error=30042.8867,\tbest estimator xgb_limitdepth's best error=16866.3720\n",
      "[flaml.automl.logger: 12-16 19:01:32] {2219} INFO - iteration 115, current learner rf\n",
      "[flaml.automl.logger: 12-16 19:01:32] {2392} INFO -  at 47.0s,\testimator rf's best error=26486.2613,\tbest estimator xgb_limitdepth's best error=16866.3720\n",
      "[flaml.automl.logger: 12-16 19:01:32] {2219} INFO - iteration 116, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 12-16 19:01:34] {2392} INFO -  at 48.6s,\testimator xgb_limitdepth's best error=16847.9112,\tbest estimator xgb_limitdepth's best error=16847.9112\n",
      "[flaml.automl.logger: 12-16 19:01:34] {2219} INFO - iteration 117, current learner rf\n",
      "[flaml.automl.logger: 12-16 19:01:34] {2392} INFO -  at 48.8s,\testimator rf's best error=26486.2613,\tbest estimator xgb_limitdepth's best error=16847.9112\n",
      "[flaml.automl.logger: 12-16 19:01:34] {2219} INFO - iteration 118, current learner rf\n",
      "[flaml.automl.logger: 12-16 19:01:34] {2392} INFO -  at 49.0s,\testimator rf's best error=26486.2613,\tbest estimator xgb_limitdepth's best error=16847.9112\n",
      "[flaml.automl.logger: 12-16 19:01:34] {2219} INFO - iteration 119, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 12-16 19:01:35] {2392} INFO -  at 49.6s,\testimator xgb_limitdepth's best error=16847.9112,\tbest estimator xgb_limitdepth's best error=16847.9112\n",
      "[flaml.automl.logger: 12-16 19:01:35] {2219} INFO - iteration 120, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 12-16 19:01:35] {2392} INFO -  at 50.2s,\testimator xgb_limitdepth's best error=16847.9112,\tbest estimator xgb_limitdepth's best error=16847.9112\n",
      "[flaml.automl.logger: 12-16 19:01:35] {2219} INFO - iteration 121, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 12-16 19:01:39] {2392} INFO -  at 53.9s,\testimator xgb_limitdepth's best error=16242.2322,\tbest estimator xgb_limitdepth's best error=16242.2322\n",
      "[flaml.automl.logger: 12-16 19:01:39] {2219} INFO - iteration 122, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 12-16 19:01:40] {2392} INFO -  at 55.2s,\testimator xgb_limitdepth's best error=15772.0599,\tbest estimator xgb_limitdepth's best error=15772.0599\n",
      "[flaml.automl.logger: 12-16 19:01:40] {2219} INFO - iteration 123, current learner rf\n",
      "[flaml.automl.logger: 12-16 19:01:41] {2392} INFO -  at 55.5s,\testimator rf's best error=24608.9550,\tbest estimator xgb_limitdepth's best error=15772.0599\n",
      "[flaml.automl.logger: 12-16 19:01:41] {2219} INFO - iteration 124, current learner rf\n",
      "[flaml.automl.logger: 12-16 19:01:41] {2392} INFO -  at 55.8s,\testimator rf's best error=24608.9550,\tbest estimator xgb_limitdepth's best error=15772.0599\n",
      "[flaml.automl.logger: 12-16 19:01:41] {2219} INFO - iteration 125, current learner rf\n",
      "[flaml.automl.logger: 12-16 19:01:41] {2392} INFO -  at 56.2s,\testimator rf's best error=23662.8664,\tbest estimator xgb_limitdepth's best error=15772.0599\n",
      "[flaml.automl.logger: 12-16 19:01:41] {2219} INFO - iteration 126, current learner rf\n",
      "[flaml.automl.logger: 12-16 19:01:42] {2392} INFO -  at 56.5s,\testimator rf's best error=23662.8664,\tbest estimator xgb_limitdepth's best error=15772.0599\n",
      "[flaml.automl.logger: 12-16 19:01:42] {2219} INFO - iteration 127, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 12-16 19:01:45] {2392} INFO -  at 60.0s,\testimator xgb_limitdepth's best error=15772.0599,\tbest estimator xgb_limitdepth's best error=15772.0599\n",
      "[flaml.automl.logger: 12-16 19:01:46] {2628} INFO - retrain xgb_limitdepth for 0.4s\n",
      "[flaml.automl.logger: 12-16 19:01:46] {2631} INFO - retrained model: XGBRegressor(base_score=None, booster=None, callbacks=[],\n",
      "             colsample_bylevel=0.9616423910817776, colsample_bynode=None,\n",
      "             colsample_bytree=0.995779245125877, device=None,\n",
      "             early_stopping_rounds=None, enable_categorical=False,\n",
      "             eval_metric=None, feature_types=None, gamma=None, grow_policy=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=0.018673966612306605, max_bin=None,\n",
      "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "             max_delta_step=None, max_depth=4, max_leaves=None,\n",
      "             min_child_weight=2.268841930034181, missing=nan,\n",
      "             monotone_constraints=None, multi_strategy=None, n_estimators=909,\n",
      "             n_jobs=-1, num_parallel_tree=None, random_state=None, ...)\n",
      "[flaml.automl.logger: 12-16 19:01:46] {1931} INFO - fit succeeded\n",
      "[flaml.automl.logger: 12-16 19:01:46] {1932} INFO - Time taken to find the best model: 55.19517183303833\n",
      "[flaml.automl.logger: 12-16 19:01:46] {1680} INFO - task = regression\n",
      "[flaml.automl.logger: 12-16 19:01:46] {1691} INFO - Evaluation method: cv\n",
      "[flaml.automl.logger: 12-16 19:01:46] {1789} INFO - Minimizing error metric: mse\n",
      "[flaml.automl.logger: 12-16 19:01:46] {1901} INFO - List of ML learners in AutoML Run: ['rf', 'xgboost', 'extra_tree', 'xgb_limitdepth']\n",
      "[flaml.automl.logger: 12-16 19:01:46] {2219} INFO - iteration 0, current learner rf\n",
      "[flaml.automl.logger: 12-16 19:01:46] {2345} INFO - Estimated sufficient time budget=1026s. Estimated necessary time budget=4s.\n",
      "[flaml.automl.logger: 12-16 19:01:46] {2392} INFO -  at 0.1s,\testimator rf's best error=89051.6247,\tbest estimator rf's best error=89051.6247\n",
      "[flaml.automl.logger: 12-16 19:01:46] {2219} INFO - iteration 1, current learner xgboost\n",
      "[flaml.automl.logger: 12-16 19:01:46] {2392} INFO -  at 0.1s,\testimator xgboost's best error=130380.7344,\tbest estimator rf's best error=89051.6247\n",
      "[flaml.automl.logger: 12-16 19:01:46] {2219} INFO - iteration 2, current learner xgboost\n",
      "[flaml.automl.logger: 12-16 19:01:46] {2392} INFO -  at 0.2s,\testimator xgboost's best error=130380.7344,\tbest estimator rf's best error=89051.6247\n",
      "[flaml.automl.logger: 12-16 19:01:46] {2219} INFO - iteration 3, current learner xgboost\n",
      "[flaml.automl.logger: 12-16 19:01:46] {2392} INFO -  at 0.2s,\testimator xgboost's best error=48569.2787,\tbest estimator xgboost's best error=48569.2787\n",
      "[flaml.automl.logger: 12-16 19:01:46] {2219} INFO - iteration 4, current learner rf\n",
      "[flaml.automl.logger: 12-16 19:01:46] {2392} INFO -  at 0.4s,\testimator rf's best error=83456.1080,\tbest estimator xgboost's best error=48569.2787\n",
      "[flaml.automl.logger: 12-16 19:01:46] {2219} INFO - iteration 5, current learner xgboost\n",
      "[flaml.automl.logger: 12-16 19:01:46] {2392} INFO -  at 0.4s,\testimator xgboost's best error=48569.2787,\tbest estimator xgboost's best error=48569.2787\n",
      "[flaml.automl.logger: 12-16 19:01:46] {2219} INFO - iteration 6, current learner xgboost\n",
      "[flaml.automl.logger: 12-16 19:01:46] {2392} INFO -  at 0.4s,\testimator xgboost's best error=29700.2070,\tbest estimator xgboost's best error=29700.2070\n",
      "[flaml.automl.logger: 12-16 19:01:46] {2219} INFO - iteration 7, current learner xgboost\n",
      "[flaml.automl.logger: 12-16 19:01:46] {2392} INFO -  at 0.5s,\testimator xgboost's best error=29700.2070,\tbest estimator xgboost's best error=29700.2070\n",
      "[flaml.automl.logger: 12-16 19:01:46] {2219} INFO - iteration 8, current learner xgboost\n",
      "[flaml.automl.logger: 12-16 19:01:46] {2392} INFO -  at 0.5s,\testimator xgboost's best error=25693.0614,\tbest estimator xgboost's best error=25693.0614\n",
      "[flaml.automl.logger: 12-16 19:01:46] {2219} INFO - iteration 9, current learner xgboost\n",
      "[flaml.automl.logger: 12-16 19:01:46] {2392} INFO -  at 0.5s,\testimator xgboost's best error=25693.0614,\tbest estimator xgboost's best error=25693.0614\n",
      "[flaml.automl.logger: 12-16 19:01:46] {2219} INFO - iteration 10, current learner xgboost\n",
      "[flaml.automl.logger: 12-16 19:01:46] {2392} INFO -  at 0.7s,\testimator xgboost's best error=24803.0049,\tbest estimator xgboost's best error=24803.0049\n",
      "[flaml.automl.logger: 12-16 19:01:46] {2219} INFO - iteration 11, current learner extra_tree\n",
      "[flaml.automl.logger: 12-16 19:01:46] {2392} INFO -  at 0.8s,\testimator extra_tree's best error=92013.9239,\tbest estimator xgboost's best error=24803.0049\n",
      "[flaml.automl.logger: 12-16 19:01:46] {2219} INFO - iteration 12, current learner extra_tree\n",
      "[flaml.automl.logger: 12-16 19:01:46] {2392} INFO -  at 0.9s,\testimator extra_tree's best error=90094.9081,\tbest estimator xgboost's best error=24803.0049\n",
      "[flaml.automl.logger: 12-16 19:01:46] {2219} INFO - iteration 13, current learner xgboost\n",
      "[flaml.automl.logger: 12-16 19:01:47] {2392} INFO -  at 1.4s,\testimator xgboost's best error=24803.0049,\tbest estimator xgboost's best error=24803.0049\n",
      "[flaml.automl.logger: 12-16 19:01:47] {2219} INFO - iteration 14, current learner xgboost\n",
      "[flaml.automl.logger: 12-16 19:01:47] {2392} INFO -  at 1.5s,\testimator xgboost's best error=21457.7270,\tbest estimator xgboost's best error=21457.7270\n",
      "[flaml.automl.logger: 12-16 19:01:47] {2219} INFO - iteration 15, current learner xgboost\n",
      "[flaml.automl.logger: 12-16 19:01:47] {2392} INFO -  at 1.5s,\testimator xgboost's best error=21457.7270,\tbest estimator xgboost's best error=21457.7270\n",
      "[flaml.automl.logger: 12-16 19:01:47] {2219} INFO - iteration 16, current learner xgboost\n",
      "[flaml.automl.logger: 12-16 19:01:47] {2392} INFO -  at 1.6s,\testimator xgboost's best error=21457.7270,\tbest estimator xgboost's best error=21457.7270\n",
      "[flaml.automl.logger: 12-16 19:01:47] {2219} INFO - iteration 17, current learner rf\n",
      "[flaml.automl.logger: 12-16 19:01:47] {2392} INFO -  at 1.7s,\testimator rf's best error=66947.6328,\tbest estimator xgboost's best error=21457.7270\n",
      "[flaml.automl.logger: 12-16 19:01:47] {2219} INFO - iteration 18, current learner xgboost\n",
      "[flaml.automl.logger: 12-16 19:01:47] {2392} INFO -  at 1.9s,\testimator xgboost's best error=21457.7270,\tbest estimator xgboost's best error=21457.7270\n",
      "[flaml.automl.logger: 12-16 19:01:47] {2219} INFO - iteration 19, current learner rf\n",
      "[flaml.automl.logger: 12-16 19:01:47] {2392} INFO -  at 2.0s,\testimator rf's best error=66947.6328,\tbest estimator xgboost's best error=21457.7270\n",
      "[flaml.automl.logger: 12-16 19:01:47] {2219} INFO - iteration 20, current learner xgboost\n",
      "[flaml.automl.logger: 12-16 19:01:48] {2392} INFO -  at 2.0s,\testimator xgboost's best error=21457.7270,\tbest estimator xgboost's best error=21457.7270\n",
      "[flaml.automl.logger: 12-16 19:01:48] {2219} INFO - iteration 21, current learner rf\n",
      "[flaml.automl.logger: 12-16 19:01:48] {2392} INFO -  at 2.2s,\testimator rf's best error=58497.7739,\tbest estimator xgboost's best error=21457.7270\n",
      "[flaml.automl.logger: 12-16 19:01:48] {2219} INFO - iteration 22, current learner xgboost\n",
      "[flaml.automl.logger: 12-16 19:01:48] {2392} INFO -  at 2.5s,\testimator xgboost's best error=18456.1351,\tbest estimator xgboost's best error=18456.1351\n",
      "[flaml.automl.logger: 12-16 19:01:48] {2219} INFO - iteration 23, current learner xgboost\n",
      "[flaml.automl.logger: 12-16 19:01:48] {2392} INFO -  at 2.6s,\testimator xgboost's best error=18456.1351,\tbest estimator xgboost's best error=18456.1351\n",
      "[flaml.automl.logger: 12-16 19:01:48] {2219} INFO - iteration 24, current learner extra_tree\n",
      "[flaml.automl.logger: 12-16 19:01:48] {2392} INFO -  at 2.7s,\testimator extra_tree's best error=73107.9041,\tbest estimator xgboost's best error=18456.1351\n",
      "[flaml.automl.logger: 12-16 19:01:48] {2219} INFO - iteration 25, current learner xgboost\n",
      "[flaml.automl.logger: 12-16 19:01:49] {2392} INFO -  at 3.1s,\testimator xgboost's best error=18456.1351,\tbest estimator xgboost's best error=18456.1351\n",
      "[flaml.automl.logger: 12-16 19:01:49] {2219} INFO - iteration 26, current learner extra_tree\n",
      "[flaml.automl.logger: 12-16 19:01:49] {2392} INFO -  at 3.2s,\testimator extra_tree's best error=73107.9041,\tbest estimator xgboost's best error=18456.1351\n",
      "[flaml.automl.logger: 12-16 19:01:49] {2219} INFO - iteration 27, current learner extra_tree\n",
      "[flaml.automl.logger: 12-16 19:01:49] {2392} INFO -  at 3.3s,\testimator extra_tree's best error=63748.0857,\tbest estimator xgboost's best error=18456.1351\n",
      "[flaml.automl.logger: 12-16 19:01:49] {2219} INFO - iteration 28, current learner extra_tree\n",
      "[flaml.automl.logger: 12-16 19:01:49] {2392} INFO -  at 3.5s,\testimator extra_tree's best error=47545.4938,\tbest estimator xgboost's best error=18456.1351\n",
      "[flaml.automl.logger: 12-16 19:01:49] {2219} INFO - iteration 29, current learner rf\n",
      "[flaml.automl.logger: 12-16 19:01:49] {2392} INFO -  at 3.6s,\testimator rf's best error=42435.7041,\tbest estimator xgboost's best error=18456.1351\n",
      "[flaml.automl.logger: 12-16 19:01:49] {2219} INFO - iteration 30, current learner rf\n",
      "[flaml.automl.logger: 12-16 19:01:49] {2392} INFO -  at 3.8s,\testimator rf's best error=42435.7041,\tbest estimator xgboost's best error=18456.1351\n",
      "[flaml.automl.logger: 12-16 19:01:49] {2219} INFO - iteration 31, current learner rf\n",
      "[flaml.automl.logger: 12-16 19:01:49] {2392} INFO -  at 3.9s,\testimator rf's best error=42435.7041,\tbest estimator xgboost's best error=18456.1351\n",
      "[flaml.automl.logger: 12-16 19:01:49] {2219} INFO - iteration 32, current learner extra_tree\n",
      "[flaml.automl.logger: 12-16 19:01:50] {2392} INFO -  at 4.0s,\testimator extra_tree's best error=47545.4938,\tbest estimator xgboost's best error=18456.1351\n",
      "[flaml.automl.logger: 12-16 19:01:50] {2219} INFO - iteration 33, current learner rf\n",
      "[flaml.automl.logger: 12-16 19:01:50] {2392} INFO -  at 4.2s,\testimator rf's best error=37617.6388,\tbest estimator xgboost's best error=18456.1351\n",
      "[flaml.automl.logger: 12-16 19:01:50] {2219} INFO - iteration 34, current learner xgboost\n",
      "[flaml.automl.logger: 12-16 19:01:50] {2392} INFO -  at 4.3s,\testimator xgboost's best error=18456.1351,\tbest estimator xgboost's best error=18456.1351\n",
      "[flaml.automl.logger: 12-16 19:01:50] {2219} INFO - iteration 35, current learner extra_tree\n",
      "[flaml.automl.logger: 12-16 19:01:50] {2392} INFO -  at 4.4s,\testimator extra_tree's best error=47545.4938,\tbest estimator xgboost's best error=18456.1351\n",
      "[flaml.automl.logger: 12-16 19:01:50] {2219} INFO - iteration 36, current learner xgboost\n",
      "[flaml.automl.logger: 12-16 19:01:50] {2392} INFO -  at 4.5s,\testimator xgboost's best error=18456.1351,\tbest estimator xgboost's best error=18456.1351\n",
      "[flaml.automl.logger: 12-16 19:01:50] {2219} INFO - iteration 37, current learner extra_tree\n",
      "[flaml.automl.logger: 12-16 19:01:50] {2392} INFO -  at 4.7s,\testimator extra_tree's best error=37628.6181,\tbest estimator xgboost's best error=18456.1351\n",
      "[flaml.automl.logger: 12-16 19:01:50] {2219} INFO - iteration 38, current learner xgboost\n",
      "[flaml.automl.logger: 12-16 19:01:51] {2392} INFO -  at 5.2s,\testimator xgboost's best error=18456.1351,\tbest estimator xgboost's best error=18456.1351\n",
      "[flaml.automl.logger: 12-16 19:01:51] {2219} INFO - iteration 39, current learner extra_tree\n",
      "[flaml.automl.logger: 12-16 19:01:51] {2392} INFO -  at 5.3s,\testimator extra_tree's best error=37628.6181,\tbest estimator xgboost's best error=18456.1351\n",
      "[flaml.automl.logger: 12-16 19:01:51] {2219} INFO - iteration 40, current learner extra_tree\n",
      "[flaml.automl.logger: 12-16 19:01:51] {2392} INFO -  at 5.4s,\testimator extra_tree's best error=31456.6978,\tbest estimator xgboost's best error=18456.1351\n",
      "[flaml.automl.logger: 12-16 19:01:51] {2219} INFO - iteration 41, current learner rf\n",
      "[flaml.automl.logger: 12-16 19:01:51] {2392} INFO -  at 5.7s,\testimator rf's best error=37617.6388,\tbest estimator xgboost's best error=18456.1351\n",
      "[flaml.automl.logger: 12-16 19:01:51] {2219} INFO - iteration 42, current learner extra_tree\n",
      "[flaml.automl.logger: 12-16 19:01:51] {2392} INFO -  at 5.8s,\testimator extra_tree's best error=28480.4064,\tbest estimator xgboost's best error=18456.1351\n",
      "[flaml.automl.logger: 12-16 19:01:51] {2219} INFO - iteration 43, current learner extra_tree\n",
      "[flaml.automl.logger: 12-16 19:01:51] {2392} INFO -  at 5.9s,\testimator extra_tree's best error=28480.4064,\tbest estimator xgboost's best error=18456.1351\n",
      "[flaml.automl.logger: 12-16 19:01:51] {2219} INFO - iteration 44, current learner extra_tree\n",
      "[flaml.automl.logger: 12-16 19:01:52] {2392} INFO -  at 6.0s,\testimator extra_tree's best error=28480.4064,\tbest estimator xgboost's best error=18456.1351\n",
      "[flaml.automl.logger: 12-16 19:01:52] {2219} INFO - iteration 45, current learner xgboost\n",
      "[flaml.automl.logger: 12-16 19:01:52] {2392} INFO -  at 6.2s,\testimator xgboost's best error=18456.1351,\tbest estimator xgboost's best error=18456.1351\n",
      "[flaml.automl.logger: 12-16 19:01:52] {2219} INFO - iteration 46, current learner extra_tree\n",
      "[flaml.automl.logger: 12-16 19:01:52] {2392} INFO -  at 6.3s,\testimator extra_tree's best error=28480.4064,\tbest estimator xgboost's best error=18456.1351\n",
      "[flaml.automl.logger: 12-16 19:01:52] {2219} INFO - iteration 47, current learner rf\n",
      "[flaml.automl.logger: 12-16 19:01:52] {2392} INFO -  at 6.4s,\testimator rf's best error=31225.9777,\tbest estimator xgboost's best error=18456.1351\n",
      "[flaml.automl.logger: 12-16 19:01:52] {2219} INFO - iteration 48, current learner xgboost\n",
      "[flaml.automl.logger: 12-16 19:01:52] {2392} INFO -  at 6.8s,\testimator xgboost's best error=18456.1351,\tbest estimator xgboost's best error=18456.1351\n",
      "[flaml.automl.logger: 12-16 19:01:52] {2219} INFO - iteration 49, current learner extra_tree\n",
      "[flaml.automl.logger: 12-16 19:01:52] {2392} INFO -  at 6.9s,\testimator extra_tree's best error=28029.3517,\tbest estimator xgboost's best error=18456.1351\n",
      "[flaml.automl.logger: 12-16 19:01:52] {2219} INFO - iteration 50, current learner rf\n",
      "[flaml.automl.logger: 12-16 19:01:53] {2392} INFO -  at 7.0s,\testimator rf's best error=30717.5746,\tbest estimator xgboost's best error=18456.1351\n",
      "[flaml.automl.logger: 12-16 19:01:53] {2219} INFO - iteration 51, current learner xgboost\n",
      "[flaml.automl.logger: 12-16 19:01:53] {2392} INFO -  at 7.7s,\testimator xgboost's best error=18456.1351,\tbest estimator xgboost's best error=18456.1351\n",
      "[flaml.automl.logger: 12-16 19:01:53] {2219} INFO - iteration 52, current learner rf\n",
      "[flaml.automl.logger: 12-16 19:01:53] {2392} INFO -  at 7.9s,\testimator rf's best error=30717.5746,\tbest estimator xgboost's best error=18456.1351\n",
      "[flaml.automl.logger: 12-16 19:01:53] {2219} INFO - iteration 53, current learner rf\n",
      "[flaml.automl.logger: 12-16 19:01:54] {2392} INFO -  at 8.0s,\testimator rf's best error=30717.5746,\tbest estimator xgboost's best error=18456.1351\n",
      "[flaml.automl.logger: 12-16 19:01:54] {2219} INFO - iteration 54, current learner xgboost\n",
      "[flaml.automl.logger: 12-16 19:01:54] {2392} INFO -  at 8.1s,\testimator xgboost's best error=18456.1351,\tbest estimator xgboost's best error=18456.1351\n",
      "[flaml.automl.logger: 12-16 19:01:54] {2219} INFO - iteration 55, current learner xgboost\n",
      "[flaml.automl.logger: 12-16 19:01:54] {2392} INFO -  at 8.7s,\testimator xgboost's best error=18456.1351,\tbest estimator xgboost's best error=18456.1351\n",
      "[flaml.automl.logger: 12-16 19:01:54] {2219} INFO - iteration 56, current learner xgboost\n",
      "[flaml.automl.logger: 12-16 19:01:54] {2392} INFO -  at 8.7s,\testimator xgboost's best error=18456.1351,\tbest estimator xgboost's best error=18456.1351\n",
      "[flaml.automl.logger: 12-16 19:01:54] {2219} INFO - iteration 57, current learner xgboost\n",
      "[flaml.automl.logger: 12-16 19:01:55] {2392} INFO -  at 9.0s,\testimator xgboost's best error=18456.1351,\tbest estimator xgboost's best error=18456.1351\n",
      "[flaml.automl.logger: 12-16 19:01:55] {2219} INFO - iteration 58, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 12-16 19:01:55] {2392} INFO -  at 9.0s,\testimator xgb_limitdepth's best error=23847.2155,\tbest estimator xgboost's best error=18456.1351\n",
      "[flaml.automl.logger: 12-16 19:01:55] {2219} INFO - iteration 59, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 12-16 19:01:55] {2392} INFO -  at 9.2s,\testimator xgb_limitdepth's best error=23847.2155,\tbest estimator xgboost's best error=18456.1351\n",
      "[flaml.automl.logger: 12-16 19:01:55] {2219} INFO - iteration 60, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 12-16 19:01:55] {2392} INFO -  at 9.2s,\testimator xgb_limitdepth's best error=23847.2155,\tbest estimator xgboost's best error=18456.1351\n",
      "[flaml.automl.logger: 12-16 19:01:55] {2219} INFO - iteration 61, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 12-16 19:01:55] {2392} INFO -  at 9.2s,\testimator xgb_limitdepth's best error=23847.2155,\tbest estimator xgboost's best error=18456.1351\n",
      "[flaml.automl.logger: 12-16 19:01:55] {2219} INFO - iteration 62, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 12-16 19:01:55] {2392} INFO -  at 9.4s,\testimator xgb_limitdepth's best error=21240.1029,\tbest estimator xgboost's best error=18456.1351\n",
      "[flaml.automl.logger: 12-16 19:01:55] {2219} INFO - iteration 63, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 12-16 19:01:55] {2392} INFO -  at 9.4s,\testimator xgb_limitdepth's best error=21240.1029,\tbest estimator xgboost's best error=18456.1351\n",
      "[flaml.automl.logger: 12-16 19:01:55] {2219} INFO - iteration 64, current learner xgboost\n",
      "[flaml.automl.logger: 12-16 19:01:55] {2392} INFO -  at 9.6s,\testimator xgboost's best error=18456.1351,\tbest estimator xgboost's best error=18456.1351\n",
      "[flaml.automl.logger: 12-16 19:01:55] {2219} INFO - iteration 65, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 12-16 19:01:55] {2392} INFO -  at 9.7s,\testimator xgb_limitdepth's best error=21240.1029,\tbest estimator xgboost's best error=18456.1351\n",
      "[flaml.automl.logger: 12-16 19:01:55] {2219} INFO - iteration 66, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 12-16 19:01:55] {2392} INFO -  at 9.7s,\testimator xgb_limitdepth's best error=21240.1029,\tbest estimator xgboost's best error=18456.1351\n",
      "[flaml.automl.logger: 12-16 19:01:55] {2219} INFO - iteration 67, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 12-16 19:01:56] {2392} INFO -  at 10.1s,\testimator xgb_limitdepth's best error=19516.6114,\tbest estimator xgboost's best error=18456.1351\n",
      "[flaml.automl.logger: 12-16 19:01:56] {2219} INFO - iteration 68, current learner xgboost\n",
      "[flaml.automl.logger: 12-16 19:01:56] {2392} INFO -  at 10.2s,\testimator xgboost's best error=18456.1351,\tbest estimator xgboost's best error=18456.1351\n",
      "[flaml.automl.logger: 12-16 19:01:56] {2219} INFO - iteration 69, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 12-16 19:01:57] {2392} INFO -  at 11.1s,\testimator xgb_limitdepth's best error=19516.6114,\tbest estimator xgboost's best error=18456.1351\n",
      "[flaml.automl.logger: 12-16 19:01:57] {2219} INFO - iteration 70, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 12-16 19:01:57] {2392} INFO -  at 11.2s,\testimator xgb_limitdepth's best error=19516.6114,\tbest estimator xgboost's best error=18456.1351\n",
      "[flaml.automl.logger: 12-16 19:01:57] {2219} INFO - iteration 71, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 12-16 19:01:57] {2392} INFO -  at 11.4s,\testimator xgb_limitdepth's best error=19516.6114,\tbest estimator xgboost's best error=18456.1351\n",
      "[flaml.automl.logger: 12-16 19:01:57] {2219} INFO - iteration 72, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 12-16 19:01:58] {2392} INFO -  at 12.0s,\testimator xgb_limitdepth's best error=19516.6114,\tbest estimator xgboost's best error=18456.1351\n",
      "[flaml.automl.logger: 12-16 19:01:58] {2219} INFO - iteration 73, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 12-16 19:01:58] {2392} INFO -  at 12.4s,\testimator xgb_limitdepth's best error=19516.6114,\tbest estimator xgboost's best error=18456.1351\n",
      "[flaml.automl.logger: 12-16 19:01:58] {2219} INFO - iteration 74, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 12-16 19:01:58] {2392} INFO -  at 12.6s,\testimator xgb_limitdepth's best error=19516.6114,\tbest estimator xgboost's best error=18456.1351\n",
      "[flaml.automl.logger: 12-16 19:01:58] {2219} INFO - iteration 75, current learner xgboost\n",
      "[flaml.automl.logger: 12-16 19:01:59] {2392} INFO -  at 13.0s,\testimator xgboost's best error=18456.1351,\tbest estimator xgboost's best error=18456.1351\n",
      "[flaml.automl.logger: 12-16 19:01:59] {2219} INFO - iteration 76, current learner xgboost\n",
      "[flaml.automl.logger: 12-16 19:02:00] {2392} INFO -  at 14.7s,\testimator xgboost's best error=18057.7387,\tbest estimator xgboost's best error=18057.7387\n",
      "[flaml.automl.logger: 12-16 19:02:00] {2219} INFO - iteration 77, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 12-16 19:02:01] {2392} INFO -  at 15.0s,\testimator xgb_limitdepth's best error=19516.6114,\tbest estimator xgboost's best error=18057.7387\n",
      "[flaml.automl.logger: 12-16 19:02:01] {2219} INFO - iteration 78, current learner xgboost\n",
      "[flaml.automl.logger: 12-16 19:02:01] {2392} INFO -  at 15.2s,\testimator xgboost's best error=18057.7387,\tbest estimator xgboost's best error=18057.7387\n",
      "[flaml.automl.logger: 12-16 19:02:01] {2219} INFO - iteration 79, current learner xgboost\n",
      "[flaml.automl.logger: 12-16 19:02:01] {2392} INFO -  at 15.5s,\testimator xgboost's best error=18057.7387,\tbest estimator xgboost's best error=18057.7387\n",
      "[flaml.automl.logger: 12-16 19:02:01] {2219} INFO - iteration 80, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 12-16 19:02:01] {2392} INFO -  at 15.6s,\testimator xgb_limitdepth's best error=19132.2328,\tbest estimator xgboost's best error=18057.7387\n",
      "[flaml.automl.logger: 12-16 19:02:01] {2219} INFO - iteration 81, current learner xgboost\n",
      "[flaml.automl.logger: 12-16 19:02:15] {2392} INFO -  at 29.1s,\testimator xgboost's best error=18057.7387,\tbest estimator xgboost's best error=18057.7387\n",
      "[flaml.automl.logger: 12-16 19:02:15] {2219} INFO - iteration 82, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 12-16 19:02:15] {2392} INFO -  at 29.4s,\testimator xgb_limitdepth's best error=19132.2328,\tbest estimator xgboost's best error=18057.7387\n",
      "[flaml.automl.logger: 12-16 19:02:15] {2219} INFO - iteration 83, current learner extra_tree\n",
      "[flaml.automl.logger: 12-16 19:02:15] {2392} INFO -  at 29.5s,\testimator extra_tree's best error=28029.3517,\tbest estimator xgboost's best error=18057.7387\n",
      "[flaml.automl.logger: 12-16 19:02:15] {2219} INFO - iteration 84, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 12-16 19:02:15] {2392} INFO -  at 29.7s,\testimator xgb_limitdepth's best error=17310.0425,\tbest estimator xgb_limitdepth's best error=17310.0425\n",
      "[flaml.automl.logger: 12-16 19:02:15] {2219} INFO - iteration 85, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 12-16 19:02:15] {2392} INFO -  at 29.8s,\testimator xgb_limitdepth's best error=17310.0425,\tbest estimator xgb_limitdepth's best error=17310.0425\n",
      "[flaml.automl.logger: 12-16 19:02:15] {2219} INFO - iteration 86, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 12-16 19:02:16] {2392} INFO -  at 30.2s,\testimator xgb_limitdepth's best error=17310.0425,\tbest estimator xgb_limitdepth's best error=17310.0425\n",
      "[flaml.automl.logger: 12-16 19:02:16] {2219} INFO - iteration 87, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 12-16 19:02:16] {2392} INFO -  at 30.4s,\testimator xgb_limitdepth's best error=17310.0425,\tbest estimator xgb_limitdepth's best error=17310.0425\n",
      "[flaml.automl.logger: 12-16 19:02:16] {2219} INFO - iteration 88, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 12-16 19:02:16] {2392} INFO -  at 30.6s,\testimator xgb_limitdepth's best error=17310.0425,\tbest estimator xgb_limitdepth's best error=17310.0425\n",
      "[flaml.automl.logger: 12-16 19:02:16] {2219} INFO - iteration 89, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 12-16 19:02:16] {2392} INFO -  at 30.9s,\testimator xgb_limitdepth's best error=17310.0425,\tbest estimator xgb_limitdepth's best error=17310.0425\n",
      "[flaml.automl.logger: 12-16 19:02:16] {2219} INFO - iteration 90, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 12-16 19:02:17] {2392} INFO -  at 31.1s,\testimator xgb_limitdepth's best error=17310.0425,\tbest estimator xgb_limitdepth's best error=17310.0425\n",
      "[flaml.automl.logger: 12-16 19:02:17] {2219} INFO - iteration 91, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 12-16 19:02:17] {2392} INFO -  at 31.5s,\testimator xgb_limitdepth's best error=17310.0425,\tbest estimator xgb_limitdepth's best error=17310.0425\n",
      "[flaml.automl.logger: 12-16 19:02:17] {2219} INFO - iteration 92, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 12-16 19:02:17] {2392} INFO -  at 31.6s,\testimator xgb_limitdepth's best error=17310.0425,\tbest estimator xgb_limitdepth's best error=17310.0425\n",
      "[flaml.automl.logger: 12-16 19:02:17] {2219} INFO - iteration 93, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 12-16 19:02:17] {2392} INFO -  at 31.9s,\testimator xgb_limitdepth's best error=17310.0425,\tbest estimator xgb_limitdepth's best error=17310.0425\n",
      "[flaml.automl.logger: 12-16 19:02:17] {2219} INFO - iteration 94, current learner extra_tree\n",
      "[flaml.automl.logger: 12-16 19:02:18] {2392} INFO -  at 32.0s,\testimator extra_tree's best error=24680.1376,\tbest estimator xgb_limitdepth's best error=17310.0425\n",
      "[flaml.automl.logger: 12-16 19:02:18] {2219} INFO - iteration 95, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 12-16 19:02:18] {2392} INFO -  at 32.2s,\testimator xgb_limitdepth's best error=17310.0425,\tbest estimator xgb_limitdepth's best error=17310.0425\n",
      "[flaml.automl.logger: 12-16 19:02:18] {2219} INFO - iteration 96, current learner extra_tree\n",
      "[flaml.automl.logger: 12-16 19:02:18] {2392} INFO -  at 32.3s,\testimator extra_tree's best error=24680.1376,\tbest estimator xgb_limitdepth's best error=17310.0425\n",
      "[flaml.automl.logger: 12-16 19:02:18] {2219} INFO - iteration 97, current learner extra_tree\n",
      "[flaml.automl.logger: 12-16 19:02:18] {2392} INFO -  at 32.4s,\testimator extra_tree's best error=24680.1376,\tbest estimator xgb_limitdepth's best error=17310.0425\n",
      "[flaml.automl.logger: 12-16 19:02:18] {2219} INFO - iteration 98, current learner extra_tree\n",
      "[flaml.automl.logger: 12-16 19:02:18] {2392} INFO -  at 32.6s,\testimator extra_tree's best error=23325.9945,\tbest estimator xgb_limitdepth's best error=17310.0425\n",
      "[flaml.automl.logger: 12-16 19:02:18] {2219} INFO - iteration 99, current learner extra_tree\n",
      "[flaml.automl.logger: 12-16 19:02:18] {2392} INFO -  at 32.9s,\testimator extra_tree's best error=23325.9945,\tbest estimator xgb_limitdepth's best error=17310.0425\n",
      "[flaml.automl.logger: 12-16 19:02:18] {2219} INFO - iteration 100, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 12-16 19:02:18] {2392} INFO -  at 33.0s,\testimator xgb_limitdepth's best error=17310.0425,\tbest estimator xgb_limitdepth's best error=17310.0425\n",
      "[flaml.automl.logger: 12-16 19:02:18] {2219} INFO - iteration 101, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 12-16 19:02:19] {2392} INFO -  at 33.3s,\testimator xgb_limitdepth's best error=17310.0425,\tbest estimator xgb_limitdepth's best error=17310.0425\n",
      "[flaml.automl.logger: 12-16 19:02:19] {2219} INFO - iteration 102, current learner rf\n",
      "[flaml.automl.logger: 12-16 19:02:19] {2392} INFO -  at 33.4s,\testimator rf's best error=30717.5746,\tbest estimator xgb_limitdepth's best error=17310.0425\n",
      "[flaml.automl.logger: 12-16 19:02:19] {2219} INFO - iteration 103, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 12-16 19:02:20] {2392} INFO -  at 34.0s,\testimator xgb_limitdepth's best error=16866.3720,\tbest estimator xgb_limitdepth's best error=16866.3720\n",
      "[flaml.automl.logger: 12-16 19:02:20] {2219} INFO - iteration 104, current learner extra_tree\n",
      "[flaml.automl.logger: 12-16 19:02:20] {2392} INFO -  at 34.2s,\testimator extra_tree's best error=23289.5892,\tbest estimator xgb_limitdepth's best error=16866.3720\n",
      "[flaml.automl.logger: 12-16 19:02:20] {2219} INFO - iteration 105, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 12-16 19:02:20] {2392} INFO -  at 34.4s,\testimator xgb_limitdepth's best error=16866.3720,\tbest estimator xgb_limitdepth's best error=16866.3720\n",
      "[flaml.automl.logger: 12-16 19:02:20] {2219} INFO - iteration 106, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 12-16 19:02:20] {2392} INFO -  at 34.6s,\testimator xgb_limitdepth's best error=16866.3720,\tbest estimator xgb_limitdepth's best error=16866.3720\n",
      "[flaml.automl.logger: 12-16 19:02:20] {2219} INFO - iteration 107, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 12-16 19:02:24] {2392} INFO -  at 38.4s,\testimator xgb_limitdepth's best error=16866.3720,\tbest estimator xgb_limitdepth's best error=16866.3720\n",
      "[flaml.automl.logger: 12-16 19:02:24] {2219} INFO - iteration 108, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 12-16 19:02:24] {2392} INFO -  at 38.6s,\testimator xgb_limitdepth's best error=16866.3720,\tbest estimator xgb_limitdepth's best error=16866.3720\n",
      "[flaml.automl.logger: 12-16 19:02:24] {2219} INFO - iteration 109, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 12-16 19:02:27] {2392} INFO -  at 41.8s,\testimator xgb_limitdepth's best error=16866.3720,\tbest estimator xgb_limitdepth's best error=16866.3720\n",
      "[flaml.automl.logger: 12-16 19:02:27] {2219} INFO - iteration 110, current learner rf\n",
      "[flaml.automl.logger: 12-16 19:02:27] {2392} INFO -  at 41.9s,\testimator rf's best error=30042.8867,\tbest estimator xgb_limitdepth's best error=16866.3720\n",
      "[flaml.automl.logger: 12-16 19:02:27] {2219} INFO - iteration 111, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 12-16 19:02:28] {2392} INFO -  at 42.7s,\testimator xgb_limitdepth's best error=16866.3720,\tbest estimator xgb_limitdepth's best error=16866.3720\n",
      "[flaml.automl.logger: 12-16 19:02:28] {2219} INFO - iteration 112, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 12-16 19:02:29] {2392} INFO -  at 43.6s,\testimator xgb_limitdepth's best error=16866.3720,\tbest estimator xgb_limitdepth's best error=16866.3720\n",
      "[flaml.automl.logger: 12-16 19:02:29] {2219} INFO - iteration 113, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 12-16 19:02:31] {2392} INFO -  at 45.5s,\testimator xgb_limitdepth's best error=16847.9112,\tbest estimator xgb_limitdepth's best error=16847.9112\n",
      "[flaml.automl.logger: 12-16 19:02:31] {2219} INFO - iteration 114, current learner rf\n",
      "[flaml.automl.logger: 12-16 19:02:31] {2392} INFO -  at 45.7s,\testimator rf's best error=30042.8867,\tbest estimator xgb_limitdepth's best error=16847.9112\n",
      "[flaml.automl.logger: 12-16 19:02:31] {2219} INFO - iteration 115, current learner rf\n",
      "[flaml.automl.logger: 12-16 19:02:31] {2392} INFO -  at 45.9s,\testimator rf's best error=26486.2613,\tbest estimator xgb_limitdepth's best error=16847.9112\n",
      "[flaml.automl.logger: 12-16 19:02:31] {2219} INFO - iteration 116, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 12-16 19:02:32] {2392} INFO -  at 46.6s,\testimator xgb_limitdepth's best error=16847.9112,\tbest estimator xgb_limitdepth's best error=16847.9112\n",
      "[flaml.automl.logger: 12-16 19:02:32] {2219} INFO - iteration 117, current learner rf\n",
      "[flaml.automl.logger: 12-16 19:02:32] {2392} INFO -  at 46.8s,\testimator rf's best error=26486.2613,\tbest estimator xgb_limitdepth's best error=16847.9112\n",
      "[flaml.automl.logger: 12-16 19:02:32] {2219} INFO - iteration 118, current learner rf\n",
      "[flaml.automl.logger: 12-16 19:02:33] {2392} INFO -  at 47.0s,\testimator rf's best error=26486.2613,\tbest estimator xgb_limitdepth's best error=16847.9112\n",
      "[flaml.automl.logger: 12-16 19:02:33] {2219} INFO - iteration 119, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 12-16 19:02:33] {2392} INFO -  at 47.9s,\testimator xgb_limitdepth's best error=16847.9112,\tbest estimator xgb_limitdepth's best error=16847.9112\n",
      "[flaml.automl.logger: 12-16 19:02:33] {2219} INFO - iteration 120, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 12-16 19:02:38] {2392} INFO -  at 52.2s,\testimator xgb_limitdepth's best error=16242.2322,\tbest estimator xgb_limitdepth's best error=16242.2322\n",
      "[flaml.automl.logger: 12-16 19:02:38] {2219} INFO - iteration 121, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 12-16 19:02:39] {2392} INFO -  at 53.9s,\testimator xgb_limitdepth's best error=15772.0599,\tbest estimator xgb_limitdepth's best error=15772.0599\n",
      "[flaml.automl.logger: 12-16 19:02:39] {2219} INFO - iteration 122, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 12-16 19:02:44] {2392} INFO -  at 58.2s,\testimator xgb_limitdepth's best error=15772.0599,\tbest estimator xgb_limitdepth's best error=15772.0599\n",
      "[flaml.automl.logger: 12-16 19:02:44] {2219} INFO - iteration 123, current learner rf\n",
      "[flaml.automl.logger: 12-16 19:02:44] {2392} INFO -  at 58.5s,\testimator rf's best error=25821.3655,\tbest estimator xgb_limitdepth's best error=15772.0599\n",
      "[flaml.automl.logger: 12-16 19:02:44] {2219} INFO - iteration 124, current learner rf\n",
      "[flaml.automl.logger: 12-16 19:02:44] {2392} INFO -  at 58.7s,\testimator rf's best error=25666.0877,\tbest estimator xgb_limitdepth's best error=15772.0599\n",
      "[flaml.automl.logger: 12-16 19:02:44] {2219} INFO - iteration 125, current learner rf\n",
      "[flaml.automl.logger: 12-16 19:02:45] {2392} INFO -  at 59.1s,\testimator rf's best error=25610.3008,\tbest estimator xgb_limitdepth's best error=15772.0599\n",
      "[flaml.automl.logger: 12-16 19:02:45] {2219} INFO - iteration 126, current learner rf\n",
      "[flaml.automl.logger: 12-16 19:02:45] {2392} INFO -  at 59.3s,\testimator rf's best error=25610.3008,\tbest estimator xgb_limitdepth's best error=15772.0599\n",
      "[flaml.automl.logger: 12-16 19:02:45] {2219} INFO - iteration 127, current learner rf\n",
      "[flaml.automl.logger: 12-16 19:02:45] {2392} INFO -  at 59.8s,\testimator rf's best error=23695.3526,\tbest estimator xgb_limitdepth's best error=15772.0599\n",
      "[flaml.automl.logger: 12-16 19:02:46] {2628} INFO - retrain xgb_limitdepth for 0.6s\n",
      "[flaml.automl.logger: 12-16 19:02:46] {2631} INFO - retrained model: XGBRegressor(base_score=None, booster=None, callbacks=[],\n",
      "             colsample_bylevel=0.9616423910817776, colsample_bynode=None,\n",
      "             colsample_bytree=0.995779245125877, device=None,\n",
      "             early_stopping_rounds=None, enable_categorical=False,\n",
      "             eval_metric=None, feature_types=None, gamma=None, grow_policy=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=0.018673966612306605, max_bin=None,\n",
      "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "             max_delta_step=None, max_depth=4, max_leaves=None,\n",
      "             min_child_weight=2.268841930034181, missing=nan,\n",
      "             monotone_constraints=None, multi_strategy=None, n_estimators=909,\n",
      "             n_jobs=-1, num_parallel_tree=None, random_state=None, ...)\n",
      "[flaml.automl.logger: 12-16 19:02:46] {1931} INFO - fit succeeded\n",
      "[flaml.automl.logger: 12-16 19:02:46] {1932} INFO - Time taken to find the best model: 53.850167989730835\n",
      "[flaml.automl.logger: 12-16 19:02:46] {1680} INFO - task = regression\n",
      "[flaml.automl.logger: 12-16 19:02:46] {1691} INFO - Evaluation method: cv\n",
      "[flaml.automl.logger: 12-16 19:02:46] {1789} INFO - Minimizing error metric: mse\n",
      "[flaml.automl.logger: 12-16 19:02:46] {1901} INFO - List of ML learners in AutoML Run: ['rf', 'xgboost', 'extra_tree', 'xgb_limitdepth']\n",
      "[flaml.automl.logger: 12-16 19:02:46] {2219} INFO - iteration 0, current learner rf\n",
      "[flaml.automl.logger: 12-16 19:02:46] {2345} INFO - Estimated sufficient time budget=1044s. Estimated necessary time budget=4s.\n",
      "[flaml.automl.logger: 12-16 19:02:46] {2392} INFO -  at 0.1s,\testimator rf's best error=31.8646,\tbest estimator rf's best error=31.8646\n",
      "[flaml.automl.logger: 12-16 19:02:46] {2219} INFO - iteration 1, current learner xgboost\n",
      "[flaml.automl.logger: 12-16 19:02:46] {2392} INFO -  at 0.2s,\testimator xgboost's best error=94.8003,\tbest estimator rf's best error=31.8646\n",
      "[flaml.automl.logger: 12-16 19:02:46] {2219} INFO - iteration 2, current learner rf\n",
      "[flaml.automl.logger: 12-16 19:02:46] {2392} INFO -  at 0.3s,\testimator rf's best error=30.0254,\tbest estimator rf's best error=30.0254\n",
      "[flaml.automl.logger: 12-16 19:02:46] {2219} INFO - iteration 3, current learner xgboost\n",
      "[flaml.automl.logger: 12-16 19:02:46] {2392} INFO -  at 0.4s,\testimator xgboost's best error=94.8003,\tbest estimator rf's best error=30.0254\n",
      "[flaml.automl.logger: 12-16 19:02:46] {2219} INFO - iteration 4, current learner extra_tree\n",
      "[flaml.automl.logger: 12-16 19:02:46] {2392} INFO -  at 0.5s,\testimator extra_tree's best error=30.9804,\tbest estimator rf's best error=30.0254\n",
      "[flaml.automl.logger: 12-16 19:02:46] {2219} INFO - iteration 5, current learner rf\n",
      "[flaml.automl.logger: 12-16 19:02:47] {2392} INFO -  at 0.6s,\testimator rf's best error=23.9625,\tbest estimator rf's best error=23.9625\n",
      "[flaml.automl.logger: 12-16 19:02:47] {2219} INFO - iteration 6, current learner rf\n",
      "[flaml.automl.logger: 12-16 19:02:47] {2392} INFO -  at 0.7s,\testimator rf's best error=23.9625,\tbest estimator rf's best error=23.9625\n",
      "[flaml.automl.logger: 12-16 19:02:47] {2219} INFO - iteration 7, current learner rf\n",
      "[flaml.automl.logger: 12-16 19:02:47] {2392} INFO -  at 0.9s,\testimator rf's best error=21.3264,\tbest estimator rf's best error=21.3264\n",
      "[flaml.automl.logger: 12-16 19:02:47] {2219} INFO - iteration 8, current learner rf\n",
      "[flaml.automl.logger: 12-16 19:02:47] {2392} INFO -  at 1.1s,\testimator rf's best error=18.1847,\tbest estimator rf's best error=18.1847\n",
      "[flaml.automl.logger: 12-16 19:02:47] {2219} INFO - iteration 9, current learner rf\n",
      "[flaml.automl.logger: 12-16 19:02:47] {2392} INFO -  at 1.2s,\testimator rf's best error=18.1847,\tbest estimator rf's best error=18.1847\n",
      "[flaml.automl.logger: 12-16 19:02:47] {2219} INFO - iteration 10, current learner xgboost\n",
      "[flaml.automl.logger: 12-16 19:02:47] {2392} INFO -  at 1.3s,\testimator xgboost's best error=19.7950,\tbest estimator rf's best error=18.1847\n",
      "[flaml.automl.logger: 12-16 19:02:47] {2219} INFO - iteration 11, current learner xgboost\n",
      "[flaml.automl.logger: 12-16 19:02:47] {2392} INFO -  at 1.3s,\testimator xgboost's best error=19.7950,\tbest estimator rf's best error=18.1847\n",
      "[flaml.automl.logger: 12-16 19:02:47] {2219} INFO - iteration 12, current learner xgboost\n",
      "[flaml.automl.logger: 12-16 19:02:47] {2392} INFO -  at 1.4s,\testimator xgboost's best error=13.6391,\tbest estimator xgboost's best error=13.6391\n",
      "[flaml.automl.logger: 12-16 19:02:47] {2219} INFO - iteration 13, current learner xgboost\n",
      "[flaml.automl.logger: 12-16 19:02:47] {2392} INFO -  at 1.5s,\testimator xgboost's best error=13.6391,\tbest estimator xgboost's best error=13.6391\n",
      "[flaml.automl.logger: 12-16 19:02:47] {2219} INFO - iteration 14, current learner extra_tree\n",
      "[flaml.automl.logger: 12-16 19:02:48] {2392} INFO -  at 1.6s,\testimator extra_tree's best error=30.9804,\tbest estimator xgboost's best error=13.6391\n",
      "[flaml.automl.logger: 12-16 19:02:48] {2219} INFO - iteration 15, current learner xgboost\n",
      "[flaml.automl.logger: 12-16 19:02:48] {2392} INFO -  at 1.7s,\testimator xgboost's best error=12.1046,\tbest estimator xgboost's best error=12.1046\n",
      "[flaml.automl.logger: 12-16 19:02:48] {2219} INFO - iteration 16, current learner extra_tree\n",
      "[flaml.automl.logger: 12-16 19:02:48] {2392} INFO -  at 1.9s,\testimator extra_tree's best error=22.1814,\tbest estimator xgboost's best error=12.1046\n",
      "[flaml.automl.logger: 12-16 19:02:48] {2219} INFO - iteration 17, current learner rf\n",
      "[flaml.automl.logger: 12-16 19:02:48] {2392} INFO -  at 2.0s,\testimator rf's best error=18.1847,\tbest estimator xgboost's best error=12.1046\n",
      "[flaml.automl.logger: 12-16 19:02:48] {2219} INFO - iteration 18, current learner xgboost\n",
      "[flaml.automl.logger: 12-16 19:02:48] {2392} INFO -  at 2.0s,\testimator xgboost's best error=12.1046,\tbest estimator xgboost's best error=12.1046\n",
      "[flaml.automl.logger: 12-16 19:02:48] {2219} INFO - iteration 19, current learner xgboost\n",
      "[flaml.automl.logger: 12-16 19:02:48] {2392} INFO -  at 2.3s,\testimator xgboost's best error=12.1046,\tbest estimator xgboost's best error=12.1046\n",
      "[flaml.automl.logger: 12-16 19:02:48] {2219} INFO - iteration 20, current learner xgboost\n",
      "[flaml.automl.logger: 12-16 19:02:48] {2392} INFO -  at 2.4s,\testimator xgboost's best error=12.1046,\tbest estimator xgboost's best error=12.1046\n",
      "[flaml.automl.logger: 12-16 19:02:48] {2219} INFO - iteration 21, current learner xgboost\n",
      "[flaml.automl.logger: 12-16 19:02:48] {2392} INFO -  at 2.5s,\testimator xgboost's best error=12.1046,\tbest estimator xgboost's best error=12.1046\n",
      "[flaml.automl.logger: 12-16 19:02:48] {2219} INFO - iteration 22, current learner xgboost\n",
      "[flaml.automl.logger: 12-16 19:02:48] {2392} INFO -  at 2.5s,\testimator xgboost's best error=12.1046,\tbest estimator xgboost's best error=12.1046\n",
      "[flaml.automl.logger: 12-16 19:02:48] {2219} INFO - iteration 23, current learner extra_tree\n",
      "[flaml.automl.logger: 12-16 19:02:49] {2392} INFO -  at 2.6s,\testimator extra_tree's best error=22.1814,\tbest estimator xgboost's best error=12.1046\n",
      "[flaml.automl.logger: 12-16 19:02:49] {2219} INFO - iteration 24, current learner extra_tree\n",
      "[flaml.automl.logger: 12-16 19:02:49] {2392} INFO -  at 2.8s,\testimator extra_tree's best error=20.3597,\tbest estimator xgboost's best error=12.1046\n",
      "[flaml.automl.logger: 12-16 19:02:49] {2219} INFO - iteration 25, current learner xgboost\n",
      "[flaml.automl.logger: 12-16 19:02:49] {2392} INFO -  at 2.9s,\testimator xgboost's best error=12.1046,\tbest estimator xgboost's best error=12.1046\n",
      "[flaml.automl.logger: 12-16 19:02:49] {2219} INFO - iteration 26, current learner xgboost\n",
      "[flaml.automl.logger: 12-16 19:02:49] {2392} INFO -  at 3.0s,\testimator xgboost's best error=12.1046,\tbest estimator xgboost's best error=12.1046\n",
      "[flaml.automl.logger: 12-16 19:02:49] {2219} INFO - iteration 27, current learner extra_tree\n",
      "[flaml.automl.logger: 12-16 19:02:49] {2392} INFO -  at 3.1s,\testimator extra_tree's best error=18.0035,\tbest estimator xgboost's best error=12.1046\n",
      "[flaml.automl.logger: 12-16 19:02:49] {2219} INFO - iteration 28, current learner extra_tree\n",
      "[flaml.automl.logger: 12-16 19:02:49] {2392} INFO -  at 3.2s,\testimator extra_tree's best error=18.0035,\tbest estimator xgboost's best error=12.1046\n",
      "[flaml.automl.logger: 12-16 19:02:49] {2219} INFO - iteration 29, current learner rf\n",
      "[flaml.automl.logger: 12-16 19:02:49] {2392} INFO -  at 3.4s,\testimator rf's best error=16.6246,\tbest estimator xgboost's best error=12.1046\n",
      "[flaml.automl.logger: 12-16 19:02:49] {2219} INFO - iteration 30, current learner rf\n",
      "[flaml.automl.logger: 12-16 19:02:50] {2392} INFO -  at 3.6s,\testimator rf's best error=16.6246,\tbest estimator xgboost's best error=12.1046\n",
      "[flaml.automl.logger: 12-16 19:02:50] {2219} INFO - iteration 31, current learner xgboost\n",
      "[flaml.automl.logger: 12-16 19:02:50] {2392} INFO -  at 3.8s,\testimator xgboost's best error=12.1046,\tbest estimator xgboost's best error=12.1046\n",
      "[flaml.automl.logger: 12-16 19:02:50] {2219} INFO - iteration 32, current learner extra_tree\n",
      "[flaml.automl.logger: 12-16 19:02:50] {2392} INFO -  at 3.9s,\testimator extra_tree's best error=18.0035,\tbest estimator xgboost's best error=12.1046\n",
      "[flaml.automl.logger: 12-16 19:02:50] {2219} INFO - iteration 33, current learner rf\n",
      "[flaml.automl.logger: 12-16 19:02:50] {2392} INFO -  at 4.1s,\testimator rf's best error=14.0367,\tbest estimator xgboost's best error=12.1046\n",
      "[flaml.automl.logger: 12-16 19:02:50] {2219} INFO - iteration 34, current learner rf\n",
      "[flaml.automl.logger: 12-16 19:02:50] {2392} INFO -  at 4.2s,\testimator rf's best error=13.2589,\tbest estimator xgboost's best error=12.1046\n",
      "[flaml.automl.logger: 12-16 19:02:50] {2219} INFO - iteration 35, current learner extra_tree\n",
      "[flaml.automl.logger: 12-16 19:02:50] {2392} INFO -  at 4.4s,\testimator extra_tree's best error=17.6427,\tbest estimator xgboost's best error=12.1046\n",
      "[flaml.automl.logger: 12-16 19:02:50] {2219} INFO - iteration 36, current learner rf\n",
      "[flaml.automl.logger: 12-16 19:02:50] {2392} INFO -  at 4.5s,\testimator rf's best error=13.2589,\tbest estimator xgboost's best error=12.1046\n",
      "[flaml.automl.logger: 12-16 19:02:50] {2219} INFO - iteration 37, current learner xgboost\n",
      "[flaml.automl.logger: 12-16 19:02:51] {2392} INFO -  at 4.8s,\testimator xgboost's best error=12.1046,\tbest estimator xgboost's best error=12.1046\n",
      "[flaml.automl.logger: 12-16 19:02:51] {2219} INFO - iteration 38, current learner rf\n",
      "[flaml.automl.logger: 12-16 19:02:51] {2392} INFO -  at 5.0s,\testimator rf's best error=13.2589,\tbest estimator xgboost's best error=12.1046\n",
      "[flaml.automl.logger: 12-16 19:02:51] {2219} INFO - iteration 39, current learner xgboost\n",
      "[flaml.automl.logger: 12-16 19:02:51] {2392} INFO -  at 5.0s,\testimator xgboost's best error=12.1046,\tbest estimator xgboost's best error=12.1046\n",
      "[flaml.automl.logger: 12-16 19:02:51] {2219} INFO - iteration 40, current learner xgboost\n",
      "[flaml.automl.logger: 12-16 19:02:51] {2392} INFO -  at 5.1s,\testimator xgboost's best error=12.1046,\tbest estimator xgboost's best error=12.1046\n",
      "[flaml.automl.logger: 12-16 19:02:51] {2219} INFO - iteration 41, current learner rf\n",
      "[flaml.automl.logger: 12-16 19:02:51] {2392} INFO -  at 5.3s,\testimator rf's best error=13.2589,\tbest estimator xgboost's best error=12.1046\n",
      "[flaml.automl.logger: 12-16 19:02:51] {2219} INFO - iteration 42, current learner xgboost\n",
      "[flaml.automl.logger: 12-16 19:02:51] {2392} INFO -  at 5.4s,\testimator xgboost's best error=12.1046,\tbest estimator xgboost's best error=12.1046\n",
      "[flaml.automl.logger: 12-16 19:02:51] {2219} INFO - iteration 43, current learner extra_tree\n",
      "[flaml.automl.logger: 12-16 19:02:51] {2392} INFO -  at 5.5s,\testimator extra_tree's best error=17.6427,\tbest estimator xgboost's best error=12.1046\n",
      "[flaml.automl.logger: 12-16 19:02:51] {2219} INFO - iteration 44, current learner xgboost\n",
      "[flaml.automl.logger: 12-16 19:02:52] {2392} INFO -  at 5.6s,\testimator xgboost's best error=12.1046,\tbest estimator xgboost's best error=12.1046\n",
      "[flaml.automl.logger: 12-16 19:02:52] {2219} INFO - iteration 45, current learner rf\n",
      "[flaml.automl.logger: 12-16 19:02:52] {2392} INFO -  at 5.8s,\testimator rf's best error=13.2589,\tbest estimator xgboost's best error=12.1046\n",
      "[flaml.automl.logger: 12-16 19:02:52] {2219} INFO - iteration 46, current learner xgboost\n",
      "[flaml.automl.logger: 12-16 19:02:52] {2392} INFO -  at 6.0s,\testimator xgboost's best error=12.1046,\tbest estimator xgboost's best error=12.1046\n",
      "[flaml.automl.logger: 12-16 19:02:52] {2219} INFO - iteration 47, current learner rf\n",
      "[flaml.automl.logger: 12-16 19:02:52] {2392} INFO -  at 6.2s,\testimator rf's best error=13.2589,\tbest estimator xgboost's best error=12.1046\n",
      "[flaml.automl.logger: 12-16 19:02:52] {2219} INFO - iteration 48, current learner xgboost\n",
      "[flaml.automl.logger: 12-16 19:02:52] {2392} INFO -  at 6.2s,\testimator xgboost's best error=12.1046,\tbest estimator xgboost's best error=12.1046\n",
      "[flaml.automl.logger: 12-16 19:02:52] {2219} INFO - iteration 49, current learner xgboost\n",
      "[flaml.automl.logger: 12-16 19:02:52] {2392} INFO -  at 6.4s,\testimator xgboost's best error=12.1046,\tbest estimator xgboost's best error=12.1046\n",
      "[flaml.automl.logger: 12-16 19:02:52] {2219} INFO - iteration 50, current learner rf\n",
      "[flaml.automl.logger: 12-16 19:02:53] {2392} INFO -  at 6.6s,\testimator rf's best error=12.7684,\tbest estimator xgboost's best error=12.1046\n",
      "[flaml.automl.logger: 12-16 19:02:53] {2219} INFO - iteration 51, current learner rf\n",
      "[flaml.automl.logger: 12-16 19:02:53] {2392} INFO -  at 6.8s,\testimator rf's best error=12.7684,\tbest estimator xgboost's best error=12.1046\n",
      "[flaml.automl.logger: 12-16 19:02:53] {2219} INFO - iteration 52, current learner rf\n",
      "[flaml.automl.logger: 12-16 19:02:53] {2392} INFO -  at 6.9s,\testimator rf's best error=12.7684,\tbest estimator xgboost's best error=12.1046\n",
      "[flaml.automl.logger: 12-16 19:02:53] {2219} INFO - iteration 53, current learner rf\n",
      "[flaml.automl.logger: 12-16 19:02:53] {2392} INFO -  at 7.2s,\testimator rf's best error=12.5899,\tbest estimator xgboost's best error=12.1046\n",
      "[flaml.automl.logger: 12-16 19:02:53] {2219} INFO - iteration 54, current learner xgboost\n",
      "[flaml.automl.logger: 12-16 19:02:53] {2392} INFO -  at 7.4s,\testimator xgboost's best error=12.1046,\tbest estimator xgboost's best error=12.1046\n",
      "[flaml.automl.logger: 12-16 19:02:53] {2219} INFO - iteration 55, current learner rf\n",
      "[flaml.automl.logger: 12-16 19:02:54] {2392} INFO -  at 7.6s,\testimator rf's best error=12.5899,\tbest estimator xgboost's best error=12.1046\n",
      "[flaml.automl.logger: 12-16 19:02:54] {2219} INFO - iteration 56, current learner rf\n",
      "[flaml.automl.logger: 12-16 19:02:54] {2392} INFO -  at 8.0s,\testimator rf's best error=12.3924,\tbest estimator xgboost's best error=12.1046\n",
      "[flaml.automl.logger: 12-16 19:02:54] {2219} INFO - iteration 57, current learner rf\n",
      "[flaml.automl.logger: 12-16 19:02:54] {2392} INFO -  at 8.3s,\testimator rf's best error=12.3924,\tbest estimator xgboost's best error=12.1046\n",
      "[flaml.automl.logger: 12-16 19:02:54] {2219} INFO - iteration 58, current learner rf\n",
      "[flaml.automl.logger: 12-16 19:02:55] {2392} INFO -  at 8.9s,\testimator rf's best error=11.9543,\tbest estimator rf's best error=11.9543\n",
      "[flaml.automl.logger: 12-16 19:02:55] {2219} INFO - iteration 59, current learner rf\n",
      "[flaml.automl.logger: 12-16 19:02:55] {2392} INFO -  at 9.5s,\testimator rf's best error=11.9543,\tbest estimator rf's best error=11.9543\n",
      "[flaml.automl.logger: 12-16 19:02:55] {2219} INFO - iteration 60, current learner rf\n",
      "[flaml.automl.logger: 12-16 19:02:56] {2392} INFO -  at 10.0s,\testimator rf's best error=11.9543,\tbest estimator rf's best error=11.9543\n",
      "[flaml.automl.logger: 12-16 19:02:56] {2219} INFO - iteration 61, current learner rf\n",
      "[flaml.automl.logger: 12-16 19:02:57] {2392} INFO -  at 10.9s,\testimator rf's best error=11.7348,\tbest estimator rf's best error=11.7348\n",
      "[flaml.automl.logger: 12-16 19:02:57] {2219} INFO - iteration 62, current learner xgboost\n",
      "[flaml.automl.logger: 12-16 19:02:57] {2392} INFO -  at 10.9s,\testimator xgboost's best error=12.1046,\tbest estimator rf's best error=11.7348\n",
      "[flaml.automl.logger: 12-16 19:02:57] {2219} INFO - iteration 63, current learner rf\n",
      "[flaml.automl.logger: 12-16 19:02:58] {2392} INFO -  at 11.6s,\testimator rf's best error=11.7348,\tbest estimator rf's best error=11.7348\n",
      "[flaml.automl.logger: 12-16 19:02:58] {2219} INFO - iteration 64, current learner rf\n",
      "[flaml.automl.logger: 12-16 19:02:58] {2392} INFO -  at 12.5s,\testimator rf's best error=11.7348,\tbest estimator rf's best error=11.7348\n",
      "[flaml.automl.logger: 12-16 19:02:58] {2219} INFO - iteration 65, current learner xgboost\n",
      "[flaml.automl.logger: 12-16 19:02:59] {2392} INFO -  at 12.7s,\testimator xgboost's best error=11.0220,\tbest estimator xgboost's best error=11.0220\n",
      "[flaml.automl.logger: 12-16 19:02:59] {2219} INFO - iteration 66, current learner xgboost\n",
      "[flaml.automl.logger: 12-16 19:02:59] {2392} INFO -  at 13.0s,\testimator xgboost's best error=11.0220,\tbest estimator xgboost's best error=11.0220\n",
      "[flaml.automl.logger: 12-16 19:02:59] {2219} INFO - iteration 67, current learner rf\n",
      "[flaml.automl.logger: 12-16 19:03:00] {2392} INFO -  at 13.9s,\testimator rf's best error=11.7348,\tbest estimator xgboost's best error=11.0220\n",
      "[flaml.automl.logger: 12-16 19:03:00] {2219} INFO - iteration 68, current learner xgboost\n",
      "[flaml.automl.logger: 12-16 19:03:00] {2392} INFO -  at 14.1s,\testimator xgboost's best error=11.0220,\tbest estimator xgboost's best error=11.0220\n",
      "[flaml.automl.logger: 12-16 19:03:00] {2219} INFO - iteration 69, current learner xgboost\n",
      "[flaml.automl.logger: 12-16 19:03:00] {2392} INFO -  at 14.2s,\testimator xgboost's best error=11.0220,\tbest estimator xgboost's best error=11.0220\n",
      "[flaml.automl.logger: 12-16 19:03:00] {2219} INFO - iteration 70, current learner xgboost\n",
      "[flaml.automl.logger: 12-16 19:03:00] {2392} INFO -  at 14.4s,\testimator xgboost's best error=11.0220,\tbest estimator xgboost's best error=11.0220\n",
      "[flaml.automl.logger: 12-16 19:03:00] {2219} INFO - iteration 71, current learner extra_tree\n",
      "[flaml.automl.logger: 12-16 19:03:00] {2392} INFO -  at 14.5s,\testimator extra_tree's best error=15.4983,\tbest estimator xgboost's best error=11.0220\n",
      "[flaml.automl.logger: 12-16 19:03:00] {2219} INFO - iteration 72, current learner extra_tree\n",
      "[flaml.automl.logger: 12-16 19:03:01] {2392} INFO -  at 14.6s,\testimator extra_tree's best error=14.7748,\tbest estimator xgboost's best error=11.0220\n",
      "[flaml.automl.logger: 12-16 19:03:01] {2219} INFO - iteration 73, current learner extra_tree\n",
      "[flaml.automl.logger: 12-16 19:03:01] {2392} INFO -  at 14.7s,\testimator extra_tree's best error=14.7748,\tbest estimator xgboost's best error=11.0220\n",
      "[flaml.automl.logger: 12-16 19:03:01] {2219} INFO - iteration 74, current learner xgboost\n",
      "[flaml.automl.logger: 12-16 19:03:01] {2392} INFO -  at 15.5s,\testimator xgboost's best error=10.6607,\tbest estimator xgboost's best error=10.6607\n",
      "[flaml.automl.logger: 12-16 19:03:01] {2219} INFO - iteration 75, current learner xgboost\n",
      "[flaml.automl.logger: 12-16 19:03:02] {2392} INFO -  at 15.6s,\testimator xgboost's best error=10.6607,\tbest estimator xgboost's best error=10.6607\n",
      "[flaml.automl.logger: 12-16 19:03:02] {2219} INFO - iteration 76, current learner extra_tree\n",
      "[flaml.automl.logger: 12-16 19:03:02] {2392} INFO -  at 15.7s,\testimator extra_tree's best error=14.1516,\tbest estimator xgboost's best error=10.6607\n",
      "[flaml.automl.logger: 12-16 19:03:02] {2219} INFO - iteration 77, current learner xgboost\n",
      "[flaml.automl.logger: 12-16 19:03:02] {2392} INFO -  at 15.9s,\testimator xgboost's best error=10.6607,\tbest estimator xgboost's best error=10.6607\n",
      "[flaml.automl.logger: 12-16 19:03:02] {2219} INFO - iteration 78, current learner xgboost\n",
      "[flaml.automl.logger: 12-16 19:03:08] {2392} INFO -  at 22.6s,\testimator xgboost's best error=10.6607,\tbest estimator xgboost's best error=10.6607\n",
      "[flaml.automl.logger: 12-16 19:03:08] {2219} INFO - iteration 79, current learner extra_tree\n",
      "[flaml.automl.logger: 12-16 19:03:09] {2392} INFO -  at 22.7s,\testimator extra_tree's best error=14.1516,\tbest estimator xgboost's best error=10.6607\n",
      "[flaml.automl.logger: 12-16 19:03:09] {2219} INFO - iteration 80, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 12-16 19:03:09] {2392} INFO -  at 22.8s,\testimator xgb_limitdepth's best error=12.5890,\tbest estimator xgboost's best error=10.6607\n",
      "[flaml.automl.logger: 12-16 19:03:09] {2219} INFO - iteration 81, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 12-16 19:03:09] {2392} INFO -  at 22.9s,\testimator xgb_limitdepth's best error=12.5890,\tbest estimator xgboost's best error=10.6607\n",
      "[flaml.automl.logger: 12-16 19:03:09] {2219} INFO - iteration 82, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 12-16 19:03:09] {2392} INFO -  at 23.0s,\testimator xgb_limitdepth's best error=12.5890,\tbest estimator xgboost's best error=10.6607\n",
      "[flaml.automl.logger: 12-16 19:03:09] {2219} INFO - iteration 83, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 12-16 19:03:09] {2392} INFO -  at 23.0s,\testimator xgb_limitdepth's best error=12.5890,\tbest estimator xgboost's best error=10.6607\n",
      "[flaml.automl.logger: 12-16 19:03:09] {2219} INFO - iteration 84, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 12-16 19:03:09] {2392} INFO -  at 23.1s,\testimator xgb_limitdepth's best error=11.6269,\tbest estimator xgboost's best error=10.6607\n",
      "[flaml.automl.logger: 12-16 19:03:09] {2219} INFO - iteration 85, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 12-16 19:03:09] {2392} INFO -  at 23.2s,\testimator xgb_limitdepth's best error=11.6269,\tbest estimator xgboost's best error=10.6607\n",
      "[flaml.automl.logger: 12-16 19:03:09] {2219} INFO - iteration 86, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 12-16 19:03:09] {2392} INFO -  at 23.4s,\testimator xgb_limitdepth's best error=11.6269,\tbest estimator xgboost's best error=10.6607\n",
      "[flaml.automl.logger: 12-16 19:03:09] {2219} INFO - iteration 87, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 12-16 19:03:09] {2392} INFO -  at 23.5s,\testimator xgb_limitdepth's best error=11.6269,\tbest estimator xgboost's best error=10.6607\n",
      "[flaml.automl.logger: 12-16 19:03:09] {2219} INFO - iteration 88, current learner extra_tree\n",
      "[flaml.automl.logger: 12-16 19:03:10] {2392} INFO -  at 23.6s,\testimator extra_tree's best error=14.1516,\tbest estimator xgboost's best error=10.6607\n",
      "[flaml.automl.logger: 12-16 19:03:10] {2219} INFO - iteration 89, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 12-16 19:03:10] {2392} INFO -  at 24.0s,\testimator xgb_limitdepth's best error=11.6269,\tbest estimator xgboost's best error=10.6607\n",
      "[flaml.automl.logger: 12-16 19:03:10] {2219} INFO - iteration 90, current learner extra_tree\n",
      "[flaml.automl.logger: 12-16 19:03:10] {2392} INFO -  at 24.1s,\testimator extra_tree's best error=14.1516,\tbest estimator xgboost's best error=10.6607\n",
      "[flaml.automl.logger: 12-16 19:03:10] {2219} INFO - iteration 91, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 12-16 19:03:10] {2392} INFO -  at 24.3s,\testimator xgb_limitdepth's best error=11.6269,\tbest estimator xgboost's best error=10.6607\n",
      "[flaml.automl.logger: 12-16 19:03:10] {2219} INFO - iteration 92, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 12-16 19:03:10] {2392} INFO -  at 24.4s,\testimator xgb_limitdepth's best error=11.6269,\tbest estimator xgboost's best error=10.6607\n",
      "[flaml.automl.logger: 12-16 19:03:10] {2219} INFO - iteration 93, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 12-16 19:03:10] {2392} INFO -  at 24.5s,\testimator xgb_limitdepth's best error=11.6269,\tbest estimator xgboost's best error=10.6607\n",
      "[flaml.automl.logger: 12-16 19:03:10] {2219} INFO - iteration 94, current learner xgboost\n",
      "[flaml.automl.logger: 12-16 19:03:11] {2392} INFO -  at 24.7s,\testimator xgboost's best error=10.6607,\tbest estimator xgboost's best error=10.6607\n",
      "[flaml.automl.logger: 12-16 19:03:11] {2219} INFO - iteration 95, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 12-16 19:03:11] {2392} INFO -  at 25.0s,\testimator xgb_limitdepth's best error=11.6269,\tbest estimator xgboost's best error=10.6607\n",
      "[flaml.automl.logger: 12-16 19:03:11] {2219} INFO - iteration 96, current learner extra_tree\n",
      "[flaml.automl.logger: 12-16 19:03:11] {2392} INFO -  at 25.1s,\testimator extra_tree's best error=13.4994,\tbest estimator xgboost's best error=10.6607\n",
      "[flaml.automl.logger: 12-16 19:03:11] {2219} INFO - iteration 97, current learner extra_tree\n",
      "[flaml.automl.logger: 12-16 19:03:11] {2392} INFO -  at 25.2s,\testimator extra_tree's best error=13.4994,\tbest estimator xgboost's best error=10.6607\n",
      "[flaml.automl.logger: 12-16 19:03:11] {2219} INFO - iteration 98, current learner extra_tree\n",
      "[flaml.automl.logger: 12-16 19:03:11] {2392} INFO -  at 25.4s,\testimator extra_tree's best error=13.4994,\tbest estimator xgboost's best error=10.6607\n",
      "[flaml.automl.logger: 12-16 19:03:11] {2219} INFO - iteration 99, current learner xgboost\n",
      "[flaml.automl.logger: 12-16 19:03:17] {2392} INFO -  at 31.3s,\testimator xgboost's best error=10.6607,\tbest estimator xgboost's best error=10.6607\n",
      "[flaml.automl.logger: 12-16 19:03:17] {2219} INFO - iteration 100, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 12-16 19:03:17] {2392} INFO -  at 31.5s,\testimator xgb_limitdepth's best error=11.6269,\tbest estimator xgboost's best error=10.6607\n",
      "[flaml.automl.logger: 12-16 19:03:17] {2219} INFO - iteration 101, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 12-16 19:03:18] {2392} INFO -  at 31.7s,\testimator xgb_limitdepth's best error=11.6269,\tbest estimator xgboost's best error=10.6607\n",
      "[flaml.automl.logger: 12-16 19:03:18] {2219} INFO - iteration 102, current learner rf\n",
      "[flaml.automl.logger: 12-16 19:03:18] {2392} INFO -  at 32.1s,\testimator rf's best error=11.7348,\tbest estimator xgboost's best error=10.6607\n",
      "[flaml.automl.logger: 12-16 19:03:18] {2219} INFO - iteration 103, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 12-16 19:03:18] {2392} INFO -  at 32.3s,\testimator xgb_limitdepth's best error=11.6269,\tbest estimator xgboost's best error=10.6607\n",
      "[flaml.automl.logger: 12-16 19:03:18] {2219} INFO - iteration 104, current learner extra_tree\n",
      "[flaml.automl.logger: 12-16 19:03:18] {2392} INFO -  at 32.5s,\testimator extra_tree's best error=13.4335,\tbest estimator xgboost's best error=10.6607\n",
      "[flaml.automl.logger: 12-16 19:03:18] {2219} INFO - iteration 105, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 12-16 19:03:19] {2392} INFO -  at 32.6s,\testimator xgb_limitdepth's best error=10.9463,\tbest estimator xgboost's best error=10.6607\n",
      "[flaml.automl.logger: 12-16 19:03:19] {2219} INFO - iteration 106, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 12-16 19:03:19] {2392} INFO -  at 32.8s,\testimator xgb_limitdepth's best error=10.9463,\tbest estimator xgboost's best error=10.6607\n",
      "[flaml.automl.logger: 12-16 19:03:19] {2219} INFO - iteration 107, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 12-16 19:03:19] {2392} INFO -  at 32.8s,\testimator xgb_limitdepth's best error=10.9463,\tbest estimator xgboost's best error=10.6607\n",
      "[flaml.automl.logger: 12-16 19:03:19] {2219} INFO - iteration 108, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 12-16 19:03:19] {2392} INFO -  at 32.9s,\testimator xgb_limitdepth's best error=10.9463,\tbest estimator xgboost's best error=10.6607\n",
      "[flaml.automl.logger: 12-16 19:03:19] {2219} INFO - iteration 109, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 12-16 19:03:19] {2392} INFO -  at 33.1s,\testimator xgb_limitdepth's best error=10.9463,\tbest estimator xgboost's best error=10.6607\n",
      "[flaml.automl.logger: 12-16 19:03:19] {2219} INFO - iteration 110, current learner rf\n",
      "[flaml.automl.logger: 12-16 19:03:21] {2392} INFO -  at 35.1s,\testimator rf's best error=11.6885,\tbest estimator xgboost's best error=10.6607\n",
      "[flaml.automl.logger: 12-16 19:03:21] {2219} INFO - iteration 111, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 12-16 19:03:21] {2392} INFO -  at 35.2s,\testimator xgb_limitdepth's best error=10.9463,\tbest estimator xgboost's best error=10.6607\n",
      "[flaml.automl.logger: 12-16 19:03:21] {2219} INFO - iteration 112, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 12-16 19:03:21] {2392} INFO -  at 35.4s,\testimator xgb_limitdepth's best error=10.9463,\tbest estimator xgboost's best error=10.6607\n",
      "[flaml.automl.logger: 12-16 19:03:21] {2219} INFO - iteration 113, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 12-16 19:03:21] {2392} INFO -  at 35.5s,\testimator xgb_limitdepth's best error=10.9463,\tbest estimator xgboost's best error=10.6607\n",
      "[flaml.automl.logger: 12-16 19:03:21] {2219} INFO - iteration 114, current learner extra_tree\n",
      "[flaml.automl.logger: 12-16 19:03:22] {2392} INFO -  at 35.7s,\testimator extra_tree's best error=13.0504,\tbest estimator xgboost's best error=10.6607\n",
      "[flaml.automl.logger: 12-16 19:03:22] {2219} INFO - iteration 115, current learner extra_tree\n",
      "[flaml.automl.logger: 12-16 19:03:22] {2392} INFO -  at 35.9s,\testimator extra_tree's best error=13.0504,\tbest estimator xgboost's best error=10.6607\n",
      "[flaml.automl.logger: 12-16 19:03:22] {2219} INFO - iteration 116, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 12-16 19:03:22] {2392} INFO -  at 35.9s,\testimator xgb_limitdepth's best error=10.9463,\tbest estimator xgboost's best error=10.6607\n",
      "[flaml.automl.logger: 12-16 19:03:22] {2219} INFO - iteration 117, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 12-16 19:03:22] {2392} INFO -  at 36.1s,\testimator xgb_limitdepth's best error=10.9463,\tbest estimator xgboost's best error=10.6607\n",
      "[flaml.automl.logger: 12-16 19:03:22] {2219} INFO - iteration 118, current learner xgboost\n",
      "[flaml.automl.logger: 12-16 19:03:23] {2392} INFO -  at 36.8s,\testimator xgboost's best error=10.6607,\tbest estimator xgboost's best error=10.6607\n",
      "[flaml.automl.logger: 12-16 19:03:23] {2219} INFO - iteration 119, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 12-16 19:03:23] {2392} INFO -  at 36.9s,\testimator xgb_limitdepth's best error=10.9463,\tbest estimator xgboost's best error=10.6607\n",
      "[flaml.automl.logger: 12-16 19:03:23] {2219} INFO - iteration 120, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 12-16 19:03:23] {2392} INFO -  at 37.0s,\testimator xgb_limitdepth's best error=10.9463,\tbest estimator xgboost's best error=10.6607\n",
      "[flaml.automl.logger: 12-16 19:03:23] {2219} INFO - iteration 121, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 12-16 19:03:23] {2392} INFO -  at 37.1s,\testimator xgb_limitdepth's best error=10.9463,\tbest estimator xgboost's best error=10.6607\n",
      "[flaml.automl.logger: 12-16 19:03:23] {2219} INFO - iteration 122, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 12-16 19:03:23] {2392} INFO -  at 37.2s,\testimator xgb_limitdepth's best error=10.9463,\tbest estimator xgboost's best error=10.6607\n",
      "[flaml.automl.logger: 12-16 19:03:23] {2219} INFO - iteration 123, current learner extra_tree\n",
      "[flaml.automl.logger: 12-16 19:03:23] {2392} INFO -  at 37.3s,\testimator extra_tree's best error=13.0504,\tbest estimator xgboost's best error=10.6607\n",
      "[flaml.automl.logger: 12-16 19:03:23] {2219} INFO - iteration 124, current learner xgboost\n",
      "[flaml.automl.logger: 12-16 19:03:24] {2392} INFO -  at 38.3s,\testimator xgboost's best error=10.6607,\tbest estimator xgboost's best error=10.6607\n",
      "[flaml.automl.logger: 12-16 19:03:24] {2219} INFO - iteration 125, current learner xgboost\n",
      "[flaml.automl.logger: 12-16 19:03:26] {2392} INFO -  at 40.4s,\testimator xgboost's best error=10.4075,\tbest estimator xgboost's best error=10.4075\n",
      "[flaml.automl.logger: 12-16 19:03:26] {2219} INFO - iteration 126, current learner xgboost\n",
      "[flaml.automl.logger: 12-16 19:03:27] {2392} INFO -  at 41.3s,\testimator xgboost's best error=10.4075,\tbest estimator xgboost's best error=10.4075\n",
      "[flaml.automl.logger: 12-16 19:03:27] {2219} INFO - iteration 127, current learner extra_tree\n",
      "[flaml.automl.logger: 12-16 19:03:27] {2392} INFO -  at 41.5s,\testimator extra_tree's best error=12.8820,\tbest estimator xgboost's best error=10.4075\n",
      "[flaml.automl.logger: 12-16 19:03:27] {2219} INFO - iteration 128, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 12-16 19:03:27] {2392} INFO -  at 41.6s,\testimator xgb_limitdepth's best error=10.9366,\tbest estimator xgboost's best error=10.4075\n",
      "[flaml.automl.logger: 12-16 19:03:27] {2219} INFO - iteration 129, current learner extra_tree\n",
      "[flaml.automl.logger: 12-16 19:03:28] {2392} INFO -  at 41.8s,\testimator extra_tree's best error=12.5124,\tbest estimator xgboost's best error=10.4075\n",
      "[flaml.automl.logger: 12-16 19:03:28] {2219} INFO - iteration 130, current learner extra_tree\n",
      "[flaml.automl.logger: 12-16 19:03:28] {2392} INFO -  at 41.9s,\testimator extra_tree's best error=12.5124,\tbest estimator xgboost's best error=10.4075\n",
      "[flaml.automl.logger: 12-16 19:03:28] {2219} INFO - iteration 131, current learner extra_tree\n",
      "[flaml.automl.logger: 12-16 19:03:28] {2392} INFO -  at 42.2s,\testimator extra_tree's best error=12.5124,\tbest estimator xgboost's best error=10.4075\n",
      "[flaml.automl.logger: 12-16 19:03:28] {2219} INFO - iteration 132, current learner xgboost\n",
      "[flaml.automl.logger: 12-16 19:03:30] {2392} INFO -  at 43.8s,\testimator xgboost's best error=10.4075,\tbest estimator xgboost's best error=10.4075\n",
      "[flaml.automl.logger: 12-16 19:03:30] {2219} INFO - iteration 133, current learner xgboost\n",
      "[flaml.automl.logger: 12-16 19:03:32] {2392} INFO -  at 45.8s,\testimator xgboost's best error=10.2720,\tbest estimator xgboost's best error=10.2720\n",
      "[flaml.automl.logger: 12-16 19:03:32] {2219} INFO - iteration 134, current learner xgboost\n",
      "[flaml.automl.logger: 12-16 19:03:32] {2392} INFO -  at 46.6s,\testimator xgboost's best error=10.2720,\tbest estimator xgboost's best error=10.2720\n",
      "[flaml.automl.logger: 12-16 19:03:32] {2219} INFO - iteration 135, current learner extra_tree\n",
      "[flaml.automl.logger: 12-16 19:03:33] {2392} INFO -  at 46.8s,\testimator extra_tree's best error=12.5124,\tbest estimator xgboost's best error=10.2720\n",
      "[flaml.automl.logger: 12-16 19:03:33] {2219} INFO - iteration 136, current learner xgboost\n",
      "[flaml.automl.logger: 12-16 19:03:39] {2392} INFO -  at 53.4s,\testimator xgboost's best error=10.2720,\tbest estimator xgboost's best error=10.2720\n",
      "[flaml.automl.logger: 12-16 19:03:39] {2219} INFO - iteration 137, current learner xgboost\n",
      "[flaml.automl.logger: 12-16 19:03:42] {2392} INFO -  at 55.7s,\testimator xgboost's best error=10.2720,\tbest estimator xgboost's best error=10.2720\n",
      "[flaml.automl.logger: 12-16 19:03:42] {2219} INFO - iteration 138, current learner extra_tree\n",
      "[flaml.automl.logger: 12-16 19:03:42] {2392} INFO -  at 55.9s,\testimator extra_tree's best error=12.5124,\tbest estimator xgboost's best error=10.2720\n",
      "[flaml.automl.logger: 12-16 19:03:42] {2219} INFO - iteration 139, current learner xgboost\n",
      "[flaml.automl.logger: 12-16 19:03:44] {2392} INFO -  at 57.8s,\testimator xgboost's best error=10.0972,\tbest estimator xgboost's best error=10.0972\n",
      "[flaml.automl.logger: 12-16 19:03:44] {2219} INFO - iteration 140, current learner extra_tree\n",
      "[flaml.automl.logger: 12-16 19:03:44] {2392} INFO -  at 58.0s,\testimator extra_tree's best error=12.5124,\tbest estimator xgboost's best error=10.0972\n",
      "[flaml.automl.logger: 12-16 19:03:44] {2219} INFO - iteration 141, current learner xgboost\n",
      "[flaml.automl.logger: 12-16 19:03:44] {2392} INFO -  at 58.5s,\testimator xgboost's best error=10.0972,\tbest estimator xgboost's best error=10.0972\n",
      "[flaml.automl.logger: 12-16 19:03:44] {2219} INFO - iteration 142, current learner extra_tree\n",
      "[flaml.automl.logger: 12-16 19:03:45] {2392} INFO -  at 58.7s,\testimator extra_tree's best error=12.5124,\tbest estimator xgboost's best error=10.0972\n",
      "[flaml.automl.logger: 12-16 19:03:45] {2219} INFO - iteration 143, current learner extra_tree\n",
      "[flaml.automl.logger: 12-16 19:03:45] {2392} INFO -  at 59.0s,\testimator extra_tree's best error=12.5124,\tbest estimator xgboost's best error=10.0972\n",
      "[flaml.automl.logger: 12-16 19:03:45] {2219} INFO - iteration 144, current learner extra_tree\n",
      "[flaml.automl.logger: 12-16 19:03:45] {2392} INFO -  at 59.2s,\testimator extra_tree's best error=12.5124,\tbest estimator xgboost's best error=10.0972\n",
      "[flaml.automl.logger: 12-16 19:03:45] {2219} INFO - iteration 145, current learner extra_tree\n",
      "[flaml.automl.logger: 12-16 19:03:45] {2392} INFO -  at 59.5s,\testimator extra_tree's best error=12.5124,\tbest estimator xgboost's best error=10.0972\n",
      "[flaml.automl.logger: 12-16 19:03:45] {2219} INFO - iteration 146, current learner extra_tree\n",
      "[flaml.automl.logger: 12-16 19:03:46] {2392} INFO -  at 59.8s,\testimator extra_tree's best error=12.5124,\tbest estimator xgboost's best error=10.0972\n",
      "[flaml.automl.logger: 12-16 19:03:46] {2219} INFO - iteration 147, current learner extra_tree\n",
      "[flaml.automl.logger: 12-16 19:03:46] {2392} INFO -  at 59.9s,\testimator extra_tree's best error=12.5124,\tbest estimator xgboost's best error=10.0972\n",
      "[flaml.automl.logger: 12-16 19:03:46] {2628} INFO - retrain xgboost for 0.6s\n",
      "[flaml.automl.logger: 12-16 19:03:46] {2631} INFO - retrained model: XGBRegressor(base_score=None, booster=None, callbacks=[],\n",
      "             colsample_bylevel=0.9071630278331562, colsample_bynode=None,\n",
      "             colsample_bytree=0.9019064002023752, device=None,\n",
      "             early_stopping_rounds=None, enable_categorical=False,\n",
      "             eval_metric=None, feature_types=None, gamma=None,\n",
      "             grow_policy='lossguide', importance_type=None,\n",
      "             interaction_constraints=None, learning_rate=0.01749038763148113,\n",
      "             max_bin=None, max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "             max_delta_step=None, max_depth=0, max_leaves=7,\n",
      "             min_child_weight=0.24896890529521287, missing=nan,\n",
      "             monotone_constraints=None, multi_strategy=None, n_estimators=1169,\n",
      "             n_jobs=-1, num_parallel_tree=None, random_state=None, ...)\n",
      "[flaml.automl.logger: 12-16 19:03:46] {1931} INFO - fit succeeded\n",
      "[flaml.automl.logger: 12-16 19:03:46] {1932} INFO - Time taken to find the best model: 57.80294942855835\n"
     ]
    }
   ],
   "source": [
    "caml.auto_nuisance_functions(\n",
    "    flaml_Y_kwargs={\"time_budget\": 60},\n",
    "    flaml_T_kwargs={\"time_budget\": 60},\n",
    "    use_ray=False,\n",
    "    use_spark=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fit and ensemble CATE models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[flaml.automl.logger: 12-16 19:03:50] {1680} INFO - task = regression\n",
      "[flaml.automl.logger: 12-16 19:03:50] {1691} INFO - Evaluation method: cv\n",
      "[flaml.automl.logger: 12-16 19:03:50] {1789} INFO - Minimizing error metric: mse\n",
      "[flaml.automl.logger: 12-16 19:03:50] {1901} INFO - List of ML learners in AutoML Run: ['lgbm', 'rf', 'xgboost', 'extra_tree', 'xgb_limitdepth']\n",
      "[flaml.automl.logger: 12-16 19:03:50] {2219} INFO - iteration 0, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:03:53] {2345} INFO - Estimated sufficient time budget=28991s. Estimated necessary time budget=204s.\n",
      "[flaml.automl.logger: 12-16 19:03:53] {2392} INFO -  at 2.9s,\testimator lgbm's best error=1043.5261,\tbest estimator lgbm's best error=1043.5261\n",
      "[flaml.automl.logger: 12-16 19:03:53] {2219} INFO - iteration 1, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:03:56] {2392} INFO -  at 5.8s,\testimator lgbm's best error=1043.5261,\tbest estimator lgbm's best error=1043.5261\n",
      "[flaml.automl.logger: 12-16 19:03:56] {2219} INFO - iteration 2, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:03:59] {2392} INFO -  at 8.6s,\testimator lgbm's best error=901.5923,\tbest estimator lgbm's best error=901.5923\n",
      "[flaml.automl.logger: 12-16 19:03:59] {2219} INFO - iteration 3, current learner xgboost\n",
      "[flaml.automl.logger: 12-16 19:03:59] {2392} INFO -  at 8.7s,\testimator xgboost's best error=1075.2196,\tbest estimator lgbm's best error=901.5923\n",
      "[flaml.automl.logger: 12-16 19:03:59] {2219} INFO - iteration 4, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:04] {2392} INFO -  at 14.4s,\testimator lgbm's best error=901.5923,\tbest estimator lgbm's best error=901.5923\n",
      "[flaml.automl.logger: 12-16 19:04:04] {2219} INFO - iteration 5, current learner xgboost\n",
      "[flaml.automl.logger: 12-16 19:04:05] {2392} INFO -  at 14.4s,\testimator xgboost's best error=1075.2196,\tbest estimator lgbm's best error=901.5923\n",
      "[flaml.automl.logger: 12-16 19:04:05] {2219} INFO - iteration 6, current learner xgboost\n",
      "[flaml.automl.logger: 12-16 19:04:05] {2392} INFO -  at 14.4s,\testimator xgboost's best error=1053.7512,\tbest estimator lgbm's best error=901.5923\n",
      "[flaml.automl.logger: 12-16 19:04:05] {2219} INFO - iteration 7, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:07] {2392} INFO -  at 17.3s,\testimator lgbm's best error=901.5923,\tbest estimator lgbm's best error=901.5923\n",
      "[flaml.automl.logger: 12-16 19:04:07] {2219} INFO - iteration 8, current learner xgboost\n",
      "[flaml.automl.logger: 12-16 19:04:07] {2392} INFO -  at 17.3s,\testimator xgboost's best error=1014.3005,\tbest estimator lgbm's best error=901.5923\n",
      "[flaml.automl.logger: 12-16 19:04:07] {2219} INFO - iteration 9, current learner xgboost\n",
      "[flaml.automl.logger: 12-16 19:04:07] {2392} INFO -  at 17.3s,\testimator xgboost's best error=985.4234,\tbest estimator lgbm's best error=901.5923\n",
      "[flaml.automl.logger: 12-16 19:04:07] {2219} INFO - iteration 10, current learner xgboost\n",
      "[flaml.automl.logger: 12-16 19:04:07] {2392} INFO -  at 17.4s,\testimator xgboost's best error=985.4234,\tbest estimator lgbm's best error=901.5923\n",
      "[flaml.automl.logger: 12-16 19:04:07] {2219} INFO - iteration 11, current learner xgboost\n",
      "[flaml.automl.logger: 12-16 19:04:07] {2392} INFO -  at 17.4s,\testimator xgboost's best error=965.1382,\tbest estimator lgbm's best error=901.5923\n",
      "[flaml.automl.logger: 12-16 19:04:07] {2219} INFO - iteration 12, current learner xgboost\n",
      "[flaml.automl.logger: 12-16 19:04:08] {2392} INFO -  at 17.4s,\testimator xgboost's best error=965.1382,\tbest estimator lgbm's best error=901.5923\n",
      "[flaml.automl.logger: 12-16 19:04:08] {2219} INFO - iteration 13, current learner xgboost\n",
      "[flaml.automl.logger: 12-16 19:04:08] {2392} INFO -  at 17.5s,\testimator xgboost's best error=965.1382,\tbest estimator lgbm's best error=901.5923\n",
      "[flaml.automl.logger: 12-16 19:04:08] {2219} INFO - iteration 14, current learner xgboost\n",
      "[flaml.automl.logger: 12-16 19:04:08] {2392} INFO -  at 17.5s,\testimator xgboost's best error=965.1382,\tbest estimator lgbm's best error=901.5923\n",
      "[flaml.automl.logger: 12-16 19:04:08] {2219} INFO - iteration 15, current learner xgboost\n",
      "[flaml.automl.logger: 12-16 19:04:08] {2392} INFO -  at 17.5s,\testimator xgboost's best error=965.1382,\tbest estimator lgbm's best error=901.5923\n",
      "[flaml.automl.logger: 12-16 19:04:08] {2219} INFO - iteration 16, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:12] {2392} INFO -  at 21.6s,\testimator lgbm's best error=886.5582,\tbest estimator lgbm's best error=886.5582\n",
      "[flaml.automl.logger: 12-16 19:04:12] {2219} INFO - iteration 17, current learner xgboost\n",
      "[flaml.automl.logger: 12-16 19:04:12] {2392} INFO -  at 21.6s,\testimator xgboost's best error=965.1382,\tbest estimator lgbm's best error=886.5582\n",
      "[flaml.automl.logger: 12-16 19:04:12] {2219} INFO - iteration 18, current learner xgboost\n",
      "[flaml.automl.logger: 12-16 19:04:12] {2392} INFO -  at 21.6s,\testimator xgboost's best error=965.1382,\tbest estimator lgbm's best error=886.5582\n",
      "[flaml.automl.logger: 12-16 19:04:12] {2219} INFO - iteration 19, current learner xgboost\n",
      "[flaml.automl.logger: 12-16 19:04:12] {2392} INFO -  at 21.7s,\testimator xgboost's best error=965.1382,\tbest estimator lgbm's best error=886.5582\n",
      "[flaml.automl.logger: 12-16 19:04:12] {2219} INFO - iteration 20, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:15] {2392} INFO -  at 24.5s,\testimator lgbm's best error=886.5582,\tbest estimator lgbm's best error=886.5582\n",
      "[flaml.automl.logger: 12-16 19:04:15] {2219} INFO - iteration 21, current learner xgboost\n",
      "[flaml.automl.logger: 12-16 19:04:15] {2392} INFO -  at 24.5s,\testimator xgboost's best error=901.7258,\tbest estimator lgbm's best error=886.5582\n",
      "[flaml.automl.logger: 12-16 19:04:15] {2219} INFO - iteration 22, current learner xgboost\n",
      "[flaml.automl.logger: 12-16 19:04:15] {2392} INFO -  at 24.6s,\testimator xgboost's best error=901.7258,\tbest estimator lgbm's best error=886.5582\n",
      "[flaml.automl.logger: 12-16 19:04:15] {2219} INFO - iteration 23, current learner xgboost\n",
      "[flaml.automl.logger: 12-16 19:04:15] {2392} INFO -  at 24.6s,\testimator xgboost's best error=901.7258,\tbest estimator lgbm's best error=886.5582\n",
      "[flaml.automl.logger: 12-16 19:04:15] {2219} INFO - iteration 24, current learner xgboost\n",
      "[flaml.automl.logger: 12-16 19:04:15] {2392} INFO -  at 24.7s,\testimator xgboost's best error=901.7258,\tbest estimator lgbm's best error=886.5582\n",
      "[flaml.automl.logger: 12-16 19:04:15] {2219} INFO - iteration 25, current learner xgboost\n",
      "[flaml.automl.logger: 12-16 19:04:15] {2392} INFO -  at 24.7s,\testimator xgboost's best error=873.9739,\tbest estimator xgboost's best error=873.9739\n",
      "[flaml.automl.logger: 12-16 19:04:15] {2219} INFO - iteration 26, current learner xgboost\n",
      "[flaml.automl.logger: 12-16 19:04:15] {2392} INFO -  at 24.7s,\testimator xgboost's best error=873.9739,\tbest estimator xgboost's best error=873.9739\n",
      "[flaml.automl.logger: 12-16 19:04:15] {2219} INFO - iteration 27, current learner xgboost\n",
      "[flaml.automl.logger: 12-16 19:04:15] {2392} INFO -  at 25.0s,\testimator xgboost's best error=873.9739,\tbest estimator xgboost's best error=873.9739\n",
      "[flaml.automl.logger: 12-16 19:04:15] {2219} INFO - iteration 28, current learner xgboost\n",
      "[flaml.automl.logger: 12-16 19:04:15] {2392} INFO -  at 25.0s,\testimator xgboost's best error=873.9739,\tbest estimator xgboost's best error=873.9739\n",
      "[flaml.automl.logger: 12-16 19:04:15] {2219} INFO - iteration 29, current learner xgboost\n",
      "[flaml.automl.logger: 12-16 19:04:15] {2392} INFO -  at 25.1s,\testimator xgboost's best error=873.9739,\tbest estimator xgboost's best error=873.9739\n",
      "[flaml.automl.logger: 12-16 19:04:15] {2219} INFO - iteration 30, current learner xgboost\n",
      "[flaml.automl.logger: 12-16 19:04:15] {2392} INFO -  at 25.2s,\testimator xgboost's best error=873.9739,\tbest estimator xgboost's best error=873.9739\n",
      "[flaml.automl.logger: 12-16 19:04:15] {2219} INFO - iteration 31, current learner xgboost\n",
      "[flaml.automl.logger: 12-16 19:04:15] {2392} INFO -  at 25.2s,\testimator xgboost's best error=866.4737,\tbest estimator xgboost's best error=866.4737\n",
      "[flaml.automl.logger: 12-16 19:04:15] {2219} INFO - iteration 32, current learner xgboost\n",
      "[flaml.automl.logger: 12-16 19:04:15] {2392} INFO -  at 25.3s,\testimator xgboost's best error=866.4737,\tbest estimator xgboost's best error=866.4737\n",
      "[flaml.automl.logger: 12-16 19:04:15] {2219} INFO - iteration 33, current learner xgboost\n",
      "[flaml.automl.logger: 12-16 19:04:16] {2392} INFO -  at 25.6s,\testimator xgboost's best error=866.4737,\tbest estimator xgboost's best error=866.4737\n",
      "[flaml.automl.logger: 12-16 19:04:16] {2219} INFO - iteration 34, current learner xgboost\n",
      "[flaml.automl.logger: 12-16 19:04:16] {2392} INFO -  at 25.6s,\testimator xgboost's best error=862.9837,\tbest estimator xgboost's best error=862.9837\n",
      "[flaml.automl.logger: 12-16 19:04:16] {2219} INFO - iteration 35, current learner xgboost\n",
      "[flaml.automl.logger: 12-16 19:04:16] {2392} INFO -  at 25.7s,\testimator xgboost's best error=862.9837,\tbest estimator xgboost's best error=862.9837\n",
      "[flaml.automl.logger: 12-16 19:04:16] {2219} INFO - iteration 36, current learner xgboost\n",
      "[flaml.automl.logger: 12-16 19:04:16] {2392} INFO -  at 25.8s,\testimator xgboost's best error=862.9837,\tbest estimator xgboost's best error=862.9837\n",
      "[flaml.automl.logger: 12-16 19:04:16] {2219} INFO - iteration 37, current learner xgboost\n",
      "[flaml.automl.logger: 12-16 19:04:16] {2392} INFO -  at 25.9s,\testimator xgboost's best error=813.0451,\tbest estimator xgboost's best error=813.0451\n",
      "[flaml.automl.logger: 12-16 19:04:16] {2219} INFO - iteration 38, current learner xgboost\n",
      "[flaml.automl.logger: 12-16 19:04:16] {2392} INFO -  at 26.2s,\testimator xgboost's best error=810.0528,\tbest estimator xgboost's best error=810.0528\n",
      "[flaml.automl.logger: 12-16 19:04:16] {2219} INFO - iteration 39, current learner xgboost\n",
      "[flaml.automl.logger: 12-16 19:04:16] {2392} INFO -  at 26.4s,\testimator xgboost's best error=810.0528,\tbest estimator xgboost's best error=810.0528\n",
      "[flaml.automl.logger: 12-16 19:04:16] {2219} INFO - iteration 40, current learner xgboost\n",
      "[flaml.automl.logger: 12-16 19:04:17] {2392} INFO -  at 26.8s,\testimator xgboost's best error=810.0528,\tbest estimator xgboost's best error=810.0528\n",
      "[flaml.automl.logger: 12-16 19:04:17] {2219} INFO - iteration 41, current learner xgboost\n",
      "[flaml.automl.logger: 12-16 19:04:17] {2392} INFO -  at 27.0s,\testimator xgboost's best error=810.0528,\tbest estimator xgboost's best error=810.0528\n",
      "[flaml.automl.logger: 12-16 19:04:17] {2219} INFO - iteration 42, current learner xgboost\n",
      "[flaml.automl.logger: 12-16 19:04:18] {2392} INFO -  at 28.2s,\testimator xgboost's best error=810.0528,\tbest estimator xgboost's best error=810.0528\n",
      "[flaml.automl.logger: 12-16 19:04:18] {2219} INFO - iteration 43, current learner xgboost\n",
      "[flaml.automl.logger: 12-16 19:04:18] {2392} INFO -  at 28.3s,\testimator xgboost's best error=810.0528,\tbest estimator xgboost's best error=810.0528\n",
      "[flaml.automl.logger: 12-16 19:04:18] {2219} INFO - iteration 44, current learner xgboost\n",
      "[flaml.automl.logger: 12-16 19:04:19] {2392} INFO -  at 28.7s,\testimator xgboost's best error=810.0528,\tbest estimator xgboost's best error=810.0528\n",
      "[flaml.automl.logger: 12-16 19:04:19] {2219} INFO - iteration 45, current learner xgboost\n",
      "[flaml.automl.logger: 12-16 19:04:19] {2392} INFO -  at 29.0s,\testimator xgboost's best error=810.0528,\tbest estimator xgboost's best error=810.0528\n",
      "[flaml.automl.logger: 12-16 19:04:19] {2219} INFO - iteration 46, current learner xgboost\n",
      "[flaml.automl.logger: 12-16 19:04:19] {2392} INFO -  at 29.3s,\testimator xgboost's best error=810.0528,\tbest estimator xgboost's best error=810.0528\n",
      "[flaml.automl.logger: 12-16 19:04:19] {2219} INFO - iteration 47, current learner xgboost\n",
      "[flaml.automl.logger: 12-16 19:04:20] {2392} INFO -  at 29.5s,\testimator xgboost's best error=810.0528,\tbest estimator xgboost's best error=810.0528\n",
      "[flaml.automl.logger: 12-16 19:04:20] {2219} INFO - iteration 48, current learner xgboost\n",
      "[flaml.automl.logger: 12-16 19:04:20] {2392} INFO -  at 29.6s,\testimator xgboost's best error=810.0528,\tbest estimator xgboost's best error=810.0528\n",
      "[flaml.automl.logger: 12-16 19:04:20] {2219} INFO - iteration 49, current learner xgboost\n",
      "[flaml.automl.logger: 12-16 19:04:21] {2392} INFO -  at 30.5s,\testimator xgboost's best error=810.0528,\tbest estimator xgboost's best error=810.0528\n",
      "[flaml.automl.logger: 12-16 19:04:21] {2219} INFO - iteration 50, current learner xgboost\n",
      "[flaml.automl.logger: 12-16 19:04:21] {2392} INFO -  at 30.9s,\testimator xgboost's best error=810.0528,\tbest estimator xgboost's best error=810.0528\n",
      "[flaml.automl.logger: 12-16 19:04:21] {2219} INFO - iteration 51, current learner xgboost\n",
      "[flaml.automl.logger: 12-16 19:04:21] {2392} INFO -  at 31.1s,\testimator xgboost's best error=810.0528,\tbest estimator xgboost's best error=810.0528\n",
      "[flaml.automl.logger: 12-16 19:04:21] {2219} INFO - iteration 52, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:21] {2392} INFO -  at 31.2s,\testimator lgbm's best error=823.9456,\tbest estimator xgboost's best error=810.0528\n",
      "[flaml.automl.logger: 12-16 19:04:21] {2219} INFO - iteration 53, current learner xgboost\n",
      "[flaml.automl.logger: 12-16 19:04:22] {2392} INFO -  at 31.7s,\testimator xgboost's best error=810.0528,\tbest estimator xgboost's best error=810.0528\n",
      "[flaml.automl.logger: 12-16 19:04:22] {2219} INFO - iteration 54, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:22] {2392} INFO -  at 31.8s,\testimator lgbm's best error=823.9456,\tbest estimator xgboost's best error=810.0528\n",
      "[flaml.automl.logger: 12-16 19:04:22] {2219} INFO - iteration 55, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:22] {2392} INFO -  at 31.8s,\testimator lgbm's best error=823.9456,\tbest estimator xgboost's best error=810.0528\n",
      "[flaml.automl.logger: 12-16 19:04:22] {2219} INFO - iteration 56, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:22] {2392} INFO -  at 31.8s,\testimator lgbm's best error=823.9456,\tbest estimator xgboost's best error=810.0528\n",
      "[flaml.automl.logger: 12-16 19:04:22] {2219} INFO - iteration 57, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:22] {2392} INFO -  at 31.9s,\testimator lgbm's best error=823.9456,\tbest estimator xgboost's best error=810.0528\n",
      "[flaml.automl.logger: 12-16 19:04:22] {2219} INFO - iteration 58, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:22] {2392} INFO -  at 31.9s,\testimator lgbm's best error=823.9456,\tbest estimator xgboost's best error=810.0528\n",
      "[flaml.automl.logger: 12-16 19:04:22] {2219} INFO - iteration 59, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:22] {2392} INFO -  at 31.9s,\testimator lgbm's best error=823.9456,\tbest estimator xgboost's best error=810.0528\n",
      "[flaml.automl.logger: 12-16 19:04:22] {2219} INFO - iteration 60, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:22] {2392} INFO -  at 31.9s,\testimator lgbm's best error=823.9456,\tbest estimator xgboost's best error=810.0528\n",
      "[flaml.automl.logger: 12-16 19:04:22] {2219} INFO - iteration 61, current learner xgboost\n",
      "[flaml.automl.logger: 12-16 19:04:22] {2392} INFO -  at 32.1s,\testimator xgboost's best error=810.0528,\tbest estimator xgboost's best error=810.0528\n",
      "[flaml.automl.logger: 12-16 19:04:22] {2219} INFO - iteration 62, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:22] {2392} INFO -  at 32.1s,\testimator lgbm's best error=823.9456,\tbest estimator xgboost's best error=810.0528\n",
      "[flaml.automl.logger: 12-16 19:04:22] {2219} INFO - iteration 63, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:22] {2392} INFO -  at 32.1s,\testimator lgbm's best error=823.9456,\tbest estimator xgboost's best error=810.0528\n",
      "[flaml.automl.logger: 12-16 19:04:22] {2219} INFO - iteration 64, current learner xgboost\n",
      "[flaml.automl.logger: 12-16 19:04:23] {2392} INFO -  at 32.5s,\testimator xgboost's best error=810.0528,\tbest estimator xgboost's best error=810.0528\n",
      "[flaml.automl.logger: 12-16 19:04:23] {2219} INFO - iteration 65, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:23] {2392} INFO -  at 32.5s,\testimator lgbm's best error=823.9456,\tbest estimator xgboost's best error=810.0528\n",
      "[flaml.automl.logger: 12-16 19:04:23] {2219} INFO - iteration 66, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:23] {2392} INFO -  at 32.6s,\testimator lgbm's best error=823.9456,\tbest estimator xgboost's best error=810.0528\n",
      "[flaml.automl.logger: 12-16 19:04:23] {2219} INFO - iteration 67, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:23] {2392} INFO -  at 32.6s,\testimator lgbm's best error=823.9456,\tbest estimator xgboost's best error=810.0528\n",
      "[flaml.automl.logger: 12-16 19:04:23] {2219} INFO - iteration 68, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:23] {2392} INFO -  at 32.6s,\testimator lgbm's best error=823.9456,\tbest estimator xgboost's best error=810.0528\n",
      "[flaml.automl.logger: 12-16 19:04:23] {2219} INFO - iteration 69, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:23] {2392} INFO -  at 32.7s,\testimator lgbm's best error=823.9456,\tbest estimator xgboost's best error=810.0528\n",
      "[flaml.automl.logger: 12-16 19:04:23] {2219} INFO - iteration 70, current learner xgboost\n",
      "[flaml.automl.logger: 12-16 19:04:23] {2392} INFO -  at 33.0s,\testimator xgboost's best error=810.0528,\tbest estimator xgboost's best error=810.0528\n",
      "[flaml.automl.logger: 12-16 19:04:23] {2219} INFO - iteration 71, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:23] {2392} INFO -  at 33.0s,\testimator lgbm's best error=823.9456,\tbest estimator xgboost's best error=810.0528\n",
      "[flaml.automl.logger: 12-16 19:04:23] {2219} INFO - iteration 72, current learner xgboost\n",
      "[flaml.automl.logger: 12-16 19:04:23] {2392} INFO -  at 33.3s,\testimator xgboost's best error=810.0528,\tbest estimator xgboost's best error=810.0528\n",
      "[flaml.automl.logger: 12-16 19:04:23] {2219} INFO - iteration 73, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:23] {2392} INFO -  at 33.3s,\testimator lgbm's best error=823.9456,\tbest estimator xgboost's best error=810.0528\n",
      "[flaml.automl.logger: 12-16 19:04:23] {2219} INFO - iteration 74, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:23] {2392} INFO -  at 33.4s,\testimator lgbm's best error=823.9456,\tbest estimator xgboost's best error=810.0528\n",
      "[flaml.automl.logger: 12-16 19:04:23] {2219} INFO - iteration 75, current learner xgboost\n",
      "[flaml.automl.logger: 12-16 19:04:24] {2392} INFO -  at 33.7s,\testimator xgboost's best error=810.0528,\tbest estimator xgboost's best error=810.0528\n",
      "[flaml.automl.logger: 12-16 19:04:24] {2219} INFO - iteration 76, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:24] {2392} INFO -  at 33.7s,\testimator lgbm's best error=823.9456,\tbest estimator xgboost's best error=810.0528\n",
      "[flaml.automl.logger: 12-16 19:04:24] {2219} INFO - iteration 77, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:24] {2392} INFO -  at 33.7s,\testimator lgbm's best error=823.9456,\tbest estimator xgboost's best error=810.0528\n",
      "[flaml.automl.logger: 12-16 19:04:24] {2219} INFO - iteration 78, current learner xgboost\n",
      "[flaml.automl.logger: 12-16 19:04:24] {2392} INFO -  at 34.3s,\testimator xgboost's best error=810.0528,\tbest estimator xgboost's best error=810.0528\n",
      "[flaml.automl.logger: 12-16 19:04:24] {2219} INFO - iteration 79, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:24] {2392} INFO -  at 34.4s,\testimator lgbm's best error=823.9456,\tbest estimator xgboost's best error=810.0528\n",
      "[flaml.automl.logger: 12-16 19:04:24] {2219} INFO - iteration 80, current learner xgboost\n",
      "[flaml.automl.logger: 12-16 19:04:25] {2392} INFO -  at 34.5s,\testimator xgboost's best error=810.0528,\tbest estimator xgboost's best error=810.0528\n",
      "[flaml.automl.logger: 12-16 19:04:25] {2219} INFO - iteration 81, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:25] {2392} INFO -  at 34.6s,\testimator lgbm's best error=823.9456,\tbest estimator xgboost's best error=810.0528\n",
      "[flaml.automl.logger: 12-16 19:04:25] {2219} INFO - iteration 82, current learner xgboost\n",
      "[flaml.automl.logger: 12-16 19:04:25] {2392} INFO -  at 34.9s,\testimator xgboost's best error=810.0528,\tbest estimator xgboost's best error=810.0528\n",
      "[flaml.automl.logger: 12-16 19:04:25] {2219} INFO - iteration 83, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:25] {2392} INFO -  at 34.9s,\testimator lgbm's best error=823.9456,\tbest estimator xgboost's best error=810.0528\n",
      "[flaml.automl.logger: 12-16 19:04:25] {2219} INFO - iteration 84, current learner xgboost\n",
      "[flaml.automl.logger: 12-16 19:04:25] {2392} INFO -  at 35.2s,\testimator xgboost's best error=810.0528,\tbest estimator xgboost's best error=810.0528\n",
      "[flaml.automl.logger: 12-16 19:04:25] {2219} INFO - iteration 85, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:25] {2392} INFO -  at 35.2s,\testimator lgbm's best error=823.9456,\tbest estimator xgboost's best error=810.0528\n",
      "[flaml.automl.logger: 12-16 19:04:25] {2219} INFO - iteration 86, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:25] {2392} INFO -  at 35.3s,\testimator lgbm's best error=823.9456,\tbest estimator xgboost's best error=810.0528\n",
      "[flaml.automl.logger: 12-16 19:04:25] {2219} INFO - iteration 87, current learner xgboost\n",
      "[flaml.automl.logger: 12-16 19:04:26] {2392} INFO -  at 35.5s,\testimator xgboost's best error=810.0528,\tbest estimator xgboost's best error=810.0528\n",
      "[flaml.automl.logger: 12-16 19:04:26] {2219} INFO - iteration 88, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:26] {2392} INFO -  at 35.6s,\testimator lgbm's best error=803.0640,\tbest estimator lgbm's best error=803.0640\n",
      "[flaml.automl.logger: 12-16 19:04:26] {2219} INFO - iteration 89, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:26] {2392} INFO -  at 35.6s,\testimator lgbm's best error=803.0640,\tbest estimator lgbm's best error=803.0640\n",
      "[flaml.automl.logger: 12-16 19:04:26] {2219} INFO - iteration 90, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:26] {2392} INFO -  at 35.7s,\testimator lgbm's best error=803.0640,\tbest estimator lgbm's best error=803.0640\n",
      "[flaml.automl.logger: 12-16 19:04:26] {2219} INFO - iteration 91, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:26] {2392} INFO -  at 35.7s,\testimator lgbm's best error=803.0640,\tbest estimator lgbm's best error=803.0640\n",
      "[flaml.automl.logger: 12-16 19:04:26] {2219} INFO - iteration 92, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:26] {2392} INFO -  at 35.7s,\testimator lgbm's best error=803.0640,\tbest estimator lgbm's best error=803.0640\n",
      "[flaml.automl.logger: 12-16 19:04:26] {2219} INFO - iteration 93, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:26] {2392} INFO -  at 35.8s,\testimator lgbm's best error=803.0640,\tbest estimator lgbm's best error=803.0640\n",
      "[flaml.automl.logger: 12-16 19:04:26] {2219} INFO - iteration 94, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:26] {2392} INFO -  at 35.8s,\testimator lgbm's best error=803.0640,\tbest estimator lgbm's best error=803.0640\n",
      "[flaml.automl.logger: 12-16 19:04:26] {2219} INFO - iteration 95, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:26] {2392} INFO -  at 35.8s,\testimator lgbm's best error=803.0640,\tbest estimator lgbm's best error=803.0640\n",
      "[flaml.automl.logger: 12-16 19:04:26] {2219} INFO - iteration 96, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:26] {2392} INFO -  at 35.9s,\testimator lgbm's best error=803.0640,\tbest estimator lgbm's best error=803.0640\n",
      "[flaml.automl.logger: 12-16 19:04:26] {2219} INFO - iteration 97, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:26] {2392} INFO -  at 35.9s,\testimator lgbm's best error=803.0640,\tbest estimator lgbm's best error=803.0640\n",
      "[flaml.automl.logger: 12-16 19:04:26] {2219} INFO - iteration 98, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:26] {2392} INFO -  at 36.0s,\testimator lgbm's best error=803.0640,\tbest estimator lgbm's best error=803.0640\n",
      "[flaml.automl.logger: 12-16 19:04:26] {2219} INFO - iteration 99, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:26] {2392} INFO -  at 36.0s,\testimator lgbm's best error=803.0640,\tbest estimator lgbm's best error=803.0640\n",
      "[flaml.automl.logger: 12-16 19:04:26] {2219} INFO - iteration 100, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:26] {2392} INFO -  at 36.0s,\testimator lgbm's best error=803.0640,\tbest estimator lgbm's best error=803.0640\n",
      "[flaml.automl.logger: 12-16 19:04:26] {2219} INFO - iteration 101, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:26] {2392} INFO -  at 36.1s,\testimator lgbm's best error=803.0640,\tbest estimator lgbm's best error=803.0640\n",
      "[flaml.automl.logger: 12-16 19:04:26] {2219} INFO - iteration 102, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:26] {2392} INFO -  at 36.1s,\testimator lgbm's best error=803.0640,\tbest estimator lgbm's best error=803.0640\n",
      "[flaml.automl.logger: 12-16 19:04:26] {2219} INFO - iteration 103, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:26] {2392} INFO -  at 36.1s,\testimator lgbm's best error=803.0640,\tbest estimator lgbm's best error=803.0640\n",
      "[flaml.automl.logger: 12-16 19:04:26] {2219} INFO - iteration 104, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:26] {2392} INFO -  at 36.2s,\testimator lgbm's best error=803.0640,\tbest estimator lgbm's best error=803.0640\n",
      "[flaml.automl.logger: 12-16 19:04:26] {2219} INFO - iteration 105, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:26] {2392} INFO -  at 36.2s,\testimator lgbm's best error=803.0640,\tbest estimator lgbm's best error=803.0640\n",
      "[flaml.automl.logger: 12-16 19:04:26] {2219} INFO - iteration 106, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:26] {2392} INFO -  at 36.3s,\testimator lgbm's best error=803.0640,\tbest estimator lgbm's best error=803.0640\n",
      "[flaml.automl.logger: 12-16 19:04:26] {2219} INFO - iteration 107, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:26] {2392} INFO -  at 36.4s,\testimator lgbm's best error=803.0640,\tbest estimator lgbm's best error=803.0640\n",
      "[flaml.automl.logger: 12-16 19:04:26] {2219} INFO - iteration 108, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:27] {2392} INFO -  at 36.5s,\testimator lgbm's best error=803.0640,\tbest estimator lgbm's best error=803.0640\n",
      "[flaml.automl.logger: 12-16 19:04:27] {2219} INFO - iteration 109, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:27] {2392} INFO -  at 36.5s,\testimator lgbm's best error=794.3361,\tbest estimator lgbm's best error=794.3361\n",
      "[flaml.automl.logger: 12-16 19:04:27] {2219} INFO - iteration 110, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:27] {2392} INFO -  at 36.5s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:27] {2219} INFO - iteration 111, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:27] {2392} INFO -  at 36.6s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:27] {2219} INFO - iteration 112, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:27] {2392} INFO -  at 36.6s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:27] {2219} INFO - iteration 113, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:27] {2392} INFO -  at 36.6s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:27] {2219} INFO - iteration 114, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:27] {2392} INFO -  at 36.7s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:27] {2219} INFO - iteration 115, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:27] {2392} INFO -  at 36.7s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:27] {2219} INFO - iteration 116, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:27] {2392} INFO -  at 36.7s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:27] {2219} INFO - iteration 117, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:27] {2392} INFO -  at 36.8s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:27] {2219} INFO - iteration 118, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:27] {2392} INFO -  at 36.8s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:27] {2219} INFO - iteration 119, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:27] {2392} INFO -  at 36.8s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:27] {2219} INFO - iteration 120, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:27] {2392} INFO -  at 36.9s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:27] {2219} INFO - iteration 121, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:27] {2392} INFO -  at 36.9s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:27] {2219} INFO - iteration 122, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:27] {2392} INFO -  at 36.9s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:27] {2219} INFO - iteration 123, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:27] {2392} INFO -  at 37.0s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:27] {2219} INFO - iteration 124, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:27] {2392} INFO -  at 37.1s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:27] {2219} INFO - iteration 125, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:27] {2392} INFO -  at 37.2s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:27] {2219} INFO - iteration 126, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:27] {2392} INFO -  at 37.2s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:27] {2219} INFO - iteration 127, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:27] {2392} INFO -  at 37.2s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:27] {2219} INFO - iteration 128, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:27] {2392} INFO -  at 37.2s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:27] {2219} INFO - iteration 129, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:27] {2392} INFO -  at 37.3s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:27] {2219} INFO - iteration 130, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:27] {2392} INFO -  at 37.3s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:27] {2219} INFO - iteration 131, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:27] {2392} INFO -  at 37.4s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:27] {2219} INFO - iteration 132, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:27] {2392} INFO -  at 37.4s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:27] {2219} INFO - iteration 133, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:27] {2392} INFO -  at 37.4s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:27] {2219} INFO - iteration 134, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:28] {2392} INFO -  at 37.5s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:28] {2219} INFO - iteration 135, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:28] {2392} INFO -  at 37.6s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:28] {2219} INFO - iteration 136, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:28] {2392} INFO -  at 37.6s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:28] {2219} INFO - iteration 137, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:28] {2392} INFO -  at 37.6s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:28] {2219} INFO - iteration 138, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:28] {2392} INFO -  at 37.7s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:28] {2219} INFO - iteration 139, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:28] {2392} INFO -  at 37.7s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:28] {2219} INFO - iteration 140, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:28] {2392} INFO -  at 37.7s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:28] {2219} INFO - iteration 141, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:28] {2392} INFO -  at 37.8s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:28] {2219} INFO - iteration 142, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:28] {2392} INFO -  at 37.8s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:28] {2219} INFO - iteration 143, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:28] {2392} INFO -  at 37.9s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:28] {2219} INFO - iteration 144, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:28] {2392} INFO -  at 37.9s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:28] {2219} INFO - iteration 145, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:28] {2392} INFO -  at 37.9s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:28] {2219} INFO - iteration 146, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:28] {2392} INFO -  at 38.0s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:28] {2219} INFO - iteration 147, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:28] {2392} INFO -  at 38.0s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:28] {2219} INFO - iteration 148, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:28] {2392} INFO -  at 38.0s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:28] {2219} INFO - iteration 149, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:28] {2392} INFO -  at 38.1s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:28] {2219} INFO - iteration 150, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:28] {2392} INFO -  at 38.1s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:28] {2219} INFO - iteration 151, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:28] {2392} INFO -  at 38.2s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:28] {2219} INFO - iteration 152, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:28] {2392} INFO -  at 38.2s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:28] {2219} INFO - iteration 153, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:28] {2392} INFO -  at 38.2s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:28] {2219} INFO - iteration 154, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:28] {2392} INFO -  at 38.3s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:28] {2219} INFO - iteration 155, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:28] {2392} INFO -  at 38.3s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:28] {2219} INFO - iteration 156, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:28] {2392} INFO -  at 38.3s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:28] {2219} INFO - iteration 157, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:28] {2392} INFO -  at 38.4s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:28] {2219} INFO - iteration 158, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:28] {2392} INFO -  at 38.4s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:28] {2219} INFO - iteration 159, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:28] {2392} INFO -  at 38.4s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:28] {2219} INFO - iteration 160, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:29] {2392} INFO -  at 38.5s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:29] {2219} INFO - iteration 161, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:29] {2392} INFO -  at 38.6s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:29] {2219} INFO - iteration 162, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:29] {2392} INFO -  at 38.6s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:29] {2219} INFO - iteration 163, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:29] {2392} INFO -  at 38.6s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:29] {2219} INFO - iteration 164, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:29] {2392} INFO -  at 38.7s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:29] {2219} INFO - iteration 165, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:29] {2392} INFO -  at 38.7s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:29] {2219} INFO - iteration 166, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:29] {2392} INFO -  at 38.7s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:29] {2219} INFO - iteration 167, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:29] {2392} INFO -  at 38.8s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:29] {2219} INFO - iteration 168, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:29] {2392} INFO -  at 38.8s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:29] {2219} INFO - iteration 169, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:29] {2392} INFO -  at 38.8s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:29] {2219} INFO - iteration 170, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:29] {2392} INFO -  at 38.9s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:29] {2219} INFO - iteration 171, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:29] {2392} INFO -  at 38.9s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:29] {2219} INFO - iteration 172, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:29] {2392} INFO -  at 38.9s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:29] {2219} INFO - iteration 173, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:29] {2392} INFO -  at 39.0s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:29] {2219} INFO - iteration 174, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:29] {2392} INFO -  at 39.0s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:29] {2219} INFO - iteration 175, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:29] {2392} INFO -  at 39.0s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:29] {2219} INFO - iteration 176, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:29] {2392} INFO -  at 39.1s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:29] {2219} INFO - iteration 177, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:29] {2392} INFO -  at 39.1s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:29] {2219} INFO - iteration 178, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:29] {2392} INFO -  at 39.1s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:29] {2219} INFO - iteration 179, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:29] {2392} INFO -  at 39.2s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:29] {2219} INFO - iteration 180, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:29] {2392} INFO -  at 39.2s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:29] {2219} INFO - iteration 181, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:29] {2392} INFO -  at 39.2s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:29] {2219} INFO - iteration 182, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:29] {2392} INFO -  at 39.2s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:29] {2219} INFO - iteration 183, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:29] {2392} INFO -  at 39.3s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:29] {2219} INFO - iteration 184, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:29] {2392} INFO -  at 39.4s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:29] {2219} INFO - iteration 185, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:29] {2392} INFO -  at 39.4s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:29] {2219} INFO - iteration 186, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:29] {2392} INFO -  at 39.4s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:29] {2219} INFO - iteration 187, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:30] {2392} INFO -  at 39.4s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:30] {2219} INFO - iteration 188, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:30] {2392} INFO -  at 39.5s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:30] {2219} INFO - iteration 189, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:30] {2392} INFO -  at 39.6s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:30] {2219} INFO - iteration 190, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:30] {2392} INFO -  at 39.6s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:30] {2219} INFO - iteration 191, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:30] {2392} INFO -  at 39.6s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:30] {2219} INFO - iteration 192, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:30] {2392} INFO -  at 39.6s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:30] {2219} INFO - iteration 193, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:30] {2392} INFO -  at 39.7s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:30] {2219} INFO - iteration 194, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:30] {2392} INFO -  at 39.7s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:30] {2219} INFO - iteration 195, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:30] {2392} INFO -  at 39.7s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:30] {2219} INFO - iteration 196, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:30] {2392} INFO -  at 39.8s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:30] {2219} INFO - iteration 197, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:30] {2392} INFO -  at 39.8s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:30] {2219} INFO - iteration 198, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:30] {2392} INFO -  at 39.8s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:30] {2219} INFO - iteration 199, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:30] {2392} INFO -  at 39.9s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:30] {2219} INFO - iteration 200, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:30] {2392} INFO -  at 39.9s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:30] {2219} INFO - iteration 201, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:30] {2392} INFO -  at 39.9s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:30] {2219} INFO - iteration 202, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:30] {2392} INFO -  at 40.0s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:30] {2219} INFO - iteration 203, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:30] {2392} INFO -  at 40.0s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:30] {2219} INFO - iteration 204, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:30] {2392} INFO -  at 40.1s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:30] {2219} INFO - iteration 205, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:30] {2392} INFO -  at 40.1s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:30] {2219} INFO - iteration 206, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:30] {2392} INFO -  at 40.2s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:30] {2219} INFO - iteration 207, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:30] {2392} INFO -  at 40.2s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:30] {2219} INFO - iteration 208, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:30] {2392} INFO -  at 40.2s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:30] {2219} INFO - iteration 209, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:30] {2392} INFO -  at 40.3s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:30] {2219} INFO - iteration 210, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:30] {2392} INFO -  at 40.3s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:30] {2219} INFO - iteration 211, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:30] {2392} INFO -  at 40.3s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:30] {2219} INFO - iteration 212, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:30] {2392} INFO -  at 40.4s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:30] {2219} INFO - iteration 213, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:30] {2392} INFO -  at 40.4s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:30] {2219} INFO - iteration 214, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:31] {2392} INFO -  at 40.5s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:31] {2219} INFO - iteration 215, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:31] {2392} INFO -  at 40.5s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:31] {2219} INFO - iteration 216, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:31] {2392} INFO -  at 40.6s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:31] {2219} INFO - iteration 217, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:31] {2392} INFO -  at 40.6s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:31] {2219} INFO - iteration 218, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:31] {2392} INFO -  at 40.6s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:31] {2219} INFO - iteration 219, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:31] {2392} INFO -  at 40.6s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:31] {2219} INFO - iteration 220, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:31] {2392} INFO -  at 40.6s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:31] {2219} INFO - iteration 221, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:31] {2392} INFO -  at 40.7s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:31] {2219} INFO - iteration 222, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:31] {2392} INFO -  at 40.7s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:31] {2219} INFO - iteration 223, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:31] {2392} INFO -  at 40.7s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:31] {2219} INFO - iteration 224, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:31] {2392} INFO -  at 40.9s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:31] {2219} INFO - iteration 225, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:31] {2392} INFO -  at 40.9s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:31] {2219} INFO - iteration 226, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:31] {2392} INFO -  at 40.9s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:31] {2219} INFO - iteration 227, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:31] {2392} INFO -  at 41.0s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:31] {2219} INFO - iteration 228, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:31] {2392} INFO -  at 41.0s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:31] {2219} INFO - iteration 229, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:31] {2392} INFO -  at 41.0s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:31] {2219} INFO - iteration 230, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:31] {2392} INFO -  at 41.0s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:31] {2219} INFO - iteration 231, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:31] {2392} INFO -  at 41.1s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:31] {2219} INFO - iteration 232, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:31] {2392} INFO -  at 41.1s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:31] {2219} INFO - iteration 233, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:31] {2392} INFO -  at 41.1s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:31] {2219} INFO - iteration 234, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:31] {2392} INFO -  at 41.2s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:31] {2219} INFO - iteration 235, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:31] {2392} INFO -  at 41.2s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:31] {2219} INFO - iteration 236, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:31] {2392} INFO -  at 41.2s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:31] {2219} INFO - iteration 237, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:31] {2392} INFO -  at 41.2s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:31] {2219} INFO - iteration 238, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:31] {2392} INFO -  at 41.3s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:31] {2219} INFO - iteration 239, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:31] {2392} INFO -  at 41.3s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:31] {2219} INFO - iteration 240, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:31] {2392} INFO -  at 41.3s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:31] {2219} INFO - iteration 241, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:31] {2392} INFO -  at 41.3s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:31] {2219} INFO - iteration 242, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:31] {2392} INFO -  at 41.4s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:31] {2219} INFO - iteration 243, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:32] {2392} INFO -  at 41.4s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:32] {2219} INFO - iteration 244, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:32] {2392} INFO -  at 41.5s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:32] {2219} INFO - iteration 245, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:32] {2392} INFO -  at 41.5s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:32] {2219} INFO - iteration 246, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:32] {2392} INFO -  at 41.6s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:32] {2219} INFO - iteration 247, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:32] {2392} INFO -  at 41.6s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:32] {2219} INFO - iteration 248, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:32] {2392} INFO -  at 41.7s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:32] {2219} INFO - iteration 249, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:32] {2392} INFO -  at 41.7s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:32] {2219} INFO - iteration 250, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:32] {2392} INFO -  at 41.7s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:32] {2219} INFO - iteration 251, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:32] {2392} INFO -  at 41.8s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:32] {2219} INFO - iteration 252, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:32] {2392} INFO -  at 41.8s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:32] {2219} INFO - iteration 253, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:32] {2392} INFO -  at 41.8s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:32] {2219} INFO - iteration 254, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:32] {2392} INFO -  at 41.9s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:32] {2219} INFO - iteration 255, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:32] {2392} INFO -  at 41.9s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:32] {2219} INFO - iteration 256, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:32] {2392} INFO -  at 41.9s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:32] {2219} INFO - iteration 257, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:32] {2392} INFO -  at 42.0s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:32] {2219} INFO - iteration 258, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:32] {2392} INFO -  at 42.0s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:32] {2219} INFO - iteration 259, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:32] {2392} INFO -  at 42.0s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:32] {2219} INFO - iteration 260, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:32] {2392} INFO -  at 42.0s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:32] {2219} INFO - iteration 261, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:32] {2392} INFO -  at 42.1s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:32] {2219} INFO - iteration 262, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:32] {2392} INFO -  at 42.1s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:32] {2219} INFO - iteration 263, current learner extra_tree\n",
      "[flaml.automl.logger: 12-16 19:04:32] {2392} INFO -  at 42.2s,\testimator extra_tree's best error=985.3322,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:32] {2219} INFO - iteration 264, current learner extra_tree\n",
      "[flaml.automl.logger: 12-16 19:04:32] {2392} INFO -  at 42.3s,\testimator extra_tree's best error=985.3322,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:32] {2219} INFO - iteration 265, current learner extra_tree\n",
      "[flaml.automl.logger: 12-16 19:04:33] {2392} INFO -  at 42.5s,\testimator extra_tree's best error=985.3322,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:33] {2219} INFO - iteration 266, current learner extra_tree\n",
      "[flaml.automl.logger: 12-16 19:04:33] {2392} INFO -  at 42.6s,\testimator extra_tree's best error=985.3322,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:33] {2219} INFO - iteration 267, current learner extra_tree\n",
      "[flaml.automl.logger: 12-16 19:04:33] {2392} INFO -  at 42.7s,\testimator extra_tree's best error=972.7814,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:33] {2219} INFO - iteration 268, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:33] {2392} INFO -  at 42.7s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:33] {2219} INFO - iteration 269, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:33] {2392} INFO -  at 42.7s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:33] {2219} INFO - iteration 270, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:33] {2392} INFO -  at 42.7s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:33] {2219} INFO - iteration 271, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:33] {2392} INFO -  at 42.8s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:33] {2219} INFO - iteration 272, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:33] {2392} INFO -  at 42.8s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:33] {2219} INFO - iteration 273, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:33] {2392} INFO -  at 42.8s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:33] {2219} INFO - iteration 274, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:33] {2392} INFO -  at 42.9s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:33] {2219} INFO - iteration 275, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:33] {2392} INFO -  at 42.9s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:33] {2219} INFO - iteration 276, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:33] {2392} INFO -  at 42.9s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:33] {2219} INFO - iteration 277, current learner extra_tree\n",
      "[flaml.automl.logger: 12-16 19:04:33] {2392} INFO -  at 43.1s,\testimator extra_tree's best error=972.7814,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:33] {2219} INFO - iteration 278, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:33] {2392} INFO -  at 43.1s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:33] {2219} INFO - iteration 279, current learner rf\n",
      "[flaml.automl.logger: 12-16 19:04:33] {2392} INFO -  at 43.2s,\testimator rf's best error=1005.3886,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:33] {2219} INFO - iteration 280, current learner rf\n",
      "[flaml.automl.logger: 12-16 19:04:33] {2392} INFO -  at 43.3s,\testimator rf's best error=1005.3886,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:33] {2219} INFO - iteration 281, current learner rf\n",
      "[flaml.automl.logger: 12-16 19:04:34] {2392} INFO -  at 43.4s,\testimator rf's best error=1005.3886,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:34] {2219} INFO - iteration 282, current learner rf\n",
      "[flaml.automl.logger: 12-16 19:04:34] {2392} INFO -  at 43.5s,\testimator rf's best error=1005.3886,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:34] {2219} INFO - iteration 283, current learner rf\n",
      "[flaml.automl.logger: 12-16 19:04:34] {2392} INFO -  at 43.7s,\testimator rf's best error=988.2294,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:34] {2219} INFO - iteration 284, current learner extra_tree\n",
      "[flaml.automl.logger: 12-16 19:04:34] {2392} INFO -  at 43.8s,\testimator extra_tree's best error=946.4831,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:34] {2219} INFO - iteration 285, current learner extra_tree\n",
      "[flaml.automl.logger: 12-16 19:04:34] {2392} INFO -  at 43.9s,\testimator extra_tree's best error=946.4831,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:34] {2219} INFO - iteration 286, current learner extra_tree\n",
      "[flaml.automl.logger: 12-16 19:04:34] {2392} INFO -  at 44.0s,\testimator extra_tree's best error=946.4831,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:34] {2219} INFO - iteration 287, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:34] {2392} INFO -  at 44.1s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:34] {2219} INFO - iteration 288, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:34] {2392} INFO -  at 44.1s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:34] {2219} INFO - iteration 289, current learner extra_tree\n",
      "[flaml.automl.logger: 12-16 19:04:34] {2392} INFO -  at 44.3s,\testimator extra_tree's best error=946.4831,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:34] {2219} INFO - iteration 290, current learner rf\n",
      "[flaml.automl.logger: 12-16 19:04:34] {2392} INFO -  at 44.4s,\testimator rf's best error=988.2294,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:34] {2219} INFO - iteration 291, current learner extra_tree\n",
      "[flaml.automl.logger: 12-16 19:04:35] {2392} INFO -  at 44.5s,\testimator extra_tree's best error=946.4831,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:35] {2219} INFO - iteration 292, current learner rf\n",
      "[flaml.automl.logger: 12-16 19:04:35] {2392} INFO -  at 44.7s,\testimator rf's best error=988.2294,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:35] {2219} INFO - iteration 293, current learner extra_tree\n",
      "[flaml.automl.logger: 12-16 19:04:35] {2392} INFO -  at 44.8s,\testimator extra_tree's best error=946.4831,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:35] {2219} INFO - iteration 294, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:35] {2392} INFO -  at 44.9s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:35] {2219} INFO - iteration 295, current learner extra_tree\n",
      "[flaml.automl.logger: 12-16 19:04:35] {2392} INFO -  at 45.0s,\testimator extra_tree's best error=946.4831,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:35] {2219} INFO - iteration 296, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:35] {2392} INFO -  at 45.0s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:35] {2219} INFO - iteration 297, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:35] {2392} INFO -  at 45.1s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:35] {2219} INFO - iteration 298, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:35] {2392} INFO -  at 45.1s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:35] {2219} INFO - iteration 299, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:35] {2392} INFO -  at 45.1s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:35] {2219} INFO - iteration 300, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:35] {2392} INFO -  at 45.2s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:35] {2219} INFO - iteration 301, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:35] {2392} INFO -  at 45.2s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:35] {2219} INFO - iteration 302, current learner extra_tree\n",
      "[flaml.automl.logger: 12-16 19:04:35] {2392} INFO -  at 45.3s,\testimator extra_tree's best error=946.4831,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:35] {2219} INFO - iteration 303, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:35] {2392} INFO -  at 45.4s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:35] {2219} INFO - iteration 304, current learner extra_tree\n",
      "[flaml.automl.logger: 12-16 19:04:36] {2392} INFO -  at 45.5s,\testimator extra_tree's best error=946.4831,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:36] {2219} INFO - iteration 305, current learner extra_tree\n",
      "[flaml.automl.logger: 12-16 19:04:36] {2392} INFO -  at 45.7s,\testimator extra_tree's best error=946.4831,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:36] {2219} INFO - iteration 306, current learner rf\n",
      "[flaml.automl.logger: 12-16 19:04:36] {2392} INFO -  at 45.8s,\testimator rf's best error=988.2294,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:36] {2219} INFO - iteration 307, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:36] {2392} INFO -  at 45.8s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:36] {2219} INFO - iteration 308, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:36] {2392} INFO -  at 45.9s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:36] {2219} INFO - iteration 309, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:36] {2392} INFO -  at 45.9s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:36] {2219} INFO - iteration 310, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:36] {2392} INFO -  at 45.9s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:36] {2219} INFO - iteration 311, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:36] {2392} INFO -  at 46.0s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:36] {2219} INFO - iteration 312, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:36] {2392} INFO -  at 46.0s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:36] {2219} INFO - iteration 313, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:36] {2392} INFO -  at 46.0s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:36] {2219} INFO - iteration 314, current learner extra_tree\n",
      "[flaml.automl.logger: 12-16 19:04:36] {2392} INFO -  at 46.2s,\testimator extra_tree's best error=946.4831,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:36] {2219} INFO - iteration 315, current learner extra_tree\n",
      "[flaml.automl.logger: 12-16 19:04:36] {2392} INFO -  at 46.3s,\testimator extra_tree's best error=946.4831,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:36] {2219} INFO - iteration 316, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:36] {2392} INFO -  at 46.3s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:36] {2219} INFO - iteration 317, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:36] {2392} INFO -  at 46.3s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:36] {2219} INFO - iteration 318, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:36] {2392} INFO -  at 46.4s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:36] {2219} INFO - iteration 319, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:36] {2392} INFO -  at 46.4s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:36] {2219} INFO - iteration 320, current learner rf\n",
      "[flaml.automl.logger: 12-16 19:04:37] {2392} INFO -  at 46.6s,\testimator rf's best error=965.5411,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:37] {2219} INFO - iteration 321, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:37] {2392} INFO -  at 46.6s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:37] {2219} INFO - iteration 322, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:37] {2392} INFO -  at 46.6s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:37] {2219} INFO - iteration 323, current learner xgboost\n",
      "[flaml.automl.logger: 12-16 19:04:37] {2392} INFO -  at 46.9s,\testimator xgboost's best error=810.0528,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:37] {2219} INFO - iteration 324, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:37] {2392} INFO -  at 47.0s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:37] {2219} INFO - iteration 325, current learner rf\n",
      "[flaml.automl.logger: 12-16 19:04:37] {2392} INFO -  at 47.1s,\testimator rf's best error=965.5411,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:37] {2219} INFO - iteration 326, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:37] {2392} INFO -  at 47.1s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:37] {2219} INFO - iteration 327, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:37] {2392} INFO -  at 47.2s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:37] {2219} INFO - iteration 328, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:37] {2392} INFO -  at 47.2s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:37] {2219} INFO - iteration 329, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:37] {2392} INFO -  at 47.2s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:37] {2219} INFO - iteration 330, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:37] {2392} INFO -  at 47.3s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:37] {2219} INFO - iteration 331, current learner rf\n",
      "[flaml.automl.logger: 12-16 19:04:38] {2392} INFO -  at 47.5s,\testimator rf's best error=965.5411,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:38] {2219} INFO - iteration 332, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:38] {2392} INFO -  at 47.5s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:38] {2219} INFO - iteration 333, current learner rf\n",
      "[flaml.automl.logger: 12-16 19:04:38] {2392} INFO -  at 47.6s,\testimator rf's best error=965.5411,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:38] {2219} INFO - iteration 334, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:38] {2392} INFO -  at 47.7s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:38] {2219} INFO - iteration 335, current learner rf\n",
      "[flaml.automl.logger: 12-16 19:04:38] {2392} INFO -  at 47.8s,\testimator rf's best error=965.5411,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:38] {2219} INFO - iteration 336, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:38] {2392} INFO -  at 47.9s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:38] {2219} INFO - iteration 337, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:38] {2392} INFO -  at 47.9s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:38] {2219} INFO - iteration 338, current learner rf\n",
      "[flaml.automl.logger: 12-16 19:04:38] {2392} INFO -  at 48.0s,\testimator rf's best error=965.5411,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:38] {2219} INFO - iteration 339, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:38] {2392} INFO -  at 48.1s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:38] {2219} INFO - iteration 340, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:38] {2392} INFO -  at 48.1s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:38] {2219} INFO - iteration 341, current learner extra_tree\n",
      "[flaml.automl.logger: 12-16 19:04:38] {2392} INFO -  at 48.2s,\testimator extra_tree's best error=946.4831,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:38] {2219} INFO - iteration 342, current learner extra_tree\n",
      "[flaml.automl.logger: 12-16 19:04:38] {2392} INFO -  at 48.4s,\testimator extra_tree's best error=946.4831,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:38] {2219} INFO - iteration 343, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:38] {2392} INFO -  at 48.4s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:38] {2219} INFO - iteration 344, current learner extra_tree\n",
      "[flaml.automl.logger: 12-16 19:04:39] {2392} INFO -  at 48.5s,\testimator extra_tree's best error=946.4831,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:39] {2219} INFO - iteration 345, current learner extra_tree\n",
      "[flaml.automl.logger: 12-16 19:04:39] {2392} INFO -  at 48.7s,\testimator extra_tree's best error=946.4831,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:39] {2219} INFO - iteration 346, current learner rf\n",
      "[flaml.automl.logger: 12-16 19:04:39] {2392} INFO -  at 48.9s,\testimator rf's best error=965.5411,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:39] {2219} INFO - iteration 347, current learner extra_tree\n",
      "[flaml.automl.logger: 12-16 19:04:39] {2392} INFO -  at 49.0s,\testimator extra_tree's best error=946.4831,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:39] {2219} INFO - iteration 348, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:39] {2392} INFO -  at 49.1s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:39] {2219} INFO - iteration 349, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:39] {2392} INFO -  at 49.1s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:39] {2219} INFO - iteration 350, current learner rf\n",
      "[flaml.automl.logger: 12-16 19:04:39] {2392} INFO -  at 49.3s,\testimator rf's best error=965.5411,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:39] {2219} INFO - iteration 351, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:39] {2392} INFO -  at 49.3s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:39] {2219} INFO - iteration 352, current learner rf\n",
      "[flaml.automl.logger: 12-16 19:04:40] {2392} INFO -  at 49.5s,\testimator rf's best error=965.5411,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:40] {2219} INFO - iteration 353, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:40] {2392} INFO -  at 49.5s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:40] {2219} INFO - iteration 354, current learner rf\n",
      "[flaml.automl.logger: 12-16 19:04:40] {2392} INFO -  at 49.7s,\testimator rf's best error=965.5411,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:40] {2219} INFO - iteration 355, current learner rf\n",
      "[flaml.automl.logger: 12-16 19:04:40] {2392} INFO -  at 49.8s,\testimator rf's best error=965.5411,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:40] {2219} INFO - iteration 356, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:40] {2392} INFO -  at 49.9s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:40] {2219} INFO - iteration 357, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:40] {2392} INFO -  at 49.9s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:40] {2219} INFO - iteration 358, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:40] {2392} INFO -  at 50.0s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:40] {2219} INFO - iteration 359, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:40] {2392} INFO -  at 50.0s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:40] {2219} INFO - iteration 360, current learner rf\n",
      "[flaml.automl.logger: 12-16 19:04:40] {2392} INFO -  at 50.1s,\testimator rf's best error=965.5411,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:40] {2219} INFO - iteration 361, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:40] {2392} INFO -  at 50.2s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:40] {2219} INFO - iteration 362, current learner rf\n",
      "[flaml.automl.logger: 12-16 19:04:40] {2392} INFO -  at 50.4s,\testimator rf's best error=965.5411,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:40] {2219} INFO - iteration 363, current learner extra_tree\n",
      "[flaml.automl.logger: 12-16 19:04:41] {2392} INFO -  at 50.5s,\testimator extra_tree's best error=946.4831,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:41] {2219} INFO - iteration 364, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:41] {2392} INFO -  at 50.5s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:41] {2219} INFO - iteration 365, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:41] {2392} INFO -  at 50.6s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:41] {2219} INFO - iteration 366, current learner extra_tree\n",
      "[flaml.automl.logger: 12-16 19:04:41] {2392} INFO -  at 50.7s,\testimator extra_tree's best error=946.4831,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:41] {2219} INFO - iteration 367, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:41] {2392} INFO -  at 50.8s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:41] {2219} INFO - iteration 368, current learner extra_tree\n",
      "[flaml.automl.logger: 12-16 19:04:41] {2392} INFO -  at 50.9s,\testimator extra_tree's best error=946.4831,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:41] {2219} INFO - iteration 369, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:41] {2392} INFO -  at 50.9s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:41] {2219} INFO - iteration 370, current learner extra_tree\n",
      "[flaml.automl.logger: 12-16 19:04:41] {2392} INFO -  at 51.1s,\testimator extra_tree's best error=946.4831,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:41] {2219} INFO - iteration 371, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:41] {2392} INFO -  at 51.1s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:41] {2219} INFO - iteration 372, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:41] {2392} INFO -  at 51.1s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:41] {2219} INFO - iteration 373, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:41] {2392} INFO -  at 51.1s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:41] {2219} INFO - iteration 374, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:41] {2392} INFO -  at 51.2s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:41] {2219} INFO - iteration 375, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:41] {2392} INFO -  at 51.2s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:41] {2219} INFO - iteration 376, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:41] {2392} INFO -  at 51.2s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:41] {2219} INFO - iteration 377, current learner rf\n",
      "[flaml.automl.logger: 12-16 19:04:41] {2392} INFO -  at 51.4s,\testimator rf's best error=965.5411,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:41] {2219} INFO - iteration 378, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:42] {2392} INFO -  at 51.5s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:42] {2219} INFO - iteration 379, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:42] {2392} INFO -  at 51.6s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:42] {2219} INFO - iteration 380, current learner extra_tree\n",
      "[flaml.automl.logger: 12-16 19:04:42] {2392} INFO -  at 51.8s,\testimator extra_tree's best error=946.4831,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:42] {2219} INFO - iteration 381, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:42] {2392} INFO -  at 51.8s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:42] {2219} INFO - iteration 382, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:42] {2392} INFO -  at 51.8s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:42] {2219} INFO - iteration 383, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:42] {2392} INFO -  at 51.9s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:42] {2219} INFO - iteration 384, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:42] {2392} INFO -  at 51.9s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:42] {2219} INFO - iteration 385, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:42] {2392} INFO -  at 51.9s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:42] {2219} INFO - iteration 386, current learner extra_tree\n",
      "[flaml.automl.logger: 12-16 19:04:42] {2392} INFO -  at 52.0s,\testimator extra_tree's best error=946.4831,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:42] {2219} INFO - iteration 387, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:42] {2392} INFO -  at 52.1s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:42] {2219} INFO - iteration 388, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:42] {2392} INFO -  at 52.1s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:42] {2219} INFO - iteration 389, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:42] {2392} INFO -  at 52.2s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:42] {2219} INFO - iteration 390, current learner rf\n",
      "[flaml.automl.logger: 12-16 19:04:42] {2392} INFO -  at 52.3s,\testimator rf's best error=950.0224,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:42] {2219} INFO - iteration 391, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:42] {2392} INFO -  at 52.4s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:42] {2219} INFO - iteration 392, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:42] {2392} INFO -  at 52.4s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:42] {2219} INFO - iteration 393, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:42] {2392} INFO -  at 52.4s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:42] {2219} INFO - iteration 394, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:43] {2392} INFO -  at 52.4s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:43] {2219} INFO - iteration 395, current learner rf\n",
      "[flaml.automl.logger: 12-16 19:04:43] {2392} INFO -  at 52.6s,\testimator rf's best error=950.0224,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:43] {2219} INFO - iteration 396, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:43] {2392} INFO -  at 52.6s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:43] {2219} INFO - iteration 397, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:43] {2392} INFO -  at 52.7s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:43] {2219} INFO - iteration 398, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:43] {2392} INFO -  at 52.7s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:43] {2219} INFO - iteration 399, current learner xgboost\n",
      "[flaml.automl.logger: 12-16 19:04:44] {2392} INFO -  at 53.5s,\testimator xgboost's best error=810.0528,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:44] {2219} INFO - iteration 400, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:44] {2392} INFO -  at 53.6s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:44] {2219} INFO - iteration 401, current learner rf\n",
      "[flaml.automl.logger: 12-16 19:04:44] {2392} INFO -  at 53.7s,\testimator rf's best error=950.0224,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:44] {2219} INFO - iteration 402, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:44] {2392} INFO -  at 53.8s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:44] {2219} INFO - iteration 403, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:44] {2392} INFO -  at 53.8s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:44] {2219} INFO - iteration 404, current learner extra_tree\n",
      "[flaml.automl.logger: 12-16 19:04:44] {2392} INFO -  at 53.9s,\testimator extra_tree's best error=946.4831,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:44] {2219} INFO - iteration 405, current learner rf\n",
      "[flaml.automl.logger: 12-16 19:04:44] {2392} INFO -  at 54.1s,\testimator rf's best error=950.0224,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:44] {2219} INFO - iteration 406, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:44] {2392} INFO -  at 54.1s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:44] {2219} INFO - iteration 407, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:44] {2392} INFO -  at 54.2s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:44] {2219} INFO - iteration 408, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:44] {2392} INFO -  at 54.2s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:44] {2219} INFO - iteration 409, current learner extra_tree\n",
      "[flaml.automl.logger: 12-16 19:04:44] {2392} INFO -  at 54.3s,\testimator extra_tree's best error=946.4831,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:44] {2219} INFO - iteration 410, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:44] {2392} INFO -  at 54.3s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:44] {2219} INFO - iteration 411, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:44] {2392} INFO -  at 54.4s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:44] {2219} INFO - iteration 412, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:44] {2392} INFO -  at 54.4s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:44] {2219} INFO - iteration 413, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:45] {2392} INFO -  at 54.4s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:45] {2219} INFO - iteration 414, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:45] {2392} INFO -  at 54.5s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:45] {2219} INFO - iteration 415, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:45] {2392} INFO -  at 54.5s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:45] {2219} INFO - iteration 416, current learner rf\n",
      "[flaml.automl.logger: 12-16 19:04:45] {2392} INFO -  at 54.7s,\testimator rf's best error=950.0224,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:45] {2219} INFO - iteration 417, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:45] {2392} INFO -  at 54.7s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:45] {2219} INFO - iteration 418, current learner rf\n",
      "[flaml.automl.logger: 12-16 19:04:45] {2392} INFO -  at 54.9s,\testimator rf's best error=950.0224,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:45] {2219} INFO - iteration 419, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:45] {2392} INFO -  at 54.9s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:45] {2219} INFO - iteration 420, current learner xgboost\n",
      "[flaml.automl.logger: 12-16 19:04:45] {2392} INFO -  at 55.0s,\testimator xgboost's best error=810.0528,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:45] {2219} INFO - iteration 421, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:45] {2392} INFO -  at 55.1s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:45] {2219} INFO - iteration 422, current learner rf\n",
      "[flaml.automl.logger: 12-16 19:04:45] {2392} INFO -  at 55.2s,\testimator rf's best error=950.0224,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:45] {2219} INFO - iteration 423, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:45] {2392} INFO -  at 55.3s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:45] {2219} INFO - iteration 424, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:45] {2392} INFO -  at 55.3s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:45] {2219} INFO - iteration 425, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:45] {2392} INFO -  at 55.4s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:45] {2219} INFO - iteration 426, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:45] {2392} INFO -  at 55.4s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:45] {2219} INFO - iteration 427, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:46] {2392} INFO -  at 55.4s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:46] {2219} INFO - iteration 428, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:46] {2392} INFO -  at 55.5s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:46] {2219} INFO - iteration 429, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:46] {2392} INFO -  at 55.5s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:46] {2219} INFO - iteration 430, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:46] {2392} INFO -  at 55.6s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:46] {2219} INFO - iteration 431, current learner rf\n",
      "[flaml.automl.logger: 12-16 19:04:46] {2392} INFO -  at 55.7s,\testimator rf's best error=950.0224,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:46] {2219} INFO - iteration 432, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:46] {2392} INFO -  at 55.8s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:46] {2219} INFO - iteration 433, current learner rf\n",
      "[flaml.automl.logger: 12-16 19:04:46] {2392} INFO -  at 55.9s,\testimator rf's best error=950.0224,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:46] {2219} INFO - iteration 434, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:46] {2392} INFO -  at 56.0s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:46] {2219} INFO - iteration 435, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:46] {2392} INFO -  at 56.0s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:46] {2219} INFO - iteration 436, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:46] {2392} INFO -  at 56.0s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:46] {2219} INFO - iteration 437, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:46] {2392} INFO -  at 56.1s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:46] {2219} INFO - iteration 438, current learner rf\n",
      "[flaml.automl.logger: 12-16 19:04:46] {2392} INFO -  at 56.3s,\testimator rf's best error=950.0224,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:46] {2219} INFO - iteration 439, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:46] {2392} INFO -  at 56.3s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:46] {2219} INFO - iteration 440, current learner extra_tree\n",
      "[flaml.automl.logger: 12-16 19:04:46] {2392} INFO -  at 56.4s,\testimator extra_tree's best error=946.4831,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:46] {2219} INFO - iteration 441, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:47] {2392} INFO -  at 56.4s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:47] {2219} INFO - iteration 442, current learner rf\n",
      "[flaml.automl.logger: 12-16 19:04:47] {2392} INFO -  at 56.6s,\testimator rf's best error=946.9964,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:47] {2219} INFO - iteration 443, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:47] {2392} INFO -  at 56.6s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:47] {2219} INFO - iteration 444, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:47] {2392} INFO -  at 56.6s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:47] {2219} INFO - iteration 445, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:47] {2392} INFO -  at 56.6s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:47] {2219} INFO - iteration 446, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:47] {2392} INFO -  at 56.7s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:47] {2219} INFO - iteration 447, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:47] {2392} INFO -  at 56.7s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:47] {2219} INFO - iteration 448, current learner extra_tree\n",
      "[flaml.automl.logger: 12-16 19:04:47] {2392} INFO -  at 56.8s,\testimator extra_tree's best error=946.4831,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:47] {2219} INFO - iteration 449, current learner extra_tree\n",
      "[flaml.automl.logger: 12-16 19:04:47] {2392} INFO -  at 57.0s,\testimator extra_tree's best error=946.4831,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:47] {2219} INFO - iteration 450, current learner rf\n",
      "[flaml.automl.logger: 12-16 19:04:47] {2392} INFO -  at 57.1s,\testimator rf's best error=946.9964,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:47] {2219} INFO - iteration 451, current learner extra_tree\n",
      "[flaml.automl.logger: 12-16 19:04:47] {2392} INFO -  at 57.2s,\testimator extra_tree's best error=946.4831,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:47] {2219} INFO - iteration 452, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:47] {2392} INFO -  at 57.2s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:47] {2219} INFO - iteration 453, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:47] {2392} INFO -  at 57.2s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:47] {2219} INFO - iteration 454, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:47] {2392} INFO -  at 57.3s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:47] {2219} INFO - iteration 455, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:47] {2392} INFO -  at 57.3s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:47] {2219} INFO - iteration 456, current learner extra_tree\n",
      "[flaml.automl.logger: 12-16 19:04:48] {2392} INFO -  at 57.4s,\testimator extra_tree's best error=946.4831,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:48] {2219} INFO - iteration 457, current learner extra_tree\n",
      "[flaml.automl.logger: 12-16 19:04:48] {2392} INFO -  at 57.6s,\testimator extra_tree's best error=946.4831,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:48] {2219} INFO - iteration 458, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:48] {2392} INFO -  at 57.6s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:48] {2219} INFO - iteration 459, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:48] {2392} INFO -  at 57.6s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:48] {2219} INFO - iteration 460, current learner extra_tree\n",
      "[flaml.automl.logger: 12-16 19:04:48] {2392} INFO -  at 57.8s,\testimator extra_tree's best error=934.9907,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:48] {2219} INFO - iteration 461, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:48] {2392} INFO -  at 57.8s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:48] {2219} INFO - iteration 462, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:48] {2392} INFO -  at 57.8s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:48] {2219} INFO - iteration 463, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:48] {2392} INFO -  at 57.9s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:48] {2219} INFO - iteration 464, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:48] {2392} INFO -  at 57.9s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:48] {2219} INFO - iteration 465, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:48] {2392} INFO -  at 57.9s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:48] {2219} INFO - iteration 466, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:48] {2392} INFO -  at 57.9s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:48] {2219} INFO - iteration 467, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:48] {2392} INFO -  at 58.0s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:48] {2219} INFO - iteration 468, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:48] {2392} INFO -  at 58.0s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:48] {2219} INFO - iteration 469, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:48] {2392} INFO -  at 58.0s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:48] {2219} INFO - iteration 470, current learner extra_tree\n",
      "[flaml.automl.logger: 12-16 19:04:48] {2392} INFO -  at 58.1s,\testimator extra_tree's best error=934.9907,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:48] {2219} INFO - iteration 471, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:48] {2392} INFO -  at 58.2s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:48] {2219} INFO - iteration 472, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:48] {2392} INFO -  at 58.2s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:48] {2219} INFO - iteration 473, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:48] {2392} INFO -  at 58.2s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:48] {2219} INFO - iteration 474, current learner xgboost\n",
      "[flaml.automl.logger: 12-16 19:04:48] {2392} INFO -  at 58.4s,\testimator xgboost's best error=810.0528,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:48] {2219} INFO - iteration 475, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:48] {2392} INFO -  at 58.4s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:48] {2219} INFO - iteration 476, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:49] {2392} INFO -  at 58.4s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:49] {2219} INFO - iteration 477, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:49] {2392} INFO -  at 58.5s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:49] {2219} INFO - iteration 478, current learner extra_tree\n",
      "[flaml.automl.logger: 12-16 19:04:49] {2392} INFO -  at 58.6s,\testimator extra_tree's best error=934.9907,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:49] {2219} INFO - iteration 479, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:49] {2392} INFO -  at 58.6s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:49] {2219} INFO - iteration 480, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:49] {2392} INFO -  at 58.7s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:49] {2219} INFO - iteration 481, current learner rf\n",
      "[flaml.automl.logger: 12-16 19:04:49] {2392} INFO -  at 58.8s,\testimator rf's best error=946.9964,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:49] {2219} INFO - iteration 482, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:49] {2392} INFO -  at 58.8s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:49] {2219} INFO - iteration 483, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:49] {2392} INFO -  at 58.9s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:49] {2219} INFO - iteration 484, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:49] {2392} INFO -  at 58.9s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:49] {2219} INFO - iteration 485, current learner rf\n",
      "[flaml.automl.logger: 12-16 19:04:49] {2392} INFO -  at 59.1s,\testimator rf's best error=946.9964,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:49] {2219} INFO - iteration 486, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:49] {2392} INFO -  at 59.1s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:49] {2219} INFO - iteration 487, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:49] {2392} INFO -  at 59.1s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:49] {2219} INFO - iteration 488, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:49] {2392} INFO -  at 59.2s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:49] {2219} INFO - iteration 489, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:49] {2392} INFO -  at 59.2s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:49] {2219} INFO - iteration 490, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:49] {2392} INFO -  at 59.2s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:49] {2219} INFO - iteration 491, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:49] {2392} INFO -  at 59.3s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:49] {2219} INFO - iteration 492, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:49] {2392} INFO -  at 59.3s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:49] {2219} INFO - iteration 493, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:49] {2392} INFO -  at 59.3s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:49] {2219} INFO - iteration 494, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:49] {2392} INFO -  at 59.4s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:49] {2219} INFO - iteration 495, current learner xgboost\n",
      "[flaml.automl.logger: 12-16 19:04:50] {2392} INFO -  at 60.0s,\testimator xgboost's best error=810.0528,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:50] {2219} INFO - iteration 496, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:50] {2392} INFO -  at 60.0s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:50] {2219} INFO - iteration 497, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:50] {2392} INFO -  at 60.0s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:50] {2219} INFO - iteration 498, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:50] {2392} INFO -  at 60.0s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:50] {2219} INFO - iteration 499, current learner extra_tree\n",
      "[flaml.automl.logger: 12-16 19:04:50] {2392} INFO -  at 60.2s,\testimator extra_tree's best error=934.9907,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:50] {2219} INFO - iteration 500, current learner extra_tree\n",
      "[flaml.automl.logger: 12-16 19:04:50] {2392} INFO -  at 60.3s,\testimator extra_tree's best error=934.9907,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:50] {2219} INFO - iteration 501, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:50] {2392} INFO -  at 60.3s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:50] {2219} INFO - iteration 502, current learner xgboost\n",
      "[flaml.automl.logger: 12-16 19:04:51] {2392} INFO -  at 60.8s,\testimator xgboost's best error=810.0528,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:51] {2219} INFO - iteration 503, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:51] {2392} INFO -  at 60.8s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:51] {2219} INFO - iteration 504, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:51] {2392} INFO -  at 60.9s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:51] {2219} INFO - iteration 505, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:51] {2392} INFO -  at 60.9s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:51] {2219} INFO - iteration 506, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:51] {2392} INFO -  at 60.9s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:51] {2219} INFO - iteration 507, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:51] {2392} INFO -  at 60.9s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:51] {2219} INFO - iteration 508, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:51] {2392} INFO -  at 61.0s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:51] {2219} INFO - iteration 509, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:51] {2392} INFO -  at 61.0s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:51] {2219} INFO - iteration 510, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:51] {2392} INFO -  at 61.0s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:51] {2219} INFO - iteration 511, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:51] {2392} INFO -  at 61.1s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:51] {2219} INFO - iteration 512, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:51] {2392} INFO -  at 61.1s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:51] {2219} INFO - iteration 513, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:51] {2392} INFO -  at 61.2s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:51] {2219} INFO - iteration 514, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:51] {2392} INFO -  at 61.2s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:51] {2219} INFO - iteration 515, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:51] {2392} INFO -  at 61.2s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:51] {2219} INFO - iteration 516, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:51] {2392} INFO -  at 61.2s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:51] {2219} INFO - iteration 517, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:51] {2392} INFO -  at 61.3s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:51] {2219} INFO - iteration 518, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:51] {2392} INFO -  at 61.3s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:51] {2219} INFO - iteration 519, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:51] {2392} INFO -  at 61.4s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:51] {2219} INFO - iteration 520, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:51] {2392} INFO -  at 61.4s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:51] {2219} INFO - iteration 521, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:52] {2392} INFO -  at 61.4s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:52] {2219} INFO - iteration 522, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:52] {2392} INFO -  at 61.5s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:52] {2219} INFO - iteration 523, current learner extra_tree\n",
      "[flaml.automl.logger: 12-16 19:04:52] {2392} INFO -  at 61.6s,\testimator extra_tree's best error=934.9907,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:52] {2219} INFO - iteration 524, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:52] {2392} INFO -  at 61.6s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:52] {2219} INFO - iteration 525, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:52] {2392} INFO -  at 61.7s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:52] {2219} INFO - iteration 526, current learner extra_tree\n",
      "[flaml.automl.logger: 12-16 19:04:52] {2392} INFO -  at 61.8s,\testimator extra_tree's best error=934.9907,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:52] {2219} INFO - iteration 527, current learner xgboost\n",
      "[flaml.automl.logger: 12-16 19:04:52] {2392} INFO -  at 62.0s,\testimator xgboost's best error=810.0528,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:52] {2219} INFO - iteration 528, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:52] {2392} INFO -  at 62.1s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:52] {2219} INFO - iteration 529, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:52] {2392} INFO -  at 62.1s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:52] {2219} INFO - iteration 530, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:52] {2392} INFO -  at 62.1s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:52] {2219} INFO - iteration 531, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:52] {2392} INFO -  at 62.1s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:52] {2219} INFO - iteration 532, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:52] {2392} INFO -  at 62.2s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:52] {2219} INFO - iteration 533, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:52] {2392} INFO -  at 62.2s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:52] {2219} INFO - iteration 534, current learner extra_tree\n",
      "[flaml.automl.logger: 12-16 19:04:52] {2392} INFO -  at 62.3s,\testimator extra_tree's best error=934.9907,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:52] {2219} INFO - iteration 535, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:52] {2392} INFO -  at 62.4s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:52] {2219} INFO - iteration 536, current learner extra_tree\n",
      "[flaml.automl.logger: 12-16 19:04:53] {2392} INFO -  at 62.5s,\testimator extra_tree's best error=934.9907,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:53] {2219} INFO - iteration 537, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:53] {2392} INFO -  at 62.6s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:53] {2219} INFO - iteration 538, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:53] {2392} INFO -  at 62.6s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:53] {2219} INFO - iteration 539, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:53] {2392} INFO -  at 62.6s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:53] {2219} INFO - iteration 540, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:53] {2392} INFO -  at 62.7s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:53] {2219} INFO - iteration 541, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:53] {2392} INFO -  at 62.7s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:53] {2219} INFO - iteration 542, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:53] {2392} INFO -  at 62.8s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:53] {2219} INFO - iteration 543, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:53] {2392} INFO -  at 62.8s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:53] {2219} INFO - iteration 544, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:53] {2392} INFO -  at 62.8s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:53] {2219} INFO - iteration 545, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:53] {2392} INFO -  at 62.9s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:53] {2219} INFO - iteration 546, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:53] {2392} INFO -  at 62.9s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:53] {2219} INFO - iteration 547, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:53] {2392} INFO -  at 62.9s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:53] {2219} INFO - iteration 548, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:53] {2392} INFO -  at 62.9s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:53] {2219} INFO - iteration 549, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:53] {2392} INFO -  at 63.0s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:53] {2219} INFO - iteration 550, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:53] {2392} INFO -  at 63.0s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:53] {2219} INFO - iteration 551, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:53] {2392} INFO -  at 63.1s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:53] {2219} INFO - iteration 552, current learner extra_tree\n",
      "[flaml.automl.logger: 12-16 19:04:53] {2392} INFO -  at 63.2s,\testimator extra_tree's best error=934.9907,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:53] {2219} INFO - iteration 553, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:53] {2392} INFO -  at 63.3s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:53] {2219} INFO - iteration 554, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:53] {2392} INFO -  at 63.3s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:53] {2219} INFO - iteration 555, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:53] {2392} INFO -  at 63.3s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:53] {2219} INFO - iteration 556, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:53] {2392} INFO -  at 63.4s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:53] {2219} INFO - iteration 557, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:53] {2392} INFO -  at 63.4s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:53] {2219} INFO - iteration 558, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:54] {2392} INFO -  at 63.5s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:54] {2219} INFO - iteration 559, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:54] {2392} INFO -  at 63.5s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:54] {2219} INFO - iteration 560, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:54] {2392} INFO -  at 63.5s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:54] {2219} INFO - iteration 561, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:54] {2392} INFO -  at 63.6s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:54] {2219} INFO - iteration 562, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:54] {2392} INFO -  at 63.6s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:54] {2219} INFO - iteration 563, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:54] {2392} INFO -  at 63.6s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:54] {2219} INFO - iteration 564, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:54] {2392} INFO -  at 63.7s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:54] {2219} INFO - iteration 565, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:54] {2392} INFO -  at 63.7s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:54] {2219} INFO - iteration 566, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:54] {2392} INFO -  at 63.7s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:54] {2219} INFO - iteration 567, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:54] {2392} INFO -  at 63.7s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:54] {2219} INFO - iteration 568, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:54] {2392} INFO -  at 63.8s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:54] {2219} INFO - iteration 569, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:54] {2392} INFO -  at 63.8s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:54] {2219} INFO - iteration 570, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:54] {2392} INFO -  at 63.8s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:54] {2219} INFO - iteration 571, current learner xgboost\n",
      "[flaml.automl.logger: 12-16 19:04:54] {2392} INFO -  at 64.2s,\testimator xgboost's best error=810.0528,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:54] {2219} INFO - iteration 572, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:54] {2392} INFO -  at 64.2s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:54] {2219} INFO - iteration 573, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:54] {2392} INFO -  at 64.2s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:54] {2219} INFO - iteration 574, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:54] {2392} INFO -  at 64.3s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:54] {2219} INFO - iteration 575, current learner rf\n",
      "[flaml.automl.logger: 12-16 19:04:54] {2392} INFO -  at 64.4s,\testimator rf's best error=946.9964,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:54] {2219} INFO - iteration 576, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:55] {2392} INFO -  at 64.4s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:55] {2219} INFO - iteration 577, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:55] {2392} INFO -  at 64.4s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:55] {2219} INFO - iteration 578, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:55] {2392} INFO -  at 64.5s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:55] {2219} INFO - iteration 579, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:55] {2392} INFO -  at 64.5s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:55] {2219} INFO - iteration 580, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:55] {2392} INFO -  at 64.5s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:55] {2219} INFO - iteration 581, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:55] {2392} INFO -  at 64.6s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:55] {2219} INFO - iteration 582, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:55] {2392} INFO -  at 64.6s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:55] {2219} INFO - iteration 583, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:55] {2392} INFO -  at 64.6s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:55] {2219} INFO - iteration 584, current learner rf\n",
      "[flaml.automl.logger: 12-16 19:04:55] {2392} INFO -  at 64.8s,\testimator rf's best error=946.9964,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:55] {2219} INFO - iteration 585, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:55] {2392} INFO -  at 64.8s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:55] {2219} INFO - iteration 586, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:55] {2392} INFO -  at 64.9s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:55] {2219} INFO - iteration 587, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:55] {2392} INFO -  at 64.9s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:55] {2219} INFO - iteration 588, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:55] {2392} INFO -  at 64.9s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:55] {2219} INFO - iteration 589, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:55] {2392} INFO -  at 65.0s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:55] {2219} INFO - iteration 590, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:55] {2392} INFO -  at 65.0s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:55] {2219} INFO - iteration 591, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:55] {2392} INFO -  at 65.0s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:55] {2219} INFO - iteration 592, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:55] {2392} INFO -  at 65.1s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:55] {2219} INFO - iteration 593, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:55] {2392} INFO -  at 65.1s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:55] {2219} INFO - iteration 594, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:55] {2392} INFO -  at 65.2s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:55] {2219} INFO - iteration 595, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:55] {2392} INFO -  at 65.2s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:55] {2219} INFO - iteration 596, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:55] {2392} INFO -  at 65.2s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:55] {2219} INFO - iteration 597, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:55] {2392} INFO -  at 65.3s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:55] {2219} INFO - iteration 598, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:55] {2392} INFO -  at 65.3s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:55] {2219} INFO - iteration 599, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:56] {2392} INFO -  at 65.5s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:56] {2219} INFO - iteration 600, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:56] {2392} INFO -  at 65.5s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:56] {2219} INFO - iteration 601, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:56] {2392} INFO -  at 65.5s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:56] {2219} INFO - iteration 602, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:56] {2392} INFO -  at 65.6s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:56] {2219} INFO - iteration 603, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:56] {2392} INFO -  at 65.6s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:56] {2219} INFO - iteration 604, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:56] {2392} INFO -  at 65.6s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:56] {2219} INFO - iteration 605, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:56] {2392} INFO -  at 65.6s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:56] {2219} INFO - iteration 606, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:56] {2392} INFO -  at 65.7s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:56] {2219} INFO - iteration 607, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:56] {2392} INFO -  at 65.7s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:56] {2219} INFO - iteration 608, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:56] {2392} INFO -  at 65.8s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:56] {2219} INFO - iteration 609, current learner xgboost\n",
      "[flaml.automl.logger: 12-16 19:04:56] {2392} INFO -  at 66.0s,\testimator xgboost's best error=810.0528,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:56] {2219} INFO - iteration 610, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:56] {2392} INFO -  at 66.0s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:56] {2219} INFO - iteration 611, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:56] {2392} INFO -  at 66.1s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:56] {2219} INFO - iteration 612, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:56] {2392} INFO -  at 66.1s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:56] {2219} INFO - iteration 613, current learner rf\n",
      "[flaml.automl.logger: 12-16 19:04:56] {2392} INFO -  at 66.2s,\testimator rf's best error=946.9964,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:56] {2219} INFO - iteration 614, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:56] {2392} INFO -  at 66.3s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:56] {2219} INFO - iteration 615, current learner extra_tree\n",
      "[flaml.automl.logger: 12-16 19:04:56] {2392} INFO -  at 66.4s,\testimator extra_tree's best error=934.9907,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:56] {2219} INFO - iteration 616, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:56] {2392} INFO -  at 66.4s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:56] {2219} INFO - iteration 617, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:57] {2392} INFO -  at 66.5s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:57] {2219} INFO - iteration 618, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:57] {2392} INFO -  at 66.6s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:57] {2219} INFO - iteration 619, current learner extra_tree\n",
      "[flaml.automl.logger: 12-16 19:04:57] {2392} INFO -  at 66.7s,\testimator extra_tree's best error=934.9907,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:57] {2219} INFO - iteration 620, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:57] {2392} INFO -  at 66.7s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:57] {2219} INFO - iteration 621, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:57] {2392} INFO -  at 66.8s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:57] {2219} INFO - iteration 622, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:57] {2392} INFO -  at 66.8s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:57] {2219} INFO - iteration 623, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:57] {2392} INFO -  at 66.8s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:57] {2219} INFO - iteration 624, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:57] {2392} INFO -  at 66.8s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:57] {2219} INFO - iteration 625, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:57] {2392} INFO -  at 66.9s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:57] {2219} INFO - iteration 626, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:57] {2392} INFO -  at 66.9s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:57] {2219} INFO - iteration 627, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:57] {2392} INFO -  at 66.9s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:57] {2219} INFO - iteration 628, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:57] {2392} INFO -  at 66.9s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:57] {2219} INFO - iteration 629, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:57] {2392} INFO -  at 67.0s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:57] {2219} INFO - iteration 630, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:57] {2392} INFO -  at 67.0s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:57] {2219} INFO - iteration 631, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:57] {2392} INFO -  at 67.0s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:57] {2219} INFO - iteration 632, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:57] {2392} INFO -  at 67.1s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:57] {2219} INFO - iteration 633, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:57] {2392} INFO -  at 67.1s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:57] {2219} INFO - iteration 634, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:57] {2392} INFO -  at 67.1s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:57] {2219} INFO - iteration 635, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:57] {2392} INFO -  at 67.2s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:57] {2219} INFO - iteration 636, current learner extra_tree\n",
      "[flaml.automl.logger: 12-16 19:04:57] {2392} INFO -  at 67.3s,\testimator extra_tree's best error=934.9907,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:57] {2219} INFO - iteration 637, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:57] {2392} INFO -  at 67.3s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:57] {2219} INFO - iteration 638, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:57] {2392} INFO -  at 67.3s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:57] {2219} INFO - iteration 639, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:57] {2392} INFO -  at 67.4s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:57] {2219} INFO - iteration 640, current learner rf\n",
      "[flaml.automl.logger: 12-16 19:04:58] {2392} INFO -  at 67.5s,\testimator rf's best error=946.9964,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:58] {2219} INFO - iteration 641, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:58] {2392} INFO -  at 67.6s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:58] {2219} INFO - iteration 642, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:58] {2392} INFO -  at 67.6s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:58] {2219} INFO - iteration 643, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:58] {2392} INFO -  at 67.6s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:58] {2219} INFO - iteration 644, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:58] {2392} INFO -  at 67.6s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:58] {2219} INFO - iteration 645, current learner xgboost\n",
      "[flaml.automl.logger: 12-16 19:04:58] {2392} INFO -  at 67.7s,\testimator xgboost's best error=810.0528,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:58] {2219} INFO - iteration 646, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:58] {2392} INFO -  at 67.7s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:58] {2219} INFO - iteration 647, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:58] {2392} INFO -  at 67.8s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:58] {2219} INFO - iteration 648, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:58] {2392} INFO -  at 67.8s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:58] {2219} INFO - iteration 649, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:58] {2392} INFO -  at 67.8s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:58] {2219} INFO - iteration 650, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:58] {2392} INFO -  at 67.9s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:58] {2219} INFO - iteration 651, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:58] {2392} INFO -  at 67.9s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:58] {2219} INFO - iteration 652, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:58] {2392} INFO -  at 67.9s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:58] {2219} INFO - iteration 653, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:58] {2392} INFO -  at 67.9s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:58] {2219} INFO - iteration 654, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:58] {2392} INFO -  at 68.0s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:58] {2219} INFO - iteration 655, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:58] {2392} INFO -  at 68.0s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:58] {2219} INFO - iteration 656, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:58] {2392} INFO -  at 68.1s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:58] {2219} INFO - iteration 657, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:58] {2392} INFO -  at 68.1s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:58] {2219} INFO - iteration 658, current learner extra_tree\n",
      "[flaml.automl.logger: 12-16 19:04:58] {2392} INFO -  at 68.2s,\testimator extra_tree's best error=934.9907,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:58] {2219} INFO - iteration 659, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:58] {2392} INFO -  at 68.3s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:58] {2219} INFO - iteration 660, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:58] {2392} INFO -  at 68.3s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:58] {2219} INFO - iteration 661, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:58] {2392} INFO -  at 68.3s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:58] {2219} INFO - iteration 662, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:58] {2392} INFO -  at 68.3s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:58] {2219} INFO - iteration 663, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:58] {2392} INFO -  at 68.3s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:58] {2219} INFO - iteration 664, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:58] {2392} INFO -  at 68.4s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:58] {2219} INFO - iteration 665, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:58] {2392} INFO -  at 68.4s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:58] {2219} INFO - iteration 666, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:58] {2392} INFO -  at 68.4s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:58] {2219} INFO - iteration 667, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:59] {2392} INFO -  at 68.4s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:59] {2219} INFO - iteration 668, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:59] {2392} INFO -  at 68.5s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:59] {2219} INFO - iteration 669, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:59] {2392} INFO -  at 68.5s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:59] {2219} INFO - iteration 670, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:59] {2392} INFO -  at 68.6s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:59] {2219} INFO - iteration 671, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:59] {2392} INFO -  at 68.6s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:59] {2219} INFO - iteration 672, current learner rf\n",
      "[flaml.automl.logger: 12-16 19:04:59] {2392} INFO -  at 68.7s,\testimator rf's best error=946.9964,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:59] {2219} INFO - iteration 673, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:59] {2392} INFO -  at 68.8s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:59] {2219} INFO - iteration 674, current learner rf\n",
      "[flaml.automl.logger: 12-16 19:04:59] {2392} INFO -  at 68.9s,\testimator rf's best error=946.9964,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:59] {2219} INFO - iteration 675, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:59] {2392} INFO -  at 69.0s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:59] {2219} INFO - iteration 676, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:59] {2392} INFO -  at 69.0s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:59] {2219} INFO - iteration 677, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:59] {2392} INFO -  at 69.0s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:59] {2219} INFO - iteration 678, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:59] {2392} INFO -  at 69.0s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:59] {2219} INFO - iteration 679, current learner extra_tree\n",
      "[flaml.automl.logger: 12-16 19:04:59] {2392} INFO -  at 69.1s,\testimator extra_tree's best error=934.9907,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:59] {2219} INFO - iteration 680, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:59] {2392} INFO -  at 69.2s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:59] {2219} INFO - iteration 681, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:04:59] {2392} INFO -  at 69.2s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:59] {2219} INFO - iteration 682, current learner extra_tree\n",
      "[flaml.automl.logger: 12-16 19:04:59] {2392} INFO -  at 69.4s,\testimator extra_tree's best error=934.9907,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:04:59] {2219} INFO - iteration 683, current learner rf\n",
      "[flaml.automl.logger: 12-16 19:05:00] {2392} INFO -  at 69.5s,\testimator rf's best error=946.9964,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:05:00] {2219} INFO - iteration 684, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:05:00] {2392} INFO -  at 69.5s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:05:00] {2219} INFO - iteration 685, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:05:00] {2392} INFO -  at 69.6s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:05:00] {2219} INFO - iteration 686, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:05:00] {2392} INFO -  at 69.6s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:05:00] {2219} INFO - iteration 687, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:05:00] {2392} INFO -  at 69.6s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:05:00] {2219} INFO - iteration 688, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:05:00] {2392} INFO -  at 69.7s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:05:00] {2219} INFO - iteration 689, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:05:00] {2392} INFO -  at 69.7s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:05:00] {2219} INFO - iteration 690, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:05:00] {2392} INFO -  at 69.8s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:05:00] {2219} INFO - iteration 691, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:05:00] {2392} INFO -  at 69.8s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:05:00] {2219} INFO - iteration 692, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:05:00] {2392} INFO -  at 69.8s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:05:00] {2219} INFO - iteration 693, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:05:00] {2392} INFO -  at 69.9s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:05:00] {2219} INFO - iteration 694, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:05:00] {2392} INFO -  at 69.9s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:05:00] {2219} INFO - iteration 695, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:05:00] {2392} INFO -  at 69.9s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:05:00] {2219} INFO - iteration 696, current learner xgboost\n",
      "[flaml.automl.logger: 12-16 19:05:02] {2392} INFO -  at 71.5s,\testimator xgboost's best error=810.0528,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:05:02] {2219} INFO - iteration 697, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:05:02] {2392} INFO -  at 71.5s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:05:02] {2219} INFO - iteration 698, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:05:02] {2392} INFO -  at 71.6s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:05:02] {2219} INFO - iteration 699, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:05:02] {2392} INFO -  at 71.6s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:05:02] {2219} INFO - iteration 700, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:05:02] {2392} INFO -  at 71.6s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:05:02] {2219} INFO - iteration 701, current learner xgboost\n",
      "[flaml.automl.logger: 12-16 19:05:02] {2392} INFO -  at 72.1s,\testimator xgboost's best error=810.0528,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:05:02] {2219} INFO - iteration 702, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:05:02] {2392} INFO -  at 72.2s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:05:02] {2219} INFO - iteration 703, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:05:02] {2392} INFO -  at 72.2s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:05:02] {2219} INFO - iteration 704, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:05:02] {2392} INFO -  at 72.2s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:05:02] {2219} INFO - iteration 705, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:05:02] {2392} INFO -  at 72.2s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:05:02] {2219} INFO - iteration 706, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:05:02] {2392} INFO -  at 72.2s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:05:02] {2219} INFO - iteration 707, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:05:02] {2392} INFO -  at 72.3s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:05:02] {2219} INFO - iteration 708, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:05:02] {2392} INFO -  at 72.3s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:05:02] {2219} INFO - iteration 709, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:05:02] {2392} INFO -  at 72.4s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:05:02] {2219} INFO - iteration 710, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:05:02] {2392} INFO -  at 72.4s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:05:02] {2219} INFO - iteration 711, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:05:02] {2392} INFO -  at 72.4s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:05:02] {2219} INFO - iteration 712, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:05:03] {2392} INFO -  at 72.4s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:05:03] {2219} INFO - iteration 713, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:05:03] {2392} INFO -  at 72.5s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:05:03] {2219} INFO - iteration 714, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:05:03] {2392} INFO -  at 72.5s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:05:03] {2219} INFO - iteration 715, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:05:03] {2392} INFO -  at 72.6s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:05:03] {2219} INFO - iteration 716, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:05:03] {2392} INFO -  at 72.6s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:05:03] {2219} INFO - iteration 717, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:05:03] {2392} INFO -  at 72.6s,\testimator lgbm's best error=772.0458,\tbest estimator lgbm's best error=772.0458\n",
      "[flaml.automl.logger: 12-16 19:05:03] {2219} INFO - iteration 718, current learner xgboost\n",
      "[flaml.automl.logger: 12-16 19:05:03] {2392} INFO -  at 72.8s,\testimator xgboost's best error=765.8599,\tbest estimator xgboost's best error=765.8599\n",
      "[flaml.automl.logger: 12-16 19:05:03] {2219} INFO - iteration 719, current learner xgboost\n",
      "[flaml.automl.logger: 12-16 19:05:03] {2392} INFO -  at 73.2s,\testimator xgboost's best error=765.8599,\tbest estimator xgboost's best error=765.8599\n",
      "[flaml.automl.logger: 12-16 19:05:03] {2219} INFO - iteration 720, current learner xgboost\n",
      "[flaml.automl.logger: 12-16 19:05:03] {2392} INFO -  at 73.3s,\testimator xgboost's best error=765.8599,\tbest estimator xgboost's best error=765.8599\n",
      "[flaml.automl.logger: 12-16 19:05:03] {2219} INFO - iteration 721, current learner xgboost\n",
      "[flaml.automl.logger: 12-16 19:05:04] {2392} INFO -  at 73.6s,\testimator xgboost's best error=765.8599,\tbest estimator xgboost's best error=765.8599\n",
      "[flaml.automl.logger: 12-16 19:05:04] {2219} INFO - iteration 722, current learner xgboost\n",
      "[flaml.automl.logger: 12-16 19:05:04] {2392} INFO -  at 73.7s,\testimator xgboost's best error=765.8599,\tbest estimator xgboost's best error=765.8599\n",
      "[flaml.automl.logger: 12-16 19:05:04] {2219} INFO - iteration 723, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:05:04] {2392} INFO -  at 73.7s,\testimator lgbm's best error=772.0458,\tbest estimator xgboost's best error=765.8599\n",
      "[flaml.automl.logger: 12-16 19:05:04] {2219} INFO - iteration 724, current learner rf\n",
      "[flaml.automl.logger: 12-16 19:05:04] {2392} INFO -  at 73.8s,\testimator rf's best error=946.9964,\tbest estimator xgboost's best error=765.8599\n",
      "[flaml.automl.logger: 12-16 19:05:04] {2219} INFO - iteration 725, current learner xgboost\n",
      "[flaml.automl.logger: 12-16 19:05:04] {2392} INFO -  at 74.1s,\testimator xgboost's best error=765.8599,\tbest estimator xgboost's best error=765.8599\n",
      "[flaml.automl.logger: 12-16 19:05:04] {2219} INFO - iteration 726, current learner xgboost\n",
      "[flaml.automl.logger: 12-16 19:05:04] {2392} INFO -  at 74.2s,\testimator xgboost's best error=765.8599,\tbest estimator xgboost's best error=765.8599\n",
      "[flaml.automl.logger: 12-16 19:05:04] {2219} INFO - iteration 727, current learner xgboost\n",
      "[flaml.automl.logger: 12-16 19:05:04] {2392} INFO -  at 74.4s,\testimator xgboost's best error=765.8599,\tbest estimator xgboost's best error=765.8599\n",
      "[flaml.automl.logger: 12-16 19:05:04] {2219} INFO - iteration 728, current learner xgboost\n",
      "[flaml.automl.logger: 12-16 19:05:05] {2392} INFO -  at 74.6s,\testimator xgboost's best error=765.8599,\tbest estimator xgboost's best error=765.8599\n",
      "[flaml.automl.logger: 12-16 19:05:05] {2219} INFO - iteration 729, current learner xgboost\n",
      "[flaml.automl.logger: 12-16 19:05:05] {2392} INFO -  at 74.9s,\testimator xgboost's best error=765.8599,\tbest estimator xgboost's best error=765.8599\n",
      "[flaml.automl.logger: 12-16 19:05:05] {2219} INFO - iteration 730, current learner xgboost\n",
      "[flaml.automl.logger: 12-16 19:05:05] {2392} INFO -  at 75.0s,\testimator xgboost's best error=765.8599,\tbest estimator xgboost's best error=765.8599\n",
      "[flaml.automl.logger: 12-16 19:05:05] {2219} INFO - iteration 731, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:05:05] {2392} INFO -  at 75.0s,\testimator lgbm's best error=772.0458,\tbest estimator xgboost's best error=765.8599\n",
      "[flaml.automl.logger: 12-16 19:05:05] {2219} INFO - iteration 732, current learner xgboost\n",
      "[flaml.automl.logger: 12-16 19:05:05] {2392} INFO -  at 75.3s,\testimator xgboost's best error=765.8599,\tbest estimator xgboost's best error=765.8599\n",
      "[flaml.automl.logger: 12-16 19:05:05] {2219} INFO - iteration 733, current learner xgboost\n",
      "[flaml.automl.logger: 12-16 19:05:05] {2392} INFO -  at 75.4s,\testimator xgboost's best error=765.8599,\tbest estimator xgboost's best error=765.8599\n",
      "[flaml.automl.logger: 12-16 19:05:05] {2219} INFO - iteration 734, current learner xgboost\n",
      "[flaml.automl.logger: 12-16 19:05:06] {2392} INFO -  at 75.5s,\testimator xgboost's best error=765.8599,\tbest estimator xgboost's best error=765.8599\n",
      "[flaml.automl.logger: 12-16 19:05:06] {2219} INFO - iteration 735, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:05:06] {2392} INFO -  at 75.6s,\testimator lgbm's best error=772.0458,\tbest estimator xgboost's best error=765.8599\n",
      "[flaml.automl.logger: 12-16 19:05:06] {2219} INFO - iteration 736, current learner xgboost\n",
      "[flaml.automl.logger: 12-16 19:05:06] {2392} INFO -  at 75.8s,\testimator xgboost's best error=765.8599,\tbest estimator xgboost's best error=765.8599\n",
      "[flaml.automl.logger: 12-16 19:05:06] {2219} INFO - iteration 737, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:05:06] {2392} INFO -  at 75.8s,\testimator lgbm's best error=772.0458,\tbest estimator xgboost's best error=765.8599\n",
      "[flaml.automl.logger: 12-16 19:05:06] {2219} INFO - iteration 738, current learner xgboost\n",
      "[flaml.automl.logger: 12-16 19:05:06] {2392} INFO -  at 76.1s,\testimator xgboost's best error=765.8599,\tbest estimator xgboost's best error=765.8599\n",
      "[flaml.automl.logger: 12-16 19:05:06] {2219} INFO - iteration 739, current learner xgboost\n",
      "[flaml.automl.logger: 12-16 19:05:06] {2392} INFO -  at 76.2s,\testimator xgboost's best error=765.8599,\tbest estimator xgboost's best error=765.8599\n",
      "[flaml.automl.logger: 12-16 19:05:06] {2219} INFO - iteration 740, current learner xgboost\n",
      "[flaml.automl.logger: 12-16 19:05:06] {2392} INFO -  at 76.4s,\testimator xgboost's best error=765.8599,\tbest estimator xgboost's best error=765.8599\n",
      "[flaml.automl.logger: 12-16 19:05:06] {2219} INFO - iteration 741, current learner xgboost\n",
      "[flaml.automl.logger: 12-16 19:05:07] {2392} INFO -  at 76.7s,\testimator xgboost's best error=765.8599,\tbest estimator xgboost's best error=765.8599\n",
      "[flaml.automl.logger: 12-16 19:05:07] {2219} INFO - iteration 742, current learner xgboost\n",
      "[flaml.automl.logger: 12-16 19:05:07] {2392} INFO -  at 77.0s,\testimator xgboost's best error=765.8599,\tbest estimator xgboost's best error=765.8599\n",
      "[flaml.automl.logger: 12-16 19:05:07] {2219} INFO - iteration 743, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:05:07] {2392} INFO -  at 77.1s,\testimator lgbm's best error=772.0458,\tbest estimator xgboost's best error=765.8599\n",
      "[flaml.automl.logger: 12-16 19:05:07] {2219} INFO - iteration 744, current learner extra_tree\n",
      "[flaml.automl.logger: 12-16 19:05:07] {2392} INFO -  at 77.2s,\testimator extra_tree's best error=934.9907,\tbest estimator xgboost's best error=765.8599\n",
      "[flaml.automl.logger: 12-16 19:05:07] {2219} INFO - iteration 745, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:05:07] {2392} INFO -  at 77.2s,\testimator lgbm's best error=772.0458,\tbest estimator xgboost's best error=765.8599\n",
      "[flaml.automl.logger: 12-16 19:05:07] {2219} INFO - iteration 746, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:05:07] {2392} INFO -  at 77.3s,\testimator lgbm's best error=772.0458,\tbest estimator xgboost's best error=765.8599\n",
      "[flaml.automl.logger: 12-16 19:05:07] {2219} INFO - iteration 747, current learner xgboost\n",
      "[flaml.automl.logger: 12-16 19:05:07] {2392} INFO -  at 77.4s,\testimator xgboost's best error=765.8599,\tbest estimator xgboost's best error=765.8599\n",
      "[flaml.automl.logger: 12-16 19:05:07] {2219} INFO - iteration 748, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:05:08] {2392} INFO -  at 77.5s,\testimator lgbm's best error=772.0458,\tbest estimator xgboost's best error=765.8599\n",
      "[flaml.automl.logger: 12-16 19:05:08] {2219} INFO - iteration 749, current learner xgboost\n",
      "[flaml.automl.logger: 12-16 19:05:08] {2392} INFO -  at 77.7s,\testimator xgboost's best error=765.8599,\tbest estimator xgboost's best error=765.8599\n",
      "[flaml.automl.logger: 12-16 19:05:08] {2219} INFO - iteration 750, current learner xgboost\n",
      "[flaml.automl.logger: 12-16 19:05:08] {2392} INFO -  at 77.8s,\testimator xgboost's best error=765.8599,\tbest estimator xgboost's best error=765.8599\n",
      "[flaml.automl.logger: 12-16 19:05:08] {2219} INFO - iteration 751, current learner xgboost\n",
      "[flaml.automl.logger: 12-16 19:05:08] {2392} INFO -  at 78.0s,\testimator xgboost's best error=765.8599,\tbest estimator xgboost's best error=765.8599\n",
      "[flaml.automl.logger: 12-16 19:05:08] {2219} INFO - iteration 752, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:05:08] {2392} INFO -  at 78.1s,\testimator lgbm's best error=772.0458,\tbest estimator xgboost's best error=765.8599\n",
      "[flaml.automl.logger: 12-16 19:05:08] {2219} INFO - iteration 753, current learner xgboost\n",
      "[flaml.automl.logger: 12-16 19:05:08] {2392} INFO -  at 78.2s,\testimator xgboost's best error=765.8599,\tbest estimator xgboost's best error=765.8599\n",
      "[flaml.automl.logger: 12-16 19:05:08] {2219} INFO - iteration 754, current learner xgboost\n",
      "[flaml.automl.logger: 12-16 19:05:08] {2392} INFO -  at 78.4s,\testimator xgboost's best error=765.8599,\tbest estimator xgboost's best error=765.8599\n",
      "[flaml.automl.logger: 12-16 19:05:08] {2219} INFO - iteration 755, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:05:08] {2392} INFO -  at 78.4s,\testimator lgbm's best error=772.0458,\tbest estimator xgboost's best error=765.8599\n",
      "[flaml.automl.logger: 12-16 19:05:08] {2219} INFO - iteration 756, current learner xgboost\n",
      "[flaml.automl.logger: 12-16 19:05:09] {2392} INFO -  at 78.6s,\testimator xgboost's best error=765.8599,\tbest estimator xgboost's best error=765.8599\n",
      "[flaml.automl.logger: 12-16 19:05:09] {2219} INFO - iteration 757, current learner xgboost\n",
      "[flaml.automl.logger: 12-16 19:05:09] {2392} INFO -  at 79.0s,\testimator xgboost's best error=765.8599,\tbest estimator xgboost's best error=765.8599\n",
      "[flaml.automl.logger: 12-16 19:05:09] {2219} INFO - iteration 758, current learner xgboost\n",
      "[flaml.automl.logger: 12-16 19:05:09] {2392} INFO -  at 79.1s,\testimator xgboost's best error=765.8599,\tbest estimator xgboost's best error=765.8599\n",
      "[flaml.automl.logger: 12-16 19:05:09] {2219} INFO - iteration 759, current learner xgboost\n",
      "[flaml.automl.logger: 12-16 19:05:09] {2392} INFO -  at 79.2s,\testimator xgboost's best error=765.8599,\tbest estimator xgboost's best error=765.8599\n",
      "[flaml.automl.logger: 12-16 19:05:09] {2219} INFO - iteration 760, current learner rf\n",
      "[flaml.automl.logger: 12-16 19:05:09] {2392} INFO -  at 79.3s,\testimator rf's best error=946.9964,\tbest estimator xgboost's best error=765.8599\n",
      "[flaml.automl.logger: 12-16 19:05:09] {2219} INFO - iteration 761, current learner xgboost\n",
      "[flaml.automl.logger: 12-16 19:05:10] {2392} INFO -  at 79.6s,\testimator xgboost's best error=765.8599,\tbest estimator xgboost's best error=765.8599\n",
      "[flaml.automl.logger: 12-16 19:05:10] {2219} INFO - iteration 762, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:05:10] {2392} INFO -  at 79.6s,\testimator lgbm's best error=772.0458,\tbest estimator xgboost's best error=765.8599\n",
      "[flaml.automl.logger: 12-16 19:05:10] {2219} INFO - iteration 763, current learner xgboost\n",
      "[flaml.automl.logger: 12-16 19:05:10] {2392} INFO -  at 80.0s,\testimator xgboost's best error=765.8599,\tbest estimator xgboost's best error=765.8599\n",
      "[flaml.automl.logger: 12-16 19:05:10] {2219} INFO - iteration 764, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:05:10] {2392} INFO -  at 80.0s,\testimator lgbm's best error=772.0458,\tbest estimator xgboost's best error=765.8599\n",
      "[flaml.automl.logger: 12-16 19:05:10] {2219} INFO - iteration 765, current learner extra_tree\n",
      "[flaml.automl.logger: 12-16 19:05:10] {2392} INFO -  at 80.1s,\testimator extra_tree's best error=934.9907,\tbest estimator xgboost's best error=765.8599\n",
      "[flaml.automl.logger: 12-16 19:05:10] {2219} INFO - iteration 766, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:05:10] {2392} INFO -  at 80.2s,\testimator lgbm's best error=772.0458,\tbest estimator xgboost's best error=765.8599\n",
      "[flaml.automl.logger: 12-16 19:05:10] {2219} INFO - iteration 767, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:05:10] {2392} INFO -  at 80.2s,\testimator lgbm's best error=772.0458,\tbest estimator xgboost's best error=765.8599\n",
      "[flaml.automl.logger: 12-16 19:05:10] {2219} INFO - iteration 768, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:05:10] {2392} INFO -  at 80.3s,\testimator lgbm's best error=772.0458,\tbest estimator xgboost's best error=765.8599\n",
      "[flaml.automl.logger: 12-16 19:05:10] {2219} INFO - iteration 769, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:05:10] {2392} INFO -  at 80.3s,\testimator lgbm's best error=772.0458,\tbest estimator xgboost's best error=765.8599\n",
      "[flaml.automl.logger: 12-16 19:05:10] {2219} INFO - iteration 770, current learner xgboost\n",
      "[flaml.automl.logger: 12-16 19:05:10] {2392} INFO -  at 80.4s,\testimator xgboost's best error=765.8599,\tbest estimator xgboost's best error=765.8599\n",
      "[flaml.automl.logger: 12-16 19:05:10] {2219} INFO - iteration 771, current learner xgboost\n",
      "[flaml.automl.logger: 12-16 19:05:11] {2392} INFO -  at 80.9s,\testimator xgboost's best error=765.8599,\tbest estimator xgboost's best error=765.8599\n",
      "[flaml.automl.logger: 12-16 19:05:11] {2219} INFO - iteration 772, current learner xgboost\n",
      "[flaml.automl.logger: 12-16 19:05:11] {2392} INFO -  at 80.9s,\testimator xgboost's best error=765.8599,\tbest estimator xgboost's best error=765.8599\n",
      "[flaml.automl.logger: 12-16 19:05:11] {2219} INFO - iteration 773, current learner xgboost\n",
      "[flaml.automl.logger: 12-16 19:05:11] {2392} INFO -  at 81.1s,\testimator xgboost's best error=765.8599,\tbest estimator xgboost's best error=765.8599\n",
      "[flaml.automl.logger: 12-16 19:05:11] {2219} INFO - iteration 774, current learner xgboost\n",
      "[flaml.automl.logger: 12-16 19:05:11] {2392} INFO -  at 81.3s,\testimator xgboost's best error=765.8599,\tbest estimator xgboost's best error=765.8599\n",
      "[flaml.automl.logger: 12-16 19:05:11] {2219} INFO - iteration 775, current learner xgboost\n",
      "[flaml.automl.logger: 12-16 19:05:11] {2392} INFO -  at 81.4s,\testimator xgboost's best error=765.8599,\tbest estimator xgboost's best error=765.8599\n",
      "[flaml.automl.logger: 12-16 19:05:11] {2219} INFO - iteration 776, current learner xgboost\n",
      "[flaml.automl.logger: 12-16 19:05:12] {2392} INFO -  at 81.7s,\testimator xgboost's best error=765.8599,\tbest estimator xgboost's best error=765.8599\n",
      "[flaml.automl.logger: 12-16 19:05:12] {2219} INFO - iteration 777, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:05:12] {2392} INFO -  at 81.8s,\testimator lgbm's best error=772.0458,\tbest estimator xgboost's best error=765.8599\n",
      "[flaml.automl.logger: 12-16 19:05:12] {2219} INFO - iteration 778, current learner xgboost\n",
      "[flaml.automl.logger: 12-16 19:05:12] {2392} INFO -  at 81.9s,\testimator xgboost's best error=765.8599,\tbest estimator xgboost's best error=765.8599\n",
      "[flaml.automl.logger: 12-16 19:05:12] {2219} INFO - iteration 779, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:05:12] {2392} INFO -  at 81.9s,\testimator lgbm's best error=772.0458,\tbest estimator xgboost's best error=765.8599\n",
      "[flaml.automl.logger: 12-16 19:05:12] {2219} INFO - iteration 780, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:05:12] {2392} INFO -  at 82.0s,\testimator lgbm's best error=772.0458,\tbest estimator xgboost's best error=765.8599\n",
      "[flaml.automl.logger: 12-16 19:05:12] {2219} INFO - iteration 781, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:05:12] {2392} INFO -  at 82.0s,\testimator lgbm's best error=772.0458,\tbest estimator xgboost's best error=765.8599\n",
      "[flaml.automl.logger: 12-16 19:05:12] {2219} INFO - iteration 782, current learner rf\n",
      "[flaml.automl.logger: 12-16 19:05:12] {2392} INFO -  at 82.1s,\testimator rf's best error=946.9964,\tbest estimator xgboost's best error=765.8599\n",
      "[flaml.automl.logger: 12-16 19:05:12] {2219} INFO - iteration 783, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:05:12] {2392} INFO -  at 82.2s,\testimator lgbm's best error=772.0458,\tbest estimator xgboost's best error=765.8599\n",
      "[flaml.automl.logger: 12-16 19:05:12] {2219} INFO - iteration 784, current learner rf\n",
      "[flaml.automl.logger: 12-16 19:05:12] {2392} INFO -  at 82.3s,\testimator rf's best error=946.9964,\tbest estimator xgboost's best error=765.8599\n",
      "[flaml.automl.logger: 12-16 19:05:12] {2219} INFO - iteration 785, current learner extra_tree\n",
      "[flaml.automl.logger: 12-16 19:05:13] {2392} INFO -  at 82.5s,\testimator extra_tree's best error=934.9907,\tbest estimator xgboost's best error=765.8599\n",
      "[flaml.automl.logger: 12-16 19:05:13] {2219} INFO - iteration 786, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:05:13] {2392} INFO -  at 82.6s,\testimator lgbm's best error=772.0458,\tbest estimator xgboost's best error=765.8599\n",
      "[flaml.automl.logger: 12-16 19:05:13] {2219} INFO - iteration 787, current learner extra_tree\n",
      "[flaml.automl.logger: 12-16 19:05:13] {2392} INFO -  at 82.7s,\testimator extra_tree's best error=934.9907,\tbest estimator xgboost's best error=765.8599\n",
      "[flaml.automl.logger: 12-16 19:05:13] {2219} INFO - iteration 788, current learner xgboost\n",
      "[flaml.automl.logger: 12-16 19:05:13] {2392} INFO -  at 83.0s,\testimator xgboost's best error=765.8599,\tbest estimator xgboost's best error=765.8599\n",
      "[flaml.automl.logger: 12-16 19:05:13] {2219} INFO - iteration 789, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:05:13] {2392} INFO -  at 83.0s,\testimator lgbm's best error=772.0458,\tbest estimator xgboost's best error=765.8599\n",
      "[flaml.automl.logger: 12-16 19:05:13] {2219} INFO - iteration 790, current learner xgboost\n",
      "[flaml.automl.logger: 12-16 19:05:13] {2392} INFO -  at 83.2s,\testimator xgboost's best error=765.8599,\tbest estimator xgboost's best error=765.8599\n",
      "[flaml.automl.logger: 12-16 19:05:13] {2219} INFO - iteration 791, current learner xgboost\n",
      "[flaml.automl.logger: 12-16 19:05:13] {2392} INFO -  at 83.4s,\testimator xgboost's best error=765.8599,\tbest estimator xgboost's best error=765.8599\n",
      "[flaml.automl.logger: 12-16 19:05:13] {2219} INFO - iteration 792, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:05:14] {2392} INFO -  at 83.5s,\testimator lgbm's best error=772.0458,\tbest estimator xgboost's best error=765.8599\n",
      "[flaml.automl.logger: 12-16 19:05:14] {2219} INFO - iteration 793, current learner xgboost\n",
      "[flaml.automl.logger: 12-16 19:05:14] {2392} INFO -  at 83.5s,\testimator xgboost's best error=765.8599,\tbest estimator xgboost's best error=765.8599\n",
      "[flaml.automl.logger: 12-16 19:05:14] {2219} INFO - iteration 794, current learner xgboost\n",
      "[flaml.automl.logger: 12-16 19:05:14] {2392} INFO -  at 84.2s,\testimator xgboost's best error=765.8599,\tbest estimator xgboost's best error=765.8599\n",
      "[flaml.automl.logger: 12-16 19:05:14] {2219} INFO - iteration 795, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:05:14] {2392} INFO -  at 84.2s,\testimator lgbm's best error=772.0458,\tbest estimator xgboost's best error=765.8599\n",
      "[flaml.automl.logger: 12-16 19:05:14] {2219} INFO - iteration 796, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:05:14] {2392} INFO -  at 84.2s,\testimator lgbm's best error=772.0458,\tbest estimator xgboost's best error=765.8599\n",
      "[flaml.automl.logger: 12-16 19:05:14] {2219} INFO - iteration 797, current learner xgboost\n",
      "[flaml.automl.logger: 12-16 19:05:15] {2392} INFO -  at 84.8s,\testimator xgboost's best error=765.8599,\tbest estimator xgboost's best error=765.8599\n",
      "[flaml.automl.logger: 12-16 19:05:15] {2219} INFO - iteration 798, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:05:15] {2392} INFO -  at 84.8s,\testimator lgbm's best error=772.0458,\tbest estimator xgboost's best error=765.8599\n",
      "[flaml.automl.logger: 12-16 19:05:15] {2219} INFO - iteration 799, current learner xgboost\n",
      "[flaml.automl.logger: 12-16 19:05:15] {2392} INFO -  at 84.9s,\testimator xgboost's best error=765.8599,\tbest estimator xgboost's best error=765.8599\n",
      "[flaml.automl.logger: 12-16 19:05:15] {2219} INFO - iteration 800, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:05:15] {2392} INFO -  at 84.9s,\testimator lgbm's best error=772.0458,\tbest estimator xgboost's best error=765.8599\n",
      "[flaml.automl.logger: 12-16 19:05:15] {2219} INFO - iteration 801, current learner xgboost\n",
      "[flaml.automl.logger: 12-16 19:05:15] {2392} INFO -  at 85.0s,\testimator xgboost's best error=765.8599,\tbest estimator xgboost's best error=765.8599\n",
      "[flaml.automl.logger: 12-16 19:05:15] {2219} INFO - iteration 802, current learner xgboost\n",
      "[flaml.automl.logger: 12-16 19:05:16] {2392} INFO -  at 85.6s,\testimator xgboost's best error=765.8599,\tbest estimator xgboost's best error=765.8599\n",
      "[flaml.automl.logger: 12-16 19:05:16] {2219} INFO - iteration 803, current learner xgboost\n",
      "[flaml.automl.logger: 12-16 19:05:16] {2392} INFO -  at 85.7s,\testimator xgboost's best error=765.8599,\tbest estimator xgboost's best error=765.8599\n",
      "[flaml.automl.logger: 12-16 19:05:16] {2219} INFO - iteration 804, current learner xgboost\n",
      "[flaml.automl.logger: 12-16 19:05:16] {2392} INFO -  at 85.9s,\testimator xgboost's best error=765.8599,\tbest estimator xgboost's best error=765.8599\n",
      "[flaml.automl.logger: 12-16 19:05:16] {2219} INFO - iteration 805, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:05:16] {2392} INFO -  at 86.0s,\testimator lgbm's best error=772.0458,\tbest estimator xgboost's best error=765.8599\n",
      "[flaml.automl.logger: 12-16 19:05:16] {2219} INFO - iteration 806, current learner xgboost\n",
      "[flaml.automl.logger: 12-16 19:05:16] {2392} INFO -  at 86.1s,\testimator xgboost's best error=765.8599,\tbest estimator xgboost's best error=765.8599\n",
      "[flaml.automl.logger: 12-16 19:05:16] {2219} INFO - iteration 807, current learner xgboost\n",
      "[flaml.automl.logger: 12-16 19:05:17] {2392} INFO -  at 86.5s,\testimator xgboost's best error=765.8599,\tbest estimator xgboost's best error=765.8599\n",
      "[flaml.automl.logger: 12-16 19:05:17] {2219} INFO - iteration 808, current learner xgboost\n",
      "[flaml.automl.logger: 12-16 19:05:17] {2392} INFO -  at 86.6s,\testimator xgboost's best error=765.8599,\tbest estimator xgboost's best error=765.8599\n",
      "[flaml.automl.logger: 12-16 19:05:17] {2219} INFO - iteration 809, current learner xgboost\n",
      "[flaml.automl.logger: 12-16 19:05:17] {2392} INFO -  at 86.9s,\testimator xgboost's best error=765.8599,\tbest estimator xgboost's best error=765.8599\n",
      "[flaml.automl.logger: 12-16 19:05:17] {2219} INFO - iteration 810, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:05:17] {2392} INFO -  at 86.9s,\testimator lgbm's best error=772.0458,\tbest estimator xgboost's best error=765.8599\n",
      "[flaml.automl.logger: 12-16 19:05:17] {2219} INFO - iteration 811, current learner xgboost\n",
      "[flaml.automl.logger: 12-16 19:05:17] {2392} INFO -  at 87.1s,\testimator xgboost's best error=765.8599,\tbest estimator xgboost's best error=765.8599\n",
      "[flaml.automl.logger: 12-16 19:05:17] {2219} INFO - iteration 812, current learner xgboost\n",
      "[flaml.automl.logger: 12-16 19:05:17] {2392} INFO -  at 87.3s,\testimator xgboost's best error=765.8599,\tbest estimator xgboost's best error=765.8599\n",
      "[flaml.automl.logger: 12-16 19:05:17] {2219} INFO - iteration 813, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:05:17] {2392} INFO -  at 87.4s,\testimator lgbm's best error=772.0458,\tbest estimator xgboost's best error=765.8599\n",
      "[flaml.automl.logger: 12-16 19:05:17] {2219} INFO - iteration 814, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:05:17] {2392} INFO -  at 87.4s,\testimator lgbm's best error=772.0458,\tbest estimator xgboost's best error=765.8599\n",
      "[flaml.automl.logger: 12-16 19:05:17] {2219} INFO - iteration 815, current learner rf\n",
      "[flaml.automl.logger: 12-16 19:05:18] {2392} INFO -  at 87.5s,\testimator rf's best error=946.9964,\tbest estimator xgboost's best error=765.8599\n",
      "[flaml.automl.logger: 12-16 19:05:18] {2219} INFO - iteration 816, current learner xgboost\n",
      "[flaml.automl.logger: 12-16 19:05:18] {2392} INFO -  at 87.6s,\testimator xgboost's best error=765.8599,\tbest estimator xgboost's best error=765.8599\n",
      "[flaml.automl.logger: 12-16 19:05:18] {2219} INFO - iteration 817, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:05:18] {2392} INFO -  at 87.6s,\testimator lgbm's best error=772.0458,\tbest estimator xgboost's best error=765.8599\n",
      "[flaml.automl.logger: 12-16 19:05:18] {2219} INFO - iteration 818, current learner xgboost\n",
      "[flaml.automl.logger: 12-16 19:05:18] {2392} INFO -  at 88.1s,\testimator xgboost's best error=765.8599,\tbest estimator xgboost's best error=765.8599\n",
      "[flaml.automl.logger: 12-16 19:05:18] {2219} INFO - iteration 819, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:05:18] {2392} INFO -  at 88.1s,\testimator lgbm's best error=772.0458,\tbest estimator xgboost's best error=765.8599\n",
      "[flaml.automl.logger: 12-16 19:05:18] {2219} INFO - iteration 820, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:05:18] {2392} INFO -  at 88.2s,\testimator lgbm's best error=772.0458,\tbest estimator xgboost's best error=765.8599\n",
      "[flaml.automl.logger: 12-16 19:05:18] {2219} INFO - iteration 821, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:05:18] {2392} INFO -  at 88.2s,\testimator lgbm's best error=772.0458,\tbest estimator xgboost's best error=765.8599\n",
      "[flaml.automl.logger: 12-16 19:05:18] {2219} INFO - iteration 822, current learner xgboost\n",
      "[flaml.automl.logger: 12-16 19:05:18] {2392} INFO -  at 88.3s,\testimator xgboost's best error=765.8599,\tbest estimator xgboost's best error=765.8599\n",
      "[flaml.automl.logger: 12-16 19:05:18] {2219} INFO - iteration 823, current learner xgboost\n",
      "[flaml.automl.logger: 12-16 19:05:19] {2392} INFO -  at 88.7s,\testimator xgboost's best error=765.8599,\tbest estimator xgboost's best error=765.8599\n",
      "[flaml.automl.logger: 12-16 19:05:19] {2219} INFO - iteration 824, current learner xgboost\n",
      "[flaml.automl.logger: 12-16 19:05:19] {2392} INFO -  at 88.8s,\testimator xgboost's best error=765.8599,\tbest estimator xgboost's best error=765.8599\n",
      "[flaml.automl.logger: 12-16 19:05:19] {2219} INFO - iteration 825, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:05:19] {2392} INFO -  at 88.8s,\testimator lgbm's best error=772.0458,\tbest estimator xgboost's best error=765.8599\n",
      "[flaml.automl.logger: 12-16 19:05:19] {2219} INFO - iteration 826, current learner xgboost\n",
      "[flaml.automl.logger: 12-16 19:05:20] {2392} INFO -  at 89.6s,\testimator xgboost's best error=765.8599,\tbest estimator xgboost's best error=765.8599\n",
      "[flaml.automl.logger: 12-16 19:05:20] {2219} INFO - iteration 827, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:05:20] {2392} INFO -  at 89.6s,\testimator lgbm's best error=772.0458,\tbest estimator xgboost's best error=765.8599\n",
      "[flaml.automl.logger: 12-16 19:05:20] {2219} INFO - iteration 828, current learner xgboost\n",
      "[flaml.automl.logger: 12-16 19:05:20] {2392} INFO -  at 89.8s,\testimator xgboost's best error=765.8599,\tbest estimator xgboost's best error=765.8599\n",
      "[flaml.automl.logger: 12-16 19:05:20] {2219} INFO - iteration 829, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:05:20] {2392} INFO -  at 89.8s,\testimator lgbm's best error=772.0458,\tbest estimator xgboost's best error=765.8599\n",
      "[flaml.automl.logger: 12-16 19:05:20] {2219} INFO - iteration 830, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:05:20] {2392} INFO -  at 89.9s,\testimator lgbm's best error=772.0458,\tbest estimator xgboost's best error=765.8599\n",
      "[flaml.automl.logger: 12-16 19:05:20] {2219} INFO - iteration 831, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:05:20] {2392} INFO -  at 89.9s,\testimator lgbm's best error=772.0458,\tbest estimator xgboost's best error=765.8599\n",
      "[flaml.automl.logger: 12-16 19:05:20] {2219} INFO - iteration 832, current learner xgboost\n",
      "[flaml.automl.logger: 12-16 19:05:20] {2392} INFO -  at 90.0s,\testimator xgboost's best error=765.8599,\tbest estimator xgboost's best error=765.8599\n",
      "[flaml.automl.logger: 12-16 19:05:20] {2219} INFO - iteration 833, current learner xgboost\n",
      "[flaml.automl.logger: 12-16 19:05:20] {2392} INFO -  at 90.1s,\testimator xgboost's best error=765.8599,\tbest estimator xgboost's best error=765.8599\n",
      "[flaml.automl.logger: 12-16 19:05:20] {2219} INFO - iteration 834, current learner xgboost\n",
      "[flaml.automl.logger: 12-16 19:05:21] {2392} INFO -  at 90.5s,\testimator xgboost's best error=765.8599,\tbest estimator xgboost's best error=765.8599\n",
      "[flaml.automl.logger: 12-16 19:05:21] {2219} INFO - iteration 835, current learner xgboost\n",
      "[flaml.automl.logger: 12-16 19:05:21] {2392} INFO -  at 90.6s,\testimator xgboost's best error=765.8599,\tbest estimator xgboost's best error=765.8599\n",
      "[flaml.automl.logger: 12-16 19:05:21] {2219} INFO - iteration 836, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:05:21] {2392} INFO -  at 90.6s,\testimator lgbm's best error=772.0458,\tbest estimator xgboost's best error=765.8599\n",
      "[flaml.automl.logger: 12-16 19:05:21] {2219} INFO - iteration 837, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:05:21] {2392} INFO -  at 90.6s,\testimator lgbm's best error=772.0458,\tbest estimator xgboost's best error=765.8599\n",
      "[flaml.automl.logger: 12-16 19:05:21] {2219} INFO - iteration 838, current learner xgboost\n",
      "[flaml.automl.logger: 12-16 19:05:21] {2392} INFO -  at 91.0s,\testimator xgboost's best error=765.8599,\tbest estimator xgboost's best error=765.8599\n",
      "[flaml.automl.logger: 12-16 19:05:21] {2219} INFO - iteration 839, current learner xgboost\n",
      "[flaml.automl.logger: 12-16 19:05:21] {2392} INFO -  at 91.2s,\testimator xgboost's best error=765.8599,\tbest estimator xgboost's best error=765.8599\n",
      "[flaml.automl.logger: 12-16 19:05:21] {2219} INFO - iteration 840, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:05:21] {2392} INFO -  at 91.2s,\testimator lgbm's best error=772.0458,\tbest estimator xgboost's best error=765.8599\n",
      "[flaml.automl.logger: 12-16 19:05:21] {2219} INFO - iteration 841, current learner xgboost\n",
      "[flaml.automl.logger: 12-16 19:05:21] {2392} INFO -  at 91.4s,\testimator xgboost's best error=765.8599,\tbest estimator xgboost's best error=765.8599\n",
      "[flaml.automl.logger: 12-16 19:05:21] {2219} INFO - iteration 842, current learner rf\n",
      "[flaml.automl.logger: 12-16 19:05:22] {2392} INFO -  at 91.5s,\testimator rf's best error=946.9964,\tbest estimator xgboost's best error=765.8599\n",
      "[flaml.automl.logger: 12-16 19:05:22] {2219} INFO - iteration 843, current learner xgboost\n",
      "[flaml.automl.logger: 12-16 19:05:22] {2392} INFO -  at 91.7s,\testimator xgboost's best error=765.8599,\tbest estimator xgboost's best error=765.8599\n",
      "[flaml.automl.logger: 12-16 19:05:22] {2219} INFO - iteration 844, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:05:22] {2392} INFO -  at 91.7s,\testimator lgbm's best error=772.0458,\tbest estimator xgboost's best error=765.8599\n",
      "[flaml.automl.logger: 12-16 19:05:22] {2219} INFO - iteration 845, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:05:22] {2392} INFO -  at 91.7s,\testimator lgbm's best error=772.0458,\tbest estimator xgboost's best error=765.8599\n",
      "[flaml.automl.logger: 12-16 19:05:22] {2219} INFO - iteration 846, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:05:22] {2392} INFO -  at 91.7s,\testimator lgbm's best error=772.0458,\tbest estimator xgboost's best error=765.8599\n",
      "[flaml.automl.logger: 12-16 19:05:22] {2219} INFO - iteration 847, current learner xgboost\n",
      "[flaml.automl.logger: 12-16 19:05:22] {2392} INFO -  at 92.0s,\testimator xgboost's best error=765.8599,\tbest estimator xgboost's best error=765.8599\n",
      "[flaml.automl.logger: 12-16 19:05:22] {2219} INFO - iteration 848, current learner xgboost\n",
      "[flaml.automl.logger: 12-16 19:05:22] {2392} INFO -  at 92.4s,\testimator xgboost's best error=765.8599,\tbest estimator xgboost's best error=765.8599\n",
      "[flaml.automl.logger: 12-16 19:05:22] {2219} INFO - iteration 849, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:05:22] {2392} INFO -  at 92.4s,\testimator lgbm's best error=772.0458,\tbest estimator xgboost's best error=765.8599\n",
      "[flaml.automl.logger: 12-16 19:05:22] {2219} INFO - iteration 850, current learner xgboost\n",
      "[flaml.automl.logger: 12-16 19:05:23] {2392} INFO -  at 92.5s,\testimator xgboost's best error=765.8599,\tbest estimator xgboost's best error=765.8599\n",
      "[flaml.automl.logger: 12-16 19:05:23] {2219} INFO - iteration 851, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:05:23] {2392} INFO -  at 92.5s,\testimator lgbm's best error=772.0458,\tbest estimator xgboost's best error=765.8599\n",
      "[flaml.automl.logger: 12-16 19:05:23] {2219} INFO - iteration 852, current learner xgboost\n",
      "[flaml.automl.logger: 12-16 19:05:23] {2392} INFO -  at 92.6s,\testimator xgboost's best error=765.8599,\tbest estimator xgboost's best error=765.8599\n",
      "[flaml.automl.logger: 12-16 19:05:23] {2219} INFO - iteration 853, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:05:23] {2392} INFO -  at 92.7s,\testimator lgbm's best error=772.0458,\tbest estimator xgboost's best error=765.8599\n",
      "[flaml.automl.logger: 12-16 19:05:23] {2219} INFO - iteration 854, current learner xgboost\n",
      "[flaml.automl.logger: 12-16 19:05:23] {2392} INFO -  at 92.9s,\testimator xgboost's best error=765.8599,\tbest estimator xgboost's best error=765.8599\n",
      "[flaml.automl.logger: 12-16 19:05:23] {2219} INFO - iteration 855, current learner xgboost\n",
      "[flaml.automl.logger: 12-16 19:05:23] {2392} INFO -  at 93.1s,\testimator xgboost's best error=765.8599,\tbest estimator xgboost's best error=765.8599\n",
      "[flaml.automl.logger: 12-16 19:05:23] {2219} INFO - iteration 856, current learner xgboost\n",
      "[flaml.automl.logger: 12-16 19:05:23] {2392} INFO -  at 93.3s,\testimator xgboost's best error=765.8599,\tbest estimator xgboost's best error=765.8599\n",
      "[flaml.automl.logger: 12-16 19:05:23] {2219} INFO - iteration 857, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:05:23] {2392} INFO -  at 93.4s,\testimator lgbm's best error=772.0458,\tbest estimator xgboost's best error=765.8599\n",
      "[flaml.automl.logger: 12-16 19:05:23] {2219} INFO - iteration 858, current learner xgboost\n",
      "[flaml.automl.logger: 12-16 19:05:24] {2392} INFO -  at 93.7s,\testimator xgboost's best error=765.8599,\tbest estimator xgboost's best error=765.8599\n",
      "[flaml.automl.logger: 12-16 19:05:24] {2219} INFO - iteration 859, current learner extra_tree\n",
      "[flaml.automl.logger: 12-16 19:05:24] {2392} INFO -  at 93.8s,\testimator extra_tree's best error=934.9907,\tbest estimator xgboost's best error=765.8599\n",
      "[flaml.automl.logger: 12-16 19:05:24] {2219} INFO - iteration 860, current learner xgboost\n",
      "[flaml.automl.logger: 12-16 19:05:24] {2392} INFO -  at 94.0s,\testimator xgboost's best error=765.8599,\tbest estimator xgboost's best error=765.8599\n",
      "[flaml.automl.logger: 12-16 19:05:24] {2219} INFO - iteration 861, current learner xgboost\n",
      "[flaml.automl.logger: 12-16 19:05:24] {2392} INFO -  at 94.2s,\testimator xgboost's best error=765.8599,\tbest estimator xgboost's best error=765.8599\n",
      "[flaml.automl.logger: 12-16 19:05:24] {2219} INFO - iteration 862, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:05:24] {2392} INFO -  at 94.3s,\testimator lgbm's best error=772.0458,\tbest estimator xgboost's best error=765.8599\n",
      "[flaml.automl.logger: 12-16 19:05:24] {2219} INFO - iteration 863, current learner xgboost\n",
      "[flaml.automl.logger: 12-16 19:05:24] {2392} INFO -  at 94.4s,\testimator xgboost's best error=765.8599,\tbest estimator xgboost's best error=765.8599\n",
      "[flaml.automl.logger: 12-16 19:05:24] {2219} INFO - iteration 864, current learner xgboost\n",
      "[flaml.automl.logger: 12-16 19:05:25] {2392} INFO -  at 94.6s,\testimator xgboost's best error=765.8599,\tbest estimator xgboost's best error=765.8599\n",
      "[flaml.automl.logger: 12-16 19:05:25] {2219} INFO - iteration 865, current learner rf\n",
      "[flaml.automl.logger: 12-16 19:05:25] {2392} INFO -  at 94.7s,\testimator rf's best error=946.9964,\tbest estimator xgboost's best error=765.8599\n",
      "[flaml.automl.logger: 12-16 19:05:25] {2219} INFO - iteration 866, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:05:25] {2392} INFO -  at 94.7s,\testimator lgbm's best error=772.0458,\tbest estimator xgboost's best error=765.8599\n",
      "[flaml.automl.logger: 12-16 19:05:25] {2219} INFO - iteration 867, current learner xgboost\n",
      "[flaml.automl.logger: 12-16 19:05:25] {2392} INFO -  at 94.9s,\testimator xgboost's best error=765.8599,\tbest estimator xgboost's best error=765.8599\n",
      "[flaml.automl.logger: 12-16 19:05:25] {2219} INFO - iteration 868, current learner xgboost\n",
      "[flaml.automl.logger: 12-16 19:05:25] {2392} INFO -  at 95.0s,\testimator xgboost's best error=765.8599,\tbest estimator xgboost's best error=765.8599\n",
      "[flaml.automl.logger: 12-16 19:05:25] {2219} INFO - iteration 869, current learner xgboost\n",
      "[flaml.automl.logger: 12-16 19:05:25] {2392} INFO -  at 95.4s,\testimator xgboost's best error=765.8599,\tbest estimator xgboost's best error=765.8599\n",
      "[flaml.automl.logger: 12-16 19:05:25] {2219} INFO - iteration 870, current learner xgboost\n",
      "[flaml.automl.logger: 12-16 19:05:26] {2392} INFO -  at 95.5s,\testimator xgboost's best error=765.8599,\tbest estimator xgboost's best error=765.8599\n",
      "[flaml.automl.logger: 12-16 19:05:26] {2219} INFO - iteration 871, current learner xgboost\n",
      "[flaml.automl.logger: 12-16 19:05:26] {2392} INFO -  at 95.9s,\testimator xgboost's best error=765.8599,\tbest estimator xgboost's best error=765.8599\n",
      "[flaml.automl.logger: 12-16 19:05:26] {2219} INFO - iteration 872, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:05:26] {2392} INFO -  at 95.9s,\testimator lgbm's best error=772.0458,\tbest estimator xgboost's best error=765.8599\n",
      "[flaml.automl.logger: 12-16 19:05:26] {2219} INFO - iteration 873, current learner extra_tree\n",
      "[flaml.automl.logger: 12-16 19:05:26] {2392} INFO -  at 96.0s,\testimator extra_tree's best error=934.9907,\tbest estimator xgboost's best error=765.8599\n",
      "[flaml.automl.logger: 12-16 19:05:26] {2219} INFO - iteration 874, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:05:26] {2392} INFO -  at 96.0s,\testimator lgbm's best error=772.0458,\tbest estimator xgboost's best error=765.8599\n",
      "[flaml.automl.logger: 12-16 19:05:26] {2219} INFO - iteration 875, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:05:26] {2392} INFO -  at 96.1s,\testimator lgbm's best error=772.0458,\tbest estimator xgboost's best error=765.8599\n",
      "[flaml.automl.logger: 12-16 19:05:26] {2219} INFO - iteration 876, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:05:26] {2392} INFO -  at 96.1s,\testimator lgbm's best error=772.0458,\tbest estimator xgboost's best error=765.8599\n",
      "[flaml.automl.logger: 12-16 19:05:26] {2219} INFO - iteration 877, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:05:26] {2392} INFO -  at 96.2s,\testimator lgbm's best error=772.0458,\tbest estimator xgboost's best error=765.8599\n",
      "[flaml.automl.logger: 12-16 19:05:26] {2219} INFO - iteration 878, current learner xgboost\n",
      "[flaml.automl.logger: 12-16 19:05:26] {2392} INFO -  at 96.4s,\testimator xgboost's best error=765.8599,\tbest estimator xgboost's best error=765.8599\n",
      "[flaml.automl.logger: 12-16 19:05:26] {2219} INFO - iteration 879, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:05:26] {2392} INFO -  at 96.4s,\testimator lgbm's best error=772.0458,\tbest estimator xgboost's best error=765.8599\n",
      "[flaml.automl.logger: 12-16 19:05:26] {2219} INFO - iteration 880, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:05:26] {2392} INFO -  at 96.4s,\testimator lgbm's best error=772.0458,\tbest estimator xgboost's best error=765.8599\n",
      "[flaml.automl.logger: 12-16 19:05:26] {2219} INFO - iteration 881, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:05:27] {2392} INFO -  at 96.4s,\testimator lgbm's best error=772.0458,\tbest estimator xgboost's best error=765.8599\n",
      "[flaml.automl.logger: 12-16 19:05:27] {2219} INFO - iteration 882, current learner xgboost\n",
      "[flaml.automl.logger: 12-16 19:05:27] {2392} INFO -  at 96.6s,\testimator xgboost's best error=765.8599,\tbest estimator xgboost's best error=765.8599\n",
      "[flaml.automl.logger: 12-16 19:05:27] {2219} INFO - iteration 883, current learner xgboost\n",
      "[flaml.automl.logger: 12-16 19:05:27] {2392} INFO -  at 97.1s,\testimator xgboost's best error=765.8599,\tbest estimator xgboost's best error=765.8599\n",
      "[flaml.automl.logger: 12-16 19:05:27] {2219} INFO - iteration 884, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:05:27] {2392} INFO -  at 97.1s,\testimator lgbm's best error=772.0458,\tbest estimator xgboost's best error=765.8599\n",
      "[flaml.automl.logger: 12-16 19:05:27] {2219} INFO - iteration 885, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:05:27] {2392} INFO -  at 97.1s,\testimator lgbm's best error=772.0458,\tbest estimator xgboost's best error=765.8599\n",
      "[flaml.automl.logger: 12-16 19:05:27] {2219} INFO - iteration 886, current learner xgboost\n",
      "[flaml.automl.logger: 12-16 19:05:27] {2392} INFO -  at 97.2s,\testimator xgboost's best error=765.8599,\tbest estimator xgboost's best error=765.8599\n",
      "[flaml.automl.logger: 12-16 19:05:27] {2219} INFO - iteration 887, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:05:27] {2392} INFO -  at 97.2s,\testimator lgbm's best error=772.0458,\tbest estimator xgboost's best error=765.8599\n",
      "[flaml.automl.logger: 12-16 19:05:27] {2219} INFO - iteration 888, current learner xgboost\n",
      "[flaml.automl.logger: 12-16 19:05:28] {2392} INFO -  at 97.5s,\testimator xgboost's best error=765.8599,\tbest estimator xgboost's best error=765.8599\n",
      "[flaml.automl.logger: 12-16 19:05:28] {2219} INFO - iteration 889, current learner rf\n",
      "[flaml.automl.logger: 12-16 19:05:28] {2392} INFO -  at 97.6s,\testimator rf's best error=946.9964,\tbest estimator xgboost's best error=765.8599\n",
      "[flaml.automl.logger: 12-16 19:05:28] {2219} INFO - iteration 890, current learner xgboost\n",
      "[flaml.automl.logger: 12-16 19:05:28] {2392} INFO -  at 97.7s,\testimator xgboost's best error=765.8599,\tbest estimator xgboost's best error=765.8599\n",
      "[flaml.automl.logger: 12-16 19:05:28] {2219} INFO - iteration 891, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:05:28] {2392} INFO -  at 97.8s,\testimator lgbm's best error=772.0458,\tbest estimator xgboost's best error=765.8599\n",
      "[flaml.automl.logger: 12-16 19:05:28] {2219} INFO - iteration 892, current learner xgboost\n",
      "[flaml.automl.logger: 12-16 19:05:28] {2392} INFO -  at 98.2s,\testimator xgboost's best error=765.8599,\tbest estimator xgboost's best error=765.8599\n",
      "[flaml.automl.logger: 12-16 19:05:28] {2219} INFO - iteration 893, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:05:28] {2392} INFO -  at 98.3s,\testimator lgbm's best error=772.0458,\tbest estimator xgboost's best error=765.8599\n",
      "[flaml.automl.logger: 12-16 19:05:28] {2219} INFO - iteration 894, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:05:28] {2392} INFO -  at 98.3s,\testimator lgbm's best error=772.0458,\tbest estimator xgboost's best error=765.8599\n",
      "[flaml.automl.logger: 12-16 19:05:28] {2219} INFO - iteration 895, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:05:28] {2392} INFO -  at 98.3s,\testimator lgbm's best error=772.0458,\tbest estimator xgboost's best error=765.8599\n",
      "[flaml.automl.logger: 12-16 19:05:28] {2219} INFO - iteration 896, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:05:28] {2392} INFO -  at 98.3s,\testimator lgbm's best error=772.0458,\tbest estimator xgboost's best error=765.8599\n",
      "[flaml.automl.logger: 12-16 19:05:28] {2219} INFO - iteration 897, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:05:28] {2392} INFO -  at 98.4s,\testimator lgbm's best error=772.0458,\tbest estimator xgboost's best error=765.8599\n",
      "[flaml.automl.logger: 12-16 19:05:28] {2219} INFO - iteration 898, current learner extra_tree\n",
      "[flaml.automl.logger: 12-16 19:05:29] {2392} INFO -  at 98.5s,\testimator extra_tree's best error=934.9907,\tbest estimator xgboost's best error=765.8599\n",
      "[flaml.automl.logger: 12-16 19:05:29] {2219} INFO - iteration 899, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:05:29] {2392} INFO -  at 98.5s,\testimator lgbm's best error=772.0458,\tbest estimator xgboost's best error=765.8599\n",
      "[flaml.automl.logger: 12-16 19:05:29] {2219} INFO - iteration 900, current learner xgboost\n",
      "[flaml.automl.logger: 12-16 19:05:29] {2392} INFO -  at 98.6s,\testimator xgboost's best error=765.8599,\tbest estimator xgboost's best error=765.8599\n",
      "[flaml.automl.logger: 12-16 19:05:29] {2219} INFO - iteration 901, current learner xgboost\n",
      "[flaml.automl.logger: 12-16 19:05:29] {2392} INFO -  at 98.8s,\testimator xgboost's best error=765.8599,\tbest estimator xgboost's best error=765.8599\n",
      "[flaml.automl.logger: 12-16 19:05:29] {2219} INFO - iteration 902, current learner xgboost\n",
      "[flaml.automl.logger: 12-16 19:05:29] {2392} INFO -  at 99.0s,\testimator xgboost's best error=765.8599,\tbest estimator xgboost's best error=765.8599\n",
      "[flaml.automl.logger: 12-16 19:05:29] {2219} INFO - iteration 903, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:05:29] {2392} INFO -  at 99.0s,\testimator lgbm's best error=772.0458,\tbest estimator xgboost's best error=765.8599\n",
      "[flaml.automl.logger: 12-16 19:05:29] {2219} INFO - iteration 904, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:05:29] {2392} INFO -  at 99.0s,\testimator lgbm's best error=772.0458,\tbest estimator xgboost's best error=765.8599\n",
      "[flaml.automl.logger: 12-16 19:05:29] {2219} INFO - iteration 905, current learner xgboost\n",
      "[flaml.automl.logger: 12-16 19:05:29] {2392} INFO -  at 99.1s,\testimator xgboost's best error=765.8599,\tbest estimator xgboost's best error=765.8599\n",
      "[flaml.automl.logger: 12-16 19:05:29] {2219} INFO - iteration 906, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:05:29] {2392} INFO -  at 99.2s,\testimator lgbm's best error=772.0458,\tbest estimator xgboost's best error=765.8599\n",
      "[flaml.automl.logger: 12-16 19:05:29] {2219} INFO - iteration 907, current learner xgboost\n",
      "[flaml.automl.logger: 12-16 19:05:30] {2392} INFO -  at 99.4s,\testimator xgboost's best error=765.8599,\tbest estimator xgboost's best error=765.8599\n",
      "[flaml.automl.logger: 12-16 19:05:30] {2219} INFO - iteration 908, current learner xgboost\n",
      "[flaml.automl.logger: 12-16 19:05:30] {2392} INFO -  at 99.6s,\testimator xgboost's best error=765.8599,\tbest estimator xgboost's best error=765.8599\n",
      "[flaml.automl.logger: 12-16 19:05:30] {2219} INFO - iteration 909, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:05:30] {2392} INFO -  at 99.6s,\testimator lgbm's best error=772.0458,\tbest estimator xgboost's best error=765.8599\n",
      "[flaml.automl.logger: 12-16 19:05:30] {2219} INFO - iteration 910, current learner extra_tree\n",
      "[flaml.automl.logger: 12-16 19:05:30] {2392} INFO -  at 99.7s,\testimator extra_tree's best error=934.9907,\tbest estimator xgboost's best error=765.8599\n",
      "[flaml.automl.logger: 12-16 19:05:30] {2219} INFO - iteration 911, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:05:30] {2392} INFO -  at 99.8s,\testimator lgbm's best error=772.0458,\tbest estimator xgboost's best error=765.8599\n",
      "[flaml.automl.logger: 12-16 19:05:30] {2219} INFO - iteration 912, current learner xgboost\n",
      "[flaml.automl.logger: 12-16 19:05:30] {2392} INFO -  at 100.1s,\testimator xgboost's best error=765.8599,\tbest estimator xgboost's best error=765.8599\n",
      "[flaml.automl.logger: 12-16 19:05:30] {2219} INFO - iteration 913, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:05:30] {2392} INFO -  at 100.1s,\testimator lgbm's best error=772.0458,\tbest estimator xgboost's best error=765.8599\n",
      "[flaml.automl.logger: 12-16 19:05:30] {2219} INFO - iteration 914, current learner xgboost\n",
      "[flaml.automl.logger: 12-16 19:05:30] {2392} INFO -  at 100.2s,\testimator xgboost's best error=765.8599,\tbest estimator xgboost's best error=765.8599\n",
      "[flaml.automl.logger: 12-16 19:05:30] {2219} INFO - iteration 915, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:05:30] {2392} INFO -  at 100.2s,\testimator lgbm's best error=772.0458,\tbest estimator xgboost's best error=765.8599\n",
      "[flaml.automl.logger: 12-16 19:05:30] {2219} INFO - iteration 916, current learner xgboost\n",
      "[flaml.automl.logger: 12-16 19:05:31] {2392} INFO -  at 100.7s,\testimator xgboost's best error=765.8599,\tbest estimator xgboost's best error=765.8599\n",
      "[flaml.automl.logger: 12-16 19:05:31] {2219} INFO - iteration 917, current learner extra_tree\n",
      "[flaml.automl.logger: 12-16 19:05:31] {2392} INFO -  at 100.8s,\testimator extra_tree's best error=934.9907,\tbest estimator xgboost's best error=765.8599\n",
      "[flaml.automl.logger: 12-16 19:05:31] {2219} INFO - iteration 918, current learner xgboost\n",
      "[flaml.automl.logger: 12-16 19:05:31] {2392} INFO -  at 101.1s,\testimator xgboost's best error=765.8599,\tbest estimator xgboost's best error=765.8599\n",
      "[flaml.automl.logger: 12-16 19:05:31] {2219} INFO - iteration 919, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:05:31] {2392} INFO -  at 101.1s,\testimator lgbm's best error=772.0458,\tbest estimator xgboost's best error=765.8599\n",
      "[flaml.automl.logger: 12-16 19:05:31] {2219} INFO - iteration 920, current learner xgboost\n",
      "[flaml.automl.logger: 12-16 19:05:31] {2392} INFO -  at 101.2s,\testimator xgboost's best error=765.8599,\tbest estimator xgboost's best error=765.8599\n",
      "[flaml.automl.logger: 12-16 19:05:31] {2219} INFO - iteration 921, current learner xgboost\n",
      "[flaml.automl.logger: 12-16 19:05:32] {2392} INFO -  at 101.6s,\testimator xgboost's best error=765.8599,\tbest estimator xgboost's best error=765.8599\n",
      "[flaml.automl.logger: 12-16 19:05:32] {2219} INFO - iteration 922, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:05:32] {2392} INFO -  at 101.6s,\testimator lgbm's best error=772.0458,\tbest estimator xgboost's best error=765.8599\n",
      "[flaml.automl.logger: 12-16 19:05:32] {2219} INFO - iteration 923, current learner xgboost\n",
      "[flaml.automl.logger: 12-16 19:05:32] {2392} INFO -  at 101.7s,\testimator xgboost's best error=765.8599,\tbest estimator xgboost's best error=765.8599\n",
      "[flaml.automl.logger: 12-16 19:05:32] {2219} INFO - iteration 924, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:05:32] {2392} INFO -  at 101.8s,\testimator lgbm's best error=772.0458,\tbest estimator xgboost's best error=765.8599\n",
      "[flaml.automl.logger: 12-16 19:05:32] {2219} INFO - iteration 925, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:05:32] {2392} INFO -  at 101.8s,\testimator lgbm's best error=772.0458,\tbest estimator xgboost's best error=765.8599\n",
      "[flaml.automl.logger: 12-16 19:05:32] {2219} INFO - iteration 926, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:05:32] {2392} INFO -  at 101.8s,\testimator lgbm's best error=772.0458,\tbest estimator xgboost's best error=765.8599\n",
      "[flaml.automl.logger: 12-16 19:05:32] {2219} INFO - iteration 927, current learner xgboost\n",
      "[flaml.automl.logger: 12-16 19:05:32] {2392} INFO -  at 102.0s,\testimator xgboost's best error=765.8599,\tbest estimator xgboost's best error=765.8599\n",
      "[flaml.automl.logger: 12-16 19:05:32] {2219} INFO - iteration 928, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:05:32] {2392} INFO -  at 102.1s,\testimator lgbm's best error=772.0458,\tbest estimator xgboost's best error=765.8599\n",
      "[flaml.automl.logger: 12-16 19:05:32] {2219} INFO - iteration 929, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:05:32] {2392} INFO -  at 102.1s,\testimator lgbm's best error=772.0458,\tbest estimator xgboost's best error=765.8599\n",
      "[flaml.automl.logger: 12-16 19:05:32] {2219} INFO - iteration 930, current learner xgboost\n",
      "[flaml.automl.logger: 12-16 19:05:32] {2392} INFO -  at 102.2s,\testimator xgboost's best error=765.8599,\tbest estimator xgboost's best error=765.8599\n",
      "[flaml.automl.logger: 12-16 19:05:32] {2219} INFO - iteration 931, current learner rf\n",
      "[flaml.automl.logger: 12-16 19:05:32] {2392} INFO -  at 102.4s,\testimator rf's best error=946.9964,\tbest estimator xgboost's best error=765.8599\n",
      "[flaml.automl.logger: 12-16 19:05:32] {2219} INFO - iteration 932, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:05:32] {2392} INFO -  at 102.4s,\testimator lgbm's best error=772.0458,\tbest estimator xgboost's best error=765.8599\n",
      "[flaml.automl.logger: 12-16 19:05:32] {2219} INFO - iteration 933, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:05:32] {2392} INFO -  at 102.4s,\testimator lgbm's best error=772.0458,\tbest estimator xgboost's best error=765.8599\n",
      "[flaml.automl.logger: 12-16 19:05:32] {2219} INFO - iteration 934, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:05:33] {2392} INFO -  at 102.4s,\testimator lgbm's best error=772.0458,\tbest estimator xgboost's best error=765.8599\n",
      "[flaml.automl.logger: 12-16 19:05:33] {2219} INFO - iteration 935, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:05:33] {2392} INFO -  at 102.5s,\testimator lgbm's best error=772.0458,\tbest estimator xgboost's best error=765.8599\n",
      "[flaml.automl.logger: 12-16 19:05:33] {2219} INFO - iteration 936, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:05:33] {2392} INFO -  at 102.5s,\testimator lgbm's best error=772.0458,\tbest estimator xgboost's best error=765.8599\n",
      "[flaml.automl.logger: 12-16 19:05:33] {2219} INFO - iteration 937, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:05:33] {2392} INFO -  at 102.5s,\testimator lgbm's best error=772.0458,\tbest estimator xgboost's best error=765.8599\n",
      "[flaml.automl.logger: 12-16 19:05:33] {2219} INFO - iteration 938, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:05:33] {2392} INFO -  at 102.6s,\testimator lgbm's best error=772.0458,\tbest estimator xgboost's best error=765.8599\n",
      "[flaml.automl.logger: 12-16 19:05:33] {2219} INFO - iteration 939, current learner extra_tree\n",
      "[flaml.automl.logger: 12-16 19:05:33] {2392} INFO -  at 102.7s,\testimator extra_tree's best error=934.9907,\tbest estimator xgboost's best error=765.8599\n",
      "[flaml.automl.logger: 12-16 19:05:33] {2219} INFO - iteration 940, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:05:33] {2392} INFO -  at 102.8s,\testimator lgbm's best error=772.0458,\tbest estimator xgboost's best error=765.8599\n",
      "[flaml.automl.logger: 12-16 19:05:33] {2219} INFO - iteration 941, current learner xgboost\n",
      "[flaml.automl.logger: 12-16 19:05:33] {2392} INFO -  at 102.9s,\testimator xgboost's best error=765.8599,\tbest estimator xgboost's best error=765.8599\n",
      "[flaml.automl.logger: 12-16 19:05:33] {2219} INFO - iteration 942, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:05:33] {2392} INFO -  at 103.0s,\testimator lgbm's best error=772.0458,\tbest estimator xgboost's best error=765.8599\n",
      "[flaml.automl.logger: 12-16 19:05:33] {2219} INFO - iteration 943, current learner xgboost\n",
      "[flaml.automl.logger: 12-16 19:05:33] {2392} INFO -  at 103.1s,\testimator xgboost's best error=765.8599,\tbest estimator xgboost's best error=765.8599\n",
      "[flaml.automl.logger: 12-16 19:05:33] {2219} INFO - iteration 944, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:05:33] {2392} INFO -  at 103.2s,\testimator lgbm's best error=772.0458,\tbest estimator xgboost's best error=765.8599\n",
      "[flaml.automl.logger: 12-16 19:05:33] {2219} INFO - iteration 945, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:05:33] {2392} INFO -  at 103.2s,\testimator lgbm's best error=772.0458,\tbest estimator xgboost's best error=765.8599\n",
      "[flaml.automl.logger: 12-16 19:05:33] {2219} INFO - iteration 946, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:05:33] {2392} INFO -  at 103.3s,\testimator lgbm's best error=772.0458,\tbest estimator xgboost's best error=765.8599\n",
      "[flaml.automl.logger: 12-16 19:05:33] {2219} INFO - iteration 947, current learner xgboost\n",
      "[flaml.automl.logger: 12-16 19:05:34] {2392} INFO -  at 103.6s,\testimator xgboost's best error=765.8599,\tbest estimator xgboost's best error=765.8599\n",
      "[flaml.automl.logger: 12-16 19:05:34] {2219} INFO - iteration 948, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:05:34] {2392} INFO -  at 103.7s,\testimator lgbm's best error=772.0458,\tbest estimator xgboost's best error=765.8599\n",
      "[flaml.automl.logger: 12-16 19:05:34] {2219} INFO - iteration 949, current learner xgboost\n",
      "[flaml.automl.logger: 12-16 19:05:34] {2392} INFO -  at 103.7s,\testimator xgboost's best error=765.8599,\tbest estimator xgboost's best error=765.8599\n",
      "[flaml.automl.logger: 12-16 19:05:34] {2219} INFO - iteration 950, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:05:34] {2392} INFO -  at 103.8s,\testimator lgbm's best error=772.0458,\tbest estimator xgboost's best error=765.8599\n",
      "[flaml.automl.logger: 12-16 19:05:34] {2219} INFO - iteration 951, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:05:34] {2392} INFO -  at 103.8s,\testimator lgbm's best error=772.0458,\tbest estimator xgboost's best error=765.8599\n",
      "[flaml.automl.logger: 12-16 19:05:34] {2219} INFO - iteration 952, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:05:34] {2392} INFO -  at 103.9s,\testimator lgbm's best error=772.0458,\tbest estimator xgboost's best error=765.8599\n",
      "[flaml.automl.logger: 12-16 19:05:34] {2219} INFO - iteration 953, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:05:34] {2392} INFO -  at 103.9s,\testimator lgbm's best error=772.0458,\tbest estimator xgboost's best error=765.8599\n",
      "[flaml.automl.logger: 12-16 19:05:34] {2219} INFO - iteration 954, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:05:34] {2392} INFO -  at 103.9s,\testimator lgbm's best error=772.0458,\tbest estimator xgboost's best error=765.8599\n",
      "[flaml.automl.logger: 12-16 19:05:34] {2219} INFO - iteration 955, current learner xgboost\n",
      "[flaml.automl.logger: 12-16 19:05:34] {2392} INFO -  at 104.2s,\testimator xgboost's best error=765.8599,\tbest estimator xgboost's best error=765.8599\n",
      "[flaml.automl.logger: 12-16 19:05:34] {2219} INFO - iteration 956, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:05:34] {2392} INFO -  at 104.2s,\testimator lgbm's best error=772.0458,\tbest estimator xgboost's best error=765.8599\n",
      "[flaml.automl.logger: 12-16 19:05:34] {2219} INFO - iteration 957, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:05:34] {2392} INFO -  at 104.3s,\testimator lgbm's best error=772.0458,\tbest estimator xgboost's best error=765.8599\n",
      "[flaml.automl.logger: 12-16 19:05:34] {2219} INFO - iteration 958, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:05:34] {2392} INFO -  at 104.3s,\testimator lgbm's best error=772.0458,\tbest estimator xgboost's best error=765.8599\n",
      "[flaml.automl.logger: 12-16 19:05:34] {2219} INFO - iteration 959, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:05:34] {2392} INFO -  at 104.3s,\testimator lgbm's best error=772.0458,\tbest estimator xgboost's best error=765.8599\n",
      "[flaml.automl.logger: 12-16 19:05:34] {2219} INFO - iteration 960, current learner xgboost\n",
      "[flaml.automl.logger: 12-16 19:05:35] {2392} INFO -  at 104.4s,\testimator xgboost's best error=765.8599,\tbest estimator xgboost's best error=765.8599\n",
      "[flaml.automl.logger: 12-16 19:05:35] {2219} INFO - iteration 961, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:05:35] {2392} INFO -  at 104.5s,\testimator lgbm's best error=772.0458,\tbest estimator xgboost's best error=765.8599\n",
      "[flaml.automl.logger: 12-16 19:05:35] {2219} INFO - iteration 962, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:05:35] {2392} INFO -  at 104.5s,\testimator lgbm's best error=772.0458,\tbest estimator xgboost's best error=765.8599\n",
      "[flaml.automl.logger: 12-16 19:05:35] {2219} INFO - iteration 963, current learner xgboost\n",
      "[flaml.automl.logger: 12-16 19:05:35] {2392} INFO -  at 104.6s,\testimator xgboost's best error=765.8599,\tbest estimator xgboost's best error=765.8599\n",
      "[flaml.automl.logger: 12-16 19:05:35] {2219} INFO - iteration 964, current learner extra_tree\n",
      "[flaml.automl.logger: 12-16 19:05:35] {2392} INFO -  at 104.7s,\testimator extra_tree's best error=934.9907,\tbest estimator xgboost's best error=765.8599\n",
      "[flaml.automl.logger: 12-16 19:05:35] {2219} INFO - iteration 965, current learner xgboost\n",
      "[flaml.automl.logger: 12-16 19:05:36] {2392} INFO -  at 105.6s,\testimator xgboost's best error=765.8599,\tbest estimator xgboost's best error=765.8599\n",
      "[flaml.automl.logger: 12-16 19:05:36] {2219} INFO - iteration 966, current learner xgboost\n",
      "[flaml.automl.logger: 12-16 19:05:36] {2392} INFO -  at 105.7s,\testimator xgboost's best error=765.8599,\tbest estimator xgboost's best error=765.8599\n",
      "[flaml.automl.logger: 12-16 19:05:36] {2219} INFO - iteration 967, current learner xgboost\n",
      "[flaml.automl.logger: 12-16 19:05:36] {2392} INFO -  at 105.9s,\testimator xgboost's best error=765.8599,\tbest estimator xgboost's best error=765.8599\n",
      "[flaml.automl.logger: 12-16 19:05:36] {2219} INFO - iteration 968, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:05:36] {2392} INFO -  at 105.9s,\testimator lgbm's best error=772.0458,\tbest estimator xgboost's best error=765.8599\n",
      "[flaml.automl.logger: 12-16 19:05:36] {2219} INFO - iteration 969, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:05:36] {2392} INFO -  at 106.0s,\testimator lgbm's best error=772.0458,\tbest estimator xgboost's best error=765.8599\n",
      "[flaml.automl.logger: 12-16 19:05:36] {2219} INFO - iteration 970, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:05:36] {2392} INFO -  at 106.0s,\testimator lgbm's best error=772.0458,\tbest estimator xgboost's best error=765.8599\n",
      "[flaml.automl.logger: 12-16 19:05:36] {2219} INFO - iteration 971, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:05:36] {2392} INFO -  at 106.0s,\testimator lgbm's best error=772.0458,\tbest estimator xgboost's best error=765.8599\n",
      "[flaml.automl.logger: 12-16 19:05:36] {2219} INFO - iteration 972, current learner xgboost\n",
      "[flaml.automl.logger: 12-16 19:05:37] {2392} INFO -  at 106.9s,\testimator xgboost's best error=765.8599,\tbest estimator xgboost's best error=765.8599\n",
      "[flaml.automl.logger: 12-16 19:05:37] {2219} INFO - iteration 973, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:05:37] {2392} INFO -  at 106.9s,\testimator lgbm's best error=772.0458,\tbest estimator xgboost's best error=765.8599\n",
      "[flaml.automl.logger: 12-16 19:05:37] {2219} INFO - iteration 974, current learner rf\n",
      "[flaml.automl.logger: 12-16 19:05:37] {2392} INFO -  at 107.0s,\testimator rf's best error=946.9964,\tbest estimator xgboost's best error=765.8599\n",
      "[flaml.automl.logger: 12-16 19:05:37] {2219} INFO - iteration 975, current learner xgboost\n",
      "[flaml.automl.logger: 12-16 19:05:37] {2392} INFO -  at 107.1s,\testimator xgboost's best error=765.8599,\tbest estimator xgboost's best error=765.8599\n",
      "[flaml.automl.logger: 12-16 19:05:37] {2219} INFO - iteration 976, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:05:37] {2392} INFO -  at 107.1s,\testimator lgbm's best error=772.0458,\tbest estimator xgboost's best error=765.8599\n",
      "[flaml.automl.logger: 12-16 19:05:37] {2219} INFO - iteration 977, current learner xgboost\n",
      "[flaml.automl.logger: 12-16 19:05:37] {2392} INFO -  at 107.3s,\testimator xgboost's best error=765.8599,\tbest estimator xgboost's best error=765.8599\n",
      "[flaml.automl.logger: 12-16 19:05:37] {2219} INFO - iteration 978, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:05:37] {2392} INFO -  at 107.4s,\testimator lgbm's best error=772.0458,\tbest estimator xgboost's best error=765.8599\n",
      "[flaml.automl.logger: 12-16 19:05:37] {2219} INFO - iteration 979, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:05:37] {2392} INFO -  at 107.4s,\testimator lgbm's best error=772.0458,\tbest estimator xgboost's best error=765.8599\n",
      "[flaml.automl.logger: 12-16 19:05:37] {2219} INFO - iteration 980, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:05:37] {2392} INFO -  at 107.4s,\testimator lgbm's best error=772.0458,\tbest estimator xgboost's best error=765.8599\n",
      "[flaml.automl.logger: 12-16 19:05:37] {2219} INFO - iteration 981, current learner rf\n",
      "[flaml.automl.logger: 12-16 19:05:38] {2392} INFO -  at 107.5s,\testimator rf's best error=946.9964,\tbest estimator xgboost's best error=765.8599\n",
      "[flaml.automl.logger: 12-16 19:05:38] {2219} INFO - iteration 982, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:05:38] {2392} INFO -  at 107.6s,\testimator lgbm's best error=772.0458,\tbest estimator xgboost's best error=765.8599\n",
      "[flaml.automl.logger: 12-16 19:05:38] {2219} INFO - iteration 983, current learner xgboost\n",
      "[flaml.automl.logger: 12-16 19:05:38] {2392} INFO -  at 107.8s,\testimator xgboost's best error=765.8599,\tbest estimator xgboost's best error=765.8599\n",
      "[flaml.automl.logger: 12-16 19:05:38] {2219} INFO - iteration 984, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:05:38] {2392} INFO -  at 107.8s,\testimator lgbm's best error=772.0458,\tbest estimator xgboost's best error=765.8599\n",
      "[flaml.automl.logger: 12-16 19:05:38] {2219} INFO - iteration 985, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:05:38] {2392} INFO -  at 107.8s,\testimator lgbm's best error=772.0458,\tbest estimator xgboost's best error=765.8599\n",
      "[flaml.automl.logger: 12-16 19:05:38] {2219} INFO - iteration 986, current learner xgboost\n",
      "[flaml.automl.logger: 12-16 19:05:38] {2392} INFO -  at 108.0s,\testimator xgboost's best error=765.8599,\tbest estimator xgboost's best error=765.8599\n",
      "[flaml.automl.logger: 12-16 19:05:38] {2219} INFO - iteration 987, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:05:38] {2392} INFO -  at 108.0s,\testimator lgbm's best error=772.0458,\tbest estimator xgboost's best error=765.8599\n",
      "[flaml.automl.logger: 12-16 19:05:38] {2219} INFO - iteration 988, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:05:38] {2392} INFO -  at 108.0s,\testimator lgbm's best error=772.0458,\tbest estimator xgboost's best error=765.8599\n",
      "[flaml.automl.logger: 12-16 19:05:38] {2219} INFO - iteration 989, current learner xgboost\n",
      "[flaml.automl.logger: 12-16 19:05:38] {2392} INFO -  at 108.3s,\testimator xgboost's best error=765.8599,\tbest estimator xgboost's best error=765.8599\n",
      "[flaml.automl.logger: 12-16 19:05:38] {2219} INFO - iteration 990, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:05:38] {2392} INFO -  at 108.4s,\testimator lgbm's best error=772.0458,\tbest estimator xgboost's best error=765.8599\n",
      "[flaml.automl.logger: 12-16 19:05:38] {2219} INFO - iteration 991, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:05:38] {2392} INFO -  at 108.4s,\testimator lgbm's best error=772.0458,\tbest estimator xgboost's best error=765.8599\n",
      "[flaml.automl.logger: 12-16 19:05:38] {2219} INFO - iteration 992, current learner xgboost\n",
      "[flaml.automl.logger: 12-16 19:05:39] {2392} INFO -  at 108.7s,\testimator xgboost's best error=765.8599,\tbest estimator xgboost's best error=765.8599\n",
      "[flaml.automl.logger: 12-16 19:05:39] {2219} INFO - iteration 993, current learner extra_tree\n",
      "[flaml.automl.logger: 12-16 19:05:39] {2392} INFO -  at 108.8s,\testimator extra_tree's best error=934.9907,\tbest estimator xgboost's best error=765.8599\n",
      "[flaml.automl.logger: 12-16 19:05:39] {2219} INFO - iteration 994, current learner xgboost\n",
      "[flaml.automl.logger: 12-16 19:05:39] {2392} INFO -  at 108.9s,\testimator xgboost's best error=765.8599,\tbest estimator xgboost's best error=765.8599\n",
      "[flaml.automl.logger: 12-16 19:05:39] {2219} INFO - iteration 995, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:05:39] {2392} INFO -  at 108.9s,\testimator lgbm's best error=772.0458,\tbest estimator xgboost's best error=765.8599\n",
      "[flaml.automl.logger: 12-16 19:05:39] {2219} INFO - iteration 996, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:05:39] {2392} INFO -  at 109.0s,\testimator lgbm's best error=772.0458,\tbest estimator xgboost's best error=765.8599\n",
      "[flaml.automl.logger: 12-16 19:05:39] {2219} INFO - iteration 997, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:05:39] {2392} INFO -  at 109.0s,\testimator lgbm's best error=772.0458,\tbest estimator xgboost's best error=765.8599\n",
      "[flaml.automl.logger: 12-16 19:05:39] {2219} INFO - iteration 998, current learner xgboost\n",
      "[flaml.automl.logger: 12-16 19:05:39] {2392} INFO -  at 109.2s,\testimator xgboost's best error=765.8599,\tbest estimator xgboost's best error=765.8599\n",
      "[flaml.automl.logger: 12-16 19:05:39] {2219} INFO - iteration 999, current learner extra_tree\n",
      "[flaml.automl.logger: 12-16 19:05:39] {2392} INFO -  at 109.4s,\testimator extra_tree's best error=934.9907,\tbest estimator xgboost's best error=765.8599\n",
      "[flaml.automl.logger: 12-16 19:05:39] {2219} INFO - iteration 1000, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:05:39] {2392} INFO -  at 109.4s,\testimator lgbm's best error=772.0458,\tbest estimator xgboost's best error=765.8599\n",
      "[flaml.automl.logger: 12-16 19:05:39] {2219} INFO - iteration 1001, current learner xgboost\n",
      "[flaml.automl.logger: 12-16 19:05:40] {2392} INFO -  at 109.5s,\testimator xgboost's best error=765.8599,\tbest estimator xgboost's best error=765.8599\n",
      "[flaml.automl.logger: 12-16 19:05:40] {2219} INFO - iteration 1002, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:05:40] {2392} INFO -  at 109.6s,\testimator lgbm's best error=772.0458,\tbest estimator xgboost's best error=765.8599\n",
      "[flaml.automl.logger: 12-16 19:05:40] {2219} INFO - iteration 1003, current learner xgboost\n",
      "[flaml.automl.logger: 12-16 19:05:40] {2392} INFO -  at 109.7s,\testimator xgboost's best error=765.8599,\tbest estimator xgboost's best error=765.8599\n",
      "[flaml.automl.logger: 12-16 19:05:40] {2219} INFO - iteration 1004, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:05:40] {2392} INFO -  at 109.7s,\testimator lgbm's best error=772.0458,\tbest estimator xgboost's best error=765.8599\n",
      "[flaml.automl.logger: 12-16 19:05:40] {2219} INFO - iteration 1005, current learner xgboost\n",
      "[flaml.automl.logger: 12-16 19:05:40] {2392} INFO -  at 110.0s,\testimator xgboost's best error=765.8599,\tbest estimator xgboost's best error=765.8599\n",
      "[flaml.automl.logger: 12-16 19:05:40] {2219} INFO - iteration 1006, current learner xgboost\n",
      "[flaml.automl.logger: 12-16 19:05:41] {2392} INFO -  at 110.6s,\testimator xgboost's best error=765.8599,\tbest estimator xgboost's best error=765.8599\n",
      "[flaml.automl.logger: 12-16 19:05:41] {2219} INFO - iteration 1007, current learner xgboost\n",
      "[flaml.automl.logger: 12-16 19:05:41] {2392} INFO -  at 110.7s,\testimator xgboost's best error=765.8599,\tbest estimator xgboost's best error=765.8599\n",
      "[flaml.automl.logger: 12-16 19:05:41] {2219} INFO - iteration 1008, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:05:41] {2392} INFO -  at 110.7s,\testimator lgbm's best error=772.0458,\tbest estimator xgboost's best error=765.8599\n",
      "[flaml.automl.logger: 12-16 19:05:41] {2219} INFO - iteration 1009, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:05:41] {2392} INFO -  at 110.8s,\testimator lgbm's best error=772.0458,\tbest estimator xgboost's best error=765.8599\n",
      "[flaml.automl.logger: 12-16 19:05:41] {2219} INFO - iteration 1010, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:05:41] {2392} INFO -  at 110.8s,\testimator lgbm's best error=772.0458,\tbest estimator xgboost's best error=765.8599\n",
      "[flaml.automl.logger: 12-16 19:05:41] {2219} INFO - iteration 1011, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:05:41] {2392} INFO -  at 110.8s,\testimator lgbm's best error=772.0458,\tbest estimator xgboost's best error=765.8599\n",
      "[flaml.automl.logger: 12-16 19:05:41] {2219} INFO - iteration 1012, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:05:41] {2392} INFO -  at 110.8s,\testimator lgbm's best error=772.0458,\tbest estimator xgboost's best error=765.8599\n",
      "[flaml.automl.logger: 12-16 19:05:41] {2219} INFO - iteration 1013, current learner xgboost\n",
      "[flaml.automl.logger: 12-16 19:05:41] {2392} INFO -  at 110.9s,\testimator xgboost's best error=765.8599,\tbest estimator xgboost's best error=765.8599\n",
      "[flaml.automl.logger: 12-16 19:05:41] {2219} INFO - iteration 1014, current learner xgboost\n",
      "[flaml.automl.logger: 12-16 19:05:41] {2392} INFO -  at 111.4s,\testimator xgboost's best error=765.8599,\tbest estimator xgboost's best error=765.8599\n",
      "[flaml.automl.logger: 12-16 19:05:41] {2219} INFO - iteration 1015, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:05:41] {2392} INFO -  at 111.4s,\testimator lgbm's best error=772.0458,\tbest estimator xgboost's best error=765.8599\n",
      "[flaml.automl.logger: 12-16 19:05:41] {2219} INFO - iteration 1016, current learner xgboost\n",
      "[flaml.automl.logger: 12-16 19:05:42] {2392} INFO -  at 111.5s,\testimator xgboost's best error=765.8599,\tbest estimator xgboost's best error=765.8599\n",
      "[flaml.automl.logger: 12-16 19:05:42] {2219} INFO - iteration 1017, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:05:42] {2392} INFO -  at 111.6s,\testimator lgbm's best error=772.0458,\tbest estimator xgboost's best error=765.8599\n",
      "[flaml.automl.logger: 12-16 19:05:42] {2219} INFO - iteration 1018, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:05:42] {2392} INFO -  at 111.6s,\testimator lgbm's best error=772.0458,\tbest estimator xgboost's best error=765.8599\n",
      "[flaml.automl.logger: 12-16 19:05:42] {2219} INFO - iteration 1019, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:05:42] {2392} INFO -  at 111.7s,\testimator lgbm's best error=772.0458,\tbest estimator xgboost's best error=765.8599\n",
      "[flaml.automl.logger: 12-16 19:05:42] {2219} INFO - iteration 1020, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:05:42] {2392} INFO -  at 111.7s,\testimator lgbm's best error=772.0458,\tbest estimator xgboost's best error=765.8599\n",
      "[flaml.automl.logger: 12-16 19:05:42] {2219} INFO - iteration 1021, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:05:42] {2392} INFO -  at 111.7s,\testimator lgbm's best error=772.0458,\tbest estimator xgboost's best error=765.8599\n",
      "[flaml.automl.logger: 12-16 19:05:42] {2219} INFO - iteration 1022, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:05:42] {2392} INFO -  at 111.7s,\testimator lgbm's best error=772.0458,\tbest estimator xgboost's best error=765.8599\n",
      "[flaml.automl.logger: 12-16 19:05:42] {2219} INFO - iteration 1023, current learner xgboost\n",
      "[flaml.automl.logger: 12-16 19:05:42] {2392} INFO -  at 111.9s,\testimator xgboost's best error=765.8599,\tbest estimator xgboost's best error=765.8599\n",
      "[flaml.automl.logger: 12-16 19:05:42] {2219} INFO - iteration 1024, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:05:42] {2392} INFO -  at 111.9s,\testimator lgbm's best error=772.0458,\tbest estimator xgboost's best error=765.8599\n",
      "[flaml.automl.logger: 12-16 19:05:42] {2219} INFO - iteration 1025, current learner xgboost\n",
      "[flaml.automl.logger: 12-16 19:05:42] {2392} INFO -  at 112.2s,\testimator xgboost's best error=765.8599,\tbest estimator xgboost's best error=765.8599\n",
      "[flaml.automl.logger: 12-16 19:05:42] {2219} INFO - iteration 1026, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:05:42] {2392} INFO -  at 112.2s,\testimator lgbm's best error=772.0458,\tbest estimator xgboost's best error=765.8599\n",
      "[flaml.automl.logger: 12-16 19:05:42] {2219} INFO - iteration 1027, current learner xgboost\n",
      "[flaml.automl.logger: 12-16 19:05:42] {2392} INFO -  at 112.3s,\testimator xgboost's best error=765.8599,\tbest estimator xgboost's best error=765.8599\n",
      "[flaml.automl.logger: 12-16 19:05:42] {2219} INFO - iteration 1028, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:05:43] {2392} INFO -  at 112.4s,\testimator lgbm's best error=772.0458,\tbest estimator xgboost's best error=765.8599\n",
      "[flaml.automl.logger: 12-16 19:05:43] {2219} INFO - iteration 1029, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:05:43] {2392} INFO -  at 112.5s,\testimator lgbm's best error=772.0458,\tbest estimator xgboost's best error=765.8599\n",
      "[flaml.automl.logger: 12-16 19:05:43] {2219} INFO - iteration 1030, current learner xgboost\n",
      "[flaml.automl.logger: 12-16 19:05:43] {2392} INFO -  at 112.7s,\testimator xgboost's best error=765.8599,\tbest estimator xgboost's best error=765.8599\n",
      "[flaml.automl.logger: 12-16 19:05:43] {2219} INFO - iteration 1031, current learner xgboost\n",
      "[flaml.automl.logger: 12-16 19:05:43] {2392} INFO -  at 112.8s,\testimator xgboost's best error=765.8599,\tbest estimator xgboost's best error=765.8599\n",
      "[flaml.automl.logger: 12-16 19:05:43] {2219} INFO - iteration 1032, current learner xgboost\n",
      "[flaml.automl.logger: 12-16 19:05:43] {2392} INFO -  at 113.1s,\testimator xgboost's best error=765.8599,\tbest estimator xgboost's best error=765.8599\n",
      "[flaml.automl.logger: 12-16 19:05:43] {2219} INFO - iteration 1033, current learner extra_tree\n",
      "[flaml.automl.logger: 12-16 19:05:43] {2392} INFO -  at 113.2s,\testimator extra_tree's best error=934.9907,\tbest estimator xgboost's best error=765.8599\n",
      "[flaml.automl.logger: 12-16 19:05:43] {2219} INFO - iteration 1034, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:05:43] {2392} INFO -  at 113.3s,\testimator lgbm's best error=772.0458,\tbest estimator xgboost's best error=765.8599\n",
      "[flaml.automl.logger: 12-16 19:05:43] {2219} INFO - iteration 1035, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:05:43] {2392} INFO -  at 113.3s,\testimator lgbm's best error=772.0458,\tbest estimator xgboost's best error=765.8599\n",
      "[flaml.automl.logger: 12-16 19:05:43] {2219} INFO - iteration 1036, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:05:43] {2392} INFO -  at 113.4s,\testimator lgbm's best error=772.0458,\tbest estimator xgboost's best error=765.8599\n",
      "[flaml.automl.logger: 12-16 19:05:43] {2219} INFO - iteration 1037, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:05:43] {2392} INFO -  at 113.4s,\testimator lgbm's best error=772.0458,\tbest estimator xgboost's best error=765.8599\n",
      "[flaml.automl.logger: 12-16 19:05:43] {2219} INFO - iteration 1038, current learner xgboost\n",
      "[flaml.automl.logger: 12-16 19:05:44] {2392} INFO -  at 113.6s,\testimator xgboost's best error=765.8599,\tbest estimator xgboost's best error=765.8599\n",
      "[flaml.automl.logger: 12-16 19:05:44] {2219} INFO - iteration 1039, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:05:44] {2392} INFO -  at 113.6s,\testimator lgbm's best error=772.0458,\tbest estimator xgboost's best error=765.8599\n",
      "[flaml.automl.logger: 12-16 19:05:44] {2219} INFO - iteration 1040, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:05:44] {2392} INFO -  at 113.6s,\testimator lgbm's best error=772.0458,\tbest estimator xgboost's best error=765.8599\n",
      "[flaml.automl.logger: 12-16 19:05:44] {2219} INFO - iteration 1041, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:05:44] {2392} INFO -  at 113.7s,\testimator lgbm's best error=772.0458,\tbest estimator xgboost's best error=765.8599\n",
      "[flaml.automl.logger: 12-16 19:05:44] {2219} INFO - iteration 1042, current learner xgboost\n",
      "[flaml.automl.logger: 12-16 19:05:44] {2392} INFO -  at 113.8s,\testimator xgboost's best error=765.8599,\tbest estimator xgboost's best error=765.8599\n",
      "[flaml.automl.logger: 12-16 19:05:44] {2219} INFO - iteration 1043, current learner xgboost\n",
      "[flaml.automl.logger: 12-16 19:05:44] {2392} INFO -  at 114.1s,\testimator xgboost's best error=765.8599,\tbest estimator xgboost's best error=765.8599\n",
      "[flaml.automl.logger: 12-16 19:05:44] {2219} INFO - iteration 1044, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:05:44] {2392} INFO -  at 114.2s,\testimator lgbm's best error=772.0458,\tbest estimator xgboost's best error=765.8599\n",
      "[flaml.automl.logger: 12-16 19:05:44] {2219} INFO - iteration 1045, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:05:44] {2392} INFO -  at 114.2s,\testimator lgbm's best error=772.0458,\tbest estimator xgboost's best error=765.8599\n",
      "[flaml.automl.logger: 12-16 19:05:44] {2219} INFO - iteration 1046, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:05:44] {2392} INFO -  at 114.2s,\testimator lgbm's best error=772.0458,\tbest estimator xgboost's best error=765.8599\n",
      "[flaml.automl.logger: 12-16 19:05:44] {2219} INFO - iteration 1047, current learner extra_tree\n",
      "[flaml.automl.logger: 12-16 19:05:44] {2392} INFO -  at 114.3s,\testimator extra_tree's best error=934.9907,\tbest estimator xgboost's best error=765.8599\n",
      "[flaml.automl.logger: 12-16 19:05:44] {2219} INFO - iteration 1048, current learner xgboost\n",
      "[flaml.automl.logger: 12-16 19:05:45] {2392} INFO -  at 114.7s,\testimator xgboost's best error=765.8599,\tbest estimator xgboost's best error=765.8599\n",
      "[flaml.automl.logger: 12-16 19:05:45] {2219} INFO - iteration 1049, current learner xgboost\n",
      "[flaml.automl.logger: 12-16 19:05:45] {2392} INFO -  at 114.8s,\testimator xgboost's best error=765.8599,\tbest estimator xgboost's best error=765.8599\n",
      "[flaml.automl.logger: 12-16 19:05:45] {2219} INFO - iteration 1050, current learner extra_tree\n",
      "[flaml.automl.logger: 12-16 19:05:45] {2392} INFO -  at 114.9s,\testimator extra_tree's best error=934.9907,\tbest estimator xgboost's best error=765.8599\n",
      "[flaml.automl.logger: 12-16 19:05:45] {2219} INFO - iteration 1051, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:05:45] {2392} INFO -  at 115.0s,\testimator lgbm's best error=772.0458,\tbest estimator xgboost's best error=765.8599\n",
      "[flaml.automl.logger: 12-16 19:05:45] {2219} INFO - iteration 1052, current learner xgboost\n",
      "[flaml.automl.logger: 12-16 19:05:45] {2392} INFO -  at 115.3s,\testimator xgboost's best error=765.8599,\tbest estimator xgboost's best error=765.8599\n",
      "[flaml.automl.logger: 12-16 19:05:45] {2219} INFO - iteration 1053, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:05:45] {2392} INFO -  at 115.3s,\testimator lgbm's best error=772.0458,\tbest estimator xgboost's best error=765.8599\n",
      "[flaml.automl.logger: 12-16 19:05:45] {2219} INFO - iteration 1054, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:05:45] {2392} INFO -  at 115.3s,\testimator lgbm's best error=772.0458,\tbest estimator xgboost's best error=765.8599\n",
      "[flaml.automl.logger: 12-16 19:05:45] {2219} INFO - iteration 1055, current learner xgboost\n",
      "[flaml.automl.logger: 12-16 19:05:46] {2392} INFO -  at 115.6s,\testimator xgboost's best error=765.8599,\tbest estimator xgboost's best error=765.8599\n",
      "[flaml.automl.logger: 12-16 19:05:46] {2219} INFO - iteration 1056, current learner xgboost\n",
      "[flaml.automl.logger: 12-16 19:05:46] {2392} INFO -  at 116.0s,\testimator xgboost's best error=765.8599,\tbest estimator xgboost's best error=765.8599\n",
      "[flaml.automl.logger: 12-16 19:05:46] {2219} INFO - iteration 1057, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:05:46] {2392} INFO -  at 116.0s,\testimator lgbm's best error=772.0458,\tbest estimator xgboost's best error=765.8599\n",
      "[flaml.automl.logger: 12-16 19:05:46] {2219} INFO - iteration 1058, current learner xgboost\n",
      "[flaml.automl.logger: 12-16 19:05:46] {2392} INFO -  at 116.1s,\testimator xgboost's best error=765.8599,\tbest estimator xgboost's best error=765.8599\n",
      "[flaml.automl.logger: 12-16 19:05:46] {2219} INFO - iteration 1059, current learner xgboost\n",
      "[flaml.automl.logger: 12-16 19:05:46] {2392} INFO -  at 116.2s,\testimator xgboost's best error=765.8599,\tbest estimator xgboost's best error=765.8599\n",
      "[flaml.automl.logger: 12-16 19:05:46] {2219} INFO - iteration 1060, current learner xgboost\n",
      "[flaml.automl.logger: 12-16 19:05:47] {2392} INFO -  at 116.5s,\testimator xgboost's best error=765.8599,\tbest estimator xgboost's best error=765.8599\n",
      "[flaml.automl.logger: 12-16 19:05:47] {2219} INFO - iteration 1061, current learner xgboost\n",
      "[flaml.automl.logger: 12-16 19:05:47] {2392} INFO -  at 116.8s,\testimator xgboost's best error=765.8599,\tbest estimator xgboost's best error=765.8599\n",
      "[flaml.automl.logger: 12-16 19:05:47] {2219} INFO - iteration 1062, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:05:47] {2392} INFO -  at 116.8s,\testimator lgbm's best error=772.0458,\tbest estimator xgboost's best error=765.8599\n",
      "[flaml.automl.logger: 12-16 19:05:47] {2219} INFO - iteration 1063, current learner xgboost\n",
      "[flaml.automl.logger: 12-16 19:05:47] {2392} INFO -  at 116.9s,\testimator xgboost's best error=765.8599,\tbest estimator xgboost's best error=765.8599\n",
      "[flaml.automl.logger: 12-16 19:05:47] {2219} INFO - iteration 1064, current learner xgboost\n",
      "[flaml.automl.logger: 12-16 19:05:48] {2392} INFO -  at 117.8s,\testimator xgboost's best error=765.8599,\tbest estimator xgboost's best error=765.8599\n",
      "[flaml.automl.logger: 12-16 19:05:48] {2219} INFO - iteration 1065, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:05:48] {2392} INFO -  at 117.8s,\testimator lgbm's best error=772.0458,\tbest estimator xgboost's best error=765.8599\n",
      "[flaml.automl.logger: 12-16 19:05:48] {2219} INFO - iteration 1066, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:05:48] {2392} INFO -  at 117.9s,\testimator lgbm's best error=772.0458,\tbest estimator xgboost's best error=765.8599\n",
      "[flaml.automl.logger: 12-16 19:05:48] {2219} INFO - iteration 1067, current learner xgboost\n",
      "[flaml.automl.logger: 12-16 19:05:48] {2392} INFO -  at 117.9s,\testimator xgboost's best error=765.8599,\tbest estimator xgboost's best error=765.8599\n",
      "[flaml.automl.logger: 12-16 19:05:48] {2219} INFO - iteration 1068, current learner xgboost\n",
      "[flaml.automl.logger: 12-16 19:05:48] {2392} INFO -  at 118.2s,\testimator xgboost's best error=765.8599,\tbest estimator xgboost's best error=765.8599\n",
      "[flaml.automl.logger: 12-16 19:05:48] {2219} INFO - iteration 1069, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:05:48] {2392} INFO -  at 118.2s,\testimator lgbm's best error=772.0458,\tbest estimator xgboost's best error=765.8599\n",
      "[flaml.automl.logger: 12-16 19:05:48] {2219} INFO - iteration 1070, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:05:48] {2392} INFO -  at 118.3s,\testimator lgbm's best error=772.0458,\tbest estimator xgboost's best error=765.8599\n",
      "[flaml.automl.logger: 12-16 19:05:48] {2219} INFO - iteration 1071, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:05:48] {2392} INFO -  at 118.3s,\testimator lgbm's best error=772.0458,\tbest estimator xgboost's best error=765.8599\n",
      "[flaml.automl.logger: 12-16 19:05:48] {2219} INFO - iteration 1072, current learner xgboost\n",
      "[flaml.automl.logger: 12-16 19:05:48] {2392} INFO -  at 118.4s,\testimator xgboost's best error=765.8599,\tbest estimator xgboost's best error=765.8599\n",
      "[flaml.automl.logger: 12-16 19:05:48] {2219} INFO - iteration 1073, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:05:49] {2392} INFO -  at 118.5s,\testimator lgbm's best error=772.0458,\tbest estimator xgboost's best error=765.8599\n",
      "[flaml.automl.logger: 12-16 19:05:49] {2219} INFO - iteration 1074, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:05:49] {2392} INFO -  at 118.5s,\testimator lgbm's best error=772.0458,\tbest estimator xgboost's best error=765.8599\n",
      "[flaml.automl.logger: 12-16 19:05:49] {2219} INFO - iteration 1075, current learner xgboost\n",
      "[flaml.automl.logger: 12-16 19:05:49] {2392} INFO -  at 118.8s,\testimator xgboost's best error=765.8599,\tbest estimator xgboost's best error=765.8599\n",
      "[flaml.automl.logger: 12-16 19:05:49] {2219} INFO - iteration 1076, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:05:49] {2392} INFO -  at 118.8s,\testimator lgbm's best error=772.0458,\tbest estimator xgboost's best error=765.8599\n",
      "[flaml.automl.logger: 12-16 19:05:49] {2219} INFO - iteration 1077, current learner xgboost\n",
      "[flaml.automl.logger: 12-16 19:05:49] {2392} INFO -  at 119.0s,\testimator xgboost's best error=765.8599,\tbest estimator xgboost's best error=765.8599\n",
      "[flaml.automl.logger: 12-16 19:05:49] {2219} INFO - iteration 1078, current learner xgboost\n",
      "[flaml.automl.logger: 12-16 19:05:49] {2392} INFO -  at 119.3s,\testimator xgboost's best error=765.8599,\tbest estimator xgboost's best error=765.8599\n",
      "[flaml.automl.logger: 12-16 19:05:49] {2219} INFO - iteration 1079, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:05:49] {2392} INFO -  at 119.3s,\testimator lgbm's best error=772.0458,\tbest estimator xgboost's best error=765.8599\n",
      "[flaml.automl.logger: 12-16 19:05:49] {2219} INFO - iteration 1080, current learner xgboost\n",
      "[flaml.automl.logger: 12-16 19:05:50] {2392} INFO -  at 119.4s,\testimator xgboost's best error=765.8599,\tbest estimator xgboost's best error=765.8599\n",
      "[flaml.automl.logger: 12-16 19:05:50] {2219} INFO - iteration 1081, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:05:50] {2392} INFO -  at 119.5s,\testimator lgbm's best error=772.0458,\tbest estimator xgboost's best error=765.8599\n",
      "[flaml.automl.logger: 12-16 19:05:50] {2219} INFO - iteration 1082, current learner xgboost\n",
      "[flaml.automl.logger: 12-16 19:05:50] {2392} INFO -  at 119.7s,\testimator xgboost's best error=765.8599,\tbest estimator xgboost's best error=765.8599\n",
      "[flaml.automl.logger: 12-16 19:05:50] {2219} INFO - iteration 1083, current learner xgboost\n",
      "[flaml.automl.logger: 12-16 19:05:50] {2392} INFO -  at 119.9s,\testimator xgboost's best error=765.8599,\tbest estimator xgboost's best error=765.8599\n",
      "[flaml.automl.logger: 12-16 19:05:50] {2219} INFO - iteration 1084, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:05:50] {2392} INFO -  at 119.9s,\testimator lgbm's best error=772.0458,\tbest estimator xgboost's best error=765.8599\n",
      "[flaml.automl.logger: 12-16 19:05:50] {2219} INFO - iteration 1085, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:05:50] {2392} INFO -  at 119.9s,\testimator lgbm's best error=772.0458,\tbest estimator xgboost's best error=765.8599\n",
      "[flaml.automl.logger: 12-16 19:05:50] {2219} INFO - iteration 1086, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:05:50] {2392} INFO -  at 120.0s,\testimator lgbm's best error=772.0458,\tbest estimator xgboost's best error=765.8599\n",
      "[flaml.automl.logger: 12-16 19:05:50] {2219} INFO - iteration 1087, current learner lgbm\n",
      "[flaml.automl.logger: 12-16 19:05:50] {2392} INFO -  at 120.0s,\testimator lgbm's best error=772.0458,\tbest estimator xgboost's best error=765.8599\n",
      "[flaml.automl.logger: 12-16 19:05:50] {2219} INFO - iteration 1088, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 12-16 19:05:50] {2392} INFO -  at 120.0s,\testimator xgb_limitdepth's best error=1159.1935,\tbest estimator xgboost's best error=765.8599\n",
      "[flaml.automl.logger: 12-16 19:05:50] {2628} INFO - retrain xgboost for 0.1s\n",
      "[flaml.automl.logger: 12-16 19:05:50] {2631} INFO - retrained model: XGBRegressor(base_score=None, booster=None, callbacks=[],\n",
      "             colsample_bylevel=0.2754204488040437, colsample_bynode=None,\n",
      "             colsample_bytree=1.0, device=None, early_stopping_rounds=None,\n",
      "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "             gamma=None, grow_policy='lossguide', importance_type=None,\n",
      "             interaction_constraints=None, learning_rate=0.04655469376625845,\n",
      "             max_bin=None, max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "             max_delta_step=None, max_depth=0, max_leaves=10,\n",
      "             min_child_weight=1.9424862680135921, missing=nan,\n",
      "             monotone_constraints=None, multi_strategy=None, n_estimators=239,\n",
      "             n_jobs=-1, num_parallel_tree=None, random_state=None, ...)\n",
      "[flaml.automl.logger: 12-16 19:05:50] {1931} INFO - fit succeeded\n",
      "[flaml.automl.logger: 12-16 19:05:50] {1932} INFO - Time taken to find the best model: 72.81608366966248\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[12/16/24 19:10:07] </span><span style=\"color: #008000; text-decoration-color: #008000\">INFO    </span> Ensemble Estimator RScore: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.4826976454161044</span>                              <a href=\"file:///home/jakep/projects/caml/caml/core/cate.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">cate.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/jakep/projects/caml/caml/core/cate.py#734\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">734</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[12/16/24 19:10:07]\u001b[0m\u001b[2;36m \u001b[0m\u001b[32mINFO    \u001b[0m Ensemble Estimator RScore: \u001b[1;36m0.4826976454161044\u001b[0m                              \u001b]8;id=445165;file:///home/jakep/projects/caml/caml/core/cate.py\u001b\\\u001b[2mcate.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=605138;file:///home/jakep/projects/caml/caml/core/cate.py#734\u001b\\\u001b[2m734\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #008000; text-decoration-color: #008000\">INFO    </span> Inidividual Estimator RScores: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'LinearDML'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.4826976454161044</span>,           <a href=\"file:///home/jakep/projects/caml/caml/core/cate.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">cate.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/jakep/projects/caml/caml/core/cate.py#735\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">735</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #008000; text-decoration-color: #008000\">'CausalForestDML'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.4452931209796641</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'NonParamDML'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.22005138242494082</span>, <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">           </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #008000; text-decoration-color: #008000\">'AutoNonParamDML'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.3532003139498613</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'SparseLinearDML-2D'</span>:               <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">           </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.363561689875212</span><span style=\"font-weight: bold\">}</span>                                                         <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">           </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[32mINFO    \u001b[0m Inidividual Estimator RScores: \u001b[1m{\u001b[0m\u001b[32m'LinearDML'\u001b[0m: \u001b[1;36m0.4826976454161044\u001b[0m,           \u001b]8;id=327071;file:///home/jakep/projects/caml/caml/core/cate.py\u001b\\\u001b[2mcate.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=475709;file:///home/jakep/projects/caml/caml/core/cate.py#735\u001b\\\u001b[2m735\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[32m'CausalForestDML'\u001b[0m: \u001b[1;36m0.4452931209796641\u001b[0m, \u001b[32m'NonParamDML'\u001b[0m: \u001b[1;36m0.22005138242494082\u001b[0m, \u001b[2m           \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[32m'AutoNonParamDML'\u001b[0m: \u001b[1;36m0.3532003139498613\u001b[0m, \u001b[32m'SparseLinearDML-2D'\u001b[0m:               \u001b[2m           \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[1;36m0.363561689875212\u001b[0m\u001b[1m}\u001b[0m                                                         \u001b[2m           \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #008000; text-decoration-color: #008000\">INFO    </span> The best estimator is greater than the ensemble estimator. Returning that  <a href=\"file:///home/jakep/projects/caml/caml/core/cate.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">cate.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/jakep/projects/caml/caml/core/cate.py#747\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">747</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         individual estimator: <span style=\"font-weight: bold\">&lt;</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">econml.dml.dml.LinearDML</span><span style=\"color: #000000; text-decoration-color: #000000\"> object at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0x7fdd58cea560</span><span style=\"font-weight: bold\">&gt;</span>  <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">           </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[32mINFO    \u001b[0m The best estimator is greater than the ensemble estimator. Returning that  \u001b]8;id=862473;file:///home/jakep/projects/caml/caml/core/cate.py\u001b\\\u001b[2mcate.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=566813;file:///home/jakep/projects/caml/caml/core/cate.py#747\u001b\\\u001b[2m747\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         individual estimator: \u001b[1m<\u001b[0m\u001b[1;95meconml.dml.dml.LinearDML\u001b[0m\u001b[39m object at \u001b[0m\u001b[1;36m0x7fdd58cea560\u001b[0m\u001b[1m>\u001b[0m  \u001b[2m           \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "caml.fit_validator(\n",
    "    subset_cate_models=[\n",
    "        \"LinearDML\",\n",
    "        \"CausalForestDML\",\n",
    "        \"NonParamDML\",\n",
    "        \"AutoNonParamDML\",\n",
    "        \"SparseLinearDML-2D\",\n",
    "        # \"DRLearner\",\n",
    "        # \"ForestDRLearner\",\n",
    "        # \"LinearDRLearner\",\n",
    "        # \"SparseLinearDRLearner-2D\",\n",
    "        # \"DomainAdaptationLearner\",\n",
    "        # \"SLearner\",\n",
    "        # \"TLearner\",\n",
    "        # \"XLearner\"\n",
    "    ],\n",
    "    rscorer_kwargs={},\n",
    "    use_ray=False,\n",
    "    ray_remote_func_options_kwargs={},\n",
    "    sample_fraction=1.0,\n",
    "    n_jobs=-1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #008000; text-decoration-color: #008000\">INFO    </span> The validation estimator has been fit and will be returned.                <a href=\"file:///home/jakep/projects/caml/caml/core/_base.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">_base.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/jakep/projects/caml/caml/core/_base.py#61\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">61</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[32mINFO    \u001b[0m The validation estimator has been fit and will be returned.                \u001b]8;id=317785;file:///home/jakep/projects/caml/caml/core/_base.py\u001b\\\u001b[2m_base.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=914735;file:///home/jakep/projects/caml/caml/core/_base.py#61\u001b\\\u001b[2m61\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<econml.dml.dml.LinearDML at 0x7fdd58cea560>"
      ]
     },
     "execution_count": 282,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "caml.validation_estimator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CATE Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_results = caml.validate(n_groups=4,n_bootstrap=100,print_full_report=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Refit best estimator on full dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [],
   "source": [
    "caml.fit_final()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[12/16/24 19:11:34] </span><span style=\"color: #008000; text-decoration-color: #008000\">INFO    </span> The final estimator has been fit on the entire dataset and will be         <a href=\"file:///home/jakep/projects/caml/caml/core/_base.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">_base.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/jakep/projects/caml/caml/core/_base.py#71\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">71</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         returned.                                                                  <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">           </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[12/16/24 19:11:34]\u001b[0m\u001b[2;36m \u001b[0m\u001b[32mINFO    \u001b[0m The final estimator has been fit on the entire dataset and will be         \u001b]8;id=934531;file:///home/jakep/projects/caml/caml/core/_base.py\u001b\\\u001b[2m_base.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=557378;file:///home/jakep/projects/caml/caml/core/_base.py#71\u001b\\\u001b[2m71\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         returned.                                                                  \u001b[2m           \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<econml.dml.dml.LinearDML at 0x7fddb9221d80>"
      ]
     },
     "execution_count": 284,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "caml.final_estimator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predict CATEs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-57.04873947,  -4.61465146, -54.88886676, ..., -21.060014  ,\n",
       "       -32.46316524,  -5.51058523])"
      ]
     },
     "execution_count": 285,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## \"Out of sample\" predictions\n",
    "\n",
    "cate_predictions = caml.predict(T0=0,T1=1)\n",
    "\n",
    "cate_predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CATE Visualization/Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cate_predictions_0_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>10000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-21.864967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>20.547407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-185.338799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-30.712685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>-16.716835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>-7.743731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>19.351044</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       cate_predictions_0_1\n",
       "count          10000.000000\n",
       "mean             -21.864967\n",
       "std               20.547407\n",
       "min             -185.338799\n",
       "25%              -30.712685\n",
       "50%              -16.716835\n",
       "75%               -7.743731\n",
       "max               19.351044"
      ]
     },
     "execution_count": 286,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cate_summary = caml.summarize()\n",
    "\n",
    "cate_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Treatment</th>\n",
       "      <th>ATE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>T1_continuous_on_Y1_continuous</td>\n",
       "      <td>-21.791433</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Treatment        ATE\n",
       "0  T1_continuous_on_Y1_continuous -21.791433"
      ]
     },
     "execution_count": 287,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ate_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Access my dataframe, estimator object, and get string representation of class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>W1_continuous</th>\n",
       "      <th>W2_continuous</th>\n",
       "      <th>W1_binary</th>\n",
       "      <th>W2_binary</th>\n",
       "      <th>W1_discrete</th>\n",
       "      <th>W2_discrete</th>\n",
       "      <th>X1_continuous</th>\n",
       "      <th>X2_continuous</th>\n",
       "      <th>X3_continuous</th>\n",
       "      <th>X4_continuous</th>\n",
       "      <th>X1_binary</th>\n",
       "      <th>X2_binary</th>\n",
       "      <th>X3_binary</th>\n",
       "      <th>X4_binary</th>\n",
       "      <th>X1_discrete</th>\n",
       "      <th>X2_discrete</th>\n",
       "      <th>X3_discrete</th>\n",
       "      <th>X4_discrete</th>\n",
       "      <th>T1_continuous</th>\n",
       "      <th>Y1_continuous</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.406044</td>\n",
       "      <td>-0.151649</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>4.232622</td>\n",
       "      <td>0.747387</td>\n",
       "      <td>4.874727</td>\n",
       "      <td>0.726902</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-19.115807</td>\n",
       "      <td>1079.464650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.438724</td>\n",
       "      <td>-2.336934</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0.117746</td>\n",
       "      <td>6.535678</td>\n",
       "      <td>4.143518</td>\n",
       "      <td>3.091032</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-11.178740</td>\n",
       "      <td>68.928005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.884024</td>\n",
       "      <td>-2.542391</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>5.219183</td>\n",
       "      <td>3.807166</td>\n",
       "      <td>2.748808</td>\n",
       "      <td>2.267096</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-19.722470</td>\n",
       "      <td>827.325915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.113439</td>\n",
       "      <td>-0.581423</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>5.691499</td>\n",
       "      <td>7.863248</td>\n",
       "      <td>3.874850</td>\n",
       "      <td>1.311375</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>-32.111036</td>\n",
       "      <td>1997.805122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.112845</td>\n",
       "      <td>-2.602360</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>4.319512</td>\n",
       "      <td>1.853090</td>\n",
       "      <td>3.062959</td>\n",
       "      <td>4.061395</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>-41.549068</td>\n",
       "      <td>1706.448421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>0.620626</td>\n",
       "      <td>0.955814</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>45</td>\n",
       "      <td>2.212935</td>\n",
       "      <td>5.095046</td>\n",
       "      <td>4.062946</td>\n",
       "      <td>0.967618</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>-71.640000</td>\n",
       "      <td>1966.545754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>0.016592</td>\n",
       "      <td>-0.768066</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0.026808</td>\n",
       "      <td>9.745895</td>\n",
       "      <td>3.225506</td>\n",
       "      <td>3.098420</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>-6.595926</td>\n",
       "      <td>26.114568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>0.322272</td>\n",
       "      <td>-2.021281</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.981227</td>\n",
       "      <td>7.759381</td>\n",
       "      <td>3.956030</td>\n",
       "      <td>5.489068</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.000034</td>\n",
       "      <td>16.652740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>1.727967</td>\n",
       "      <td>-2.057457</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>2.102762</td>\n",
       "      <td>8.927030</td>\n",
       "      <td>4.238957</td>\n",
       "      <td>1.386538</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-7.485863</td>\n",
       "      <td>229.205593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>0.342372</td>\n",
       "      <td>-2.659079</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.978098</td>\n",
       "      <td>4.422247</td>\n",
       "      <td>3.057222</td>\n",
       "      <td>13.347594</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>-2.590074</td>\n",
       "      <td>30.334865</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      W1_continuous  W2_continuous  W1_binary  W2_binary  W1_discrete  \\\n",
       "0          0.406044      -0.151649          0          0            1   \n",
       "1          1.438724      -2.336934          1          1            1   \n",
       "2          2.884024      -2.542391          1          0            1   \n",
       "3          0.113439      -0.581423          1          1            1   \n",
       "4          5.112845      -2.602360          1          0            1   \n",
       "...             ...            ...        ...        ...          ...   \n",
       "9995       0.620626       0.955814          0          1            1   \n",
       "9996       0.016592      -0.768066          0          0            2   \n",
       "9997       0.322272      -2.021281          0          1            1   \n",
       "9998       1.727967      -2.057457          0          0            1   \n",
       "9999       0.342372      -2.659079          1          0            1   \n",
       "\n",
       "      W2_discrete  X1_continuous  X2_continuous  X3_continuous  X4_continuous  \\\n",
       "0              10       4.232622       0.747387       4.874727       0.726902   \n",
       "1               6       0.117746       6.535678       4.143518       3.091032   \n",
       "2              13       5.219183       3.807166       2.748808       2.267096   \n",
       "3              19       5.691499       7.863248       3.874850       1.311375   \n",
       "4              25       4.319512       1.853090       3.062959       4.061395   \n",
       "...           ...            ...            ...            ...            ...   \n",
       "9995           45       2.212935       5.095046       4.062946       0.967618   \n",
       "9996            4       0.026808       9.745895       3.225506       3.098420   \n",
       "9997            1       1.981227       7.759381       3.956030       5.489068   \n",
       "9998            6       2.102762       8.927030       4.238957       1.386538   \n",
       "9999            4       0.978098       4.422247       3.057222      13.347594   \n",
       "\n",
       "      X1_binary  X2_binary  X3_binary  X4_binary  X1_discrete  X2_discrete  \\\n",
       "0             0          1          1          0            6            0   \n",
       "1             0          1          1          0            8            0   \n",
       "2             0          1          0          0            8            1   \n",
       "3             1          1          1          1            7            0   \n",
       "4             0          1          0          1            9            0   \n",
       "...         ...        ...        ...        ...          ...          ...   \n",
       "9995          0          1          0          0           11            0   \n",
       "9996          0          1          0          1            7            0   \n",
       "9997          0          0          1          0            6            1   \n",
       "9998          1          1          1          0            6            0   \n",
       "9999          1          1          1          0            6            0   \n",
       "\n",
       "      X3_discrete  X4_discrete  T1_continuous  Y1_continuous  \n",
       "0               1            0     -19.115807    1079.464650  \n",
       "1               1            0     -11.178740      68.928005  \n",
       "2               1            0     -19.722470     827.325915  \n",
       "3               2            1     -32.111036    1997.805122  \n",
       "4               1            3     -41.549068    1706.448421  \n",
       "...           ...          ...            ...            ...  \n",
       "9995            1            4     -71.640000    1966.545754  \n",
       "9996            2            2      -6.595926      26.114568  \n",
       "9997            2            0      -0.000034      16.652740  \n",
       "9998            0            0      -7.485863     229.205593  \n",
       "9999            2            1      -2.590074      30.334865  \n",
       "\n",
       "[10000 rows x 20 columns]"
      ]
     },
     "execution_count": 288,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "caml.df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #008000; text-decoration-color: #008000\">INFO    </span> The final estimator has been fit on the entire dataset and will be         <a href=\"file:///home/jakep/projects/caml/caml/core/_base.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">_base.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/jakep/projects/caml/caml/core/_base.py#71\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">71</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         returned.                                                                  <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">           </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[32mINFO    \u001b[0m The final estimator has been fit on the entire dataset and will be         \u001b]8;id=655057;file:///home/jakep/projects/caml/caml/core/_base.py\u001b\\\u001b[2m_base.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=921742;file:///home/jakep/projects/caml/caml/core/_base.py#71\u001b\\\u001b[2m71\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         returned.                                                                  \u001b[2m           \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<econml.dml.dml.LinearDML object at 0x7fddb9221d80>\n",
      "{'feature_names': ['W1_continuous', 'W2_continuous', 'W1_binary', 'W2_binary', 'W1_discrete', 'W2_discrete', 'X1_continuous', 'X2_continuous', 'X3_continuous', 'X4_continuous', 'X1_binary', 'X2_binary', 'X3_binary', 'X4_binary', 'X1_discrete', 'X2_discrete', 'X3_discrete', 'X4_discrete'], 'output_names': 'Y1_continuous', 'treatment_names': 'T1_continuous'}\n"
     ]
    }
   ],
   "source": [
    "from econml.score import EnsembleCateEstimator\n",
    "\n",
    "# Use this estimator object as pickled object for optimized inference\n",
    "final_estimator = caml.final_estimator\n",
    "\n",
    "if isinstance(final_estimator, EnsembleCateEstimator):\n",
    "    for mod in final_estimator._cate_models:\n",
    "        print(mod)\n",
    "        print(mod._input_names)\n",
    "else:\n",
    "    print(final_estimator)\n",
    "    print(final_estimator._input_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================== CamlCATE Object ==================\n",
      "Data Backend: pandas\n",
      "No. of Observations: 10,000\n",
      "Outcome Variable: Y1_continuous\n",
      "Discrete Outcome: False\n",
      "Treatment Variable: T1_continuous\n",
      "Discrete Treatment: False\n",
      "Features/Confounders for Heterogeneity (X): ['W1_continuous', 'W2_continuous', 'W1_binary', 'W2_binary', 'W1_discrete', 'W2_discrete', 'X1_continuous', 'X2_continuous', 'X3_continuous', 'X4_continuous', 'X1_binary', 'X2_binary', 'X3_binary', 'X4_binary', 'X1_discrete', 'X2_discrete', 'X3_discrete', 'X4_discrete']\n",
      "Features/Confounders as Controls (W): []\n",
      "Random Seed: 10\n",
      "Nuissance Model Y_X: XGBRegressor(base_score=None, booster=None, callbacks=[],\n",
      "             colsample_bylevel=0.9616423910817776, colsample_bynode=None,\n",
      "             colsample_bytree=0.995779245125877, device=None,\n",
      "             early_stopping_rounds=None, enable_categorical=False,\n",
      "             eval_metric=None, feature_types=None, gamma=None, grow_policy=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=0.018673966612306605, max_bin=None,\n",
      "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "             max_delta_step=None, max_depth=4, max_leaves=None,\n",
      "             min_child_weight=2.268841930034181, missing=nan,\n",
      "             monotone_constraints=None, multi_strategy=None, n_estimators=909,\n",
      "             n_jobs=-1, num_parallel_tree=None, random_state=None, ...)\n",
      "Propensity/Nuissance Model T_X: XGBRegressor(base_score=None, booster=None, callbacks=[],\n",
      "             colsample_bylevel=0.9071630278331562, colsample_bynode=None,\n",
      "             colsample_bytree=0.9019064002023752, device=None,\n",
      "             early_stopping_rounds=None, enable_categorical=False,\n",
      "             eval_metric=None, feature_types=None, gamma=None,\n",
      "             grow_policy='lossguide', importance_type=None,\n",
      "             interaction_constraints=None, learning_rate=0.01749038763148113,\n",
      "             max_bin=None, max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "             max_delta_step=None, max_depth=0, max_leaves=7,\n",
      "             min_child_weight=0.24896890529521287, missing=nan,\n",
      "             monotone_constraints=None, multi_strategy=None, n_estimators=1169,\n",
      "             n_jobs=-1, num_parallel_tree=None, random_state=None, ...)\n",
      "Regression Model Y_X_T: XGBRegressor(base_score=None, booster=None, callbacks=[],\n",
      "             colsample_bylevel=0.9616423910817776, colsample_bynode=None,\n",
      "             colsample_bytree=0.995779245125877, device=None,\n",
      "             early_stopping_rounds=None, enable_categorical=False,\n",
      "             eval_metric=None, feature_types=None, gamma=None, grow_policy=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=0.018673966612306605, max_bin=None,\n",
      "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "             max_delta_step=None, max_depth=4, max_leaves=None,\n",
      "             min_child_weight=2.268841930034181, missing=nan,\n",
      "             monotone_constraints=None, multi_strategy=None, n_estimators=909,\n",
      "             n_jobs=-1, num_parallel_tree=None, random_state=None, ...)\n",
      "Final Estimator: <econml.dml.dml.LinearDML object at 0x7fddb9221d80>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(caml)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>W1_continuous</th>\n",
       "      <th>W2_continuous</th>\n",
       "      <th>W1_binary</th>\n",
       "      <th>W2_binary</th>\n",
       "      <th>W1_discrete</th>\n",
       "      <th>W2_discrete</th>\n",
       "      <th>X1_continuous</th>\n",
       "      <th>X2_continuous</th>\n",
       "      <th>X3_continuous</th>\n",
       "      <th>X4_continuous</th>\n",
       "      <th>X1_binary</th>\n",
       "      <th>X2_binary</th>\n",
       "      <th>X3_binary</th>\n",
       "      <th>X4_binary</th>\n",
       "      <th>X1_discrete</th>\n",
       "      <th>X2_discrete</th>\n",
       "      <th>X3_discrete</th>\n",
       "      <th>X4_discrete</th>\n",
       "      <th>T1_continuous</th>\n",
       "      <th>Y1_continuous</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.406044</td>\n",
       "      <td>-0.151649</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>4.232622</td>\n",
       "      <td>0.747387</td>\n",
       "      <td>4.874727</td>\n",
       "      <td>0.726902</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-19.115807</td>\n",
       "      <td>1079.464650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.438724</td>\n",
       "      <td>-2.336934</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0.117746</td>\n",
       "      <td>6.535678</td>\n",
       "      <td>4.143518</td>\n",
       "      <td>3.091032</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-11.178740</td>\n",
       "      <td>68.928005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.884024</td>\n",
       "      <td>-2.542391</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>5.219183</td>\n",
       "      <td>3.807166</td>\n",
       "      <td>2.748808</td>\n",
       "      <td>2.267096</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-19.722470</td>\n",
       "      <td>827.325915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.113439</td>\n",
       "      <td>-0.581423</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>5.691499</td>\n",
       "      <td>7.863248</td>\n",
       "      <td>3.874850</td>\n",
       "      <td>1.311375</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>-32.111036</td>\n",
       "      <td>1997.805122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.112845</td>\n",
       "      <td>-2.602360</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>4.319512</td>\n",
       "      <td>1.853090</td>\n",
       "      <td>3.062959</td>\n",
       "      <td>4.061395</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>-41.549068</td>\n",
       "      <td>1706.448421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>0.620626</td>\n",
       "      <td>0.955814</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>45</td>\n",
       "      <td>2.212935</td>\n",
       "      <td>5.095046</td>\n",
       "      <td>4.062946</td>\n",
       "      <td>0.967618</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>-71.640000</td>\n",
       "      <td>1966.545754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>0.016592</td>\n",
       "      <td>-0.768066</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0.026808</td>\n",
       "      <td>9.745895</td>\n",
       "      <td>3.225506</td>\n",
       "      <td>3.098420</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>-6.595926</td>\n",
       "      <td>26.114568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>0.322272</td>\n",
       "      <td>-2.021281</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.981227</td>\n",
       "      <td>7.759381</td>\n",
       "      <td>3.956030</td>\n",
       "      <td>5.489068</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.000034</td>\n",
       "      <td>16.652740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>1.727967</td>\n",
       "      <td>-2.057457</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>2.102762</td>\n",
       "      <td>8.927030</td>\n",
       "      <td>4.238957</td>\n",
       "      <td>1.386538</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-7.485863</td>\n",
       "      <td>229.205593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>0.342372</td>\n",
       "      <td>-2.659079</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.978098</td>\n",
       "      <td>4.422247</td>\n",
       "      <td>3.057222</td>\n",
       "      <td>13.347594</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>-2.590074</td>\n",
       "      <td>30.334865</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      W1_continuous  W2_continuous  W1_binary  W2_binary  W1_discrete  \\\n",
       "0          0.406044      -0.151649          0          0            1   \n",
       "1          1.438724      -2.336934          1          1            1   \n",
       "2          2.884024      -2.542391          1          0            1   \n",
       "3          0.113439      -0.581423          1          1            1   \n",
       "4          5.112845      -2.602360          1          0            1   \n",
       "...             ...            ...        ...        ...          ...   \n",
       "9995       0.620626       0.955814          0          1            1   \n",
       "9996       0.016592      -0.768066          0          0            2   \n",
       "9997       0.322272      -2.021281          0          1            1   \n",
       "9998       1.727967      -2.057457          0          0            1   \n",
       "9999       0.342372      -2.659079          1          0            1   \n",
       "\n",
       "      W2_discrete  X1_continuous  X2_continuous  X3_continuous  X4_continuous  \\\n",
       "0              10       4.232622       0.747387       4.874727       0.726902   \n",
       "1               6       0.117746       6.535678       4.143518       3.091032   \n",
       "2              13       5.219183       3.807166       2.748808       2.267096   \n",
       "3              19       5.691499       7.863248       3.874850       1.311375   \n",
       "4              25       4.319512       1.853090       3.062959       4.061395   \n",
       "...           ...            ...            ...            ...            ...   \n",
       "9995           45       2.212935       5.095046       4.062946       0.967618   \n",
       "9996            4       0.026808       9.745895       3.225506       3.098420   \n",
       "9997            1       1.981227       7.759381       3.956030       5.489068   \n",
       "9998            6       2.102762       8.927030       4.238957       1.386538   \n",
       "9999            4       0.978098       4.422247       3.057222      13.347594   \n",
       "\n",
       "      X1_binary  X2_binary  X3_binary  X4_binary  X1_discrete  X2_discrete  \\\n",
       "0             0          1          1          0            6            0   \n",
       "1             0          1          1          0            8            0   \n",
       "2             0          1          0          0            8            1   \n",
       "3             1          1          1          1            7            0   \n",
       "4             0          1          0          1            9            0   \n",
       "...         ...        ...        ...        ...          ...          ...   \n",
       "9995          0          1          0          0           11            0   \n",
       "9996          0          1          0          1            7            0   \n",
       "9997          0          0          1          0            6            1   \n",
       "9998          1          1          1          0            6            0   \n",
       "9999          1          1          1          0            6            0   \n",
       "\n",
       "      X3_discrete  X4_discrete  T1_continuous  Y1_continuous  \n",
       "0               1            0     -19.115807    1079.464650  \n",
       "1               1            0     -11.178740      68.928005  \n",
       "2               1            0     -19.722470     827.325915  \n",
       "3               2            1     -32.111036    1997.805122  \n",
       "4               1            3     -41.549068    1706.448421  \n",
       "...           ...          ...            ...            ...  \n",
       "9995            1            4     -71.640000    1966.545754  \n",
       "9996            2            2      -6.595926      26.114568  \n",
       "9997            2            0      -0.000034      16.652740  \n",
       "9998            0            0      -7.485863     229.205593  \n",
       "9999            2            1      -2.590074      30.334865  \n",
       "\n",
       "[10000 rows x 20 columns]"
      ]
     },
     "execution_count": 291,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CATE_of_T1_continuous_on_Y1_continuous</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-59.074667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-4.133320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-44.380636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-63.083630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-42.443864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>-27.384826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>-0.099239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>-20.968952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>-31.481700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>-9.509243</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      CATE_of_T1_continuous_on_Y1_continuous\n",
       "0                                 -59.074667\n",
       "1                                  -4.133320\n",
       "2                                 -44.380636\n",
       "3                                 -63.083630\n",
       "4                                 -42.443864\n",
       "...                                      ...\n",
       "9995                              -27.384826\n",
       "9996                               -0.099239\n",
       "9997                              -20.968952\n",
       "9998                              -31.481700\n",
       "9999                               -9.509243\n",
       "\n",
       "[10000 rows x 1 columns]"
      ]
     },
     "execution_count": 292,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cate_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [],
   "source": [
    "from caml.extensions.plots import (cate_histogram_plot, \n",
    "                                   cate_true_vs_estimated_plot, \n",
    "                                   cate_line_plot)\n",
    "\n",
    "df['cate_predictions'] = cate_predictions\n",
    "df['true_cates'] = cate_df.iloc[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "execution_count": 294,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cate_true_vs_estimated_plot(true_cates=df['true_cates'],estimated_cates=df['cate_predictions'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "execution_count": 295,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cate_histogram_plot(estimated_cates=df['cate_predictions'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "execution_count": 296,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cate_histogram_plot(estimated_cates=df['cate_predictions'],true_cates=df['true_cates'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "execution_count": 297,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cate_line_plot(estimated_cates=df['cate_predictions'],window=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "execution_count": 298,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cate_line_plot(estimated_cates=df['cate_predictions'],true_cates=df['true_cates'],window=20)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (caml)",
   "language": "python",
   "name": "caml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
